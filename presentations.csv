session,id,title,url,authors,summary
A1:NLPモデルの評価・安全性・信頼性(1)3月11日（火） 8:30-10:00   A会場(2Fコンベンションホール1+2),A1-1,LLMのアテンションヘッドに着目したジェイルブレイク攻撃の分析と防御手法の提案,/proceedings/annual_meeting/2025/pdf_dir/A1-1.pdf,"○新井 雅稀 (早大), 芝原 俊樹, 千葉 大紀, 秋山 満昭 (NTT), 内田 真人 (早大)",大規模言語モデル（Large Language Model; LLM）はジェイルブレイク攻撃に対して脆弱であり，違法行為や非倫理的な内容などの有害な出力をしてしまうリスクがある．このジェイルブレイク攻撃に対して，LLM が有害な出力をしてしまうメカニズムは十分に解明されていない．本研究ではLLM のアテンションヘッドに着目して内部状態の分析を行い，数%のアテンションヘッドが有害な出力に大きく関与していることを明らかにする．また，分析結果を利用して，アテンションヘッドへの介入による防御手法を提案する．実験の結果，提案手法によ性能の低下を3%以内に抑えつつ，攻撃成功率を2，3%程度まで低下させられることが確認された．
A1:NLPモデルの評価・安全性・信頼性(1)3月11日（火） 8:30-10:00   A会場(2Fコンベンションホール1+2),A1-2,Decoding the Mind of Large Language Models: A Quantitative Analysis of Thought Processes and Biases,/proceedings/annual_meeting/2025/pdf_dir/A1-2.pdf,"○◊廣瀬 万響, 内田 真人 (早大)","This study proposes a novel framework for evaluatingLarge Language Models (LLMs) by uncovering their ideo-logical biases through a quantitative analysis of 436 binary-choice questions. Applying the framework to ChatGPT andGemini, we found that while both models show consistentopinions, their ideologies diﬀer between models and lan-guages. Both models also exhibited problematic biases,with some responses potentially having negative societalimpacts. These ﬁndings highlight the need to address ide-ological and ethical considerations in LLM evaluation, andthe proposed framework oﬀers a ﬂexible method for assess-ing LLM behavior and developing more socially alignedAI systems."
A1:NLPモデルの評価・安全性・信頼性(1)3月11日（火） 8:30-10:00   A会場(2Fコンベンションホール1+2),A1-3,有害性評価と巻き戻しによる LLM の有害コンテンツ生成回避,/proceedings/annual_meeting/2025/pdf_dir/A1-3.pdf,"○山下 智也, 岡 佑依, 山中 友貴, 山田 真徳 (NTT)",大規模言語モデル(LLM) の普及に伴い，安全性の高いLLM への要望が高まっている．本稿ではLLMの安全性の1 要素であるLLM が有害コンテンツを出力しないことに着目し，有害コンテンツを軽量かつ効果的に回避する手法を提案する．提案手法ではトークン列生成を行う生成LLM と，トークン列の有害性を評価する評価LLM を用いて，適宜トークン列の有害性を評価しつつ推論を行うことで，有害コンテンツを含まないトークン列の生成を目指す．
A1:NLPモデルの評価・安全性・信頼性(1)3月11日（火） 8:30-10:00   A会場(2Fコンベンションホール1+2),A1-4,大規模言語モデルによる自己説明の忠実性は改善するか？,/proceedings/annual_meeting/2025/pdf_dir/A1-4.pdf,"○土井 智暉 (東大), 磯沼 大 (東大/エディンバラ大/NII), 谷中 瞳 (東大)",大規模言語モデルによる自己説明は，ブラックボックスなモデルの挙動を解釈可能な表現に変換することが期待できる．しかし近年，自己説明が必ずしもモデルの挙動を忠実に反映しておらず、自己説明と実際の挙動が矛盾しうることが明らかになっている．本研究では，入力文中で予測に最も影響を与える語を特定し，これを教師信号として継続学習することによって，自己説明の忠実性が改善するかを検証する．実験により，複数の分類タスクおよび説明様式の条件下で継続学習の有効性を検証し，とくに未学習の分類タスクおよび説明様式においても忠実性が改善することを確認した．
A1:NLPモデルの評価・安全性・信頼性(1)3月11日（火） 8:30-10:00   A会場(2Fコンベンションホール1+2),A1-5,検索拡張生成が信頼度に及ぼす影響：医療分野における分析,/proceedings/annual_meeting/2025/pdf_dir/A1-5.pdf,"○尾崎 慎太郎 (NAIST), 加藤 優汰, 馮 思遠, 富田 雅代 (東大), 林 和樹 (NAIST), 小原 涼馬, 小山田 昌史 (NEC), 林 克彦 (東大), 上垣外 英剛, 渡辺 太郎 (NAIST)","検索拡張生成(RAG) は, 外部情報を活用することで, 大規模言語モデル(LLM) の知識を補完し, 質問に対する応答の精度を改善させる. この手法は, 最新の情報を活用できる利点を活かし, 多様な分野で広く応用されている. 先行研究の多くは性能改善に注力する一方, RAG を利用した際の出力の信頼度に関する特性については十分に研究されていない. 金融, 医療, 医学などの出力への信頼性が強く要求される分野で, 出力の信頼度を分析することは重要な課題である. 本研究では, 医療分野における多様な課題および推論モデルを対象に, RAG が信頼度に与える影響を調査する. 具体的には, LLM の予測確率を出力として扱い, 期待較正誤差と適応較正誤差を出力確率に基づいて計算することで信頼度を評価する. さらに, プロンプト内の取得文書の順序が信頼度に影響するかについても分析を行う. 結果として, モデル,取得する書類数や埋め込み数などの設定, および入力プロンプトの形式に応じて, 信頼度と精度に大きな変動が見られることが明らかとなった. これらの結果は, 特定のモデルおよび条件に基づいてRAG で用いる構成を最適化する必要性を強調している.1）"
A1:NLPモデルの評価・安全性・信頼性(1)3月11日（火） 8:30-10:00   A会場(2Fコンベンションホール1+2),A1-6,手動設計の敵対的プロンプト手法の体系的分類,/proceedings/annual_meeting/2025/pdf_dir/A1-6.pdf,"○佐々木 佑, 関谷 勇司 (東大)","昨今, 大規模言語モデルは世界中で広く使われるようになったが, 安全性への懸念が叫ばれている. 本研究では, 手動設計の敵対的プロンプトに対し, 既存のデータセットを調査することで, 多種多様な敵対的プロンプト手法を把握し, それらを体系的に分類することを目指した. 既存データセットを人手で調査し, 最終的には, 敵対的プロンプトを大小49 個のカテゴリに分類した. また, データセット内で用いられた手法を数え上げることで, 手法の偏りを明らかにした. 最後に, 本分類の各カテゴリに対して敵対的プロンプト例を作成し, Github 上に公開した. https://github.com/Tasuku-Sasaki-lab/Adversarial-Prompt-Classification 本研究を通じて, 手動設計の敵対的プロンプトの手法の実態が明らかとなった. これらの成果は, LLM に対するRedTeaming テストや, 敵対的プロンプト防御手法の開発を通じて, LLM のサイバーセキュリティ向上に貢献するだろう."
B1:計算・形式言語学(1)3月11日（火） 8:30-10:00   B会場(1F会議室102),B1-1,自然言語における冪則と統語構造の関係の再考,/proceedings/annual_meeting/2025/pdf_dir/B1-1.pdf,"○中石 海, 吉田 遼, 梶川 康平, 福島 孝治, 大関 洋平 (東大)",自然言語の系列において，要素間の相関は距離について冪的に減衰することが知られている．これは，系列中のある要素を変更すると，その影響がどれだけ離れた要素にも及び得ることを意味する．先行研究[1] は，このような特徴的現象を，系列の背後にある階層的な統語構造と結びつけて説明している．しかし，この説明は統語構造に関するいくつかの仮定に依拠しており，それらの仮定が実際に自然言語で成り立つかどうかは検証されていない．そこで，本研究は，ツリーバンクを用いて統語構造の統計的性質を調べ，先行研究の仮定がいずれも成り立たないことを明らかにする．
B1:計算・形式言語学(1)3月11日（火） 8:30-10:00   B会場(1F会議室102),B1-2,自然言語推論への応用を志向したセマンティックパージングの性能評価,/proceedings/annual_meeting/2025/pdf_dir/B1-2.pdf,"○船蔵 颯 (慶應大/京大/キカガク), 峯島 宏次 (慶應大)",本研究は、セマンティックパージングで広く採用されている、Smatch をはじめとするグラフマッチングによる評価指標が、セマンティックパージングの主たる下流タスクのひとつである自然言語推論における性能を必ずしも保証しないということを示すものである。上記を示すために、ファインチューニングおよびIn-context learning に基づくパーザを構築し、グラフマッチングによる評価と自然言語推論を志向した評価をそれぞれのパーザに適用した。結果として、グラフマッチングによる評価と自然言語推論への応用可能性との間にはギャップがあるということを報告する。
B1:計算・形式言語学(1)3月11日（火） 8:30-10:00   B会場(1F会議室102),B1-3,CCG 統語解析器 lightblue と定理証明器 wani によるJSeM Verbs データセットの自動推論,/proceedings/annual_meeting/2025/pdf_dir/B1-3.pdf,"○松原 舞, 富田 朝, 戸次 大介 (お茶大)",自然言語理解の研究において，大規模言語モデル(LLM) とは対照的なアプローチとして，合理主義自然科学のパラダイムに基づく言語学的パイプラインの研究が進展している．これは理論言語学に基づく統語解析，意味合成，自動証明のモジュールを接続したものであり，仮説検証を通じてモデルを改善する点で、経験主義的なLLM と相補的な関係にある．本論文では，CCG に基づく統語解析器lightblueと，DTS のための定理証明器wani を組み合わせた自然言語推論システムを用いて，JSeM 日本語テストセットのVerb セクションの推論問題を解くことを試みた．この試みは、システムの評価，エラー分析，理論へのフィードバックを含む，合理主義的計算言語学の実践例の一つである．
B1:計算・形式言語学(1)3月11日（火） 8:30-10:00   B会場(1F会議室102),B1-4,一般化交差効果に対する型理論的アプローチ,/proceedings/annual_meeting/2025/pdf_dir/B1-4.pdf,"○松岡 大樹 (東大), 戸次 大介 (お茶大), 谷中 瞳 (東大)",理論言語学における重要な発見の1 つに，代名詞の特定の解釈が統語構造により制限されるという「交差効果」がある．交差効果は統語構造上の移動操作に基づいて分析されることが標準的であるが，近年，このような統語的な分析では説明しきれない，より一般化された形の交差効果が提唱されている．本研究はこの課題に対して，型理論に基づくアプローチを提案する．具体的には，依存型意味論という枠組みを用いて，意味表示としての型が持つ構造的関係を介して交差効果を分析することにより，従来よりも統一性の高い理論が得られることを主張する．
B1:計算・形式言語学(1)3月11日（火） 8:30-10:00   B会場(1F会議室102),B1-5,日本語話し言葉における形態素の出現数に対する統計的不定性の評価,/proceedings/annual_meeting/2025/pdf_dir/B1-5.pdf,"○田窪 洋介 (新居浜高専/KEK), 浅原 正幸 (国語研/総研大), 山崎 誠 (国語研)",自然言語と言語モデルの一致度合いを定量的に評価するためには，事前準備として自然言語のデータ点に付随する統計的不定性を正確に評価しておくことが前提となる．本研究では，日本語話し言葉における形態素の出現数に対する不定性（修正誤差）を評価した．そして，修正誤差とポアソン誤差をデータに付与した場合のZipf 則との一致度合いについて，𝜒2 検定とKS (Kolmogorov-Smirnov) 検定で定量的に比較した．
B1:計算・形式言語学(1)3月11日（火） 8:30-10:00   B会場(1F会議室102),B1-6,証明ステップの逆形式化とステップ間の構造解析を通じた形式証明の自然言語翻訳,/proceedings/annual_meeting/2025/pdf_dir/B1-6.pdf,"○服部 清志, 松崎 拓也, 藤原 誠 (東京理科大)",自動形式化とは、自然言語で書かれた数学証明を機械検証可能な形式証明に自動翻訳する技術のことである。この技術は近年の大規模言語モデルの発展に伴って盛んに研究されているが、学習に用いる自然言語証明-形式証明ペアデータの不足が課題となっている。本研究ではLLM の逆形式化能力を活用した形式証明の自然言語翻訳手法を提案する。また、自然言語証明の表現に沿って作成した形式証明データに対して本手法を適用し、生成された自然言語証明の品質を分析及び評価する。
C1:言語資源・アノテーションと評価3月11日（火） 8:30-10:00   C会場(1F会議室103),C1-1,Toward Argument Structure Parsing in German: A Rule-Based Approach with Linguistic Annotations,/proceedings/annual_meeting/2025/pdf_dir/C1-1.pdf,"○◊Hiroyuki Miyashita (KGU), Julian Michael Stawecki (HHU)","This paper introduces a novel system for the automatic identification of argument structures in German sentenc-es. Our approach addresses the complexities of German syntax, including flexible word order, rich morphological inflection, and diverse clause types. We leverage spaCy’s German language models, which provide com-prehensive pipelines for tagging, morphological analysis, parsing, and lemmatization. By combining the model outputs with linguistic rules, we have implemented a rule-based approach for argument structure identifica-tion. To evaluate our system, we created a gold-standard dataset through a systematic annotation process in which annotators validated and refined initial parser outputs. Beyond argument extraction, our parser identifies the main verb of each (sub-)clause, classifies the genus verbi (active/passive), and determines clause types (e.g., main clauses, various subordinate clauses). This work lays a foundation for large-scale corpus-based investigations of argument structures in German, enabling more compre-hensive linguistic analyses."
C1:言語資源・アノテーションと評価3月11日（火） 8:30-10:00   C会場(1F会議室103),C1-2,日本語創造性ベンチマークの構築,/proceedings/annual_meeting/2025/pdf_dir/C1-2.pdf,"○福田 創, 小川 隼斗, 堀尾 海斗, 河原 大輔 (早大), 柴田 知秀 (SB Intuitions)",大規模言語モデル（LLM）の創造性を評価するために，Japanese Creativity Questions (JCQ)，DivergentAssociation Task (DAT)，そしてStory Alteration Task(SAT) という3 つのベンチマークを構築する. JCQでは，LLM を用いて創造性を包括的に評価する. 一方，DAT とSAT では，埋め込みを用いて，創造的能力の一面を測定する. さらに，JCQ とDAT，およびJCQ とSAT の間の相関を分析する. JCQ は網羅的な評価ができるが，比較的時間とコストがかかる. 一方，DAT とSAT は網羅性が低いが，迅速に評価できる.
C1:言語資源・アノテーションと評価3月11日（火） 8:30-10:00   C会場(1F会議室103),C1-3,The KISTEC: 日本の大学生の発話データに基づく英語学習者話し言葉コーパスの構築,/proceedings/annual_meeting/2025/pdf_dir/C1-3.pdf,"○神澤 克徳 (京工繊大), 瀬戸口 彩花 (京大), 田中 悠介 (福岡大), 近 大志 (京大), 小林 雄一郎 (日大), 光永 悠彦 (名大), 森 真幸 (京工繊大), 李 在鎬 (早大)",本稿では，The KIT Speaking Test Corpus（以下，KISTEC と表記）の設計と仕様について報告する．KISTEC は日本の大学生英語学習者が受験したスピーキングテストの解答音声を基に構築した約30万語規模の話し言葉コーパスであり，書き起こしテキストとアノテーションから構成される．各種タグだけでなく，学習者の属性や，全体およびタスクごとのスコアを参照できるため，個人差やタスク特性を考慮した発話の分析を可能とする．KISTEC はL2話者の非流暢性現象を自動検出するBERT モデルの性能評価にも使われており[1]，NLP 研究への応用も十分に可能である．
C1:言語資源・アノテーションと評価3月11日（火） 8:30-10:00   C会場(1F会議室103),C1-4,SNSからの重要意見抽出のためのデータセット構築及びLLMによる分類検証,/proceedings/annual_meeting/2025/pdf_dir/C1-4.pdf,"○矢口 一晟 (明大), 櫻井 恵里子 (産能大), 櫻井 義尚 (明大)",本研究では，重要意見抽出のためのデータセット構築および大規模言語モデル（以下：LLM）を用いた重要意見抽出の手法を提案し，その有効性を検証した．そこで，人間がラベリングを実施せずにSNSから企業がマーケティング活動に必要となる重要意見抽出モデルが構築可能であることを示す．これにより，重要意見データセットの作成や抽出にかかる時間的かつ金銭的コストの削減が期待できる．データセットの構築検証ではワークショプを開催することで重要意見に関連する議論を実施し学生による重要意見データの作成が可能であるかを検証した．また重要意見の抽出検証では，LLM によるZero-shot分類および擬似データを作成した後，ファインチューニングによる重要意見分類の精度を比較した．
C1:言語資源・アノテーションと評価3月11日（火） 8:30-10:00   C会場(1F会議室103),C1-5,Swallowコーパスv2: 教育的な日本語ウェブコーパスの構築,/proceedings/annual_meeting/2025/pdf_dir/C1-5.pdf,"○服部 翔 (科学大/産総研/NII), 岡崎 直観, 水木 栄, 藤井 一喜, 中村 泰士, 大井 聖也 (科学大/産総研), 塩谷 泰平, 齋藤 幸史郎, Youmi Ma, 前田 航希, 岡本 拓己, 石田 茂樹 (科学大), 横田 理央 (科学大/産総研), 高村 大也 (産総研)",大規模言語モデル（LLM）の事前学習では，高品質なテキストを用いることが望ましい．本研究では，文書の「教育的価値」に着目した2 種類の軽量な分類器を構築して，各文書に品質スコアを付与し，大規模日本語ウェブコーパスから高品質なテキストを抽出する手法を提案する．実験により，提案手法を適用することで，同等の学習計算規模で日本語の知識に関するLLM の能力をより効率的に向上できることを示した．また，分類器の特性比較，ヒューリスティック・ルールの調整，学習のエポック数を増やす実験などを通じて，提案手法の実用性やLLM 構築の最良慣行について検証する．
C1:言語資源・アノテーションと評価3月11日（火） 8:30-10:00   C会場(1F会議室103),C1-6,『日本経済新聞記事オープンコーパス』と『日本語話し言葉コーパス』語義と読みの対応表の作成,/proceedings/annual_meeting/2025/pdf_dir/C1-6.pdf,"○大井 恵奈, 古宮 嘉那子 (農工大), 柏野 和佳子, 浅原 正幸 (国語研/総研大)",本研究では，日本経済新聞記事オープンコーパス，日本語話し言葉コーパスを対象とし，読みと意味の対応表作成のための情報付与を行い，データ整備を行う．日本経済新聞記事オープンコーパスには，語義情報が付与されているものの，読み情報が付与されていなかったため，専門家による読みのアノテーションを行った．日本語話し言葉コーパスは，話し言葉の書き起こしであるため，読み情報は正確であったが，語義情報はついていないため，語義曖昧性解消システムを利用して語義データを付与した．以上のデータから，読みと意味の対応表を作成し，関係性について調査する．
D1:機械学習3月11日（火） 8:30-10:00   D会場(1F会議室107),D1-1,ガウス過程による埋め込み点集合の時間遷移のモデル化,/proceedings/annual_meeting/2025/pdf_dir/D1-1.pdf,"○相田 太一 (都立大), 小町 守 (一橋大), 小木曽 智信 (国語研), 高村 大也 (産総研), 持橋 大地 (統数研/国語研)",単語の意味は時間とともに変化することがある．近年では，この時間的変動を捉えるため，埋め込み空間上で用例集合を分析する研究が数多く行われてきた．同様の時間的変動は，生態系の生息分布や社会学の犯罪発生分布など，他の多くの分野にも存在する．しかし，このような点集合の動的な変化は非常に複雑であり，解析が困難だという問題がある．本研究では，ガウス過程を用いて点集合を一つの複雑な分布として表現し，それを周波数空間の実ベクトルとしてコンパクトに表すことで，点集合の時間遷移を解析する手法を提案する．提案手法で単語の意味変化を分析し，応用例として社会学の空間データにも適用することで，その有用性を確認した．
D1:機械学習3月11日（火） 8:30-10:00   D会場(1F会議室107),D1-2,Transformerデコーダモデルを利用した日本語意味役割において，特徴量抽出位置およびAttention Maskの形状が与える影響,/proceedings/annual_meeting/2025/pdf_dir/D1-2.pdf,"○曽和 晃太郎, 竹内 孔一 (岡山大)",2022 年のChatGPT 登場以降，多くの大規模言語モデルが提供されているが，それらの多くがTransformer のデコーダモデルを採用している．一方，意味役割付与タスクでは依然としてTransformerエンコーダモデルが主導している現状がある．本研究では，Transformer デコーダモデルを利用した日本語意味役割付与タスクにおいて，精度向上に寄与する特徴量の位置およびAttention Mask の形状を検討し，ベースラインモデルとの比較実験を行った．EOS，LA，PS，PS-Attn. の4 つの手法を提案し，PSとPS-Attn. でベースラインモデルと比較してF1 値における大幅な精度の向上を示した．
D1:機械学習3月11日（火） 8:30-10:00   D会場(1F会議室107),D1-3,Enhancing Fake News Detection through Consistency Contrastive Learning with MLP-Mixer,/proceedings/annual_meeting/2025/pdf_dir/D1-3.pdf,"○Shaodong Cui, Wen Ma, Hiroyuki Shinnou (茨大)","Detecting and ﬁltering false information has become acritical area of academic research with the rapid spreadof multimodal fake news on major social media platforms.However, eﬀectively integrating diverse feature types forreliable fake news detection remains challenging. To ad-dress this, we propose a novel fake news detection modelbased on consistency contrastive learning. Our model usesan MLP-mixer to extract features, and consistency con-trastive learning to measure the semantic distance betweentext features and text attribute features. This approach en-hances the MLP-mixer’s ability to extract consistent high-level features. Experimental results on the LIAR datasetdemonstrate that our proposed model outperforms existingmethods in detecting fake news."
D1:機械学習3月11日（火） 8:30-10:00   D会場(1F会議室107),D1-4,ベイズ教師なし文境界認識,/proceedings/annual_meeting/2025/pdf_dir/D1-4.pdf,"内海 慶 (SB Intuitions), ○持橋 大地 (統数研/国語研)","文を単位とする言語現象を捉えるためには文分割(文境界認識) が必要となるが, 実際に我々が扱うことが多い崩れたテキストには無数の文末表現があり, 通常の教師あり学習で正しく分割することは難しい. 本研究では, 文分割をテキストの文字毎に存在する, 二値潜在変数の推定問題ととらえる. セミマルコフモデルの枠組みで動的計画法とMCMC 法を組み合わせることにより, 単純な文字𝑛グラム言語モデルを用いるだけで, 最新の大規模言語モデルによるヒューリスティックな文分割を超える, 最高精度の文分割を教師なし学習で行えることを示す."
D1:機械学習3月11日（火） 8:30-10:00   D会場(1F会議室107),D1-5,テキストの埋め込み表現に基づくデータ増強を用いた X（旧 Twitter）における日本語の皮肉検出,/proceedings/annual_meeting/2025/pdf_dir/D1-5.pdf,"○中井 紫音, 宮本 友樹, 内海 彰 (電通大)",近年，数多くのSNS が存在する中でX（旧Twitter）を対象とした皮肉判定の研究が活発に行われている．日本語の皮肉分類器の性能向上を図る手段の一つとしてデータ増強の適用が考えられるが，皮肉表現はその特性上，文章内の特定の単語を置き換えるとたとえわずかな変更であっても元の皮肉性が失われ，皮肉でなくなる（分類ラベルが反転する）可能性がある．本稿では，データ増強の際にノイズを加える箇所をTransformer のAttention を用いて選定するという，皮肉判定に特化したデータ増強を通じて皮肉分類器の性能向上を図る手法を提案する．本手法は既存手法やGPT を用いたデータ増強手法と比べ，正解率，F 値にともに高い性能を示した.
D1:機械学習3月11日（火） 8:30-10:00   D会場(1F会議室107),D1-6,大規模言語モデルに対するチューニング手法の調査：内部のアクセス性に基づく分類と比較,/proceedings/annual_meeting/2025/pdf_dir/D1-6.pdf,"○中島 京太郎, 金 輝燦, 平澤 寅庄, 榎本 大晟 (都立大), 陳 宙斯, 小町 守 (一橋大)",言語モデルを特定のタスクに対して最適化するチューニング手法は現在多くの場面で用いられている．チューニングには言語モデル内部のパラメータを更新する手法や，入力文を更新する手法など様々なアプローチが存在する．これらのチューニング手法は対象の言語モデルの内部のアクセス性によって使用できる手法が異なる．本研究では言語モデルのアクセス性に応じて分類されたチューニング手法を多角的に比較することで，それらの特徴や傾向を分析する．
E1:テーマセッション6: 人文学と言語処理(1)3月11日（火） 8:30-10:00   E会場(1F会議室108),E1-1,クレオールは計量的に峻別できるか？,/proceedings/annual_meeting/2025/pdf_dir/E1-1.pdf,"○川崎 義史 (東大), 永田 亮 (甲南大), 高村 大也 (産総研), 大谷 直輝 (東京外大)",本稿は、テキストデータから求めた指標の大小でクレオールと非クレオールを峻別できるか検証した。データとして、いずれの言語においても同一内容が保証されている聖書を用いた。実験の結果、両者を峻別こそできないが、複数の指標で大別することができた。これは、クレオールが非クレオールとは異なる性質を保有している可能性を示唆している。また、部分的に単純説を支持する結果を得た。
E1:テーマセッション6: 人文学と言語処理(1)3月11日（火） 8:30-10:00   E会場(1F会議室108),E1-2,対象言語・対象単語を選ばない汎用的な文法化度の定量化手法,/proceedings/annual_meeting/2025/pdf_dir/E1-2.pdf,"○永田 亮 (甲南大), 持橋 大地 (統数研), 井戸 美里, 窪田 悠介 (国語研), 高村 大也 (産総研), 川崎 義史 (東大), 大谷 直輝 (東京外大)",文法化とは内容語が機能語に変わる通時変化のことである．本稿では，文法化の度合いをコーパスデータに基づいて定量化する三種類の手法を提案する．提案手法は従来手法と異なり汎用性が高いにもかかわらず，人手の分析で得られた文法化度と中程度～高い相関を示す．また，提案手法を歴史コーパスに適用して文法化の一方向仮説の吟味を行う．
E1:テーマセッション6: 人文学と言語処理(1)3月11日（火） 8:30-10:00   E会場(1F会議室108),E1-3,文書筆記過程の分析に関わる墨跡の濃淡変化箇所推定手法の性能評価,/proceedings/annual_meeting/2025/pdf_dir/E1-3.pdf,"○ゴー チュイリン, 中尾 泰士 (北九大)",墨によって書かれた文書は，墨の濃淡情報を用いることで，その文書が作成された筆記過程を分析できる可能性がある．われわれは，墨の濃淡情報を時系列データとして分析し，墨が徐々に薄くなって，再び濃くなった箇所を筆に墨を含めなおした点として推定する手法を考えた．この手法による分析結果を人の眼で判断した正解と比較検討することで，われわれの手法の性能評価を行なった．
E1:テーマセッション6: 人文学と言語処理(1)3月11日（火） 8:30-10:00   E会場(1F会議室108),E1-4,大規模言語モデルを用いた発掘調査報告書からの考古学情報抽出,/proceedings/annual_meeting/2025/pdf_dir/E1-4.pdf,"○山本 湧大 (早大), 武内 樹治 (奈文研), 大内 啓樹 (NAIST), 高田 祐一 (奈文研)",遺跡の発掘調査後に作成される発掘調査報告書には、出土した遺物や遺構をはじめとする重要な考古学情報が含まれている。しかし、全国の発掘調査報告書を合算すると、その数は膨大であり、人手で全てを読み解くことは困難である。そこで本研究では、発掘調査報告書から自動的に考古学情報に関する記述（出土した遺物や遺構、それらの時代や数など）を抽出する手法を検討した。まず、奈良文化財研究所が公開している発掘調査報告書のPDF を対象に、考古学情報と判断される表現に対して人手でアノテーションを施し、評価データセットを構築した。構築したデータセットに対して、ChatGPT を利用して考古学表現の抽出し、その性能を評価した。精度(Precision) が17 ％前後、再現率(Recall)が30 ％程度という結果となり、まだ改善の余地が大きいことが明らかになった。
E1:テーマセッション6: 人文学と言語処理(1)3月11日（火） 8:30-10:00   E会場(1F会議室108),E1-5,近世・近代・現代日本語テキストに対する場所参照表現抽出,/proceedings/annual_meeting/2025/pdf_dir/E1-5.pdf,"○片山 歩希 (NAIST), 東山 翔平 (NICT/NAIST/国語研), 大内 啓樹 (NAIST/理研/国語研), 坂井 優介 (NAIST), 竹内 綾乃 (国文研), 坂東 諒 (国語研), 橋本 雄太 (歴博), 小木曽 智信 (国語研), 渡辺 太郎 (NAIST)",歴史的テキストからの場所参照表現の抽出は，大規模な史料に対する人文学的分析を支援するための基礎技術として重要である．本研究では，近代・近世の日本語テキストを用いたデータセットを構築し，これら歴史的テキストに対するTransformer 言語モデルの抽出精度を調査した．実験から，現代語ラベル付きデータの活用の有効性を確認した一方で，歴史的テキストへの適応には，さらなるモデルの改善が必要であることも示された．
E1:テーマセッション6: 人文学と言語処理(1)3月11日（火） 8:30-10:00   E会場(1F会議室108),E1-6,スタイロメトリによるコプト語文献の著者帰属の再検討,/proceedings/annual_meeting/2025/pdf_dir/E1-6.pdf,"○宮川 創 (筑波大), Eliese-Sophia Lincke (ベルリン自由大), Heike Behlmer (ゲッティンゲン大)","本稿では，コプト語説教文書「On Christian Be-haviour」(OCB) の著者帰属を，スタイロメトリ（文体統計学）を用いて再検討する．OCB は写本題辞で修道院長シェヌーテ（Shenoute, 紀元後4～5 世紀）の名を冠するが，実際にはシェヌーテの特徴である修道士向けの規律に関する厳しい忠告や厳しい断罪が乏しく，早くから「偽シェヌーテ文書」と疑われてきた．本研究では，OCB のK. H. Kuhn の校訂版テキストと，白修道院文学（シェヌーテ, ベーサ, ヨハンネス）および新約聖書，コプト語聖人伝，新学書，説教などを対象に，R 言語のstylo パッケージを用いて文体比較を行った．結果として，OCB がシェヌーテの著作群よりも新約聖書の書簡のクラスタに近いという従来の示唆を定量的に裏付け，OCB を「偽シェヌーテ文書」の範疇に位置づける客観的根拠を提供した．"
P1:ポスター3月11日（火） 8:30-10:00   P会場(2Fコンベンションホール3+4),P1-1,訳出の同時性に特化した評価データを用いた同時音声翻訳モデルの評価と分析,/proceedings/annual_meeting/2025/pdf_dir/P1-1.pdf,"○蒔苗 茉那, 坂井 優介, 上垣外 英剛, 渡辺 太郎 (NAIST)",同時音声翻訳は，原言語文のセグメント化や目的言語文を原言語文の語順に近づけることで，低遅延と高品質の両立を目指してきた．しかし，既存の評価データは語順の並び替えを多く含むため，低遅延の同時音声翻訳評価に適していない．本研究では，目的言語文が原言語文の単語・句の並びになるべく沿うような語順の単調性に焦点を当てた新しい評価データを提案する．実験の結果から，提案評価データsimul-tst-COMMON は，既存の評価データよりも適切にモデルの性能評価ができることを示した．
P1:ポスター3月11日（火） 8:30-10:00   P会場(2Fコンベンションホール3+4),P1-2,大規模反応データベースを用いた文字列化した化学反応の基盤モデル構築,/proceedings/annual_meeting/2025/pdf_dir/P1-2.pdf,"○佐川 達也, 小島 諒介 (京大)",化学反応の高精度な予測は，実験を行う前に実験結果の予測ができることから，創薬をはじめとする分野で実験コストの削減の視点から注目されている．これまでに化学反応予測モデルの開発は活発に行われてきたが，利用可能な学習データが限られていたことから，分布外データへのモデルの微調整（ファインチューニング）を想定した事前学習モデルに関する研究は限定的であった．本研究では，大規模化学反応データベースを用いた事前学習を通じて化学反応基盤モデルを構築した．本モデルを活用することで，従来のモデルと比較して非常に少ないファインチューニングデータで，優れた予測性能を実現できることを示した．
P1:ポスター3月11日（火） 8:30-10:00   P会場(2Fコンベンションホール3+4),P1-3,情報抽出による質の高い新規用途アイデアの獲得,/proceedings/annual_meeting/2025/pdf_dir/P1-3.pdf,"○谷口 友紀, 高橋 拓誠, 大熊 智子 (旭化成)",近年，材料の用途探索に自然言語処理を活用する取り組みが広がっている．材料固有の特性を発揮させる使用法が用途であることから，用途探索は，材料の特性が発揮できる用途を探し出すタスクとなる．本論文では，材料固有の特性に類似する特性エンティティを含む文書を検索したのち，特性エンティティに関係する用途エンティティを同文書中から取得することにより，材料特性を活かした用途アイデアの獲得手法を提案する．さらに本論文では，提案手法で獲得した用途アイデアを対象に専門家による新規性と実現性の評価を実施し，その有効性を確認する．
P1:ポスター3月11日（火） 8:30-10:00   P会場(2Fコンベンションホール3+4),P1-4,大規模言語モデルを用いた電子カルテのSOAP作成支援システムの開発,/proceedings/annual_meeting/2025/pdf_dir/P1-4.pdf,"○斉藤 翼, 山中 稜斗, 北岡 教英 (豊橋技科大)",医療従事者の負担軽減を目的として，大規模言語モデル（LLM）を用いたSOAP ノート生成手法を提案する．提案手法は，SOAP 生成プロセスをSO 抽出タスクとAP 生成タスクの2 段階に分割する．SO 抽出タスクでは，患者と医療従事者との対話文から主観的情報と客観的情報を抽出する．AP生成タスクでは，抽出された主観的情報と客観的情報からアセスメントと計画を生成する．さらに，Retrieval-Augmented Generation (RAG) を導入し，過去のSOAP データを参照することでLLM の医学知識を補完する．実験の結果として，論理的一貫性と安全性の配慮において高い評価を得られたが，臨床的妥当性と完全性においては課題が残った．
P1:ポスター3月11日（火） 8:30-10:00   P会場(2Fコンベンションホール3+4),P1-5,大規模言語モデルの非対称的意思決定特性：プロスペクト理論要素の実証分析,/proceedings/annual_meeting/2025/pdf_dir/P1-5.pdf,"○吉川 克正, 大萩 雅也, 高山 隼矢 (SB Intuitions)",大規模言語モデル（LLM）の意思決定特性を理解することは、人工知能技術の発展において重要な課題となっている。本研究では、行動経済学の基礎理論であるプロスペクト理論の枠組みを用いて、LLMの意思決定パターンを実験的に検証した。実験結果は、LLM の意思決定特性が人間とは異なる独特のパターンを示すことを明らかにした。具体的には、損失領域においては人間の意思決定に近い特性を示す一方で、利得領域では極端に歪んだパターンを示した。これらの結果は、LLM が人間とは質的に異なる意思決定メカニズムを持つことを示唆しており、LLM の意思決定特性の理解と制御に重要な示唆を与えるものである。
P1:ポスター3月11日（火） 8:30-10:00   P会場(2Fコンベンションホール3+4),P1-6,BERTを用いた誤訳検出とLLMを用いた誤訳訂正による特許翻訳の自動後編集,/proceedings/annual_meeting/2025/pdf_dir/P1-6.pdf,"○武馬 光星, 西村 柾人, 宇津呂 武仁 (筑波大), 永田 昌明 (NTT)",特許翻訳は，その専門性と厳密さから高い翻訳精度が求められる分野である．しかし，従来のTransformer ベースのニューラル機械翻訳(NMT) モデルでは，特許文特有の長文構造や複雑な書式に起因する訳抜けや繰り返しといった誤訳が発生しやすいという課題がある．さらに，近年急速に発展している大規模言語モデルの翻訳訂正能力については，特許翻訳における有効性が十分に検討されていない．本論文では，mBERT を用いたトークンレベルの誤訳検出と大規模言語モデル(LLM) を用いた訂正手法を組み合わせた手法を提案する．BLEU およびCOMET のスコアで評価を行い，提案手法が最も高い翻訳精度を達成し，誤訳や繰り返しの改善に寄与することが示された．一方で，訳抜け文の訂正においては，課題も確認された．
P1:ポスター3月11日（火） 8:30-10:00   P会場(2Fコンベンションホール3+4),P1-7,テキスト生成における最小ベイズリスク復号の理論的な理解に向けて,/proceedings/annual_meeting/2025/pdf_dir/P1-7.pdf,"○市原 有生希 (NAIST), 陣内 佑, 蟻生 開人, 森村 哲郎 (サイバーエージェント), 内部 英治 (ATR)","最小ベイズリスク復号(Minimum Bayes Riskdecoding) は, 自然言語処理のテキスト生成において効果的であることが知られている手法である. この手法は基盤となる人間の嗜好確率分布に基づく期待効用を最大化することを目的とし, 出力選択を行う.先行研究における実験的評価ではこのアプローチが顕著な成功を収めていることが示されているが, これらの手法が有効に機能する原因については未だ解明されていない. 本研究では最小ベイズリスク復号が何故高い性能が得られるかを明らかにすることを目的として, その理論的な性能を分析する. 分析の結果として, いくつかの仮定の下, 最小ベイズリスク復号の誤差が計算に用いる参照仮説集合の大きさ𝑛に対して高い確率で𝑂( 1√𝑛) に収まることが示された."
P1:ポスター3月11日（火） 8:30-10:00   P会場(2Fコンベンションホール3+4),P1-8,Domain-Aware Adaptation for Unsupervised Machine Translation,/proceedings/annual_meeting/2025/pdf_dir/P1-8.pdf,"○◊Youyuan Lin (京大), Rui Wang (SJTU), Chenhui Chu (京大)","Adapting Unsupervised Neural Machine Translation(UNMT) for domain-speciﬁc tasks often encounters Do-main Mismatch (DM), where one language lacks suﬃcientin-domain monolingual data. We observe that while in-domain monolingual corpora enhance translation qualityfor the language they belong to, this improvement doesnot extend to the paired language. To address DM, wepropose Domain-Aware Adaptation (DAA). DAA selectsin-domain texts according to assigns higher weights to in-domain texts from open-domain corpora. Experimentalresults on Japanese-English translation tasks across the IT,Koran, Medical, and TED2020 domains demonstrate thatDAA successfully mitigates the quality disparities in trans-lation caused by DM, enhancing overall domain-speciﬁctranslation performance."
P1:ポスター3月11日（火） 8:30-10:00   P会場(2Fコンベンションホール3+4),P1-9,JParaCrawl Chinese v2.0: クラウドソーシングを用いた日中対訳コーパスの構築,/proceedings/annual_meeting/2025/pdf_dir/P1-9.pdf,"○永田 昌明, 帖佐 克己, 安田 宜仁 (NTT)",我々はクラウドソーシングを使って、日中対訳web サイトのトップページURL の対を約1 万件収集し、約460 万文対の日中対訳コーパスを作成した。まずトップページURL を起点としてそのドメインをクロールし、次に16 万語対の日中対訳辞書を用いて文書対応と文対応を行い、最後に別途用意した
P1:ポスター3月11日（火） 8:30-10:00   P会場(2Fコンベンションホール3+4),P1-10,Towards Modular Fine-tuning of LLM-based Multilingual Neural Machine Translation,/proceedings/annual_meeting/2025/pdf_dir/P1-10.pdf,"○◊Zhe Cao, Yusuke Oda (NAIST/NII), Akiko Aizawa (NII), Taro Watanabe (NAIST)","As Large Language Models support more and more lan-guages, they face increasing challenges in alleviating lan-guage inference and adapting to unseen languages. In thiswork, we propose a modular ﬁne-tuning pipeline for mul-tilingual neural machine translation, where adapters aretrained separately for input and output languages. Dur-ing translation, the parameters of the corresponding inputand output language adapters are combined using weightedsummation. Experiments on 5 languages show that ourmethods can reach 50% of full-parameter ﬁne-tuning per-formance with only 0.5% to 1% trainable parameters.Moreover, under certain weight conﬁgurations, merginginput and output language adapters outperforms using themindividually in some language directions, highlighting thepotential of our merging strategy."
P1:ポスター3月11日（火） 8:30-10:00   P会場(2Fコンベンションホール3+4),P1-11,順送り訳データに基づく英日同時機械翻訳の評価,/proceedings/annual_meeting/2025/pdf_dir/P1-11.pdf,"○土肥 康輔, 胡 尤佳, 蒔苗 茉那 (NAIST), 須藤 克仁 (奈良女子大/NAIST), 中村 哲 (NAIST/CUHK-Shenzhen), 渡辺 太郎 (NAIST)",同時通訳では，原発話の語順を極力維持して訳出することで遅延を抑制する，順送り方略がよく用いられるが，オフライン翻訳では，流暢さを優先して原発話と語順が大きく異なる訳出がされることがある．オフライン翻訳を参照訳とする従来の評価手法では，同時機械翻訳モデルが出力する同時通訳らしい語順の訳出を十分に評価できていない可能性がある．そこで本研究では，語順差が大きい英語・日本語間のオフライン機械翻訳，および同時機械翻訳モデルを順送り訳データを用いて評価した．順送り訳データで同時機械翻訳モデルを評価すると，オフラインデータセットで評価したときに比べて高いスコアとなり，同時機械翻訳の自動評価で語順を考慮することの必要性が示唆された．
P1:ポスター3月11日（火） 8:30-10:00   P会場(2Fコンベンションホール3+4),P1-12,Towards Scene Text Translation for Complex Writing Systems,/proceedings/annual_meeting/2025/pdf_dir/P1-12.pdf,"Hour Kaing, ○◊宋 海越, 丁 塵辰 (NICT), 毛 剣楠 (岐大), 田中 英輝, 内山 将夫 (NICT)","Scene text translation aims to automatically translate textin images or videos while preserving its visual features. Inthis work, we focus on scene text translation for complexwriting system by taking Japanese as a typical example.We build a pipeline to translate from English to Japanese,leveraging publicly available modules for text detection,recognition, and translation, and train our own text replace-ment model specialized for English-to-Japanese transfor-mations. Experiments show that the system can eﬀectivelygenerate translated text in Japanese while retaining muchof the original style, although background regeneration andhandling of Kanji remain open challenges."
P1:ポスター3月11日（火） 8:30-10:00   P会場(2Fコンベンションホール3+4),P1-13,翻訳と言い換え ''（ソース）入力文:（ターゲット）入力文''の学習の有効性,/proceedings/annual_meeting/2025/pdf_dir/P1-13.pdf,○村上 仁一 (鳥取大),言い換えと翻訳は，同一言語と他言語の違いがあるが，意味が同じ文章を生成する点において同一の処理とみなせる．そこで，１つのシステムにおいて，言い換えと翻訳が同時におこなうシステムを構築することを試みた．そのとき，以下の概念を組み込んだ．• 最も精度が高い言い換え文は入力文である．つまり，入力文と出力文が同一のとき，もっとも精度の高い言い換えになる．• 翻訳は言い換えの一種である．この概念から，対訳学習文に，”（ソース）入力文：（ターゲット）入力文” を追加する．その結果，高い精度で，言い換えが得られた．また高い精度の翻訳が可能になった．
P1:ポスター3月11日（火） 8:30-10:00   P会場(2Fコンベンションホール3+4),P1-14,Adapting Multilingual Models for Specialized Translation through Mixed Fine-tuning,/proceedings/annual_meeting/2025/pdf_dir/P1-14.pdf,"○◊Liyan Wang, Haotong Wang, Yves Lepage (早大)","In this work, we dissect mixed ﬁne-tuning for adapt-ing multilingual models to English-to-Japanese translation.We explore diﬀerent sampling regimes across specializedand generic translations. Our ﬁndings indicate that over-sampling the in-domain data leads to notable improvementsin domain-speciﬁc performance, yet at the cost of severedegradation in generalization to unseen languages, per-forming even worse than basic ﬁne-tuning with no genericdata.In contrast, undersampling the generic data pre-serves more of the original multilingual capabilities whilestill achieving moderate domain adaptation gains. Theseresults highlight the critical role of managing training sizeand data coverage to optimize the trade-oﬀbetween spe-cialization and generalization during adaptation."
P1:ポスター3月11日（火） 8:30-10:00   P会場(2Fコンベンションホール3+4),P1-15,フィールドワークデータによるジンポー語機械翻訳,/proceedings/annual_meeting/2025/pdf_dir/P1-15.pdf,"○田口 智大 (ノートルダム大), 倉部 慶太 (東京外大), 坂井 優介 (NAIST), Rita Seng Mai Nbanpa (ワシントン大)",本研究では，フィールドワークによって収集されたデータを用いたジンポー語の機械翻訳システムを開発する．ジンポー語は主にミャンマー北東部のカチン州でカチン人によって話される言語であり，言語資源が極めて限られているため，機械翻訳などの言語処理タスクの応用が未だに進んでいない．そこで，本論文では，言語学者がカチン州でのフィールドワークで収集した民話と，母語話者によるその翻訳を対訳データとして用いて，英語・ジンポー語の機械翻訳システムを開発する．実験の結果，フィールドワークに基づく対訳データは少量ながら，ジンポー語から英語への機械翻訳では，民話ドメインにて最大約10.7 ポイント，会話ドメインにて最大約
P1:ポスター3月11日（火） 8:30-10:00   P会場(2Fコンベンションホール3+4),P1-16,BART 文章校正モデルにおけるコピー機構の有用性の検証,/proceedings/annual_meeting/2025/pdf_dir/P1-16.pdf,"○北岡 佑一, 真嘉比 愛 (ちゅらデータ)",近年、大規模言語モデル（LLM）の発展により、高度な自然言語処理タスクの実現が可能となっている。しかし、文章校正タスクにおいて、LLM は入力文の意図を超えた過剰な書き換えを行う傾向があり、元の文意を保持できないという課題がある。本研究では、BART モデルにコピー機構を導入することで、必要最小限の編集に限定した文章校正の実現を目指した。評価実験では、ERRANT によるF0.5 スコアを用いて編集精度を測定し、従来のBART モデルと比べて精度が向上したのを確認した。また、LLM であるGemini とも比較を行い、本手法が有効であることを示した。この成果は、我々の文章校正AI サービス「ちゅらいと」の改善に向けた重要な知見となる。
P1:ポスター3月11日（火） 8:30-10:00   P会場(2Fコンベンションホール3+4),P1-17,複数のLLMを活用した機械翻訳のための協力デコーディング,/proceedings/annual_meeting/2025/pdf_dir/P1-17.pdf,"○白井 尚登, 衣川 和尭, 伊藤 均, 美野 秀弥, 河合 吉彦 (NHK)","大規模言語モデル（LLM）は対話などの生成タスクで成功する一方，翻訳性能の向上や計算コストの高さに課題がある．そこで本論文では，これらの課題を解決するために機械翻訳に適した新たな協力デコーディング手法を提案する．本手法は各言語の単言語データの継続事前学習をしたのち，対訳データによる追加学習をした小型LLM と，より大型なLLM を組み合わせて翻訳を行う．日英・独英翻訳タスクについて双方向で実験した結果，提案手法はパラメータサイズの小さなモデルを学習することで計算コストを抑え, 既存の協力デコーディング手法を上回る翻訳性能を示した．"
P1:ポスター3月11日（火） 8:30-10:00   P会場(2Fコンベンションホール3+4),P1-18,mBART for Supervised Gloss-Free Sign Language Translation: Integrating RGB and Facial Keypoint Images,/proceedings/annual_meeting/2025/pdf_dir/P1-18.pdf,"○毛 剣楠 (岐大), 丁 塵辰, Kaing Hour, 田中 英輝, 内山 将夫 (NICT), 松本 忠博 (岐大)","Sign language translation (SLT) has traditionally de-pended on gloss annotations, which are costly and time-consuming to produce. This work presents a gloss-freeSLTframework that integrates raw RGB video input with facialkeypoint features, enabling richer visual representations.We leverage a two-stage approach: ﬁrst aligning visualand textual features with a frozen multilingual mBARTencoder, then reﬁning translation through the mBART de-coder. Evaluations on the PHOENIX-2014T dataset showperformance gains over baselines, yielding a +0.64 BLEUimprovement. These results conﬁrm that incorporating fa-cial keypoints strategy can signiﬁcantly improve gloss-freesign language translation."
P1:ポスター3月11日（火） 8:30-10:00   P会場(2Fコンベンションホール3+4),P1-19,ニューラルかな漢字変換システム Zenzai,/proceedings/annual_meeting/2025/pdf_dir/P1-19.pdf,"○三輪 敬太 (東大/Turing), 高橋 直希 (早大/CoeFont)",かな漢字変換は日本語話者において広く普及している自然言語処理応用の一つであるが，その精度は未だに十分とは言えない．本研究では，入力のかな文字列に対応する漢字かな交じり文を生成する条件付きニューラル言語モデルを用いたニューラルかな漢字変換システムを提案し，統計的かな漢字変換システムをドラフトモデルとする投機的デコーディングによって提案手法を高速化する．提案手法の精度および速度の検証を行った結果，従来手法に比べて大幅に高い変換精度と，投機的デコーディングの高速化への有効性が示された．
P1:ポスター3月11日（火） 8:30-10:00   P会場(2Fコンベンションホール3+4),P1-20,低資源言語のニュース機械翻訳のためのLLM を用いた合成対訳データの生成,/proceedings/annual_meeting/2025/pdf_dir/P1-20.pdf,"○伊藤 均, 白井 尚登, 衣川 和尭, 美野 秀弥, 河合 吉彦 (NHK)",低資源言語の機械翻訳モデル構築における課題として，十分な量の対訳データの確保が挙げられる．さらに，対象ドメインが限定されている文の翻訳などの場合，対訳データだけでなく原言語側の単言語データを確保することさえも困難な場合がある．本研究では，対象ドメインの原言語側の単言語データが少量しかない状況下で，学習データ量不足の課題を解決するための大規模言語モデル（LLM）を活用した多様で高品質な合成データ生成手法を提案する．提案手法の効果を確認するために，タイ語から日本語へのニュース翻訳の実験を行った．提案手法で合成したデータを用いてLLM をファインチューニングしたニュース機械翻訳器は，タイ語から日本語へのニュース翻訳タスクにおいて従来手法を上回る性能を達成し，BLEU 値を19.9 ポイント改善した．
P1:ポスター3月11日（火） 8:30-10:00   P会場(2Fコンベンションホール3+4),P1-21,対訳データを用いた大規模言語モデルの継続事前訓練による特許請求項翻訳,/proceedings/annual_meeting/2025/pdf_dir/P1-21.pdf,"○浅見 遥斗, 近藤 海夏斗, 宇津呂 武仁 (筑波大), 永田 昌明 (NTT)",大規模言語モデル(LLM) の技術進歩は著しく，様々な分野でその活用が進んでいる．しかし、特許翻訳の分野では依然としてTransformer ベースの翻訳が主流であり，LLM を活用した翻訳能力については十分に検討されていない．そこで本研究では、近藤ら[6] の手法を参考に，対訳データを用いた継続事前訓練とSFT(Supervised Fine-Tuning) を行ったLLM を用いて特許請求項の翻訳を行い，Transformerベースの翻訳と比較した．その結果，BLEU およびCOMET のスコアがいずれも上回り，訳抜けや繰り返しといった課題が改善されたことを確認した．一方で、従来モデルでは発生しなかったハルシネーションが一部の例で確認され，その影響で翻訳精度が低下したケースも観測された．本研究は，LLM が特許翻訳分野において有望な技術である一方で，課題も存在することを示している．
P1:ポスター3月11日（火） 8:30-10:00   P会場(2Fコンベンションホール3+4),P1-22,AoGu: A Japanese-English literary parallel corpus from Aozora Bunko and Project Gutenberg,/proceedings/annual_meeting/2025/pdf_dir/P1-22.pdf,"○◊Guanyu Ouyang, Xiaotian Wang, Takehito Utsuro (筑波大), Masaaki Nagata (NTT)","This paper introduces a Japanese-English parallel cor-pus composed of literary works, constructed mainly us-ing bilingual texts from Aozora Bunko and Project Guten-berg.Existing Japanese-English parallel datasets, suchas JParaCrawl, JaParaPat, and ASPEC [1, 2, 3], oﬀeringcoverage of common, patent, and academic domains, theylack resources speciﬁcally designed to address discourse-level phenomena and context-aware translation challengeswhich are existed in literary translation task. To bridgethis gap, we build upon the ""English-Japanese TranslationAlignment Data"" 1）developed over a decade ago, updatingand expanding it to better support research in discourse-level literary translation and document-level context mod-eling. Baseline experiments with transformer models onthe constructed dataset demonstrate limited performance,highlighting the inherent challenges of literary translationand underscoring the need for more advanced methodolo-gies and resources to enhance translation quality for literarytexts."
P1:ポスター3月11日（火） 8:30-10:00   P会場(2Fコンベンションホール3+4),P1-23,修辞構造に基づく分割統治型LLM翻訳,/proceedings/annual_meeting/2025/pdf_dir/P1-23.pdf,"○田中 邦朋 (名大), 帖佐 克己, 平尾 努 (NTT), 笹野 遼平 (名大)",大規模言語モデルの急速な発展は、機械翻訳分野にも影響を及ぼしているが、長く複雑な文の翻訳においては、原文構造の喪失、訳抜けといった課題が依然として存在する。本研究では、大規模言語モデルの特長を活かしつつ、これらの課題に対処するため、原文の修辞構造を利用した分割統治型機械翻訳法を提案する。提案手法では、原語文を修辞構造に則って分割した後、モデルによる翻訳と原文の並列構造を考慮した統治を行って、翻訳文を得る。特許請求項の日英翻訳タスクを通して評価を行った結果、翻訳精度、訳抜け抑制、文構造保持の点で、提案手法が大規模言語モデルでの直接翻訳より優れていることが確認された。
P1:ポスター3月11日（火） 8:30-10:00   P会場(2Fコンベンションホール3+4),P1-24💻,"Word order of subject, object, oblique, and verb",/proceedings/annual_meeting/2025/pdf_dir/P1-24.pdf,○江原 暉将 (江原NLP研),
Q1:ポスター3月11日（火） 8:30-10:00   Q会場(1F会議室101AB),Q1-1,書き手の孤独感を予測できるか？,/proceedings/annual_meeting/2025/pdf_dir/Q1-1.pdf,"○藤川 直也, 伊藤 和浩, 若宮 翔子, 荒牧 英治 (NAIST)",孤独感に苛まれている人を発見し介入するために，ウェブ上のテキストから孤独感を捉えるためのデータセットがいくつか構築されている．しかし，既存のデータセットは，主に読み手による評価に基づいており，書き手自身が感じる孤独感と乖離している可能性がある．本研究では，孤独感に関する自由記述と書き手自身の孤独感の程度をクラウドソーシングにより収集し，この自由記述に対する読み手の評価も含めたデータセットを構築した．さらに，そのデータセットを用いて，書き手との孤独感を機械学習モデルが予測可能か検証した．コーパスを構築した結果，読み手と書き手の評価の一致率は
Q1:ポスター3月11日（火） 8:30-10:00   Q会場(1F会議室101AB),Q1-2,BCCWJ-WLSP-LUW:『現代日本語書き言葉均衡コーパス』に対する長単位語義情報アノテーション,/proceedings/annual_meeting/2025/pdf_dir/Q1-2.pdf,"加藤 祥 (目白大), ○浅原 正幸 (国語研/総研大)",本稿では，『現代日本語書き言葉均衡コーパス』（BCCWJ）の長単位への分類語彙表番号アノテーション作業とその結果について報告する．今回構築したBCCWJ-WLSP-LUW は，BCCWJ の書籍・新聞・雑誌データに対し，『分類語彙表増補改訂版』を基に分類語彙表番号を付与し，長単位の文脈的な意味分類を可能にしたアノテーションデータである．短単位への分類語彙表番号付与作業を基盤としつつ，未定義の長単位語義については一部手作業による対応を行った．これにより，長単位においても短単位と同様に分類語彙表を用いた詳細な意味分析が可能となった．
Q1:ポスター3月11日（火） 8:30-10:00   Q会場(1F会議室101AB),Q1-3,JETHICS: 日本語道徳理解度評価用データセット,/proceedings/annual_meeting/2025/pdf_dir/Q1-3.pdf,"○竹下 昌志, ジェプカ ラファウ (北大)",本研究では、日本語道徳理解度評価用データセットJETHICS を提案する。JETHICS は、英語の既存データセットであるETHICS の構築方法を踏襲し作成されており、正義、功利主義、義務論、徳倫理、常識道徳の五つのカテゴリから構成され、約7.8 万件のデータが含まれる。常識道徳を除く各カテゴリは全て規範倫理学・政治哲学の理論や概念を参考にして作成されている。公開されている大規模言語モデル(Large Languge Model: LLM) および商用モデルとしてGPT-4o を対象として評価実験を行ったところ、GPT-4o であっても平均評価値が約0.7、平均評価値が最も高い公開LLM では約0.5 となり、既存のLLM には改善の余地があることが示された。
Q1:ポスター3月11日（火） 8:30-10:00   Q会場(1F会議室101AB),Q1-4,説得力および納得度の推定に向けたWebディベートデータセットの構築,/proceedings/annual_meeting/2025/pdf_dir/Q1-4.pdf,"○大杉 康仁, 吉田 明弘 (NTTドコモ), 中辻 真 (NTT)",話者の説得力、および、聴者の納得度を自動で推定することが可能となれば、自学自習による練習機会が増え、営業スキルやコミュニケーションスキルの向上につながる。本研究では、オンライン会議において話者の説得力や聴者の納得度をラベル付けしたデータセットを構築した。話者と聴者が明示的に交代するディベート形式を採用し、肯定側1 人・否定側1 人・判定者1 の合計3 人での会議を115 セッション収録した。第三者から見た説得力や論理性、聴者の納得度などのアノテーションを実施した。ラベルの分析からは、説得力と論理性には相関係数
Q1:ポスター3月11日（火） 8:30-10:00   Q会場(1F会議室101AB),Q1-5,改正後法令文翻訳のための疑似三つ組コーパスの構築,/proceedings/annual_meeting/2025/pdf_dir/Q1-5.pdf,"○山腰 貴大 (名大), 小川 泰弘 (名市大), 外山 勝彦 (名大)",法令の改正に伴い，その訳文を修正する際には，改正箇所のみを差分的に翻訳し直す必要がある．改正前の訳文（旧訳文）の表現をコピーして訳文を生成できる2 入力NMT は，差分的な翻訳を可能とするが，2 入力NMT の訓練には原文，旧訳文，訳文の三つ組が必要であり，言語資源の調達コストが大きい．そこで，本研究では，法令文の対訳コーパスから疑似的な三つ組を構築する．対訳コーパスの訳文に対してフレーズをランダムに削除又は置換した文を旧訳文とみなし，元の原文，訳文と合わせて三つ組とする．構築した三つ組コーパスを2 入力NMTの訓練に使用したところ，三つ組の生成元である対訳コーパスにより訓練したNMT の性能を上回った．
Q1:ポスター3月11日（火） 8:30-10:00   Q会場(1F会議室101AB),Q1-6,Fine-Grained Error Annotations for Sentence Simplification by Large Language Models,/proceedings/annual_meeting/2025/pdf_dir/Q1-6.pdf,"○Xuanxin WU (阪大), Yuki Arase (科学大)","Large language models (LLMs) demonstrate strong per-formance in text simpliﬁcation, yet current metrics lack theinformativeness of more detailed schemes that annotate in-dividual errors. Clearly stating these limitations is essentialto understand the simpliﬁcation quality of LLMs. Buildingon our previous work [1], which introduced an error-basedhuman annotation framework to assess GPT-4’s simpliﬁca-tion capabilities, this study expands the scope by includingtwo additional LLMs, Qwen2.5-72B and Llama-3.2-3B,along with more datasets. Our human-annotated corpuscomprises ﬁne-grained error analyses for 4, 500 complex-simple sentence pairs and Likert-scale ratings for 10, 471pairs, one of the largest scales to date. Results show thatLLMs generally generate fewer erroneous simpliﬁcationoutputs than the previous state-of-the-art (SOTA). How-ever, LLMs have their limitations, as seen in larger LLMsstruggle with lexical paraphrasing."
Q1:ポスター3月11日（火） 8:30-10:00   Q会場(1F会議室101AB),Q1-7,小説テキストに対する登場人物アノテーション,/proceedings/annual_meeting/2025/pdf_dir/Q1-7.pdf,"○大島 一海, 小川 浩平, 佐藤 理史 (名大)",小説理解において，登場人物の認識とセリフの話者推定は，最初の重要なステップである．本論文では，登場人物認識とセリフの話者推定を統合した処理を，登場人物アノテーションと名づけ，これを実現するシステムを提示する．さらに，そのシステムを用いて完全自動の登場人物アノテーションを実行し，セリフの話者推定において，主要登場人物リストを与える先行研究と同程度の精度を達成した．
Q1:ポスター3月11日（火） 8:30-10:00   Q会場(1F会議室101AB),Q1-8,技能者インタビュー対話コーパス (EIDC) v.2.0: コツ発話の同定に向けた相互行為アノテーション,/proceedings/annual_meeting/2025/pdf_dir/Q1-8.pdf,"○近 大志 (京大), 岡久 太郎 (静大), Yin Jou Huang, 樽谷 洋希, 松田 思鵬, 村脇 有吾, 黒橋 禎夫 (京大)",技能者インタビュー対話コーパス(Expert InterviewDialogue Corpus; EIDC) は，技能のコツを含む発話（コツ発話）の性質や，効果的な引き出し方を解明する目的で構築されている．EIDC は園芸・料理ドメインの技能者インタビュー対話を対象とし，映像・音声，書き起こし，各種アノテーションを収録している．EIDC v.2.0 では，コーパスの一部を対象として，対話の相互行為的な特徴に着目した追加アノテーションを行った．本稿では，追加アノテーションの仕様と定量的特徴を報告し，コツ発話の検出に寄与する特徴を分析する．
Q1:ポスター3月11日（火） 8:30-10:00   Q会場(1F会議室101AB),Q1-9,沿革情報を用いた企業名変遷の構造化,/proceedings/annual_meeting/2025/pdf_dir/Q1-9.pdf,"○澤田 悠冶, 大内 啓樹 (NAIST/理研), 安井 雄一郎 (日経), 寺西 裕紀 (NAIST/理研), 松本 裕治 (理研), 渡辺 太郎 (NAIST), 石井 昌之 (日経)",ニュース記事では，企業などの組織名に関する情報を報じる記事が多く，組織名が頻繁に登場する．企業名は時間と共に変化しやすく，企業名の変化がエンティティリンキングを困難にしている問題がある．本研究は，企業名の変遷に関わる情報をイベントとして抽出することで，歴代の企業名を構造化し，企業名の曖昧性を解消することを目指す．社名の変更や企業の統廃合に関する5 種類のイベントを定義し，有価証券報告書の企業沿革テキストに各イベントをアノテーションを付与した企業名変化イベント抽出データセットを作成する．作成データセットを使用した評価実験では，LLM によるイベント抽出結果を評価し，一部の企業イベントに対して改善の余地が見られることを確認した．
Q1:ポスター3月11日（火） 8:30-10:00   Q会場(1F会議室101AB),Q1-10,タンパク質立体構造データと紐づけたコーパス作成の試み,/proceedings/annual_meeting/2025/pdf_dir/Q1-10.pdf,"○佐久間 航也 (名大), 丹羽 智美 (阪大)",タンパク質の立体構造データは原子の位置座標を用いて分子の形を表現したものであり、それと同時に、構造生物学者による解釈の対象でもある。AlphaFold などの高精度な立体構造予測手法は、立体構造を計算機で取り扱うことの可能性と価値を証明したが、いまだに立体構造データの解釈、つまり「立体構造が意味するところ」をバイオインフォマティクス的に扱うことは難しい。一方、近年の自然言語処理技術の発展により、言語データを媒体とすることで「意味を計算する」ことが可能となりつつあるようにみえる。したがって、物質科学的な計算手法と自然言語処理を組み合わせることで、分子の機能予測や設計など、物性と意味が絡みあうタイプの科学の発展に寄与することができると期待される。だが、そのような物質科学的データと「それに対する記述」を詳細にペア化したデータセット──物性と意味とをリンクし得る資源──は存在しない。無いなら作れば良い。本稿では、われわれが構造生物学ドメインにおいて進めている立体構造に紐づいたコーパスの要件定義と試作について報告する。
Q1:ポスター3月11日（火） 8:30-10:00   Q会場(1F会議室101AB),Q1-11,BCCWJ-Metaphorにおける比喩表現認定と情報付与作業手順,/proceedings/annual_meeting/2025/pdf_dir/Q1-11.pdf,"○加藤 祥 (目白大), 菊地 礼 (長野高専), 浅原 正幸 (国語研)","本研究は,日本語の比喩表現コーパスとして構築した「BCCWJ-Metaphor」における比喩表現の認定手法と情報付与について報告する．MIP に基づきMRW を認定するため，MFlags や結合（選択制限違反）の抽出，比喩種別（擬人化，具象化，換喩，提喩など）の分類を付与している．日本語比喩表現に対応するため，実際の作業手順では，中村(1977)の比喩表現把握モデルを援用し，MIP の基本的意味と文脈的意味の対照による比喩認定を行うこととした．また，比喩性の認定根拠を明確化するため，転換の種別や印象評定情報を付与した．"
Q1:ポスター3月11日（火） 8:30-10:00   Q会場(1F会議室101AB),Q1-12,Evaluating Large Language Models in Mongolian,/proceedings/annual_meeting/2025/pdf_dir/Q1-12.pdf,"○◊Dorjnyam Tumur-Ochir, Fei Cheng, 村脇 有吾, Chenhui Chu (京大)","This paper presents a comprehensive evaluation for as-sessing large language model (LLM) capabilities in theMongolian language, addressing a critical gap in multilin-gual LLM evaluation. We introduce MonMLU, a novelbenchmark derived from native-level university entranceexams, alongside Mongolian adaptations of establishedbenchmarks including Vicuna, MT-Bench, MGSM, andXCOPA. Our evaluation of leading commercial and openlyavailable models reveals that while GPT-4o-mini achievesthe highest performance (8.86 on Vicuna, 8.10 on MT-Bench), openly available models signiﬁcantly underper-form.These ﬁndings highlight future opportunities forimproving LLM performance in Mongolian and other low-resource languages."
Q1:ポスター3月11日（火） 8:30-10:00   Q会場(1F会議室101AB),Q1-13,短単位版「関西弁コーパス」の構築と予備的分析,/proceedings/annual_meeting/2025/pdf_dir/Q1-13.pdf,"○尹 熙洙 (総研大/国語研), 王 竣磊 (国語研/東大), 岡田 純子 (国語研), 小木曽 智信 (国語研/総研大)",関西方言を研究するための形態論情報付きコーパスとして，ケビン・ヘファナン教授によって構築された「関西弁コーパス」のテキストの一部をUniDic短単位に分割し，171 万語に形態論情報を付与した短単位版「関西弁コーパス」を構築した．うち77.5万語は人手による検証・修正を行い，残りの93.5 万語は形態素解析器MeCab と人手検証済みデータで学習した関西方言用UniDic を利用して解析した．本稿では，短単位版「関西弁コーパス」の構築について論じ，その価値を示す活用例として予備的な分析結果を示す．短単位版「関西弁コーパス」は，関西方言の研究に有効な資料として利用されることが期待される．
Q1:ポスター3月11日（火） 8:30-10:00   Q会場(1F会議室101AB),Q1-14,日英対訳ジオパージングデータセット ATD-Para,/proceedings/annual_meeting/2025/pdf_dir/Q1-14.pdf,"○東山 翔平 (NICT/NAIST), 大内 啓樹 (NAIST/理研), 藤田 篤, 内山 将夫 (NICT)",テキストに含まれる地理情報の解析技術は，観光・防災支援などの応用に有用である．本研究では，日本語旅行記の英訳とアノテーションにより，日・英2 言語の地理的解析・生成タスクのデータセットを構築した．基本的な3 タスクにおいて，言語（日・英）および地域（国内・海外）の観点でシステムの性能評価・分析を行った．
Q1:ポスター3月11日（火） 8:30-10:00   Q会場(1F会議室101AB),Q1-15,大規模言語モデルを用いた物語分析データセットの効率的構築：日本語物語の話者推定を例として,/proceedings/annual_meeting/2025/pdf_dir/Q1-15.pdf,"○郷原 聖士, 上垣外 英剛, 渡辺 太郎 (NAIST)",物語分析におけるセリフの話者推定は，物語の中で登場人物の心情変化や成長を分析していく上で重要なタスクである。しかし，話者推定は複雑な対話，発話パターンの多様性，および曖昧なキャラクター参照のような様々な要素が組み合わさっているため，データセットを人手で作成する場合、大量の作業時間と費用が必要になる．本研究では，大規模言語モデル（LLM）と少量の人手修正を組み合わせたラベル付けをすることで，効率良く高品質なデータセットを構築する手法を示す．実験では，人手でアノテーションした一部の少数の例をLLM に回答例として入力し，最小限の人間による修正を通じてデータセットを構築した．その結果，LLM は設定と話の展開が複雑な「三国志」という物語において約90%の精度で話者名を正確に識別し，人手のアノテーションコストを抑えられることが示唆された．
Q1:ポスター3月11日（火） 8:30-10:00   Q会場(1F会議室101AB),Q1-16,Zero pronoun annotation in Malay and beyond,/proceedings/annual_meeting/2025/pdf_dir/Q1-16.pdf,"○野元 裕樹, Farhan Athirah binti Abdul Razak (東京外大), 藤田 航平 (BFT)","This study proposes a zero pronoun annotation schemethat is easy to adopt cross-linguistically, regardless of lan-guage types, due to its reliance only on raw corpus data andthe absence of prerequisites such as constituency trees orpredicate-argument structures. A spoken language Malaycorpus has been annotated using it. The results are com-pared to the distribution of zero pronouns in a Japanesecorpus, namely the NAIST Text Corpus."
Q1:ポスター3月11日（火） 8:30-10:00   Q会場(1F会議室101AB),Q1-17,ゲーム内テキスト抽出におけるOCRの性能評価―レイアウトと解像度の影響に着目して―,/proceedings/annual_meeting/2025/pdf_dir/Q1-17.pdf,○麻 子軒 (関大),ゲーム内テキスト，特にキャラクターのセリフを効率的に文字起こしする方法について，4 つのゲームを対象にGoogle Cloud Vision のOCR 認識精度を比較した．比較は，テキストのレイアウトおよび解像度の観点から行い，誤認識パターンの分析も実施した．その結果，記号類の認識が弱い傾向が見られるものの，全体的に精度が0.88～0.99 と，情報抽出に大きな影響はないことが判明した．ただ，極端に短い文の場合には別言語や類似文字への誤認識が発生する傾向が確認された．また，レイアウトが固定されていないゲームでは精度が相対的に低く，低解像度の古いゲームでは濁点の欠落や一部の文字が飛ばされて認識されない事例が観察された．
Q1:ポスター3月11日（火） 8:30-10:00   Q会場(1F会議室101AB),Q1-18,Tabidachi: 旅行代理店タスク対話コーパス,/proceedings/annual_meeting/2025/pdf_dir/Q1-18.pdf,"○稲葉 通将 (電通大), 千葉 祐弥 (NTT), 斉 志揚 (電通大), 東中 竜一郎 (名大), 駒谷 和範 (阪大), 宮尾 祐介 (東大), 長井 隆行 (阪大)",人は他者とコミュニケーションを行う際，使用語彙や話す速さ，表情やボディランゲージなどを相手に応じて使い分けている．しかし，現在の対話システムがユーザに応じて話し方や対話戦略を変更することはほとんどない．対話システムがより効率的にタスクを達成したり，ユーザの満足度をより高めるためには，ユーザに応じて対話戦略などを変更できることが望ましい．そこで我々は話し方の変化に大きく影響を与える要素として話者の年齢に着目し，幅広い年齢層の話者によるマルチモーダル対話コーパスTabidachi を構築した．本コーパスは国立情報学研究所情報学研究データリポジトリ（IDR）1）にて公開している．
Q1:ポスター3月11日（火） 8:30-10:00   Q会場(1F会議室101AB),Q1-19,大規模画像言語モデルは物体の裏側を認識できるか？物体の見えない部分の認識を問うタスクの提案,/proceedings/annual_meeting/2025/pdf_dir/Q1-19.pdf,"○竹中 誠 (三菱電機), 谷中 瞳 (東大)",人間は視覚的な情報と言語的な情報を受け取ると，それに関連する事前知識を用いて物事の“見えない部分” を想像するすることができる．物体の見えない部分を予測するタスクはコンピュータビジョンの分野では精力的に研究されているが，多くは対象物の一部が隠れた物体を対象とした物体認識であり，裏側や側面など見えない部分には焦点は当てられていない．そこで本研究では，物体の裏側や側面の認識能力を評価するためのタスクを提案し，線画と写実画像を用いてデータセットを構築した．実験では，提案タスクを用いて人間と代表的な大規模画像言語モデルの性能を比較した．その結果，人間にとって簡単なタスクであるにもかかわらず，最先端の商用モデルでも人間の性能には及ばないことを確認した．
Q1:ポスター3月11日（火） 8:30-10:00   Q会場(1F会議室101AB),Q1-20,「現代日本語書き言葉均衡コーパス」の拡張―BCCWJ2の構築―,/proceedings/annual_meeting/2025/pdf_dir/Q1-20.pdf,"○山崎 誠, 高橋 雄太, 小木曽 智信 (国語研)",国立国語研究所では，2024 年度より文化庁からの委託事業「信頼できる言語資源としての現代日本語の保存・活用のためのデジタル基盤整備事業」を開始した．この事業は「現代日本語書き言葉均衡コーパス」（BCCWJ）の拡張として企画されているものである．構築の中心となるのは，BCCWJ の出版サブコーパスの書籍部分の拡張で，2006 年～2025 年の書籍サンプル約1 億語を現在のBCCWJ に追加するものである.本発表ではその設計について報告する．
Q1:ポスター3月11日（火） 8:30-10:00   Q会場(1F会議室101AB),Q1-21,SciGA: 学術論文における Graphical Abstract 設計支援のための統合データセット,/proceedings/annual_meeting/2025/pdf_dir/Q1-21.pdf,"○川田 拓朗, 根本 颯汰, 北田 俊輔, 彌冨 仁 (法政大)","Graphical Abstract (GA) は論文の要点を視覚的に伝える重要な表現手段である. 効果的なGA の作成には高度なデザインスキルが求められ, 設計支援技術の実現が期待される. 本研究では, 約14.5 万の論文とGA を含む141 万枚の図からなるデータセットSciGA-140k を構築した. また, GA 設計支援の前段として, Abstract を基に論文内からGA として適切な図を検索するタスクAbst2GA Retrieval を提案する.我々はCLIP を基盤とするベースラインを設計し, 提案タスクの有効性を示した. ベースラインは他の論文のGA を検索し, デザイン案を提示する支援機能も提供する. 我々のアプローチはGA 設計支援の新たな方向性を示し, AI for Science の発展に貢献する."
Q1:ポスター3月11日（火） 8:30-10:00   Q会場(1F会議室101AB),Q1-22,否定の観点からみた日本語言語理解ベンチマークの評価,/proceedings/annual_meeting/2025/pdf_dir/Q1-22.pdf,"○湯浅 令子, 吉田 朝飛, 加藤 芳秀, 松原 茂樹 (名大)",言語モデルを評価するための英語言語理解ベンチマークが，否定理解能力の評価に有効であるかの分析が行われている．一方，日本語においては，ベンチマークをそのような観点から分析する取り組みはない．本研究では，日本語言語理解ベンチマークJGLUE を否定の観点から評価する．JGLUE に含まれる否定について現状と課題を明らかにする．
Q1:ポスター3月11日（火） 8:30-10:00   Q会場(1F会議室101AB),Q1-23J,オンライン誹謗中傷検出に向けた裁判例データセット,/proceedings/annual_meeting/2025/pdf_dir/Q1-23.pdf,"○久田 祥平, 若宮 翔子, 荒牧 英治 (NAIST)",
Q1:ポスター3月11日（火） 8:30-10:00   Q会場(1F会議室101AB),Q1-24J,MATCHA：専門家が平易化した記事を用いたやさしい日本語パラレルコーパス,/proceedings/annual_meeting/2025/pdf_dir/Q1-24.pdf,"○宮田 莉奈, 惟高 日向, 山内 洋輝, 柳本 大輝, 梶原 智之, 二宮 崇 (愛媛大), 西脇 靖紘 (MATCHA)",
A2:NLPモデルの評価・安全性・信頼性(2)3月11日（火） 10:20-11:50   A会場(2Fコンベンションホール1+2),A2-1,大規模言語モデルにおける複数の指示追従成功率を個々の指示追従成功率から推定する,/proceedings/annual_meeting/2025/pdf_dir/A2-1.pdf,"○原田 憲旺 (東大), 山崎 友大 (京大), 谷口 仁慈 (琉大), 小島 武, 岩澤 有祐, 松尾 豊 (東大)",規定の文字数やフォーマットを守った文章生成や数千にも及ぶ条文からなる法律を遵守するなど，大規模言語モデルの更なる応用のため複数の指示追従性能は重要な側面である．複数の指示を同時に追従する性能の正確な推定ができると，未見の指示の組み合わせリスクのシミュレーションが可能となる．更に，その組み合わせの種類が膨大になるほどシミュレーションによるリスクの把握が重要性を増す．我々は複数の指示追従性能調査のためのベンチマークManyIFEval とStyleMBPP を作成し，同時に複数の指示追従する成功率は個々の指示の追従成功率の積で推定できるという経験則を得た．経験則により指示の未知の組み合わせに対して指示追従性能を推定できることを示した．また組み合わせる指示数が多くなればなるほど，同時に追従成功する可能性は劇的に低くなることを確認した．
A2:NLPモデルの評価・安全性・信頼性(2)3月11日（火） 10:20-11:50   A会場(2Fコンベンションホール1+2),A2-2,オープン日本語LLMリーダーボードの構築と評価結果の分析,/proceedings/annual_meeting/2025/pdf_dir/A2-2.pdf,"○Namgi Han (東大), 岡本 拓己, 石田 茂樹 (科学大/NII), 林 俊宏 (Hugging Face), Akim Mousterou (AM Research), Bowen Chen (東大), 宮尾 祐介 (東大/NII)",近年の大規模言語モデルの研究において，様々なモデルの評価結果が一覧できるリーダーボードの重要性が増している．本研究ではLLM-jp とHuggingFace の協力のもとにオープンソースで開発かつ運営されるOpen Japanese LLM Leaderboard を構築した．本リーダーボードでは大規模言語モデルの評価フレームワークであるllm-jp-eval を用いて日本語大規模言語モデルの性能を評価し，その結果をリーダーボードとして公開している．本稿ではリーダーボードの詳細を紹介し，さらにこれまでに得られた評価結果を用いた統計分析を行い，日本語大規模言語モデルの評価結果に対する知見を報告する．
A2:NLPモデルの評価・安全性・信頼性(2)3月11日（火） 10:20-11:50   A会場(2Fコンベンションホール1+2),A2-3,pfgen-bench: 日本語事前学習モデルのための文章生成性能評価ベンチマーク,/proceedings/annual_meeting/2025/pdf_dir/A2-3.pdf,"○今城 健太郎, 平野 正徳, 鈴木 脩司, 三上 裕明 (PFN/PFE)",本研究では、日本語事前学習モデルの文章生成性能を評価するためのベンチマークであるpfgen-benchを提案する。本ベンチマークはFluency(流暢さ)、Truthfulness(真実性）、Helpfulness(有用性) の3 つの評価軸から構成される。まず、日本の小中高の学習指導要領を参考に、13 科目50 問からなる、日本語圏特有の常識問題集を作成した。さらに、複数のLLM とルールベースのフィルタリング手法を用いて、高品質な参照回答群を構築した。その上で、さまざまなモデルの回答と参照回答群の近さをはかる3 つの評価軸を設計し、生成結果の評価が可能なベンチマークを構築した。このベンチマークを使用した評価結果に基づくと、事前学習モデル間の性能差を明確に示し、LLM による従来の評価とも一致する点が確認された。構築したベンチマークは公開し、一般に使用可能である。
A2:NLPモデルの評価・安全性・信頼性(2)3月11日（火） 10:20-11:50   A会場(2Fコンベンションホール1+2),A2-4,固有表現抽出におけるタスク特化型BERTと大規模言語モデルの性能比較と実用性評価,/proceedings/annual_meeting/2025/pdf_dir/A2-4.pdf,"○黒澤 研二 (リクルート), 市川 聖, 原口 昌也, 狭間 美祐希 (キュリオスビークル), 桜井 駿 (ワークスアイディ)",本研究では，固有表現抽出におけるタスク特化型BERT モデルと大規模言語モデル（Large LanguageModels，LLM）の一つであるGemini との性能と実用性を比較評価した．独自に構築したデータセットを用いて，few-shot 学習とﬁne-tuning の両方の学習方法での性能を分析し，タスク適合性やコストなどを考慮に入れて実用面での評価も行った．結果として，タスク特化型BERT のﬁne-tuning において最も高い性能を示し，Gemini はfew-shot 学習での柔軟性と，ﬁne-tuning による性能向上の可能性を示した．本研究の知見は，実用的な固有表現抽出システムの設計と実装に貢献すると期待される．
A2:NLPモデルの評価・安全性・信頼性(2)3月11日（火） 10:20-11:50   A会場(2Fコンベンションホール1+2),A2-5,大規模言語モデルの規範的推論能力の評価: 論理とリーズニングの観点から,/proceedings/annual_meeting/2025/pdf_dir/A2-5.pdf,"○小関 健太郎 (慶應大/東大), 安東 里沙子, 森下 貴允, 阿部 裕彦, 峯島 宏次, 岡田 光弘 (慶應大)",規範的推論は、義務や許容(許可) といった規範的・義務論的なモダリティが関与する推論である。本論文では、大規模言語モデル(LLM) の規範的推論能力が持つ特徴を明らかにするために、論理的な妥当性や非妥当性との比較、人間のリーズニングとの比較という2 つの観点からLLM の規範的推論能力の評価と分析を行った。その結果、推論のモダリティの種類(規範的推論と認識的推論) での比較や、一部の推論パターンにおいて、LLM における規範的推論が人間のリーズニングの場合とは異なる傾向を示すことが示唆された。
A2:NLPモデルの評価・安全性・信頼性(2)3月11日（火） 10:20-11:50   A会場(2Fコンベンションホール1+2),A2-6,JaSocial：LLM の社会的知能を評価するための日本語敬語使用フレームワーク,/proceedings/annual_meeting/2025/pdf_dir/A2-6.pdf,"○Muxuan Liu (お茶大/産総研), 石垣 達也 (産総研), 宮尾 祐介 (東大/産総研), 高村 大也 (産総研), 小林 一郎 (お茶大/産総研)",本稿では，選択体系機能言語学の理論枠組みに基づき，大規模言語モデル（LLM）の社会的知能を評価するための新しいフレームワーク「JaSocial」を提案する．この理論を日本語敬語の使用に適用することで，敬語表現が持つ社会的背景や役割に基づき，より詳細かつ包括的にLLM の能力を分析することができるフレームワークを設計した．さらに，このフレームワークの運用を支える専用の評価データセットを新たに構築し，様々なLLM による日本語敬語生成の適切性を多角的に検証するための土台を提供する．
B2:計算・形式言語学(2)3月11日（火） 10:20-11:50   B会場(1F会議室102),B2-1,Modal DTSによる様相従属化の分析,/proceedings/annual_meeting/2025/pdf_dir/B2-1.pdf,"○飯村 葵, 水野 輝之, 戸次 大介 (お茶大)",本研究は，依存型理論に基づく自然言語の意味の理論である依存型意味論を通して，様相表現(modalexpressions) の分析を試みる．依存型意味論は，照応や前提が絡む複雑な言語表現に対応可能であることが示されてきたが，物事の可能性(possibility) や必然性(necessity) に関わる様相表現への分析の拡張は依然開拓の余地がある．そこで本論文は，依存型意味論を様相型で拡張したModal DTS を提案する．これにより，照応とモダリティが相互作用する様相従属化(modal subordination) をはじめ，前提を伴う様相従属化についても分析を与えるなど，依存型意味論が対象とする言語現象を拡大した．
B2:計算・形式言語学(2)3月11日（火） 10:20-11:50   B会場(1F会議室102),B2-2,二重目的語構文，与格構文におけるWeak Crossover現象の分析と検証実験,/proceedings/annual_meeting/2025/pdf_dir/B2-2.pdf,"○藤田 琴海 (お茶大), Daniel Plesniak (SNU), 福島 遥, 戸次 大介 (お茶大)",理論言語学において，統語構造を決定するテストの一つに弱交差現象がある．英語の二重目的語構文，与格構文内の二つの目的語のなす階層構造には異なる分析が存在するが，弱交差現象が観測できれば，それらの間の優劣を決めることができる．しかしながら，上述の二つの構文についての弱交差現象の判断には一般的に揺れがあり，これまで決定的な結論は得られていなかった．本研究では，言語機能科学の手法を採用して，上述の異なる分析について，判断に関わる様々な要因をコントロールした厳密な実験を行った．検証の結果は，生成文法におけるLarson の古典的な分析や，近年の継続文法を支持し，組み合わせ範疇文法と依存型意味論によるBekki の分析を反証するものである．
B2:計算・形式言語学(2)3月11日（火） 10:20-11:50   B会場(1F会議室102),B2-3,日本語推論システムlightblueの開発環境構築に向けて,/proceedings/annual_meeting/2025/pdf_dir/B2-3.pdf,"○佐伯 小遥, 富田 朝, 戸次 大介 (お茶大)",本論文では，Haskell のWeb アプリケーションフレームワークYesod を用いて，日本語推論システムlightblue による文の解析結果や推論結果を可視化する文法開発環境express の改良を行った．特に，型検査証明図や推論証明図を可視化し，解析結果や推論結果の構造を直感的に理解可能とした．また，ユーザが証明図を操作できる機能を実装し，解析プロセスを詳細に検討できるようにした．加えて，証明が失敗した場合には，その情報をユーザに明示することで，エラーの特定とデバッグ作業を効率化した．本論文では，express のシステム概要と実装についての詳細や，実使用に向けた今後の課題を示す．
B2:計算・形式言語学(2)3月11日（火） 10:20-11:50   B会場(1F会議室102),B2-4,日本語比較表現のための論理推論システムの構築,/proceedings/annual_meeting/2025/pdf_dir/B2-4.pdf,"○三上 燿輔, 松岡 大樹, 谷中 瞳 (東大)",比較表現を含む自然言語推論(NLI) は，比較対象となる性質が成り立つ程度を文から読み取り推論を行う必要があるため，挑戦的なタスクである．このような推論を頑健に扱える推論システムの実現に向けて，合成的意味論に基づく論理推論システムが提案されている．しかし，日本語の比較表現に注目したシステムの開発は十分に取り組まれていない．そこで本研究は，形式意味論に基づいた日本語比較表現のための論理推論システムを提案する．提案システムの評価には比較表現を含む日本語NLI データセットを用いる．既存のLLM との正答率の比較により本提案の有効性を示す．
B2:計算・形式言語学(2)3月11日（火） 10:20-11:50   B会場(1F会議室102),B2-5,自然言語推論システムNeural DTSの学習アルゴリズムの実装,/proceedings/annual_meeting/2025/pdf_dir/B2-5.pdf,"○飯沼 瑞稀, 戸次 大介 (お茶大)","本研究では，依存型意味論(Dependent Type Seman-tics, DTS) を基盤とした自然言語推論システムNeuralDTS の学習アルゴリズムを実装し，その挙動を検証した．DTS は文の意味を型理論に基づいて厳密に表現する一方，曖昧な述語を表現したり，言語表現同士の類似度を計算したりすることはできない．この課題に対処するため，Bekki らにより提案されたNeural DTS の枠組みを基に，その学習アルゴリズムを実装した．また，自然言語文データセットで分類器の学習を行い，DTS の述語と名前を埋め込むことによって構築したニューラル判定器の性能を検証した．"
B2:計算・形式言語学(2)3月11日（火） 10:20-11:50   B会場(1F会議室102),B2-6,情報構造の類型論に向けた談話データのコーディング,/proceedings/annual_meeting/2025/pdf_dir/B2-6.pdf,"○児倉 徳和 (東京外大), 中川 奈津子 (九大), 佐藤 久美子 (国語研), 吉村 大樹 (東京外大)",本発表では、情報構造に関する類型論的研究に向けた談話データのコーディング作業の概要と、その作業の課程で認識された理論的な問題点を報告することを通し、情報構造の研究のための談話資料のあるべきコーディングについての議論を行う。
C2:評判・感情分析，スタイル分析3月11日（火） 10:20-11:50   C会場(1F会議室103),C2-1,ドメイン特化疑似データを用いたXの感情分析による日経平均株価騰落予測の精度比較,/proceedings/annual_meeting/2025/pdf_dir/C2-1.pdf,"○今本 竜樹, 櫻井 義尚 (明大)",近年，株価予測の分野では，SNS 文書の感情分析を通じて市場の感情を推定し，予測精度を向上させる研究が注目されている．しかし，SNS 特有の主観的な感情表現と金融特有の専門用語が混在する金融SNS ドメインに適応したアノテーション済みデータの不足が課題となっている．本稿では，汎用，SNS，金融，金融SNS といった4 つのドメインにおける感情分析の精度比較とターゲットドメイン特化型学習の評価を行った．また，疑似データ生成を活用し，ポジネガ分析を用いた株価予測実験において，予測精度の向上を実現した．本稿は，金融市場において有効性を示し，他の複雑なドメインにおいても適応可能性を持つものである．
C2:評判・感情分析，スタイル分析3月11日（火） 10:20-11:50   C会場(1F会議室103),C2-2,否定語の影響と単語の重要度を考慮した近似VADスコアによる感情認識チャットシステムの開発,/proceedings/annual_meeting/2025/pdf_dir/C2-2.pdf,"○徐 恃源, 尾関 智子 (東海大)",自然言語処理分野において，データラベリングに高いコストが伴う問題を解決するために，データ拡張および自己教師あり学習手法が大きく発展してきた．感情認識・分類タスクにおいてもPark らは，Valence-Arousal-Dominance（VAD）フレームワークを利用することにより，感情のカテゴリラベル付きコーパスを相互に比較・統合し，データセットの拡充ができる可能性があることが示している[1]．本研究では，限られたデータセットを効果的に活用し，感情認識対応チャットシステムを訓練するための新しいアプローチを提案する．具体的には，否定語に影響を受ける動詞と形容詞のV スコアを反転し，LLM のアテンションロジットを加重値として用いることで，感情ラベルが付いていないデータに対して近似VAD スコアを求める．単に文章中の単語のVAD を平均する従来手法と比べ，精度が向上することを示す．
C2:評判・感情分析，スタイル分析3月11日（火） 10:20-11:50   C会場(1F会議室103),C2-3,BERTに基づいたRussell円環モデルの感情分析,/proceedings/annual_meeting/2025/pdf_dir/C2-3.pdf,"○古 泳欣, 小林 一郎 (お茶大)",Russell 円環モデルは，感情を「感情価（Valence）」と「覚醒度（Arousal）」の二軸で表現し，感情分布が円環状に配置されるを視覚化し，感情の認知構造を直感的に説明する枠組みとして広く利用される．本研究では，BERT モデルを用い，Russell 円環モデルに基づく感情分布を検証するために，次の2 つの手法を提案する．一つ目はBERT のCLS トークンを特徴量として用いる方法（方法1），二つ目はBERTのAttention ウェイトを利用して文全体の感情値を算出する方法（方法2）である．これらの手法を用いて複数の実感情データセットを用いて実際の感情分布を分析し，この理論モデルの妥当性を検証するとともに，感情分布の実態に即した新たな知見を提供することを目的とする．
C2:評判・感情分析，スタイル分析3月11日（火） 10:20-11:50   C会場(1F会議室103),C2-4,ビジネス文書を対象とした大規模言語モデルを用いた読み手にストレスを与える文章の検出,/proceedings/annual_meeting/2025/pdf_dir/C2-4.pdf,"○松永 剛之進 (東京工科大), 野島 瞳, 森下 洋平 (UCDA), 青木 輝勝 (東京工科大)","本研究は, 大規模言語モデルを用いて, ビジネス文書中の読み手にストレスを与える文章を検出する手法を提案する. BERT(Bidirectional Encoder Representations from Transformers)[1]を用いた多クラス分類モデルにより, 過剰な丁寧さ, 命令的な表現, 情報の過不足, 責任回避的な表現を検出し, 文章改善の指針を提供する.  独自のデータセットを作成し, 分類タスクに適した学習を行うことで, 従来手法では検出が困難だった微妙な文体の違いを捉えることを目指す. 実験により, 定義したラベルは文章の内容に関わらず, ストレスの要因となる表現を検出可能であることを示す."
C2:評判・感情分析，スタイル分析3月11日（火） 10:20-11:50   C会場(1F会議室103),C2-5,自動プロンプト最適化は個人的選好の予測精度を向上させるか?,/proceedings/annual_meeting/2025/pdf_dir/C2-5.pdf,"○劉 弘毅, 谷中 瞳 (東大)",LLM による自動プロンプト最適化は活発に研究されている分野であり，主に人の主観によらず一意に正解が定まるタスクに対する有効性が報告されてきた．しかし，主観的評価によって定められたラベルの予測タスクに対するこれらの手法の効果は検証されていない．本研究では，テキストへの個人的選好の予測タスクに既存の複数の自動プロンプト最適化手法を適用し，精度向上の程度を検証する．検証の結果，(1) 個人的選好の予測タスクについては既存手法による精度の向上が見られないこと，(2) プロンプト書き換えの反復が精度向上に与える効果が小さいこと，(3) LLM が生成した誤りの情報が最適化の過程でうまく参照されていないことを確認した．
D2:テーマセッション2: 人とAIの共生に向けた対話システム・言語使用の研究(1)3月11日（火） 10:20-11:50   D会場(1F会議室107),D2-1,グライスの環境とグライスの外,/proceedings/annual_meeting/2025/pdf_dir/D2-1.pdf,○高橋 速巳 (カシェウェブレト),グライス（1913 - 1988）がウィリアム・ジェームス記念講義を行った1967 年に公にされた「序論」には、かつての「戒め」は「意味と使用は同じものと心得よ」であり今は「意味と使用を混同しないよう注意すべし」という「戒め」へと変わり「手軽な哲学の常套旬」になりかけていると書かれてある.意味使用説へのグライスの姿勢を概観する前の準備として、グライスの環境と幾つかの用語の把握を試みる. 特に「効果（eﬀect）」という語に関心を払った. 「効果」という語は、グライスの特色であるとともに、グライスの外に出ることも誘引する用語であると思われる.なお著名な「会話の格率」は本稿が関心を持つ「無時間的意味を発話者の意図から説明する」箇所に直接には現れないため割愛した.
D2:テーマセッション2: 人とAIの共生に向けた対話システム・言語使用の研究(1)3月11日（火） 10:20-11:50   D会場(1F会議室107),D2-2,GPT2モデルを用いた感情を考慮する日本語対話生成,/proceedings/annual_meeting/2025/pdf_dir/D2-2.pdf,"○竹原 和輝, 全 昌勤 (神戸大)",対話生成AI の感情表現力や感情理解力を向上させることで、AI がより人間らしいコミュニケーションが可能になり、ユーザーの体験が改善されることがわかっている。本研究では単語ごとの感情情報を登録した単語感情辞書を作成し、日本語学習済みGPT2 モデルにおいて感情情報を付与する層を追加することで感情表現力や感情理解力の向上を目指した。 感情付与を行わなかったモデルと感情付与を行ったモデルを、ChatGPT を利用して比較し、感情付与によって感情表現能力が向上することを示した。
D2:テーマセッション2: 人とAIの共生に向けた対話システム・言語使用の研究(1)3月11日（火） 10:20-11:50   D会場(1F会議室107),D2-3,日本語日常二人会話における参与者の頷きと共起する発話,/proceedings/annual_meeting/2025/pdf_dir/D2-3.pdf,"○臼田 泰如, 中西 菜束萌 (静岡理工科大)",本研究は，日本語日常会話において参与者が行う頭部動作（頷き）について，発話との共起位置，共起する行為，連続回数などの観点から分析する．頷きは主要な非言語動作として注目されてきたが，発話との共起関係について体系的な検討は十分になされてきていない．本研究では，『日本語日常会話コーパス(CEJC)』を利用し，いくつかのデータに頷きのアノテーションを施し，CEJC において提供されているアノテーション情報を利用した分析を行った．本研究の結果として，頷きは発話との共起タイミングによって付随する発話のタイプが異なることがわかり，それゆえ発話連鎖上の位置によって異なる機能を持つことが示唆された．
D2:テーマセッション2: 人とAIの共生に向けた対話システム・言語使用の研究(1)3月11日（火） 10:20-11:50   D会場(1F会議室107),D2-4,大規模言語モデルを用いた実世界タスク指向対話におけるICL・ファインチューニングの効果の検証,/proceedings/annual_meeting/2025/pdf_dir/D2-4.pdf,○佐々木 裕 (豊田工大),本稿は大規模言語モデル(Large Language Model; LLM)を用いて，時々刻々変化する実世界を考慮したタスク指向対話を実現する手法について述べる． 近年，LLM は人間に近い品質の対話生成ができるまでに発展してきているが，対話モデルは汎用利用を想定して構築されており，個別のユーザの状況に応じた対話ができるわけではない．たとえば，自動走行車との対話を想定したとき，車の位置が時々刻々と変化するにつれ，最寄りのコンビニやガソリンスタンド，道路の混雑状況が変化するため，個別の状況に整合した対話を生成する必要がある．Bing Chat など検索エンジンを組み込んだLLM も存在するが，個別のユーザが存在している実世界とLLM がリアルタイムにリンクされているわけではない． そこで本研究では，実世界知識をプロンプトに組み込むことにより実世界対話を実現する手法を提案する．また，KVRET 対話データセットを用いて，GPT-
D2:テーマセッション2: 人とAIの共生に向けた対話システム・言語使用の研究(1)3月11日（火） 10:20-11:50   D会場(1F会議室107),D2-5,ChatGPTが考える日本語ジョークの面白さ：人間との比較,/proceedings/annual_meeting/2025/pdf_dir/D2-5.pdf,"○中川 隼三郎, 野元 裕樹 (東京外大)",本稿ではChatGPT (GPT-4o)と人間が日本語のジョークをどのように評価するかを比較する．人間が考えたジョークとChatGPT が生成したジョーク各9 個（1 つを除き全て対話形式）について，「面白さ」「不快さ」「わかりやすさ」の3 つの観点での評価を調べた．その結果，ChatGPT の評価は人間より「面白さ」「わかりやすさ」において甘く，「不快さ」において厳しめであること，英語ジョークに関する類似研究とは逆に，ChatGPT の生成した日本語ジョークの評価は人間によるものより低くなることが分かった．その背景には人間にはないレベルの客観性，構成的意味計算能力の不十分さがあると主張する．
E2:テーマセッション6: 人文学と言語処理(2)3月11日（火） 10:20-11:50   E会場(1F会議室108),E2-1,イノベーティブな言語使用は集団的アイデンティティの指標になりうるか？,/proceedings/annual_meeting/2025/pdf_dir/E2-1.pdf,"○伊藤 和浩 (NAIST), 矢田 竣太郎 (NAIST/筑波大), 若宮 翔子, 荒牧 英治 (NAIST)",所属集団との結びつきについての感覚を表す集団的アイデンティティは，人々の認知や行動に影響を与えることが知られている．近年，オンラインコミュニティの集団的アイデンティティを推定する重要性が高まっている．既存の辞書を使った指標では，辞書メンテナンスのコストや，低頻度語が考慮できないなどの課題がある．そのため本稿では，語のイノベーティブな使用（Linguistic Innovation）の頻度が，集団的アイデンティティの指標になるという仮説を検証する．データはYouTube 上の動画へのコメントを用いた．結果は，対象とした4 カテゴリのうち3 つのみで仮説を支持し，指標としての機能にはコミュニティの性質による条件が示唆された．
E2:テーマセッション6: 人文学と言語処理(2)3月11日（火） 10:20-11:50   E会場(1F会議室108),E2-2,文献レビューにおける構造トピックモデルの活用―　心理学概念セルフ・コンパッションを題材として―,/proceedings/annual_meeting/2025/pdf_dir/E2-2.pdf,"○岡野 裕仁, 村上 遥, 有海 春輝, 野村 理朗 (京大)",数千件を超えるような、大規模な先行文献すべてを対象にレビューすることは困難を伴う。このようなとき、タイトルや抄録に対するトピックモデルの適用が有効である。今日では、従来の古典的なトピックモデルである潜在ディリクレ配分法 (LDA) 等ではなく、論文情報に紐づいたメタ情報をモデリング過程で有効活用できる構造トピックモデル (STM) の有用性が示唆されつつあるが、心理学を含む人文学における文献レビューではSTM はほとんど用いられていない。こうした研究動向を踏まえ、本研究では、「自分への思いやり」をさすセルフ・コンパッションという心理学的概念を題材とし、STM を用いたレビューを行った。結果、解釈可能な38 のトピックが、トピック割合の時間的推移と共に抽出され、先行研究における主要なテーマを得ることができた。
E2:テーマセッション6: 人文学と言語処理(2)3月11日（火） 10:20-11:50   E会場(1F会議室108),E2-3,社会学理論と言語処理技術の接続：ブルデュー理論に基づく言語処理「界」の分析を事例に,/proceedings/annual_meeting/2025/pdf_dir/E2-3.pdf,"○高橋 祐貴 (フリー), 塚越 柚季 (東大)",本研究は，人文学の系譜に位置付く社会学理論の実証の文脈において，いかに自然言語処理が応用可能かを示すべく，言語処理の研究者集団を対象にブルデュー流の「界」の分析を行い，その分化の構造を明らかにする．ACL Anthology とresearchmap を用いて構築した有力な言語処理研究者578 名のデータセットを用いて，多重対応分析により「界」の空間を構築したところ，資本総量の差は見られたものの，解釈可能な資本構成の交差配列構造は認められなかった．BERTopic により析出した研究分野との関連もそれほど明確とは言えず，理工系の分野においてはブルデュー理論が有効とは言えないことが示唆された．
E2:テーマセッション6: 人文学と言語処理(2)3月11日（火） 10:20-11:50   E会場(1F会議室108),E2-4,大規模言語モデルを用いたサンスクリット辞書の横断的意味探索と意味提示,/proceedings/annual_meeting/2025/pdf_dir/E2-4.pdf,"○塚越 柚季, 大向 一輝 (東大)",本研究は，サンスクリット辞書の意味記述を横断的に探索する新たなアプローチを提示する．Cologne Digital Sanskrit Dictionaries が公開する21 種類のサンスクリット辞書を用い，大規模言語モデルに追加学習を行うことで，個々の辞書の限界を超えた柔軟な意味解釈を可能にするモデルを構築した．提案モデルは，既存辞書の記述を統合しつつ，辞書に記載されていない単語についても意味記述を生成する能力を示した．また，妥当性がありながら，いずれの辞書でもなされていない意味記述を生成することも可能であることを示した．
E2:テーマセッション6: 人文学と言語処理(2)3月11日（火） 10:20-11:50   E会場(1F会議室108),E2-5,語形のベクトル化による最適な言語地図の描画,/proceedings/annual_meeting/2025/pdf_dir/E2-5.pdf,"○近藤 泰弘 (青学大), 持橋 大地 (統数研/国語研)",本論文では，国立国語研究所でかつて刊行された『方言文法全国地図』[1] の原データを用いて，新しい構想で言語地図を作成した．もとの地図における語形の標識はすべて人手で作成されていたが，本研究では方言の各語形をベクトル化し，そのベクトルのクラスタによって地図のアイコンの色を割り当てた．この際に色の割り当て方についても，カーネル整列法[2] を用いて，色の類似度と語形ベクトルの類似度が最大になるような配色を行った．さらに元の地図の人手による語形分類データと，自動化された語形分類との一致度を調査することで，提案方法の妥当性を検証した．こうした統計的な手法により，非常に困難だとされてきた方言文法の言語地図を非常に見やすく，研究に使いやすい形にすることができた．
P2:ポスター3月11日（火） 10:20-11:50   P会場(2Fコンベンションホール3+4),P2-1,プロンプトの言語による数値時系列解釈能力の変化,/proceedings/annual_meeting/2025/pdf_dir/P2-1.pdf,"○新井 深月 (お茶大/産総研), 石垣 達也 (産総研), 宮尾 祐介 (東大/産総研), 高村 大也 (産総研), 小林 一郎 (お茶大/産総研)",本研究では，大規模言語モデル（LLM）の数値時系列解釈能力を測る16 の評価タスクにおいて，プロンプトの記述言語の影響を検証する．数値時系列は，マルチモーダル言語生成や時系列予測などの多くの問題で重要な入力情報となっている．従来，LLM の数値理解能力を評価するタスクは，非系列データの算術演算や数値を含む表の論理推論が中心であったが，数値時系列に特化した評価タスクの開発が進んでいる．そこで本研究では，1) イベント検出，2) 計算，3) 比較の3 つのカテゴリの評価タスクに対し，プロンプトの言語（日本語と英語）の違いによる性能差について考察する．実験より，タスクによってプロンプトの言語選択が数値解釈能力に影響を与えることが明らかとなった．
P2:ポスター3月11日（火） 10:20-11:50   P会場(2Fコンベンションホール3+4),P2-2,Representational Analysis of Binding in Language Models,/proceedings/annual_meeting/2025/pdf_dir/P2-2.pdf,"○◊代 勤 (東北大), Benjamin Heinzerling (理研/東北大), 乾 健太郎 (MBZUAI/東北大/理研)","Entity tracking is essential for complex reasoning. To per-form in-context entity tracking, language models (LMs)must bind an entity to its attribute (e.g., bind a container toits content) to recall attribute for a given entity. For exam-ple, given a context mentioning “The coﬀee is in Box Z,the stone is in Box M, the map is in Box H”, to infer “BoxZ contains the coﬀee” from the context, LMs must bind“Box Z” to “coﬀee”. To explain the binding behaviour ofLMs, Feng and Steinhardt (2023) introduce a Binding IDmechanism and state that LMs use a abstract concept calledBinding ID (BI) to internally mark entity-attribute pairs.However, they have not captured Ordering ID (OI), namelyordering index of entity, from entity activations that directlydetermines the binding behaviour. In this work, we pro-vide a novel view of the BI mechanism by localizing OI andproving the causality between OI and binding behaviour.Speciﬁcally, we discover the OI subspace and reveal causaleﬀect of OI on binding that when editing activations alongthe OI encoding direction, LMs tend to bind a given entityto other attributes (e.g., “stone” for “Box Z”) accordingly.The code and datasets used in this paper are available athttps://github.com/cl-tohoku/OI-Subspace."
P2:ポスター3月11日（火） 10:20-11:50   P会場(2Fコンベンションホール3+4),P2-3,解釈可能性の高い自動採点モデルを用いた小論文採点支援システムの構築,/proceedings/annual_meeting/2025/pdf_dir/P2-3.pdf,"○水野 友暉, 竹内 孔一 (岡山大)",本研究では，日本語の小論文採点を支援するシステムの開発を目的とし，モデルの解釈可能性向上を図るための手法を提案する．提案手法には，Attention，Masking Token，およびSparse Autoencoderの3 つを提案する．特にSparse Autoencoder を用いて特徴量ごとに概念を特定し，モデルの内部構造の解釈を可能にすることで，採点結果の透明性と信頼性を向上させることを目指す．実験結果より，Sparse Autoencoder は概念抽出の精度が高く，解釈可能性の向上に寄与することが確認された．一方で，各特徴量と得点の関連性を明確にする課題が残されており，今後の研究ではこれを解決することで，小論文採点支援システムのさらなる改良を図る．
P2:ポスター3月11日（火） 10:20-11:50   P会場(2Fコンベンションホール3+4),P2-4,ウェーブレット位置符号化,/proceedings/annual_meeting/2025/pdf_dir/P2-4.pdf,"○岡 佑依, 長谷川 拓, 西田 京介, 齋藤 邦子 (NTT)",本研究では，回転行列による位置符号化RoPE がウェーブレット変換（WT）の一種として解釈できることを示す．しかし，RoPE はWT の利点を十分に活用できていない．そこで本研究では，正弦波のみに集中していた位置符号化の理論的基盤を拡張し，WT の特性を活かした理論的基盤と新しい位置符号化手法を提案する．提案手法は，従来の手法では難しかった最大系列長を超えた符号化を可能にすることを示す．
P2:ポスター3月11日（火） 10:20-11:50   P会場(2Fコンベンションホール3+4),P2-5,Beyond the Induction Circuit: A Mechanistic Prototype for Out-of-domain In-context Learning,/proceedings/annual_meeting/2025/pdf_dir/P2-5.pdf,"○趙 羽風 (JAIST), 井之上 直也 (JAIST/理研)","In-context Learning (ICL) is a promising few-shot learn-ing paradigm with unclear mechanisms. Existing explana-tions heavily rely on Induction Heads, which fail to accountfor out-of-domain ICL, where query labels are absent indemonstrations. To address this, we model ICL as attributeresolution, where queries are mixtures of some attributes,and ICL identiﬁes and resolves relevant attributes for pre-dictions. In this paper, we propose a mechanistic prototypeusing toy models trained on synthetic data, and observe:(1) even 1-layer Transformers achieve non-trivial accuracy,with limited beneﬁt from additional demonstrations, (2)scaling models eﬀectively improve accuracy, and (3) in-ference operations can be decomposed into label spaceidentiﬁcation and generalized induction, warranting fur-ther exploration."
P2:ポスター3月11日（火） 10:20-11:50   P会場(2Fコンベンションホール3+4),P2-6,LLMにおける内部表現を用いた日本語スタイル制御メカニズムの分析,/proceedings/annual_meeting/2025/pdf_dir/P2-6.pdf,"○高橋 良允, 矢野 一樹 (東北大), 成瀬 健太, 武井 美緒, 梶 佑輔 (楽天), 鈴木 潤 (東北大)",大規模言語モデル（LLM）は質問応答や要約文生成などで高い性能を示し，企業での実用化が進んでいる．これに伴い，生成文の文体や口調の制御という新たな需要が高まっているが，従来のプロンプトによる工夫では制御に限界があり，モデルの再学習は計算コストが高いという課題が存在する．本研究では，モデル内部の表現を直接操作するアプローチに着目し，特に日本語の特徴的な口調を対象として，スタイルベクトルの抽出とその制御可能性を検証する．さらに，スタイル間の制御性能の違いを内部表現の観点から分析し，スタイルベクトルの理解を深めることで，LLM のスタイル制御技術の発展に貢献する．
P2:ポスター3月11日（火） 10:20-11:50   P会場(2Fコンベンションホール3+4),P2-7,大規模言語モデル内部における言語と計算領域の区分,/proceedings/annual_meeting/2025/pdf_dir/P2-7.pdf,"○木迫 璃玖 (名大), 栗林 樹生 (MBZUAI), 笹野 遼平 (名大)",本研究では，大規模言語モデル（LLM）の内部において，言語非依存な思考の領域が一般的な言語領域よりもどれほど・どのように切り分けられているのかを調査する．特に算術計算問題をとりあげ，これらのデータの内部表現空間における分布を分析する．実験結果から，算術計算など言語一般とは異なるデータは入力層付近でただちに分離され，また計算式と算数文章題のように似た思考を要する問題同士ですら，どこかの層で同じ領域を占めることはないことが示唆された．すなわち，算術計算と言語の領域は分離されているものの，計算のための普遍的領域が存在するわけではなく，異なるタスク用に異なる数値計算領域が存在する，ある種冗長な様相であることが想定される．
P2:ポスター3月11日（火） 10:20-11:50   P会場(2Fコンベンションホール3+4),P2-8,Transformer LLMにおける層単位のFFN層の重要度検証,/proceedings/annual_meeting/2025/pdf_dir/P2-8.pdf,"○池田 航, 矢野 一樹, 高橋 良允, 李 宰成, 柴田 圭悟 (東北大), 鈴木 潤 (東北大/理研/NII)",Transformer に基づく大規模言語モデル(LLM) の構成要素の一つであるフィードフォワードネットワーク(FFN) に着目し，モデル内の配置場所に依存した重要度を検証する．具体的には，モデル全体のパラメータ数を維持したまま，一部の連続する層でFFN の中間次元を拡大し，残りの層からFFN を除去したモデル構成を用いて標準的なタスク性能を比較する．複数のモデルサイズで評価を行った結果，全層数の70 – 90%の連続した中間から後方の層にFFNを集中配置することで，複数の下流タスクでベースラインの性能を上回った．この結果からFNN は入力に近い層より中間から後方の層で特に重要であると示唆される結果が得られた．
P2:ポスター3月11日（火） 10:20-11:50   P会場(2Fコンベンションホール3+4),P2-9,言語モデルのパラメータから探るDetokenizationメカニズム,/proceedings/annual_meeting/2025/pdf_dir/P2-9.pdf,"○◊鴨田 豪 (東北大), Benjamin Heinzerling (理研/東北大), 稲葉 達郎 (京大), 工藤 慧音, 坂口 慶祐 (東北大/理研), 乾 健太郎 (MBZUAI/東北大/理研)",トークナイザは単語を複数のサブワードに分割することがあるが，その分割が言語的に意味のあるものになるとは限らない．推論の段階仮説（Stages ofinference hypothesis）では，言語モデルの序盤層はこうしたサブワードトークン列をより意味のある表現に変換(Detokenize) するとされている．本研究では，従来のプロービングや因果介入などの経験的手法に依存せず，Detokenization をモデルの重みに基づく解析によって観測できることを示す．具体的には，GPT-2 の第1 層の注意機構を解析的に分解し，トークンタイプに由来する寄与とトークンの位置に由来する項の寄与とを切り分けた分析を行い，近いトークンや頻出Bigram への注意の偏りを明らかにする1）．
P2:ポスター3月11日（火） 10:20-11:50   P会場(2Fコンベンションホール3+4),P2-10,埋め込み表現の内在次元を測る,/proceedings/annual_meeting/2025/pdf_dir/P2-10.pdf,"○片岩 拓也 (静大), 趙 羽風 (JAIST), 大木 哲史 (静大/理研)",本研究では，言語の埋め込み表現である単語ベクトルや埋め込み層について，表現に必要十分な次元である内在次元(Intrinsic Dimension; ID) を計測し，その冗長度合いを定量評価する．具体的には，(1)Word2Vec やGloVe などの小規模モデルの埋め込みが持つID を推定し，(2) Pythia 系列を代表とする大規模言語モデルの埋め込み層におけるID をスケール別・学習過程別に解析する．実験の結果，埋め込み空間が外在的な次元に比べ低い次元の多様体上に分布する傾向が見られた．また，モデル規模の拡大に伴う冗長率の変化や，学習初期における急激なIDの形成が見られた．
P2:ポスター3月11日（火） 10:20-11:50   P会場(2Fコンベンションホール3+4),P2-11,誤字に対するTransformerベースLLMのニューロンおよびヘッドの役割調査,/proceedings/annual_meeting/2025/pdf_dir/P2-11.pdf,"○辻 航平 (NAIST), 平岡 達也 (MBZUAI), 鄭 育昌 (NAIST/富士通), 荒牧 英治 (NAIST), 岩倉 友哉 (NAIST/富士通)",本論文では，FFN 層のニューロンや，アテンション層のアテンションヘッドが誤字を認識・修復しているという仮説を立て，誤字を含む文が入力されたときに活発に働く，誤字ニューロンおよび誤字ヘッドを特定する．我々の実験結果から以下のことが判明した．1) 初期層と中間層前半に誤字の認識と修復を行うニューロンが存在し，中間層前半にあるニューロンが誤字の修復の中核である．2) 広く文脈情報を捉えるヘッドが誤字の修復に貢献している．
P2:ポスター3月11日（火） 10:20-11:50   P会場(2Fコンベンションホール3+4),P2-12,部分空間の擬似直交性によるTransformer言語モデルの内部表現の解釈,/proceedings/annual_meeting/2025/pdf_dir/P2-12.pdf,"○前田 晃弘 (JAIST/日本学術振興会), 鳥居 拓馬 (東京電機大), 日髙 昇平, 井之上 直也 (JAIST), 大関 洋平 (東大)",本研究は，Transformer 言語モデルにおける内部表現を解釈するために，擬似直交性の概念を新たに導入してそのアテンション層およびFFN 出力層の部分空間の幾何的関係を分析する．FFN 層のウェイト行列の行空間が語彙空間と擬似直交していることを示した上で，FFN 層からの出力が意味的概念を担うコンセプトベクトルとして機能し，内部表現の文脈化に寄与している可能性を明らかにする．
P2:ポスター3月11日（火） 10:20-11:50   P会場(2Fコンベンションホール3+4),P2-13,「数」に着目したLLMの多言語能力の検証,/proceedings/annual_meeting/2025/pdf_dir/P2-13.pdf,"○羽根田 賢和 (フューチャー/東北大), 岸波 洋介, 藤井 諒, 森下 睦 (フューチャー)",近年の自然言語処理技術の発展に伴い，大規模言語モデル(LLM) は様々な言語を扱うことが可能となっている．一方でこれらのモデルを用いた推論・生成では，英語で指示を与える際に，他の言語で指示を与える場合よりも性能が高くなる現象が確認されている．本研究では，誤差の大小の解釈が容易な「数」に着目したタスク設定を行い，指示言語によって生じるLLM の性能差のより精緻な検証を試みた．結果として指示言語の特徴により生成結果の誤差の生じ方に差が生じ，言語的特徴が性能に影響を及ぼしていることの示唆を得た．
P2:ポスター3月11日（火） 10:20-11:50   P会場(2Fコンベンションホール3+4),P2-14,言語モデルが有する時間的推論に関する事実知識の分析,/proceedings/annual_meeting/2025/pdf_dir/P2-14.pdf,"○中屋 和樹, 松田 源立 (成蹊大)","ニューラル言語モデルは, 大量のテキストを用いた事前学習と指示チューニングによって, 多様な知識と推論能力を獲得しているとされる. 本研究では,言語モデルが有する時間に関する事実知識, 特に過去の出来事の日付に関する知識について調査する.具体的には, 過去の出来事が発生した年月日を回答するタスクのデータセットを構築し, 言語モデルが出力する日付と実際の正解との間の誤差を分析する. 実験の結果, 言語モデルは年号に関する知識については, 月日と比較してより正確に保持していることがわかった. また, 年号を正確に認識できていない言語モデルは, 実際の年よりも後の年代として推論しやすい傾向があることが示唆された."
P2:ポスター3月11日（火） 10:20-11:50   P会場(2Fコンベンションホール3+4),P2-15,独立成分分析による事前学習済み多言語モデルの層を横断した単語埋め込み表現の分析,/proceedings/annual_meeting/2025/pdf_dir/P2-15.pdf,"○北野 雄士, 西田 悠人, 坂上 温紀, 上垣外 英剛, 渡辺 太郎 (NAIST)",多言語モデルの有用性は埋め込みによって支えられている。しかし、多言語で事前学習された言語モデルの埋め込みに内在すると考えられる単語の意味表現の分析は行われていない。本研究では、多言語翻訳モデルを対象に独立成分分析を用いて埋め込みを分析・可視化することによって、モデルの言語理解や層を横断した言語処理の流れについて調査した。分析の結果、入力に近い層では表層形によって軸が分離し、出力に近い層では意味によって分離する傾向がみられ、層を経るごとに文脈や意味情報を獲得することが示唆された。
P2:ポスター3月11日（火） 10:20-11:50   P会場(2Fコンベンションホール3+4),P2-16,事前学習言語モデルのドメイン適応能力に関する分析：ドメイン特有ニューロンの検出と分析,/proceedings/annual_meeting/2025/pdf_dir/P2-16.pdf,"○鈴木 雅弘 (東大/日興アセット), 高柳 剛弘 (東大), 坂地 泰紀 (北大), 和泉 潔 (東大)",本研究では，事前学習言語モデル（PLM）における専門ドメインに特化したニューロンの内部挙動を分析する．具体的には，金融ドメインと一般ドメインのテキストに対する，日本語のEncoder またはDecoder のアーキテクチャをもつ複数のPLM のニューロンの挙動を比較し，ドメイン特有のニューロンを検出した．分析の結果，Encoder とDecoderの両アーキテクチャに共通して，ドメイン特有のニューロンは初期層に多く存在することがわかった．次に，Decoder モデルのMLP にはドメイン特有の性質が複数の層に分散して存在することが示唆された．また，金融ドメインで追加事前学習したモデルでは，中間層でドメイン特有の表現を獲得していることがわかった．
P2:ポスター3月11日（火） 10:20-11:50   P会場(2Fコンベンションホール3+4),P2-17,文脈の記憶と想起を行う状態空間モデルによる状態遷移の分析,/proceedings/annual_meeting/2025/pdf_dir/P2-17.pdf,"○山本 悠士, 松崎 拓也 (東京理科大)",Attention は，文章生成時のメモリ消費量が入力トークン数に比例して増加するため，長文の処理や高速な文章生成を困難にする．この課題を解決するため，推論時のメモリサイズが入力長によらず一定である状態空間モデル(SSM) に基づいた言語モデルが提案されている．本研究は，SSM に基づく言語モデルがどのようにして入力文中の情報を記憶しているのかを分析する．分析では，記憶と想起を必要とする質問応答タスクにおいて，正答に必要不可欠なSSM をもつ層を特定して，そのSSM が本文中のどの文脈を参照しているかを観察する．記憶と想起のメカニズムの実現のためにSSM のパラメータが満たすべき条件を示すことは今後の課題とする．
P2:ポスター3月11日（火） 10:20-11:50   P会場(2Fコンベンションホール3+4),P2-18,ロススパイクの影響分析,/proceedings/annual_meeting/2025/pdf_dir/P2-18.pdf,"○杉浦 一瑳 (京大/NII), 栗田 修平, 小田 悠介 (NII)","ニューラルネットワークの学習中に突然損失が発散する現象はロススパイクと呼ばれ，学習が破綻する原因として知られている. モデルの学習には大きなコストがかかるため, ロススパイクの発生を予防する方法が数多く提案されてきた一方で, スパイクがモデルに与える影響については十分に理解されていない. 本稿では, ロススパイクのモデルへの影響について, 2 つのモデル間の損失地形における結びつきを表す線形峰接続性の観点から分析する. 小規模な言語モデルをロススパイクが発生する設定を含む複数の学習設定で事前学習し, 学習中のチェックポイントを用いてスパイクの影響を分析した. その結果, パラメータがスパイクの前後で大きく異なる位置に変化すること, 及び線形峰接続性のパターンが変化することがわかった."
P2:ポスター3月11日（火） 10:20-11:50   P会場(2Fコンベンションホール3+4),P2-19,多言語モデルには言語非依存の処理系統が存在するか,/proceedings/annual_meeting/2025/pdf_dir/P2-19.pdf,"○手塚 陽大 (JAIST), 井之上 直也 (JAIST/理研)",多言語モデルのプロービングによって言語モデルの多言語性を分析する動きは活発化してきているが，個別言語に依存しない，言語間で共通の処理系統が多言語モデル内に存在するのかについては十分に明らかになっていない．そこで本研究では，第二言語を獲得した言語モデルに焦点を絞り，これらの言語モデルが，第一言語(L1)，第二言語(L2) 間で対応する文の意味に関して言語非依存の共通の処理を行っているのかについて，内部表現や発火するニューロンの観点から調査する. 実験の結果，言語モデルは，対応する文の意味について個別言語に依存しない共通の処理をしていることが示唆された．
P2:ポスター3月11日（火） 10:20-11:50   P会場(2Fコンベンションホール3+4),P2-20,言語モデルの内部表現における文法情報の局所性について,/proceedings/annual_meeting/2025/pdf_dir/P2-20.pdf,"○佐藤 宏亮, 鴨田 豪 (東北大), Benjamin Heinzerling (理研/東北大), 坂口 慶祐 (東北大/理研)",言語モデルにおいて，注目する知識をエンコードするニューロンの特定は，モデルの解釈性向上や少数のニューロンの操作による出力の制御の実現に貢献し得る．本研究では，スパースプローブを用いて，隠れ状態における文法情報の局在性を調査した．結果，大部分の層において，隠れ状態の特定の
P2:ポスター3月11日（火） 10:20-11:50   P会場(2Fコンベンションホール3+4),P2-21,算術タスクを用いた文脈内学習による外挿能力の分析,/proceedings/annual_meeting/2025/pdf_dir/P2-21.pdf,"○進藤 稜真, 竹下 昌志, ジェプカ ラファウ, 伊藤 敏彦 (北大)","大規模言語モデルは文脈内学習(ICL) が可能であることが知られているが, その内部メカニズムについては未だ統一的な見解が存在しない. 争点の一つに, ICL によってパラメータを更新することなく未知のタスクに適応可能か, すなわち外挿可能かどうかという点がある. そこで本研究では, 二変数一次関数𝑧= 𝑎𝑥+ 𝑏𝑦に基づく算術データセットを構築し,ICL による内挿・外挿能力を定量的に評価した. その結果, ICL によって部分的に未学習のタスクでも解決可能であること, 文脈内の例を増加させることで, 内挿時と外挿時の内部表現が類似する傾向にあること, 学習データ内のタスクの多様性がICL 能力の創発に重要であることが示唆された."
P2:ポスター3月11日（火） 10:20-11:50   P会場(2Fコンベンションホール3+4),P2-22,単語埋め込みの独立成分分析の軸が解釈できる粒度はどれくらいか？,/proceedings/annual_meeting/2025/pdf_dir/P2-22.pdf,"○佐藤 祥太 (金沢大), 木山 朔 (都立大), 中島 秀太, 小町 守 (一橋大), 唐堂 由其 (金沢大)",単語の意味や関連性を低次元のベクトルなどで表現することを単語埋め込みと呼ぶ．単語埋め込みの次元（軸）は，各次元の値が上位の単語から類推されるカテゴリを人手で判断することで解釈できる．本研究では，このカテゴリが解釈できる次元の割合を単語埋め込みの軸の解釈性と定義する．単語埋め込みの軸の解釈性は，独立成分分析による変換を行うと向上することが先行研究で示されている．しかし，その研究の中では単語埋め込みの次元数と同じ次元数で独立成分分析を実施しており，独立成分の粒度を変化させた場合にどの程度の次元が解釈できるかは明らかではない．そこで，本研究では独立成分分析の次元数を変えた際に解釈できる粒度がどの程度かを調査する．実験結果より，独立成分の粒度が大きいほど解釈性が低下することを示した．
P2:ポスター3月11日（火） 10:20-11:50   P会場(2Fコンベンションホール3+4),P2-23,ニューロン経験勾配によるモデル出力の制御と言語知識表現の統合,/proceedings/annual_meeting/2025/pdf_dir/P2-23.pdf,"○趙 信, 江 澤輝, 吉永 直樹 (東大)",事前学習済み言語モデルのFeed Forward 層に含まれるニューロンは知識や言語スキルを捉えることが知られている．本研究では，ニューロンの活性値に注目し，ニューロン活性値と出力トークン確率との間に線形関係が存在することを明らかにする．次に，この線形関係の勾配（以降，経験勾配）を効率的に計算する手法NeurGrad を提案する．さらに，新たに構築したMCEval8K データセットを用いたskill neuron probing を通してNeurGrad で計算した経験勾配に基づく分類器を評価し，ニューロン経験勾配が多様な言語タスクを解ける情報量を有することを示す．
P2:ポスター3月11日（火） 10:20-11:50   P会場(2Fコンベンションホール3+4),P2-24,Wikipediaリダイレクト情報を活用したエンティティベース質問応答データセットの構築,/proceedings/annual_meeting/2025/pdf_dir/P2-24.pdf,"○西田 悠人 (NAIST/フューチャー), 志子田 直輝 (NAIST), 岸波 洋介, 藤井 諒, 森下 睦 (フューチャー), 上垣外 英剛, 渡辺 太郎 (NAIST)",大規模言語モデル(LLM) がどのような知識を記憶しているかを調べるために，しばしばエンティティに基づく質問応答データセットが利用される．しかし，そのような既存のデータセットはエンティティの単一の表層のみに依存しており，LLM がエンティティを記憶しているのか，特定の表層を記憶しているのかを弁別できない．そのため，本研究ではWikipedia のリダイレクト情報を活用し，複数の表層を考慮可能なエンティティベースの質問応答データセットRedirectQA を構築する．本データセットはエンティティの複数の表層と，それらに対応するカテゴリが付与されており，LLM がどのような表層を記憶しているかの調査に適している．
P2:ポスター3月11日（火） 10:20-11:50   P会場(2Fコンベンションホール3+4),P2-25,TrendScape 1.0: 言語モデルの潜在空間上の概念探索,/proceedings/annual_meeting/2025/pdf_dir/P2-25.pdf,"○本田 純也 (豊橋技科大), 坂本 航太郎 (東大), 高木 志郎 (独立研究者), 林 祐輔 (AIアライメントネットワーク), 小川 修平 (エモスタ), 松尾 豊 (東大)",本稿では，言語モデル内の潜在的な概念空間を探索・可視化するための手法であるTrendScape 1.0を紹介する．本手法では，自然言語を潜在空間にマッピングして近傍グラフを構築する．グラフ上の経路探索を通じて概念間の関係を調べる．手法の検証として，文学作品間の概念経路を可視化し，得られたネットワークを分析することで，言語モデルの概念理解に関する洞察を提供する．
P2:ポスター3月11日（火） 10:20-11:50   P会場(2Fコンベンションホール3+4),P2-26💻,紙とデジタルの違いが書く活動に及ぼす影響：漢字・熟語・慣用表現・四字熟語を対象に,/proceedings/annual_meeting/2025/pdf_dir/P2-26.pdf,"○西内 沙恵, 西川 竜矢 (北教大), 嶋田 善行 (旭川中), 大橋 賢一 (北教大)",
Q2:ポスター3月11日（火） 10:20-11:50   Q会場(1F会議室101AB),Q2-1,JHACE: Human-AI Collaborationの評価法の提案，及び，対人スキルの影響の調査,/proceedings/annual_meeting/2025/pdf_dir/Q2-1.pdf,"○西岡 竜生, 若宮 翔子 (NAIST), 清水 伸幸, 藤田 澄男 (LINEヤフー), 荒牧 英治 (NAIST)",今後社会に，AI が浸透するにつれ，人とAI の協働が新たなチームワークとして注目されるはずである．近年においては，大規模言語モデル(LargeLanguage Model; LLM) の発展により，人間とLLMの協働が様々な分野で検討されている．従来の研究ではLLM の性能向上や人間と効果的に協働するための方法に焦点が当てられてきたが，対人スキルなどのユーザ固有の能力がLLM との協働に与える影響は明らかにされていない．本研究は人間とAIの協働パフォーマンスを評価するJHACE (JapaneseHuman-AI Collaborative Evaluation) を提案し，実験によって対人スキルがAI との協働に与える影響を調査する．結果として，対人スキルはAI の回答への批判的対応に影響する可能性が示された．
Q2:ポスター3月11日（火） 10:20-11:50   Q会場(1F会議室101AB),Q2-2,LLMの安全性における大規模人手評価,/proceedings/annual_meeting/2025/pdf_dir/Q2-2.pdf,"○高橋 哲朗 (鹿児島大), 鈴木 久美, 関根 聡 (NII)",LLM の安全性の評価のために，先行研究における人手評価の結果を分析し，評価の課題を洗い出すことにより評価基準を整備した．この評価基準を用い
Q2:ポスター3月11日（火） 10:20-11:50   Q会場(1F会議室101AB),Q2-3,AnswerCarefully: 日本語LLM安全性向上のためのデータセット,/proceedings/annual_meeting/2025/pdf_dir/Q2-3.pdf,"○鈴木 久美 (NII), 勝又 智 (レトリバ), 児玉 貴志 (NII), 高橋 哲朗 (鹿児島大), 中山 功太, 関根 聡 (NII)",日本語LLM の出力の安全性・適切性向上のためのデータセットAnswerCarefully を紹介する。このデータセットは、回答に注意が必要な質問とその参考回答からなっており、先行の英語による類似データセットを参考に設定した広範な有害カテゴリを踏まえ、人手により作成されている。このデータを使用して日本語LLM をファインチューニングしたところ、一般の回答の有用性を損なうことなく、出力の安全性が向上することが確認できた。また、このデータをベンチマークとして12 の日本語LLM を評価した結果についても報告する。
Q2:ポスター3月11日（火） 10:20-11:50   Q会場(1F会議室101AB),Q2-4,llm-jp-judge: 日本語LLM-as-a-Judge評価ツール,/proceedings/annual_meeting/2025/pdf_dir/Q2-4.pdf,"○中山 功太, 児玉 貴志, 鈴木 久美 (NII), 宮尾 祐介 (NII/東大), 関根 聡 (NII)",近年，大規模言語モデル(LLM) による応答の自動評価をLLM により行う手法，LLM-as-a-Judge が広く使用されている．日本語でも複数のLLM-as-a-Judgeベンチマークが開発されている．本論文では，LLMの多面的な分析を容易にするためLLM-as-a-Judge 評価を統一的に扱うことができるツール“llm-jp-judge”を提案する．現時点では，独自のプロンプトを用いた生成品質評価，MT-Bench によるマルチターン対話評価，応答の安全性評価に対応している．また，提案ツールによる評価の妥当性を検証するためのメタ評価を行い，評価結果の信頼性や有用性について議論する．本ツールはオープンソース1）として公開しており，誰でも利用可能である2）．
Q2:ポスター3月11日（火） 10:20-11:50   Q会場(1F会議室101AB),Q2-5,アドオン型のLLMアライメント,/proceedings/annual_meeting/2025/pdf_dir/Q2-5.pdf,"○宮岡 佑弥, 井上 正樹 (慶應大)",本稿では，大規模言語モデル（Large LanguageModel，LLM）の生成テキストを人の倫理観や価値観に沿うものにするアライメントに取り組む．本稿のアプローチでは，アライメントの対象となるLLM内部のパラメータを更新するのではなく，テキスト生成過程におけるトークンの確率分布に介入する．トークンの確率分布への介入は外付けの“制御フィルタ” によって行われる．この手法では，アライメントが外部の機構によって行われるが故に，高い柔軟性と透明性を提供するものである．実験では，Llama 3 8b に対するアライメントを行い，提案手法の有効性を示している．
Q2:ポスター3月11日（火） 10:20-11:50   Q会場(1F会議室101AB),Q2-6,英語母語話者と生成AIの文法性判断の差異調査,/proceedings/annual_meeting/2025/pdf_dir/Q2-6.pdf,"○吉村 理一, 陳 曦, 伊藤 薫, 森部 想水 (九大)","本研究では，英語母語話者の文法性判断と生成AI のその判断の差異を調査した. 英語の主要56 構文（合計4,483 例）を用い，AI の文法性判断と母語話者のそれを比較した結果, 母語話者が文法的と判断した例では約82 ％，非文法的文と判断した例では約62 ％の一致率を確認した．特に話題化，外置，寄生空所など移動を伴う構文においてAI と母語話者の判断が乖離する傾向にあることが示された．本研究により，文法性判断に関して生成AI の苦手分野を特定できたことから，AI の文法性判断能力向上を目指した適切な学習データの構築とベンチマークの開発が今後の研究課題として浮き彫りになった．"
Q2:ポスター3月11日（火） 10:20-11:50   Q会場(1F会議室101AB),Q2-7,システム発話を起点とした雑談会話におけるパーソナリティを考慮した話題推薦の検討,/proceedings/annual_meeting/2025/pdf_dir/Q2-7.pdf,"○藤本 裕之, 島田 陽介, 大野 実 (セコム)",ユーザのパーソナリティ情報を用いて、興味に合わせた会話を提供することが求められている。本研究では、特にシステム発話を起点とした雑談会話を想定し、ユーザのパーソナリティ情報を利用してユーザの興味のありそうな話題かどうかを推定することができるかを検討した。追加学習したBERT がベースラインを上回る性能だった一方、GPT-4o はベースラインを下回った。パーソナリティ情報から興味の有無を一定の性能で判定できることを確認した。
Q2:ポスター3月11日（火） 10:20-11:50   Q会場(1F会議室101AB),Q2-8,ソーシャルメディアからの偽・誤情報データセットとLLM正確性ベンチマークの提案,/proceedings/annual_meeting/2025/pdf_dir/Q2-8.pdf,"○中里 朋楓 (東大), 大西 正輝 (産総研), 鈴木 久美 (NII), 澁谷 遊野, 高木 聡一郎 (東大)",大規模言語モデル（LLM）の発展に伴い，正確ではない情報の生成・流布が問題となっている．この課題に対応するため，日本語LLM の正確性の評価用ベンチマークが必要だが，既存のものは英語のものが多く日本特有の偽・誤情報を十分にカバーしていない．本研究では，実際のソーシャルメディアで流通している日本語の誤解を招く情報に基づいたベンチマークJSocialFact1）を用いたベンチマーク評価とその課題を議論する．このベンチマークは，X のコミュニティノートと投稿データを活用し，複数アノテータにより作成したデータセットであり，多様な種類の誤情報を網羅することを目指している．本研究では，提案するJSocialFact を用いて複数のLLMの正確性および安全性を評価する．
Q2:ポスター3月11日（火） 10:20-11:50   Q会場(1F会議室101AB),Q2-9,An in-depth human study of the mathematical reasoning abilities in Large Language Models,/proceedings/annual_meeting/2025/pdf_dir/Q2-9.pdf,"○◊Carolina Dias-Alexiou, Edison Marrese-Taylor, Yutaka Matsuo (東大)","We study the generalization capabilities of Large Lan-guage Models through the lens of mathematical reasoning,asking if these models can recognize that two structuresare the same even when they do not share the same nomen-clature. We propose a human study to evaluate if LLMsreproduce proofs that they have most likely seen duringtraining, but when the symbols do not match the ones seen.To test this in a controlled scenario, we look at proofs inpropositional calculus, foundational for other logic sys-tems, semantically complete and widely discussed online.We replace the implication operator (→) with an unrelated,arbitrary symbol (♠) and ask experts to evaluate how theoutput of a selection of LLMs changes in terms of com-pliance, correctness, extensiveness and coherence. Our re-sults show that nearly all our tested models produce lowerquality proofs in this test, in particular open-weights mod-els, suggesting the abilities of these LLMs to reason in thiscontext have important limitations."
Q2:ポスター3月11日（火） 10:20-11:50   Q会場(1F会議室101AB),Q2-10,Cultural Adaptability of Multilingual Large Language Models: A Comparative Study in Japanese Workplace Contexts,/proceedings/annual_meeting/2025/pdf_dir/Q2-10.pdf,"○◊Zhiwei Gao (NAIST), 清水 伸幸, 藤田 澄男 (LY), Shaowen Peng, 若宮 翔子, 荒牧 英治 (NAIST)","Given the growing use of Large Language Models(LLMs) in diverse cultural contexts, this study examinestheir adaptability to Japanese workplace norms using Hof-stede’s Cultural Dimensions Framework. Five multilingualLLMs from Japanese, English, and Chinese backgroundswere tested with prompts reﬂecting six cultural dimensions,and their outputs were analyzed for alignment through sen-timent analysis. Results reveal varying levels of culturalalignment, with models reﬂecting biases tied to their train-ing contexts. The study highlights the importance of di-verse and culturally representative datasets to improve theadaptability of LLMs in speciﬁc cultural settings."
Q2:ポスター3月11日（火） 10:20-11:50   Q会場(1F会議室101AB),Q2-11,Code LLM 事前学習時の評価データ混入への対策,/proceedings/annual_meeting/2025/pdf_dir/Q2-11.pdf,"○金山 博, 大湖 卓也, 村岡 雅康, 吉田 一星 (IBM)",本論文は、プログラムのソースコード用の言語モデルの性能を適切に評価する際に重要となる、モデルの事前学習における評価データの混入の問題について論じる。まず、コード用のモデル向けのベンチマークを網羅的に調査し、一部の評価データの内容が本質的にGitHub 由来の学習データ重複しうるという実態を示す。また、混入除去の妥当な方策として、評価データと学習データの間の文字列の一致の検出に加えて、由来となるレポジトリの情報を用いる手法を提案する。
Q2:ポスター3月11日（火） 10:20-11:50   Q会場(1F会議室101AB),Q2-12,大規模言語モデルの分布予測における常識に基づいた割合予測能力の評価,/proceedings/annual_meeting/2025/pdf_dir/Q2-12.pdf,"○鈴木 刀磨, 片山 歩希, 郷原 聖士, 辻本 陵, 中谷 響, 林 和樹, 坂井 優介, 上垣外 英剛, 渡辺 太郎 (NAIST)",近年，大規模言語モデル（LLM）を用いた回答分布予測が注目されているが，割合に関する数値的予測に合理性があるかは明らかではない．本研究では，実際のアンケートデータの分布割合を入れ替えた「常識的には不自然な擬似分布」を用いて，LLMがその説明を受けても合理的な分布推定を行えるかを検証した．その結果，説明に単に追従する能力と，常識に基づいて割合を予測する能力が異なることが明らかとなった．また，分布の性質を十分に理解していない予測における不合理性も確認された．この結果は，LLM の分布予測能力を評価する際に，常識的な推論能力だけでなく，与えられた指示への追従性能も考慮すべきであることを示唆している．
Q2:ポスター3月11日（火） 10:20-11:50   Q会場(1F会議室101AB),Q2-13,架空語に対する LLM の知ったかぶりの自動評価,/proceedings/annual_meeting/2025/pdf_dir/Q2-13.pdf,"○岩本 蘭 (IBM/慶應大), 金山 博, 村岡 雅康, 吉田 一星 (IBM)",LLM が起こす幻覚には様々な種類がある。例えば、存在しそうで存在しない「架空語」の意味を尋ねた際、LLM は「知らない」と答えるのが望ましいが、誤った説明や別の語の意味を返すことがある。本論文ではLLM が幻覚を引き起こさずに適切に未知を示す能力を評価する方法を提案する。架空語を自動生成し、架空語について問う質問に対するLLMの応答を分類することでこの能力を評価する。
Q2:ポスター3月11日（火） 10:20-11:50   Q会場(1F会議室101AB),Q2-14,評価結果の予測確率を用いたLLMによるLLMの相対評価,/proceedings/annual_meeting/2025/pdf_dir/Q2-14.pdf,"○森田 隼功 (同志社大), 大林 弘明 (トランスコスモス), 田村 晃裕 (同志社大), 濱田 充男 (トランスコスモス), 加藤 恒夫 (同志社大)",本論文では，評価結果の予測確率を用いる大規模言語モデル（LLM）によるLLM の新たな相対評価手法を提案する．従来の相対評価では，評価対象LLM の提示順を入れ替えた際に評価結果が変動する位置バイアスが生じた際，最終的な評価結果を適切に定める手法が確立されていない．そこで，本研究では，位置バイアスが生じた際に，提示順入れ替え前後の評価結果の予測確率の平均が最も高い結果を最終的な評価結果とする手法を提案する．そして，本提案手法を文章作成等のビジネスタスクを対象に評価し，有効性を確認した．
Q2:ポスター3月11日（火） 10:20-11:50   Q会場(1F会議室101AB),Q2-15,Fact-checkingのための補足コンテキストによる情報の拡充,/proceedings/annual_meeting/2025/pdf_dir/Q2-15.pdf,"○籾井 裕貴, 滝口 哲也, 有木 康雄 (神戸大)",近年では，SNS や大規模言語モデルの普及に伴い，誤った情報が拡散しやすくなっている．誤った情報の影響を抑えるには，Fact-checking が重要となる．Fact-checking は，判定対象が誤っていないか，外部のデータベースに基づいて判定するタスクである．このタスクでは，判定に必要な情報を外部データベースから検索することが求められる．本研究では，情報検索を行った後に，補足コンテキストの生成を行うことで，より多くの判定に有用な情報の取得を試みた．
Q2:ポスター3月11日（火） 10:20-11:50   Q会場(1F会議室101AB),Q2-16,復号手法が大規模言語モデルにおける不確実性推定に与える影響の調査,/proceedings/annual_meeting/2025/pdf_dir/Q2-16.pdf,"○橋本 航, 上垣外 英剛, 渡辺 太郎 (NAIST)","GPT-3.5/4 やLLaMA などの大規模言語モデル（Large Language Models, LLM）は、自然言語処理における様々なタスクの性能を大きく発展させた．しかし，生成テキストに誤情報を含む「幻覚」をはじめとした品質の低い出力が依然として存在するため，特に医療や金融といった確実性が重要な領域での活用には課題が残されている．本研究では，生成テキストの品質向上を目指す復号手法が，質問応答と要約タスクにおいて大規模言語モデルの不確実性推定性能に与える影響を調査した．実験により，貪欲探索やビーム探索のようなシンプルな復号手法が，不確実性推定性能の観点で優れていることが判明した．"
Q2:ポスター3月11日（火） 10:20-11:50   Q会場(1F会議室101AB),Q2-17,JHARS: RAG設定における日本語Hallucination評価ベンチマークの構築と分析,/proceedings/annual_meeting/2025/pdf_dir/Q2-17.pdf,"○亀井 遼平, 坂田 将樹 (東北大), 邊土名 朝飛 (サイバーエージェント/AI Shift), 栗原 健太郎 (AI Shift/サイバーエージェント), 乾 健太郎 (MBZUAI/東北大/理研)",大規模言語モデルのhallucination（与えられた情報源に存在しない内容を生成する現象）は，実応用上での重要な課題となっている．本研究では，日本語におけるhallucination 評価のための包括的なベンチマークJHARS （Japanese Hallucination Assessmentin RAG Settings）を構築し，最新のGPT-4o を含む
Q2:ポスター3月11日（火） 10:20-11:50   Q会場(1F会議室101AB),Q2-18,JamC-QA: 日本固有の知識を問う多肢選択式質問応答ベンチマークの構築,/proceedings/annual_meeting/2025/pdf_dir/Q2-18.pdf,"○岡 照晃, 柴田 知秀, 吉田 奈央 (SB Intuitions)","日本語大規模言語モデルの開発競争が活発化する中、日本の文化や風習に特化した難度の高い評価用ベンチマークが必要になっている。本稿では、現在構築している日本語の多肢選択式質問応答ベンチマークJamC-QA について述べる。JamC-QA は日本の文化や風習といった国内独自の知識を問う問題を既存のベンチマークの翻訳でなく、1 から作成しており、問題数は2024 年12 月現在、1,045 問である。評価実験では、JamC-QA を用いることで、日本固有の知識問題に関するモデル性能の差を確認できた。これは既存の日本語ベンチマークでは見えなかったものである。またスコア向上の余地もあり、解くべき難しさもまだ十分に含むことがわかった。"
Q2:ポスター3月11日（火） 10:20-11:50   Q会場(1F会議室101AB),Q2-19,LLMのクロスリンガル知識編集に関する分析,/proceedings/annual_meeting/2025/pdf_dir/Q2-19.pdf,"○友成 光, 森下 皓文, 角掛 正弥, 今一 修, 十河 泰弘 (日立)",本研究では，クロスリンガル知識編集における言語間転移と誤った知識の上書きがどの程度生じるかを明らかにするため，新たにデータセットを構築し，評価実験を行った．具体的には，Wikidata から多言語の知識トリプルを収集し，反実仮想の目的語を導入することで，モデルがもともと持つ知識に左右されずに編集効果を測定できる仕組みを整えた．さらに，新指標「過剰適応耐性（OF-TOL）」を提案し，編集対象外の主語に対する誤った知識の上書きを定量化した．Llama-3-8B モデルを用いた検証では，述語の種類や更新パラメータによって言語間転移の度合いが大きく変動する一方，既存知識が上書きされる副作用が一貫して生じることが分かった．
Q2:ポスター3月11日（火） 10:20-11:50   Q会場(1F会議室101AB),Q2-20,Evaluating Robustness of LLMs to Numerical Variations in Mathematical Reasoning,/proceedings/annual_meeting/2025/pdf_dir/Q2-20.pdf,"○Yang Yuli, 山田 寛章, 徳永 健伸 (科学大)","Evaluating an LLM’s robustness against numerical per-turbation is a good way to know if the LLM actually per-forms reasoning or just replicates patterns learned. Wepropose a novel method to augment math word problems(MWPs), producing numerical variations at a large scaleutilizing templates. We also propose an automated errorclassiﬁcation framework for scalable error analysis, distin-guishing calculation errors from reasoning errors. Our ex-periments using the methods show LLMs are weak againstnumerical variations, suggesting they are not fully capableof generating valid reasoning steps, often failing in arith-metic operations."
Q2:ポスター3月11日（火） 10:20-11:50   Q会場(1F会議室101AB),Q2-21,大規模言語モデルにおける多段推論の依存構造と推論能力の関係検証,/proceedings/annual_meeting/2025/pdf_dir/Q2-21.pdf,"○榎本 倫太郎 (早大), 新妻 巧朗 (朝日新聞社), 栗田 修平 (NII), 河原 大輔 (早大/NII)",大規模言語モデル(LLM) の多段推論能力を測るタスクとして、算術推論や演繹推論タスクがある. 一般にこれらのタスクは必要な推論ステップ数が長い問題ほど解答が難しいとされている. 本研究では推論ステップ数だけでなく、LLM の多段推論間の依存関係に着目し、複雑な依存構造がLLM の最終解答精度にどのように影響するかを分析する. 結果として、問題の提示順序や推論の依存関係の深さ、完全な対称性が正答率に影響を与えることがわかった.
Q2:ポスター3月11日（火） 10:20-11:50   Q会場(1F会議室101AB),Q2-22,Mitigating Social Bias in Large Language Models by Self-Correction,/proceedings/annual_meeting/2025/pdf_dir/Q2-22.pdf,"○◊Panatchakorn Anantaprayoon (科学大), 金子 正弘 (MBZUAI/科学大), 岡崎 直観 (科学大/産総研/NII)","Self-CorrectionenablesLargeLanguageModels(LLMs) to reﬁne their responses during inference basedon feedback. While prior research mainly examines theimpact of Self-Correction on reasoning tasks such as arith-metic reasoning, its inﬂuence on debiasing remains un-derexplored. In this work, we propose a Self-Correctionframework tailored to bias evaluation task and demonstratethat the approach has potential in debiasing LLMs’ re-sponses more robustly and consistently than the baselines,which are Chain-of-Thought and Self-Consistency.Wealso conﬁrm that factors such as the feedback source, thebias level of the feedback generator, and the social biascategories signiﬁcantly inﬂuence debiasing outcomes."
Q2:ポスター3月11日（火） 10:20-11:50   Q会場(1F会議室101AB),Q2-23,LLM は日本の民話を知っているか？ 妖怪知識評価データセットの構築へ向けて,/proceedings/annual_meeting/2025/pdf_dir/Q2-23.pdf,"○堤 歩斗 (都立大), 陣内 佑 (サイバーエージェント)",大規模言語モデル(LLM) は自然科学，数学，歴史，社会科学などの様々な分野で高い言語理解能力および言語生成能力を持つことが示されており，様々な自然言語処理タスクで利用されている．一方，多くのLLM は英語の事前学習データセットによる学習を基礎とするため，英語圏以外の文化に関わる知識については不十分であることが指摘されている．そのため，主に日本語データを用いた事前学習モデルや日本語による継続事前学習モデルなど，日本語資源を利用して日本に特化させたモデルの開発が行われている．本研究は日本の文化・民俗の中でも特に妖怪を題材として，これらのLLM が日本の文化に関する知識を持っているかを評価した．妖怪は現代でも娯楽として親しまれながらもその根拠は日本の古くからの民話や浮世絵にあるため，日本文化の理解度を評価するための題材として有用であると考えられる．評価のため，995 問の妖怪に関する知識を問う四択問題を生成し31 個のLLM で比較した．総じて明に日本語で学習したモデルの方が英語中心のモデルよりも正答率が高く，特にLlama-3をベースとした日本語による継続事前学習モデルが高い正答率であった．
Q2:ポスター3月11日（火） 10:20-11:50   Q会場(1F会議室101AB),Q2-24,大規模言語モデルの数値データ説明における例示と補足の効果,/proceedings/annual_meeting/2025/pdf_dir/Q2-24.pdf,"○江部 正周, 青山 敦 (慶應大)","大規模言語モデル（LLM）は, 質疑応答等の定性的な推論や数学等の定量的な推論が可能である. 一方で, 定性的な推論と定量的な推論を組み合わせることが必要なCSV データのような数値データを, 統計知識に基づいて自然言語で説明できるかは明らかでない. 本研究では, 数値データの統計知識に基づいた説明において, 説明能力を向上させる効果が高くコストの低い手法を, 次の3 種類のLLM への指示で検証した. すなわち, 1) 例も補足もない指示, 2) 基本的な統計量等の例示, 3) LLM の役割や分析の目的等の補足, である. その結果, 例示よりも補足の方が説明能力を向上させる効果は同等でもコストは低く,数値データを統計知識に基づいて説明できた."
Q2:ポスター3月11日（火） 10:20-11:50   Q会場(1F会議室101AB),Q2-25,議論形式のマルチエージェント自動評価の詳細分析,/proceedings/annual_meeting/2025/pdf_dir/Q2-25.pdf,"○内藤 悠, 佐藤 魁 (東北大), 佐々木 翔大 (SB Intuitions/東北大), 鈴木 潤 (東北大/理研/NII)",本研究では、大規模言語モデル（LLM）による自動評価手法として、議論形式のマルチエージェントの有効性を検証し、評価性能の向上を試みた。2 つのLLM を協調的に動作させるマルチエージェントシステムを導入し、モデル間で議論を行わせることによって、評価精度を高めることを目指した。結果として、単体モデルによる評価に比べて評価精度が低下することが確認されたが、議論形式を導入することで評価精度を向上させられる可能性が示唆された。
A3:NLPモデルの評価・安全性・信頼性(3)3月11日（火） 13:00-14:30   A会場(2Fコンベンションホール1+2),A3-1,大規模言語モデルはデータ漏洩を隠蔽できるのか,/proceedings/annual_meeting/2025/pdf_dir/A3-1.pdf,"○高橋 侑成, Youmi Ma (科学大), 金子 正弘 (MBZUAI/科学大), 岡崎 直観 (科学大/産総研/NII)",特定の文章が機械学習モデルの学習に漏洩しているかを推論する手法として，メンバーシップ推論攻撃（MIA）がある．大規模言語モデル（LLM）に対するMIA では，文字の並びなどの表層情報を利用するが，LLM はテキストをそのまま記憶しているとは限らない．本稿では，テキストの忘却と質問応答タスクの学習を同時に行うことで，LLM にテキストの文字の並びを忘却させながら，その知識を保持できることを報告する．すなわち，MIA の成功率を低減しながら，関連知識についての質問応答の性能を維持できる．この知見は，たとえテキストがMIAで推論されなくても，その知識をLLM が隠蔽できている可能性があると警鐘を鳴らすものである．
A3:NLPモデルの評価・安全性・信頼性(3)3月11日（火） 13:00-14:30   A会場(2Fコンベンションホール1+2),A3-2,LLMマルチエージェント間の相互作用の分析,/proceedings/annual_meeting/2025/pdf_dir/A3-2.pdf,"○平野 皓己, 何 子軒, 清水 勇喜, 陳 曄, 土井 智暉, 谷中 瞳 (東大)",本研究は，複数の大規模言語モデル（LLM）エージェントが協力してタスクを実行するマルチエージェント（MA）アプローチを，社会心理学的な観点から分析することを目的とする．人間同士の相互作用が問題解決に与える影響に関する理論であるSteiner’s theory に基づき，LLM のMA アプローチのエージェント間の相互作用を類型化し，新たな評価指標を設計した．複数のタスクとMA フレームワークにおいて各評価指標を計測し，誤った考えの伝播がグループ全体の結論に悪影響を及ぼすことを明らかにした．また，MA によって単一エージェント（SA）では現れなかった意見が出ることや，誤った意見が出たときに正しい意見を提示することが性能向上につながるかはタスクやフレームワークに依存することが分かった．
A3:NLPモデルの評価・安全性・信頼性(3)3月11日（火） 13:00-14:30   A会場(2Fコンベンションホール1+2),A3-3,実用的な品質観点に基づくRAG性能評価用QAデータセットの自動生成,/proceedings/annual_meeting/2025/pdf_dir/A3-3.pdf,"○寺井 孝則, 田原 英一, 大石 悠河, 湯浅 晃 (NTTデータ)","RAG システムの評価には, 高品質なQA データセットが不可欠である. しかし, 現行の手動作成方法は多大な時間的・人的コストを要し, また既存の自動生成ツールでは生成されたデータセットの品質に課題があるため実案件での利用が難しいという問題がある. そこで本論文では, RAG の評価データセットに求められる品質観点を整理した上で高品質なデータセットの自動生成手法を提案する. 実験の結果, 一定程度の品質を持つデータセットの生成が可能であり, また従来の実案件データセットと同様にRAG の精度向上を適切に捉えられることを確認した."
A3:NLPモデルの評価・安全性・信頼性(3)3月11日（火） 13:00-14:30   A会場(2Fコンベンションホール1+2),A3-4,日本語論文に特化したPDF文書解析器の構築と性能評価,/proceedings/annual_meeting/2025/pdf_dir/A3-4.pdf,"○嘉本 名晋, 梅澤 悠河, 長尾 浩良, 桂井 麻里衣 (同志社大)",学術分野のPDF 文書解析のデファクトスタンダードであるGROBID は主に英語で訓練されており，日本語論文の解析は困難であった．そこで，本研究では日本語論文を手動でアノテーションし，新たにGROBID モデルを訓練した．実験の結果，我々のモデルは既存モデルに比べて日本語論文に対する識別性能が向上し，特に非レイアウト関連の要素で優れた性能を示した．さらに，解析対象の論文PDFと同一の収録誌を訓練データに含めることの有用性を明らかにした．また，収録誌ごとに識別性能を算出し，性能差が生じる原因を定性的に分析した．
A3:NLPモデルの評価・安全性・信頼性(3)3月11日（火） 13:00-14:30   A会場(2Fコンベンションホール1+2),A3-5,事前学習データに含まれる社会的バイアスの分析と軽減,/proceedings/annual_meeting/2025/pdf_dir/A3-5.pdf,"○宇田川 拓真, 趙 陽, 金山 博, Bishwaranjan Bhattacharjee (IBM)","LLM は大規模な自己教師あり学習によって汎用的な言語知識を獲得するが, 主にWeb データから構成される事前学習データは不適切な社会的バイアスを含んでおり, LLM はこれらを強く継承してしまう問題が知られている. 本研究では, 事前学習データ内の多様な保護属性(人種・性別・宗教など) を正確に検出し, その属性に対する表現の感情極性(Regard)を分類することによってバイアスを分析・軽減する手法を提案する. また, 代表的な事前学習データとしてCommon Crawl を用いた実験により, 提案手法の効果を定性的・定量的に検証する.注意：本論文には不快な表現が一部含まれます."
A3:NLPモデルの評価・安全性・信頼性(3)3月11日（火） 13:00-14:30   A会場(2Fコンベンションホール1+2),A3-6,ローカルLLMとRAGを用いたPSU診療支援対話システムの検討,/proceedings/annual_meeting/2025/pdf_dir/A3-6.pdf,"○林 海斗 (早大), 桐山 知彦, 尾崎 理沙 (KDDI総研), 目黒 巧巳 (KDDI), 多屋 優人, 本庄 勝 (KDDI総研), 小林 七彩, 治徳 大介 (科学大), 内田 真人 (早大)",スマホ依存（Problematic Smartphone Use; PSU）患者に対する診療支援では、行動パターンの詳細な把握と、それに基づく専門的な情報提供が求められる。近年、スマホのログデータなどを分析することで患者の行動パターンを詳細に把握できるようになったが、アンケートデータや診療録などの複数の情報と組み合わせてそれらを総合的に解釈し、専門的な情報を提供することは容易ではない。そこでLLM を活用し、自動要約や情報提示による支援が期待されるが、プライバシー保護の観点から、患者個人の詳細な情報をパブリックなLLM に入力することが困難である。本研究では、ローカルLLM とRetrieval-Augmented Generation（RAG）を組み合わせたプライバシーに配慮した対話システムを提案する。具体的には、患者個別の利用履歴データ、診断経過、関連するドメイン知識を言語モデルでベクトル化し、知識ベースに格納する。プロンプトに基づき類似度検索で情報を抽出し、ローカルLLM の回答生成を支援するシステムを構築した。これにより、プライバシー保護とドメイン知識の活用を両立し、PSU 診療における意思決定を効果的に支援できることをケーススタディを通じて示す。
B3:心理言語学・認知モデリング(1)3月11日（火） 13:00-14:30   B会場(1F会議室102),B3-1,LLM による価格交渉シミュレーションにおけるアンカリング効果の検証,/proceedings/annual_meeting/2025/pdf_dir/B3-1.pdf,"○武並 佳輝, Yin Jou Huang, 村脇 有吾, Chenhui Chu (京大)",本研究は，大規模言語モデル（LLM）を用いた価格交渉シミュレーションにおいて，アンカリング効果が交渉結果や満足度に与える影響を検証した．売り手エージェントにアンカリング効果を用いるよう指示した場合，売り手の効用が向上し，買い手の効用は減少するものの，両者の主観的満足度が高まることが確認された．また，アンカリング効果の使用が買い手に事前に知らされても，その有効性が概ね維持されることが分かった．これらの結果は，人間を対象とする研究の知見と一致し，LLM が表面的な結果のみに捉われず心理的な面においても認知バイアスを再現可能であることを示唆している．
B3:心理言語学・認知モデリング(1)3月11日（火） 13:00-14:30   B会場(1F会議室102),B3-2,「心の中の言葉」はどのように予測できるか？ ―複数のモダリティの特徴に基づく脳活動デコーディングプロセスの構築―,/proceedings/annual_meeting/2025/pdf_dir/B3-2.pdf,"○Muxuan Liu (お茶大), 西田 知史 (NICT), 小林 一郎 (お茶大)",本研究では，被験者が画像観察時に想起する内容（想起文）の脳活動表現を解明するための新たな手法を模索し，fMRI 信号とLLaVA による画像と言語の統合表現を用いたデコーディングプロセスを構築した．特に，LLaVA が生成するトークン表現とfMRI 信号の時間軸不一致問題に対して，滑動平均による信号のノイズ低減とリッジ回帰による関連性学習を組み合わせることで，解読手法の整合性を向上させた．さらに，生成方式の違いがモデル性能に与える影響を検討し，想起文の脳活動表現の初歩的なデコーディングプロセスとその可能性を示す結果を得た．
B3:心理言語学・認知モデリング(1)3月11日（火） 13:00-14:30   B会場(1F会議室102),B3-3,日本語母語話者において人名の音象徴がその人の性格特性の想起に与える影響,/proceedings/annual_meeting/2025/pdf_dir/B3-3.pdf,"○平野 舜, 木山 幸子 (東北大)",本研究は、日本母語話者において人名の音象徴がその名主においてどのような性格特性を想起させるかを検証することを目的に、成人日本語母語話者を対象とした音声提示による架空の人物像の性格印象評定実験を実施した。特に子音の調音法（有声阻害音、無声阻害音、共鳴音）の違いと母音の配列の違い（[aiu]、[iua]、[uai]）の効果を比較検証した。実験では、架空の名前を持つ架空の人物の性格特性の描写を音声提示した上で、その人物像を性格特性の
B3:心理言語学・認知モデリング(1)3月11日（火） 13:00-14:30   B会場(1F会議室102),B3-4,英文リーダビリティ指標FKGLはほぼ平均文中音節数である,/proceedings/annual_meeting/2025/pdf_dir/B3-4.pdf,○江原 遥 (東京学芸大),Flesch-Kincaid 式は，英語の可読性指標として古典的だが代表的であり，近年の大規模言語モデルの出力評価においても用いられている．これらの式は単語あたりの平均文長と音節あたりの平均単語長の線形和であり，この線形和には数十年の長期の使用に耐える，人間の認知に基づく何らかの理論的要因の存在が示唆される．本研究では，これらの式の理論的解析を行いこの理論的要因を明らかにした．先行研究とは異なり，これらの式が「1 文あたりの平均音節数」として解釈できることを示した．学年が上がるにつれて語彙の範囲は拡大する可能性があるが，音節の範囲は学年や年齢に関係なく一定に保たれる．これが，長期に使われ続ける要因であろう．評価実験では，BNC を用いて本理論枠組みの妥当性を確認し，他言語版FKGL の提案も行う．
B3:心理言語学・認知モデリング(1)3月11日（火） 13:00-14:30   B会場(1F会議室102),B3-5,Shaping Personality of Large Language Models: An Approach Based on Representation Engineering,/proceedings/annual_meeting/2025/pdf_dir/B3-5.pdf,"○◊Yin Jou Huang, Prakhar Saxena, Zi Cheng Zhao (京大)","Personality is a fundamental psychological trait thatshapes an individual’s behavior patterns. This paperproposes a novel approach to personality simulation,which aims to simulate some predeﬁned personalitytraits using large language models. We conduct rep-resentation engineering and construct a set of person-ality control vectors to enable ﬁne-grained control ofthe strength of personality traits. Additionally, we usea linear model to capture the interdependencies amongpersonality traits.Evaluation based on a real-worldpersonality dataset shows that our proposed personal-ity simulation method outperforms the prompt-basedbaseline method."
B3:心理言語学・認知モデリング(1)3月11日（火） 13:00-14:30   B会場(1F会議室102),B3-6,ToMATO: 心の理論ベンチマークのためのロールプレイングLLMの心的状態の言語化,/proceedings/annual_meeting/2025/pdf_dir/B3-6.pdf,"○篠田 一聡, 北条 伸克, 西田 京介, 水野 沙希, 鈴木 啓太, 増村 亮, 杉山 弘晃, 斎藤 邦子 (NTT)",本研究では，心の理論を包括的かつ実応用に近い設定で評価可能なベンチマークであるToMATO を提案する．ToMATO はLLM 同士の情報の非対称性のある対話によって生成される．ToMATO は信念，意図，願望，感情，知識の5 類型の心的状態及びそれらについての誤信念の理解を包括的に評価できる．さらに対話を入力とし，登場人物の多様な性格特性への頑健性を評価できる点で実応用の設定に近い．実験によって，特に誤信念の理解において最新のLLM でも精度が人間に劣ること等を示す．
C3:マルチモーダル(1)3月11日（火） 13:00-14:30   C会場(1F会議室103),C3-1,大規模マルチモーダルモデルにおけるビジョンエンコーダーの付け替えと、日本語に強いモデル作成へ向けて,/proceedings/annual_meeting/2025/pdf_dir/C3-1.pdf,"○佐藤 諒, 木下 彰, 中田 乙一, 金箱 裕介, 麻場 直喜 (リコー)",本稿では画像とテキストを入力として文生成が可能なタイプの日本語向け大規模マルチモーダルモデル (LMM)開発について報告する。今回採用した開発手順は初めにLMM の構成要素であるモデルパーツの付け変えを行った後に追加で訓練を行う形態をとっている。この開発過程で行ったモデルの新しい付け替え(結合)方法やその手順、そこからさらに日本語向けにデータを用意し、追加訓練を行った内容について説明する。作成したLMM に対して日本語向けベンチマークで評価し、モデル精度とその変化についても公開する。
C3:マルチモーダル(1)3月11日（火） 13:00-14:30   C会場(1F会議室103),C3-2,物体検出モデルの信頼値を利用したVQAモデルによるぬいぐるみ画像分類,/proceedings/annual_meeting/2025/pdf_dir/C3-2.pdf,"○尾関 迅, 佐藤 伶耶, 鈴木 秀佳, 船田 眞帆, 仲宗根 太郎, 櫻井 義尚 (明大)","近年，大規模言語モデルの発展に伴い，マルチモーダルLLM(Large Language Model)の活用が進んでいる．特に画像分類においては,画像内の状況や意味を理解することで，従来の物体検出モデルでは検出困難だった画像全体を考慮した判別や新規の物体を特定する可能性が注目されている．しかしながら，マルチモーダルAI の性能は，画像とテキストのペアデータセットの収集難易度や，学習データの影響により画像分類性能に課題がある． そこで，本研究ではこの課題を克服するために物体検出モデルとマルチモーダルLLM を組み合わせたハイブリッド画像分類手法OConfVQAC(Object detection Confidence-guided VQA Classifier)の提案を行う．具体的には，物体検出モデルによって算出された信頼度をVQA モデルにプロンプトとして与え物体検出モデルの検出漏れを補完し，VQAモデルを用いた画像分類の性能向上を目指す．  また，この提案手法の有効性を検証するために，テーマパークに関するSNS の投稿画像にぬいぐるみが映っているか否かの2 値分類タスクに適用した． 本研究では，VQA モデルの画像分類性能の向上の可能性を検証した．"
C3:マルチモーダル(1)3月11日（火） 13:00-14:30   C会場(1F会議室103),C3-3,Large Vision-Language Modelを用いた非構造ドキュメント画像向け情報抽出,/proceedings/annual_meeting/2025/pdf_dir/C3-3.pdf,"○江上 尚志, 中田 百科 (リクルート), 福地 鈴佳, 久保田 茉莉花 (ビーンズラボ), 山根 大輝, 薬師寺 政和 (リクルート)",本研究では，非構造ドキュメント画像の情報抽出に取り組む．光学文字認識（OCR）の結果に対して大規模言語モデルを適用することで高精度な情報抽出が行えることが報告されているが，文書画像は一般に文字だけでなく，図形や文字の色などを含んだレイアウトも用いて情報を表現している．そのためOCR によって文字情報に劣化させる方法に比べ，画像を直接扱うLarge Vision-Language Model の方がより高精度に抽出できる可能性がある．そこで，非構造ドキュメントとしてメニュー画像を対象とし，この方法で情報抽出を行い従来手法と比較した．
C3:マルチモーダル(1)3月11日（火） 13:00-14:30   C会場(1F会議室103),C3-4,複数タスク・複数項目に跨ったマルチモーダル自動評価手法,/proceedings/annual_meeting/2025/pdf_dir/C3-4.pdf,"○大井 聖也 (科学大), 金子 正弘 (MBZUAI/科学大), 岡崎 直観 (科学大/産総研/NII), 井上 中順 (科学大)",視覚言語モデル（Vision-Language Model; VLM）は与えられた画像と指示文に基づいて文を生成できる能力を持つ。しかし、VLM の出力文を評価する既存手法は、文の総合的な品質を測定することのみに注力しているため、結果の解釈性が乏しいことに加え、必要な評価項目を網羅できていない可能性がある。本研究では、文の評価項目ごとの質を網羅的にスコア付けし、それらのスコアを元に総合スコアを決定する自動評価手法HarmonicEval を提案する。構築した人手評価データセットMMHE における実験により、HarmonicEval の人手評価との相関は既存手法を上回ることを示す1）。
C3:マルチモーダル(1)3月11日（火） 13:00-14:30   C会場(1F会議室103),C3-5,マルチモーダル大規模言語モデルはジェスチャーをどこまで理解しているのか：指標性・図像性・象徴性を問う,/proceedings/annual_meeting/2025/pdf_dir/C3-5.pdf,"○西田 典起 (理研), 井上 昂治 (京大), 中山 英樹 (東大), 坊農 真弓 (NII), 高梨 克也 (滋賀県立大)",本研究では、マルチモーダル大規模言語モデル(MLLM) がジェスチャーの意味をどの程度理解できているのか調査する。特に、MLLM は外界への参照性・依存性が高い「指標的ジェスチャー」の理解を、イメージを描写する「図像的ジェスチャー」や常識によって定められる「象徴的ジェスチャー」の理解よりも苦手とするのではないかという仮説を検証する。未来館SC コーパスの925 件のジェスチャーに対して人手でタイプラベルを付与し、GPT-4o を含むMLLM によるジェスチャー説明文の生成と評価を行った。その結果、MLLM は一貫して指標的ジェスチャーの理解に困難があることを明らかにした。
C3:マルチモーダル(1)3月11日（火） 13:00-14:30   C会場(1F会議室103),C3-6,CLIPのModality Gapを考慮したRAG検索手法の改良,/proceedings/annual_meeting/2025/pdf_dir/C3-6.pdf,"○山下 修平, 白藤 大幹, 斉藤 辰彦 (三菱電機)",CLIP の埋め込み空間はテキストと画像で大きく分離している(modality gap) ため，異なるモーダル間の類似度が低いことが問題となる．本研究では，事前実験として画像とテキストのデータを外部知識に持つRAG の検索器にCLIP を用い，画像が必要なケースにおいて正解画像データが検索上位に現れないことを確認する．そこで，外部知識のモーダルに応じて検索スコアを標準化することで，modality gapを考慮した検索手法を提案する．評価実験により，画像の外部知識を必要とするケースの検索精度は
D3:テーマセッション2: 人とAIの共生に向けた対話システム・言語使用の研究(2)3月11日（火） 13:00-14:30   D会場(1F会議室107),D3-1,日本語日常会話における他者開始修復の分析,/proceedings/annual_meeting/2025/pdf_dir/D3-1.pdf,"○坪倉 和哉, 入部 百合絵 (愛県大), 北岡 教英 (豊橋技科大)",LLM の登場により対話システムはより自然な発話が生成できるようになったが，依然として対話の破綻が生じているため，破綻を修復する手法が必要となる．本研究では対話システムの自然な修復を実現するため，人同士の会話における修復開始発話の言語パターンを分析することにより，人がどのように修復を開始するかを明らかにする．トラブルの発生をどのように伝えるかによって他者開始修復（OIR）発話のタイプが3 つ提案されているが，日本語日常会話コーパスを用いて分析を行った結果，OIR 発話タイプ毎に品詞の出現パターンが異なることが明らかになった．具体的には，OIR 発話タイプ毎に形態素数が異なることや，品詞の種類や出現頻度が異なることが示された．本結果は，対話システムが自然に修復を実行するための基礎的な知見となり得る．
D3:テーマセッション2: 人とAIの共生に向けた対話システム・言語使用の研究(2)3月11日（火） 13:00-14:30   D会場(1F会議室107),D3-2,音声対話システムのための意味的類似度を考慮した予測信頼度モデル,/proceedings/annual_meeting/2025/pdf_dir/D3-2.pdf,"○森 清忠 (NAIST/理研), 河野 誠也 (理研/NAIST), アンケル ガルシア コントレラス (理研), 吉野 幸一郎 (科学大/理研/NAIST)",一般的な音声対話システムはユーザの発話終了検知後に音声応答を生成するため，ユーザが応答生成の時間に待機するユーザ知覚遅延（UPL）が発生する．予測信頼度モデルは，予測したユーザ発話と完全なユーザ発話の文字列が一致する確率を推定するもので，UPL を軽減するために考案された．しかしシステムがユーザ発話を完全に予測せずとも，発話の途中で発話全体の意味を捉えることで，適切な対話応答を生成できる可能性がある．本研究では予測信頼度モデルを再定義し，発話同士の意味的類似度を推定させることで，応答の精度を維持しながらUPL をさらに削減できることを示す．
D3:テーマセッション2: 人とAIの共生に向けた対話システム・言語使用の研究(2)3月11日（火） 13:00-14:30   D会場(1F会議室107),D3-3,Exploring User Feedback: A Thematic and Sentiment Analysis of User Interactions with LLM-Based Dialogue Robots,/proceedings/annual_meeting/2025/pdf_dir/D3-3.pdf,"○◊Muhammad Yeza Baihaqi (NAIST/理研), Angel Garcia Contreras (理研), 河野 誠也 (理研/NAIST), 吉野 幸一郎 (科学大/理研/NAIST)","Recent advancements in large language models (LLMs)have signiﬁcantly improved dialogue agents, enabling themto generate context-aware, human-like responses. Whilequantitative evaluations eﬀectively compare performancebased on predeﬁned metrics, they may fail to capture nu-anced user experiences, such as memorable exchanges orunexpected opinions, which are crucial for reﬁning the sys-tem. To address this issue, we conducted thematic and sen-timent analysis by collecting participant feedback throughdialogue experiments. Speciﬁcally, we assessed GPT-3.5-Turbo and GPT-4o as dialogue models for dialogue robots.Thematic analysis allowed us to identify recurring patternsin user experiences, while sentiment analysis helped gaugethe emotional tone of those interactions. Our experimen-tal results provided rich insights in the form of themesand sub-themes, such as perceptions of knowledge depthand mistake correction. Sentiment analysis complementedthese ﬁndings, showing that GPT-4o received a positiveimpression, while GPT-3.5-Turbo garnered mostly nega-tive feedback."
D3:テーマセッション2: 人とAIの共生に向けた対話システム・言語使用の研究(2)3月11日（火） 13:00-14:30   D会場(1F会議室107),D3-4,生成AIと俳句創作―「対話」による学習支援はどのように可能か,/proceedings/annual_meeting/2025/pdf_dir/D3-4.pdf,○松永 典子 (九大),本研究では、俳句創作において生成AI による、どのような学習支援が可能なのかを事例をもとに明らかにすることを目的とし、AI を活用した俳句創作の具体例を示しながら、俳句創作におけるAI の学習支援の可能性と課題について検討する。その結果、AI による俳句創作を学習支援として成り立たせるには、創作者自身の発想を刺激させる問いかけを含む「対話型」支援が必要であることは示されたが、先行研究同様、俳句の評価に関する課題は残った。
D3:テーマセッション2: 人とAIの共生に向けた対話システム・言語使用の研究(2)3月11日（火） 13:00-14:30   D会場(1F会議室107),D3-5,非流暢な合成音声,/proceedings/annual_meeting/2025/pdf_dir/D3-5.pdf,"○モクタリ 明子 (県大), 波多野 博顕 (筑波大), 新井 潤 (関西学院大), キャンベル ニック (TCD), 定延 利之 (京大)",日常会話音声は，テレビなどで耳にするアナウンサーの発話とは異なり，非流暢性に満ちている．そのことから，合成音声に非流暢性を取り入れると，マシーンコミュニケーションがさらにリアルでインタラクティブになると考えられる．本研究では，まず日常会話音声データを，既存のAI による合成音声システムに学習させた．次に，同じ言語内容の非流暢性を加えた発話とそうでない発話を合成し，調査回答者にどちらがより人間味のある話し方かを尋ねた．その結果，非流暢な合成音声の方を，より人間味のある話し方だと判断する回答者の割合が優位に高かったことが明らかになった．
D3:テーマセッション2: 人とAIの共生に向けた対話システム・言語使用の研究(2)3月11日（火） 13:00-14:30   D会場(1F会議室107),D3-6,採血ロボットに求められるコミュニケーションスタイル,/proceedings/annual_meeting/2025/pdf_dir/D3-6.pdf,○西川 寛之 (明海大),採血を行うロボットの処置の精度に関する研究開発は実用化も始まっている。しかしながら、採血ロボットと患者のコミュニケーションに関する研究は十分ではない。現行のロボットは患者に対するインストラクションは行うが、口頭で行われている異常感覚やしびれの有無など、患者の感覚の確認をロボットが自律的に行ってはいない。これを実現させるための研究の手法に関する提言を行う。採血ロボットに求められるコミュニケーションスタイルの研究のためには①対ロボットと対人の違い、②医療従事者、医療消費者という立場の違い、③いわゆる文化的な違い、国や地域による違い、それぞれに焦点をあてた研究が必要であることを述べる。
E3:テーマセッション6: 人文学と言語処理(3)3月11日（火） 13:00-14:30   E会場(1F会議室108),E3-1,日本語長単位語における語彙素推定,/proceedings/annual_meeting/2025/pdf_dir/E3-1.pdf,"○尾崎 太亮, 古宮 嘉那子 (農工大), 浅原 正幸, 小木曽 智信 (国語研/総研大)",デジタル人文学やコーパス言語学研究に重要な日本語長単位語に対する語彙素を推定する試みを行った．語彙素の推定にはエンコーダ・デコーダ型の言語モデル(T5) を用い，長単位語の品詞や表層形の他，長単位語を構成する短単位語の品詞・語彙素，および本文を入力として，長単位語の語彙素を出力させた．短単位語彙素をベースラインとした推定に対し，本手法は高い性能が得られた．検討の結果，短単位語は長単位語彙素推定に有効であるが，事例検討から，特に口語的な表現や動詞の付属部などに関しては文脈情報(本文) が推定に有効であった．
E3:テーマセッション6: 人文学と言語処理(3)3月11日（火） 13:00-14:30   E会場(1F会議室108),E3-2,場所表現の地理的曖昧性を解消するための質問内容生成,/proceedings/annual_meeting/2025/pdf_dir/E3-2.pdf,"○清水 美緒奈, 林 純子, 久田 祥平, 若宮 翔子, 荒牧 英治, 大内 啓樹 (NAIST)",場所表現の地理的曖昧性は，ジオコーディングにおいて重要な課題である．従来の研究では，場所表現が登場する文脈情報の有用性が示されている一方で，文脈情報を考慮しても位置が特定できない場合も少なくない．そこで，本研究では，曖昧な場所表現の位置を特定するためのユーザへの質問内容生成を目的として，複数の場所候補を絞り込む上で手がかりとなるランドマークの抽出を試みた．実験では，GPT-4o を使用し，人手で作成した評価データを用いてその有用性を評価した．結果として，モデルは中程度の精度を示したが，カテゴリの曖昧さや過剰な推測に起因する正解ランドマークの見逃しが多い傾向にあることが分かった．
E3:テーマセッション6: 人文学と言語処理(3)3月11日（火） 13:00-14:30   E会場(1F会議室108),E3-3,満洲語古典語における母音調和の計算言語学的考察,/proceedings/annual_meeting/2025/pdf_dir/E3-3.pdf,"○坂上 温紀, 坂井 優介, 上垣外 英剛, 渡辺 太郎 (NAIST)",満洲語における母音調和は他の言語における母音調和と異なる性質を持っており、今日まで様々な記述がなされてきた。17 世紀ごろの満洲語に限れば、文字資料のみを用いてこの音声現象に向き合わねばならず、これには当時の文書を包括的に扱う必要がある。そこで本研究ではBrown Clustering による母音・音節の分類と隠れマルコフモデルによる音韻環境と確率の計算を用いて母音のグルーピングと、母音¯u についての考察を行う。結果として、[±RTR]の調和があるが、母音の階層性によって調和が阻害されることがわかり、¯u は非円唇母音、あるいは弱い円唇性を持つ母音であると示唆された。
E3:テーマセッション6: 人文学と言語処理(3)3月11日（火） 13:00-14:30   E会場(1F会議室108),E3-4,言語学からみた記号接地，問題？,/proceedings/annual_meeting/2025/pdf_dir/E3-4.pdf,○川原 功司 (名外大),大規模言語モデルの発展に伴い，記号接地問題が脚光を浴びるようになってきている．しかしながら，記号接地は大規模言語モデルにとっては問題ではなく，言語獲得においてもそれほど重要な課題ではない．問題は，記号創発による平衡状態としての言語体系にある．本稿では，理論言語学，とりわけ生成文法と呼ばれる理論から，記号接地問題について批判的に考察する．
E3:テーマセッション6: 人文学と言語処理(3)3月11日（火） 13:00-14:30   E会場(1F会議室108),E3-5,地理的言及に対するエンティティ・リンキングにおける住所階層の利用,/proceedings/annual_meeting/2025/pdf_dir/E3-5.pdf,"○三森 尊, 乾 孝司 (筑波大)",地理的位置属性を持つ言及に対するエンティティ・リンキング課題において、地名が持つ住所階層性を活用したエンティティ曖昧性解消手法を提案する。提案手法では、入力文章中に地理的位置属性を持つ言及が複数現れる場合に、それらをトリガにして入力文章を編集することで地名間の住所階層関係をモデルに伝える。評価実験を通して、提案手法は従来手法を上回るエンティティ曖昧性解消の精度を達成し、同名の地名間の混同やカテゴリの異なるエンティティとの混同を効果的に削減できることを確認した。
E3:テーマセッション6: 人文学と言語処理(3)3月11日（火） 13:00-14:30   E会場(1F会議室108),E3-6,BERTによる辞書推定システムを用いた近代以前の日本語文書の形態素解析の精度向上,/proceedings/annual_meeting/2025/pdf_dir/E3-6.pdf,"○臼井 久生, 古宮 嘉那子 (農工大), 小木曽 智信 (国語研/総研大)",本研究では，BERT により形態素解析用の辞書の推定を行うことで，近代以前の日本語文書の形態素解析の精度を向上させる手法を提案する．形態素解析用の辞書作成時に用いたデータを用いてBERT をﬁne-tuning し，文書分類を行うシステムを作成した．形態素解析の対象文書を，作成した文書分類システムに入力し，出力された文書クラスの辞書を用いて形態素解析を行った．また，二つのベースラインとその文書の正解の辞書を用いた手法（Oracle 手法）と比較した．実験の結果，提案手法はベースラインを常に上回り，いくつかの文書ではOracle 手法を上回った．
P3:ポスター3月11日（火） 13:00-14:30   P会場(2Fコンベンションホール3+4),P3-1,RoBERTaとT5を用いた2段階モデルによる国語答案の文字認識誤り訂正,/proceedings/annual_meeting/2025/pdf_dir/P3-1.pdf,"○鈴木 里菜, 臼井 久生, 尾崎 太亮, Nguyen Tuan Hung, 古宮 嘉那子 (農工大), 石岡 恒憲 (大学入試センター), 中川 正樹 (農工大)",本研究では，手書き答案の文字認識誤り訂正を目的として，RoBERTa による誤り箇所推定とT5 による誤り訂正を組み合わせた2 段階モデルを提案する．既存研究では，T5 を用いたモデルで答案全体を対象に訂正を行っていたため，必要のない箇所まで訂正される問題があった．これに対し，本手法では，RoBERTa を用いて誤り箇所を推定し，その結果に基づきT5 で該当箇所のみを訂正する．中学生
P3:ポスター3月11日（火） 13:00-14:30   P会場(2Fコンベンションホール3+4),P3-2,自動アノテーションを導入したG-Eval による英文要約課題評価,/proceedings/annual_meeting/2025/pdf_dir/P3-2.pdf,"○藤田 晃輔, 山田 寛章, 徳永 健伸 (科学大), 石井 雄隆 (千葉大), 澤木 泰代 (早大)",英語学習者向け英文要約課題の自動評価のため，大規模言語モデル(LLM) を活用し，要約の内容に基づいた評価を実現する新たな手法を提案する．本研究では，Few-shot 学習，採点基準の自動展開，要約内の重要な概念や表現の自動アノテーションを組み合わせることで，要約内容に関する質の高い評価を可能にした．
P3:ポスター3月11日（火） 13:00-14:30   P会場(2Fコンベンションホール3+4),P3-3,IMPARA-GED：言語モデルの文法誤り検出能力に着目した文法誤り訂正の参照文なし自動評価,/proceedings/annual_meeting/2025/pdf_dir/P3-3.pdf,"○坂井 優介, 五藤 巧, 渡辺 太郎 (NAIST)",本稿では，参照文なし文法誤り訂正自動評価手法であるIMPARA-GED を提案する．我々は文法誤り訂正の自動評価手法であるIMPARA に使用される品質推定モデルに着目し，文法誤り検出能力を強化した事前学習済み言語モデルを用いて，IMPARA-GEDの品質推定モデルを構築した．文法誤り訂正自動評価手法のメタ評価用データセットであるSEEDA を用いた性能評価実験の結果，IMPARA-GED は特に文単位の人手評価結果と最も高い相関を示す自動評価手法であることが示された．
P3:ポスター3月11日（火） 13:00-14:30   P会場(2Fコンベンションホール3+4),P3-4,生成AIによる多肢選択式語彙問題および錯乱肢の生成と訂正,/proceedings/annual_meeting/2025/pdf_dir/P3-4.pdf,"○内田 諭, 畔元 里沙子, 吉村 理一, 伊藤 薫 (九大)",本論では語彙学習を目的とした多肢選択式空所補充問題の作成のため生成AI 等の技術を活用し，その性能を検証した．最初に英単語300 語に対し，ChatGPT にプロンプトを与え問題文と錯乱肢を生成した．錯乱肢には人手で訂正の有無をアノテーションし，ChatGPT とGemini を用いて自動訂正の可能性を検討した．結果として，問題生成については訂正が不要であった一方，錯乱肢生成では約17.8%で訂正を要した．この結果を受けて，生成AI の錯乱肢の訂正能力を検証したところ，F1 値が最大0.291となり，不十分な結果となった．提案手法として，予め準備した錯乱肢をBERT の確率により選別する方式を試した結果，訂正が必要な場合は11.0%となり，生成AI に対する優位性が明らかになった．
P3:ポスター3月11日（火） 13:00-14:30   P会場(2Fコンベンションホール3+4),P3-5,言語モデルを用いた看護師国家試験問題の誤答選択肢自動生成,/proceedings/annual_meeting/2025/pdf_dir/P3-5.pdf,"○城戸 祐世, 山田 寛章, 徳永 健伸 (科学大), 木村 理加, 三浦 友理子, 佐居 由美, 林 直子 (聖路加大)",本研究では，看護師国家試験問題における誤答選択肢の自動生成に大規模言語モデルを活用する．生成には日本語大規模言語モデルと，API を通じて利用可能なモデルをそれぞれ複数用い，過去の試験や予備校の模擬試験の問題をデータセットとして出力の制御を行う．生成した誤答選択肢を選択肢候補として看護師国家試験問題作成経験者に提示し，実際の問題作成における負担軽減や効率改善への寄与を分析した．その結果，大規模言語モデルによる誤答選択肢は有用であり，作問作業の効率改善の可能性が示された．
P3:ポスター3月11日（火） 13:00-14:30   P会場(2Fコンベンションホール3+4),P3-6,統語的複雑性指標を用いたL2日本語学習者エッセイ評価,/proceedings/annual_meeting/2025/pdf_dir/P3-6.pdf,"○小畑 文佳, 田川 拓海, 小野 雄一 (筑波大)",本研究は，日本語学習者のエッセイ評価と言語的特徴量の関係性について，さらなる検討を試みたものである．従来，英語教育の分野ではL2 学習者によるエッセイ評価と関連する言語特徴量が盛んに研究されている一方，日本語教育分野においては言語特徴量と評価との関連性があまり盛んに議論されていない．そこで本研究では，学習者日本語エッセイ評価に有効な言語的特徴量についてより深く検討・提案し，その評価に対する有効性を示すことを目的とした．分析では13 の言語的特徴量を扱い，それぞれの特徴量が学習者の習熟度予測へどれほど寄与しているかを検討した. 結果，一文あたりの用言数が最も有効な特徴量であることや，内容語Guiraud 値や機能語Guiraud 値も一定の説明力を示すことが示された．さらに，副助詞や接続助詞，格助詞の数などの機能語の数も詳細な条件として機能していることが明らかとなった．
P3:ポスター3月11日（火） 13:00-14:30   P会場(2Fコンベンションホール3+4),P3-7,Incorporating Rule-Based Methods with Prompt-Based Techniques for Indigenous Language Generation,/proceedings/annual_meeting/2025/pdf_dir/P3-7.pdf,"○◊Justin Vasselli, Arturo Martínez Peguero, 渡辺 太郎 (NAIST)","In this work, we explore how to leverage the meta-linguistic knowledge of large language models (LLMs) bycombining rule-based techniques with few-shot prompt-ing to produce new sentences in Indigenous languages,despite the LLMs having little to no prior knowledge ofthe language.Integrating rule-based preprocessing forBribri signiﬁcantly improves accuracy―over six times theedit-tree baseline and twice that of few-shot prompting―while a simpliﬁed version enhances performance for Mayaand Guarani. This research provides a generalizable so-lution for addressing linguistic challenges in low-resourcesettings through combining structured linguistic resourceswith LLM meta-linguistic capabilities to support languagerevitalization and preservation.1）"
P3:ポスター3月11日（火） 13:00-14:30   P会場(2Fコンベンションホール3+4),P3-8,LLMとDocker環境を統合した対話型言語処理教育プラットフォームの設計と実装,/proceedings/annual_meeting/2025/pdf_dir/P3-8.pdf,○長谷部 陽一郎 (同志社大),LLM と Docker 環境を統合した対話型言語処理教育プラットフォームを提案する．本システムは，Electron ベースのデスクトップアプリケーションとして複数の OS 環境で動作し，Docker コンテナ上に構築された再現可能な言語処理環境を提供する．ユーザは 独自のWeb UI やJupyter Notebook を介して LLM と対話しながら，様々な言語処理ツールを活用した実践的な学習が可能となる．またRuby を用いたDSL による記述で独自のアプリを作成できるため，多様な教育ニーズに対応した柔軟なカスタマイズが可能である．本プラットフォームは，LLM を用いた新たな教育手法の探求を促進し，言語処理教育の質的向上に貢献すると期待される．
P3:ポスター3月11日（火） 13:00-14:30   P会場(2Fコンベンションホール3+4),P3-9,文法誤り訂正における人手評価と自動評価の乖離とその解決,/proceedings/annual_meeting/2025/pdf_dir/P3-9.pdf,"○五藤 巧, 坂井 優介, 渡辺 太郎 (NAIST)",文法誤り訂正における自動評価尺度の目的の一つは，人手評価を模倣するような訂正システムの順位づけである．しかし，現状の自動評価は人手評価と乖離した評価手順に基づいており，このことは人手評価を模倣する目的と矛盾している．具体的には，人手評価は文単位の相対的な評価結果をレーティングアルゴリズムで順位に変換するが，自動評価では文単位の絶対的な評価結果を平均するなどしてコーパス単位評価に集約し，ソートすることで順位とする．本研究では，この乖離を埋めるために既存の自動評価尺度を人手評価の方法と一致するように用いることを提案し，実際に多くの尺度で人手評価との一致度が向上することを示す．
P3:ポスター3月11日（火） 13:00-14:30   P会場(2Fコンベンションホール3+4),P3-10,文法誤り検出/訂正における訓練データと評価データのドメイン不一致による性能向上現象,/proceedings/annual_meeting/2025/pdf_dir/P3-10.pdf,"○木村 学 (理研), 永田 亮 (甲南大/理研)",本稿では，文法誤り検出/訂正においては，訓練データと評価データのドメインが同じときよりも異なるときのほうが性能が高くなるという直感に合わない現象が起こることを報告する．特に，書き手の習熟度が低いデータを訓練に用いると同現象が生じやすいことを示す．この現象は，実質の訓練データ量という観点から自然に説明できることも明らかにする．更に，このことが外国語習得研究および文法誤り検出/訂正研究に与える示唆についても述べる．
P3:ポスター3月11日（火） 13:00-14:30   P会場(2Fコンベンションホール3+4),P3-11,Attention機構を用いた授業発話分析に基づく教員発話に対するアドバイス生成とLLMによる自動評価,/proceedings/annual_meeting/2025/pdf_dir/P3-11.pdf,"○大西 朔永, 児嶋 祥成, 椎名 広光, 保森 智彦 (岡山理大)",本研究は，教員支援を目的に，授業発話分析に基づくアドバイス生成とLLM-as-a-judge による自動評価手法を提案した．教員や児童を模倣したLLM のAttention 機構を用いて，教員発話の影響を推定し，その推定結果を統合したアドバイス生成を行った．さらに，LLM による自動評価を用いて，生成されたアドバイスの質を客観的に評価する手法を提案した．実験では，影響推定を統合したアドバイス生成が，LLM による自動評価で高い評価を得る傾向を示した．提案手法の有効性が示唆されたが，自動評価の改善と信頼性向上が今後の課題である．
P3:ポスター3月11日（火） 13:00-14:30   P会場(2Fコンベンションホール3+4),P3-12,LLM を用いた複数レシピに対する調理計画手法の検討,/proceedings/annual_meeting/2025/pdf_dir/P3-12.pdf,○山口 泰弘 (クックパッド),複数の料理を同時かつ効率的に調理するには，利用可能な調理器具の制約と調理・物理現象に対する常識的な理解が不可欠である．自然言語で書かれたレシピから自動的に効率的な調理計画を組み立てるには大規模言語モデル(LLM) がもつ推論能力は非常に有用と考えられる．本研究ではLLM を活用して同時調理の工程を計画する手法を検討し，解くべきタスクと課題の考察を行った．
P3:ポスター3月11日（火） 13:00-14:30   P会場(2Fコンベンションホール3+4),P3-13,動的な Few-shot の事例選択を用いた商品属性情報の正規化,/proceedings/annual_meeting/2025/pdf_dir/P3-13.pdf,"○岡崎 真治, 伊東 賢二, 浅野 孝平, 稲田 和明, 張 信鵬 (MonotaRO)",E コマースにおいて商品の特性を表す属性情報は，ユーザーの購買判断における重要な情報であり，これらのデータの整備はユーザー体験向上のための重要な課題である．しかし未整備の属性情報には，実際には同一とみなせる表現が異なる表記で扱われていることが多く，これらを統一するためには高い精度での表現の正規化が必要となる．そこで本研究では，蓄積された人手による目視検証と修正を加えた整備済みの属性情報から，動的にFew-shot の事例選択した大規模言語モデルによる属性値正規化システムを提案し，実際のE コマースの商品情報から抽出した属性値を用いて評価と分析を行う．
P3:ポスター3月11日（火） 13:00-14:30   P会場(2Fコンベンションホール3+4),P3-14,大規模言語モデルと患者表現辞書を用いた病名診断の精度検証,/proceedings/annual_meeting/2025/pdf_dir/P3-14.pdf,"○宇都宮 和希 (工学院大), 坂野 遼平 (一橋大)",自然言語処理技術を活用した医療支援が始まりつつあり，医療分野におけるAI の需要が上昇している．本研究では大規模言語モデル（LLM）の医療応用に着目し，医療プロセスの中でもAI による診断への応用可能性を探る．具体的には，曖昧な患者表現から病名を予測するタスクについて，複数GPTモデル間の差異検証を行う．また，予測病名からICD-10 コードを階層的に推定し，その推定精度の検証を行う．結果，差異検証ではファインチューニングを行うことで，より正解病名に近い予測ができる傾向を確認した．また，予測病名が正解病名と一致しない場合においてもICD-10 コードを正しく推定可能なケースが存在することを確認した．
P3:ポスター3月11日（火） 13:00-14:30   P会場(2Fコンベンションホール3+4),P3-15,自己教師あり学習を用いた 自由会話音声からの早期アルツハイマー病の予測,/proceedings/annual_meeting/2025/pdf_dir/P3-15.pdf,"○桑山 芳明, 坪倉 和哉, 入部 百合絵 (愛県大), 横井 克典, 中村 昭範 (NCGG), 北岡 教英 (豊橋技科大), 勝野 雅央 (名大)",本研究は，アミロイドPET やタウPET など経済的・身体的負担の大きい早期アルツハイマー病の検査の代替として，雑談を含む自由会話音声から早期アルツハイマー病を識別する手法を提案する．具体的には，自由会話音声とそれを書き起こしたテキストを HuBERT とRoBERTa を活用して音声・言語特徴量を特徴抽出器として用い，識別を試みた．その結果，特徴抽出器に高齢者音声や認知障害特有の音声を学習させることにより，従来手法である音響的特徴量を用いた手法と比較して，F 値で8%，正解率で7%上回る精度で正常群とプレクリニカルAD 群を識別できることが示され，自由会話音声からの早期アルツハイマー病の予測への応用が期待できる．
P3:ポスター3月11日（火） 13:00-14:30   P会場(2Fコンベンションホール3+4),P3-16,CloudArchitectBuddy 構造的状態制御に基づくシステム主導型設計支援,/proceedings/annual_meeting/2025/pdf_dir/P3-16.pdf,"○小比田 涼介, 春日 瑛 (サイバーエージェント)",本研究では、クラウドアーキテクチャ設計の複雑さを取り上げ、その設計支援システムとしてCloudArchitectBuddy（CA-Buddy）を提案する．CA-Buddy は要件と設計を状態として構造的に表現・制御することで設計の理解と一貫性を支援し、システムが主導的に検証と具体化を進めることでスムーズな設計作業を実現する．実務者によるCA-BuddyとChatGPT の比較実験の結果、設計品質は同等ながらもCA-Buddy は高いユーザー体験を示した．またフィードバックから、CA-Buddy の構造化された設計情報とシステム主導型の設計支援はチャットUIの柔軟な対話を統合することによってより効果的なクラウド設計支援ができる可能性が示唆された．
P3:ポスター3月11日（火） 13:00-14:30   P会場(2Fコンベンションホール3+4),P3-17,国語科共通テスト試行調査を用いたRAGによる答案生成の評価と再検索RAGの提案,/proceedings/annual_meeting/2025/pdf_dir/P3-17.pdf,"○一柳 壮綱, 古宮 嘉那子 (農工大), 石岡 恒憲 (DNC), 中川 正樹 (農工大)",近年，大規模言語モデル（LLM: Large LanguageModel）は発展の一途を辿ってきたが，これまで日本語の国語問題，特に大学入学共通テストのような全国試験レベルの問題にLLM を用いて取り組む研究は十分に行われてこなかった．本研究では，この課題に取り組むため，複数のLLM を用いて大学入学共通テスト試行調査の国語科目における答案を作成し，採点ガイドラインに基づいてその答案を評価する．また，Retrieval-Augmented Generation（RAG）手法を活用し，答案生成の手法を検討する．この際，再検索プロセスを考慮した手法を取り入れることで既存のRAG 手法を改良し，生成される答案の精度や一貫性の向上を目指すとともに，単純なLLM での生成との違いを調査した．実験の結果，再検索プロセスを考慮したRAG 手法を用いることによって，より採点条件を満たした答案を生成できるようになることを確認した．
P3:ポスター3月11日（火） 13:00-14:30   P会場(2Fコンベンションホール3+4),P3-18,大規模言語モデルを用いた講義振り返りテキストからの学生の成績推定,/proceedings/annual_meeting/2025/pdf_dir/P3-18.pdf,"○青野 広太郎, 笹野 遼平 (名大)",本研究では、講義を受けた学生が質問に回答する形式で講義内容について記述したテキストである「振り返りテキスト」を用いた学生の成績推定に取り組む。具体的には、2 人の学生の初回講義の振り返りテキストから、最終的にどちらがより高い成績を収めるかを予測する成績上下予測を、Meta-Llama-3.1-8B、Llama3.1-Swallow-8B-v0.2、Llama-3-ELYZA-JP-8B、Ruri-large の4 つの言語モデルを利用して行う。九州大学の3 つの講義における振り返りテキスト及び成績データを使用した実験の結果、複数のモデルの出力を多数決によって集約することで、およそ60%の精度で成績の上下を判別することができた。
P3:ポスター3月11日（火） 13:00-14:30   P会場(2Fコンベンションホール3+4),P3-19,診療データベースを用いたカルテスクリーニング,/proceedings/annual_meeting/2025/pdf_dir/P3-19.pdf,"○柴田 大作, 辻川 剛範, 渋谷 恵, 森田 智子, 久保 雅洋 (NEC), 中川 敦寛, 重田 昌吾, 島田 宗昭 (東北大)",医師によって作成される初診時記録や経過記録などの診療記録の利活用に向け，機械学習とルールベースに基づく診療データベースの構築，そして診療データベースを用いたカルテスクリーニング(臨床試験の選択基準に適合する患者の選定作業) について検討を行う．開発した機械学習モデルは固有表現抽出がMicro-F1 で0.884，関係抽出が0.768 と一定の精度で診療記録からの情報抽出が可能であった．また診療データベースを用いたカルテスクリーニングの精度は，診療記録を直接用いた際の精度よりも最大で4.2 倍改善することが明らかとなった．本研究で構築した診療データベースはカルテスクリーニングに有用である可能性が示唆された．
P3:ポスター3月11日（火） 13:00-14:30   P会場(2Fコンベンションホール3+4),P3-20,大阪大学SEEDSプログラム受講生によるライティング成果の「科学的にダメな点」調査と分析,/proceedings/annual_meeting/2025/pdf_dir/P3-20.pdf,"○東山 愛, 堀 一成 (阪大)",大阪大学では、科学技術分野に関心のある高校生を「SEEDS プログラム」という枠組みの中で2015年から受け入れてきた。本プログラムの受講生が提出したレポートの「科学的にダメな点」を調査、分析することにより、中等教育段階の生徒にとって習得が困難なアカデミック・ライティングに求められる項目を明らかにした。その結果、SEEDSプログラム受講生のレポートの「ダメな点」は、「定量性に欠ける表現」「思い込みなどが原因の客観性に欠ける表現」「書き手の価値観が入っている表現」など、大きく分けて6 種類に特徴を分類できることが判明した。今後は、これらの項目の習得を意識した、中等教育段階の生徒向けのライティング教材の開発が期待される。
P3:ポスター3月11日（火） 13:00-14:30   P会場(2Fコンベンションホール3+4),P3-21,学生によるプロンプトチューニングを用いた謝罪するロボットのもたらす教育効果,/proceedings/annual_meeting/2025/pdf_dir/P3-21.pdf,"○酒造 正樹, 小野田 凌也 (湘南工科大)",未成熟な大学生は、謝罪の経験が不足していることが多い。例えば、授業に遅刻したり、レポートの提出期限に遅れたりする場合、教員との適切なコミュニケーション方法として、対話を通じた回復戦略を学ぶことが学生の将来にとって有益である。また、学生が教える立場に立ち自己の学びを深めるLearning by Teaching（LBT）やソーシャルスキルトレーニング（SST）の手法を活用することで、生成AI を利用した対話エージェントの開発が可能となる。このアプローチでは、過失を犯したロボット（アバター）に対し、学生自身が教育的指導を行うことで、実践的な学習素材として活用できる。本論文では、学部1 年生向け実習科目において導入した対話システムと、その教育効果について論じる。
P3:ポスター3月11日（火） 13:00-14:30   P会場(2Fコンベンションホール3+4),P3-22,生成AIによるセリフ文章を利用したタイピングゲーム,/proceedings/annual_meeting/2025/pdf_dir/P3-22.pdf,"○鈴木 里彩, 松吉 俊 (東京工科大)",既存のタイピングゲームは、固定的な文章や単純なレベル分けが中心であり、学習者が慣れていくことにより、学習者のモチベーション維持やスキル向上に限界がある。個人の嗜好に合わせてタイピング文章を毎回自動生成することができれば、学習者のモチベーション維持や向上に繋がることが期待される。本研究では、AI が自動生成した日本語文章を活用したタイピングゲームを開発した。評価実験によって、開発したタイピングゲームにはモチベーション向上効果があることが示唆された。その一方で、セリフ自動生成の精度が低いネガティブな性格語に対して、プロンプトの改良や別の大規模言語モデルの利用を検討する必要があることも明らかになった。
P3:ポスター3月11日（火） 13:00-14:30   P会場(2Fコンベンションホール3+4),P3-23,Policy-Value Monte-Carlo 木探索を用いた将棋の解説文に出現する手順の予測,/proceedings/annual_meeting/2025/pdf_dir/P3-23.pdf,"○池田 大雅, 鶴岡 慶雅 (東大)",将棋などの完全情報ゲームのプログラムは任意の盤面から最善と考えられる指し手とその評価値（形勢判断）を正確に提示できるが、その理由まで説明することは難しく解釈性が課題となっている。本研究では解説文に出現する手順を予測する部分ゲーム木（解説木）をゲームエンジンを用いて生成する手法を提案する。Policy-Value Network を用いたMonte-Carlo 木探索(PV-MCTS) によって得られたゲーム木を再帰的に枝刈りして解説木を生成する。この手法により、解説文のコーパスに依存しない解説木の予測が可能となる。また、PV-MCTS を制御するPUCT アルゴリズムを調整することによる予測精度の変化についても調査した。
Q3:ポスター3月11日（火） 13:00-14:30   Q会場(1F会議室101AB),Q3-1,移動軌跡に関する質問応答データセット,/proceedings/annual_meeting/2025/pdf_dir/Q3-1.pdf,"○浅野 輝 (東大/理研), 大内 啓樹 (NAIST/サイバーエージェント/理研), 春日 瑛, 米谷 竜 (サイバーエージェント)",本研究では，移動軌跡データに関する質問応答（QA）データセットを構築した．より具体的には，事実照会問題，選択式問題，自由記述式問題という
Q3:ポスター3月11日（火） 13:00-14:30   Q会場(1F会議室101AB),Q3-2,LLM-jp-3 VILA: 日本語マルチモーダルデータセット及び強力な日本語マルチモーダルモデルの構築,/proceedings/annual_meeting/2025/pdf_dir/Q3-2.pdf,"○笹川 慶人 (早大/NII), 前田 航希 (科学大/NII), 杉浦 一瑳 (京大/NII), 栗田 修平 (NII), 岡崎 直観 (科学大/NII), 河原 大輔 (早大/NII)",強力な視覚言語モデル(VLM) を構築するためには、画像・テキスト対データや交互配置(interleaved)データ、指示データなどのマルチモーダルデータが必要である。しかし、英語のデータは豊富にあるが、日本語のデータは限られている。この問題に対処するため、我々はゼロから日本語のマルチモーダルデータセットを構築する。我々はウェブ上の画像・テキスト対データとinterleaved データを構築し、さらに既存の大規模言語モデル(LLM) やVLM を利用して日本語のマルチモーダル指示データを構築する。これらのデータセットを利用して学習したモデルは、先行研究の機械翻訳を用いて構築したデータによるモデルよりも高い性能を示した。
Q3:ポスター3月11日（火） 13:00-14:30   Q会場(1F会議室101AB),Q3-3,Vision Language Modelを用いた走行画像認識性能の検証,/proceedings/annual_meeting/2025/pdf_dir/Q3-3.pdf,"○表野 理人, 針屋 慶吾, 福田 有輝也, 米陀 佳祐, 菅沼 直樹 (金沢大)",自動運転技術の関連研究に用いられる走行データを効率良く応用する場合，交通状況を理解するための詳細な認識が重要である．そこで，走行データの認識に，走行中の自車から撮影されたカメラ画像を深層学習ベースモデルによる分類で得られる情報を用いることが有効な手段として挙げられる．本研究では，画像情報のみを扱うConvolutional neural network(CNN)ベースモデルと画像とテキストの両方の情報を扱えるVision Language Model(VLM)の走行画像認識性能を評価・比較する．実験の結果， VLM が詳細なラベルである走行エリア，走行場所，路面状況，渋滞状況，掠れた白線の有無，工事規制されている車線の有無のラベルにおいて，CNN ベースモデルの精度を上回ったことが確認された．
Q3:ポスター3月11日（火） 13:00-14:30   Q会場(1F会議室101AB),Q3-4,視覚言語モデルの識別性能に関する評価用ベンチマークの構築,/proceedings/annual_meeting/2025/pdf_dir/Q3-4.pdf,"○村岡 雅康 (科学大), 岡崎 直観 (科学大/産総研/NII)",本稿では，視覚言語モデル(VLM) の識別性能を評価するための新たな評価用ベンチマークDiscriBenchを構築し，既存のVLM の識別性能を調査する．DiscriBench は，提示される情報の中から必要な情報を識別し質問に回答するという，人間が日常生活において行なっているプロセスに焦点を当てたベンチマークである．全100 問からなる選択肢形式のVQA であり，大学入試難易度を想定して作成している．GPT-4o を含む既存のVLM をDiscriBench で評価した結果，人間の正解率は89.2%だったのに対し，VLM はそれより18.2 - 63.2 ポイント低く，識別性能において大きな差が認められた．
Q3:ポスター3月11日（火） 13:00-14:30   Q会場(1F会議室101AB),Q3-5,Asagi: 合成データセットを活用した大規模日本語VLM,/proceedings/annual_meeting/2025/pdf_dir/Q3-5.pdf,"○上原 康平, 黒瀬 優介 (東大/理研), 安道 健一郎 (理研/東大), Jiali Chen, Fan Gao, 金澤 爽太郎, 坂本 拓彌, 竹田 悠哉, Boming Yang, Xinjie Zhao (東大), 村尾 晃平, 吉田 浩 (NII), 田村 孝之 (ROIS), 合田 憲人 (ROIS/NII), 喜連川 優 (ROIS/東大), 原田 達也 (東大/理研/NII)",大規模言語モデル（LLM）の発展として，画像など他のモダリティも扱う大規模マルチモーダルモデルの研究が進んでいる．本研究で注目するVision &Language モデル（VLM）は，画像とテキストを同時に入力可能なモデルである．しかしながら，データが潤沢な英語モデルに比べ，データの不足する日本語モデルの開発は十分とはいえない．本研究では，日本語能力に特化したVLM の開発のため，大規模な日本語テキスト・画像ペアの合成データセットを新たに構築した．なお，データセットの構築時に，ライセンスによってデータ利用が制限されるLLMは用いていない．構築したデータセットを用いて日本語VLM を訓練し，その性能を評価した．
Q3:ポスター3月11日（火） 13:00-14:30   Q会場(1F会議室101AB),Q3-6,Data Augmentation for Open-Domain Live Commentary Generation,/proceedings/annual_meeting/2025/pdf_dir/Q3-6.pdf,"○◊Erica K. Shimomoto, Edison Marrese-Taylor (産総研), 小林 一郎 (お茶大), 高村 大也 (産総研), 宮尾 祐介 (東大)","This paper proposes automatic data augmentationfor Live Commentary Generation using Large Vision-Language Models (LVLMs). This task aims to generatea set of timed subtitles commenting on the contents ofa given video, describing the actions and objects in thevideo, and including additional information. Collectingdata for live commentary generation can be an expensiveand time-consuming task. Therefore, we propose a lesslabor-intensive alternative by utilizing LVLMs to generateartiﬁcial live commentary data based on frames extractedfrom videos. Our results using a simple live commentarygeneration model reveal that training on a combination oforiginal and augmented data has the potential for perfor-mance improvement in this task in terms of BLEU score."
Q3:ポスター3月11日（火） 13:00-14:30   Q会場(1F会議室101AB),Q3-7,大規模言語モデルによるセリフを含む物語の可視化手法,/proceedings/annual_meeting/2025/pdf_dir/Q3-7.pdf,"○瀧本 隼矢, 竹内 孔一 (岡山大)",近年，大規模言語モデル（LLM: Large LanguageModel）を活用した物語の視覚的表現が注目されているが，物語のセリフや感情，キャラクターの行動といった本質的要素を取り入れる試みは十分に行われていない．本研究では，LLM を用いてChain ofThought（CoT）Prompting により物語を解析・分割し，画像生成プロンプトを構築する新たな手法を提案する．本手法の特徴は，物語中のセリフを含めた可視化に焦点を当てる点にある．CLIP Score による評価実験では，提案手法が物語本文からそのまま画像生成する手法に比べ，セリフの有無に関わらず視覚的情報が画像に正確に反映されることを示す．
Q3:ポスター3月11日（火） 13:00-14:30   Q会場(1F会議室101AB),Q3-8,半自己回帰的に拡散モデルを活用するトレースベースの意図反映キャプション生成,/proceedings/annual_meeting/2025/pdf_dir/Q3-8.pdf,"○平野 理子, 小林 一郎 (お茶大)",本研究ではユーザが画像をなぞった軌跡（トレース）が示すユーザ固有の説明意図を生成文に反映する画像キャプショニング手法を提案する．トレースの密集度から関心領域を特定し，座標変化に基づいて説明順序を決定，滞在時間を用いて各領域への関心度を評価する．これらの情報を基に拡散言語モデルを半自己回帰的に用いることで，文長や説明順序を制御しつつ，流暢性の向上を図った．実験の結果，提案手法は自己回帰モデルを含む既存手法より
Q3:ポスター3月11日（火） 13:00-14:30   Q会場(1F会議室101AB),Q3-9,バナー広告における画像と広告コピーの評価ベンチマーク構築,/proceedings/annual_meeting/2025/pdf_dir/Q3-9.pdf,"○遠藤 洸亮 (科学大), 脇本 宏平, 宮西 洋輔 (サイバーエージェント), 岡崎 直観 (科学大)",インターネット広告市場の拡大に伴い，バナー広告の需要が急増している．バナー広告は視覚的に訴求する画像と，商品の価値や特徴を伝える広告コピーで構成され，その組み合わせの「相応しさ」は広告効果に影響するとされる．しかし，この相応しさを評価する研究はこれまで行われていない．本研究では，相応しさを評価するため，「コピーがバナー画像の内容を再現しているか」および「バナー画像がコピーの内容を再現しているか」に基づくバナー画像とコピーの表現再現性評価タスクを提案し，ベンチマークを構築する．また，表現再現性とバナー広告としての相応しさの関係を調査する．そして，既存手法による表現再現性の評価実験を行い，評価の課題を明らかにする．
Q3:ポスター3月11日（火） 13:00-14:30   Q会場(1F会議室101AB),Q3-10,高精度な日本語マルチモーダル大規模言語モデルの構築にむけたデータセットの検討,/proceedings/annual_meeting/2025/pdf_dir/Q3-10.pdf,"田中 幹大, 朱 佩菲, ○横尾 修平 (LINEヤフー)",近年，大規模言語モデル(LLM) に視覚情報を統合した，マルチモーダル大規模言語モデル（MLLM）が注目を集めており，その応用範囲は急速に拡大している．しかし，日本ドメインに特化したMLLM を作る上で，英語のデータに比べて公開データが少ない課題がある．本研究では，高精度な日本語MLLMを構築するためのデータセットの作成方法について検討し，実験を行った．構築したモデルは，日本ドメインの画像理解を問うベンチマークにおいて，他のモデルよりも優位な結果を示し，その有効性を実証した．
Q3:ポスター3月11日（火） 13:00-14:30   Q会場(1F会議室101AB),Q3-11,ロールプレイングゲームの画面情報分析による選択可能テキストの抽出,/proceedings/annual_meeting/2025/pdf_dir/Q3-11.pdf,"○狩野 竜示, 森 友亮, 荒牧 岳志 (スクウェア・エニックス)",本研究では，マルチモーダル大規模言語モデルを用いてロールプレイングゲーム（RPG）の画面から，選択対象のテキストを抽出する手法を提案し，その精度を検証した．テキスト情報を多く使用するビデオゲームのジャンルであるRPG の自動プレイを機械学習モデルが行うには，画面に表示されたテキスト情報の処理能力が必要となる．本研究では，RPGの自動プレイに必要なサブタスクの一つとして，選択肢の提示された画面から，選択可能なテキストを行列形式で抽出する手法を提案する．また，データベースとの照合によるフィードバック手法を導入し，精度が向上することを確認した．
Q3:ポスター3月11日（火） 13:00-14:30   Q会場(1F会議室101AB),Q3-12,大規模視覚言語モデルにおける言語タスクに対する視覚情報の影響,/proceedings/annual_meeting/2025/pdf_dir/Q3-12.pdf,"○吉田 大城, 林 和樹, 坂井 優介, 上垣外 英剛 (NAIST), 林 克彦 (東大), 渡辺 太郎 (NAIST)",大規模視覚言語モデル（LVLM) は言語情報に加えて視覚情報も扱うことができる言語モデルである。一般的にLVLM は、視覚と言語の両方を同時に扱うようなタスクで用いられることが前提とされているが、言語情報のみで解決可能なタスク（言語タスク）に限定して使用することも可能である。ただし、LVLM の構築過程では画像情報と整合が取られているため、視覚情報が追加的に与えられる状況において、その画像がタスクに密接に関連する場合だけでなく、逆に敵対的であったり無関係であったりする場合に応答がどのように変化するのかは明らかではない。本研究では、心理学的効果検証の一種であるプライミングを参考に、LVLM を用いて言語タスクを解く際に、視覚情報を追加的に挿入することで言語タスクへの影響を調査する。実験の結果、言語タスクにおいて視覚情報を追加することで、精度と確信度の両方に変化が観測され、LVLM でもプライミング効果を確認でき、LVLM が言語タスクを扱う際でも視覚情報の影響を受けることが明らかとなった。
Q3:ポスター3月11日（火） 13:00-14:30   Q会場(1F会議室101AB),Q3-13,Large Vision Language Modelへの文書画像内テキスト埋め込みの検証,/proceedings/annual_meeting/2025/pdf_dir/Q3-13.pdf,"○會田 勇斗, 陳 実, 森長 誠, 近江 崇宏, 有馬 幸介 (ストックマーク)",Large Vision Language Model (LVLM) は近年急速に進化しており、文書画像理解のタスクにおいてもEnd-to-End で高い精度を達成している。一方で、GPT-4o クラスのモデルであっても画像内の文字認識誤りが発生することがあり、ビジネスでの実運用において課題となっている。本研究では、LVLM に文書画像内テキストを埋め込むことで、高精度な文書画像理解を実現することを目指す。既存のLVLMに文書画像内テキストをプラグイン的に埋め込む方式を提案し、その有効性を検証した。
Q3:ポスター3月11日（火） 13:00-14:30   Q会場(1F会議室101AB),Q3-14,漫画話者認識における VLM の有効性,/proceedings/annual_meeting/2025/pdf_dir/Q3-14.pdf,"○呂 博軒 (科学大/Mantra), 能地 宏 (Mantra)",本研究では，漫画におけるゼロショット話者認識という課題に取り組む．既存研究では，大規模言語モデルとコンピュータビジョンモデルを組み合わせた手法が提案されているが，複雑なパイプラインに依存し，必ずしも精度向上に貢献しないという課題がある．そこで本研究では，単一のVision andLanguage Model を活用した新たなゼロショット漫画話者認識手法を提案する．実験の結果，提案手法が既存手法を上回る精度を達成することを示す．興味深いことに，既存手法と提案手法における視覚情報の寄与を詳細に分析した結果，視覚情報が認識精度に及ぼす影響が限定的であることを明らかにする．
Q3:ポスター3月11日（火） 13:00-14:30   Q会場(1F会議室101AB),Q3-15,How Much Can Large Language Models Guide Body Movements of 3D Digital Human Agents?,/proceedings/annual_meeting/2025/pdf_dir/Q3-15.pdf,"○◊Kunhang Li, Jason Naradowsky (東大), Yansong Feng (北京大), Yusuke Miyao (東大)","We aim to explore the extent to which Large LanguageModels (LLMs) can guide 3D digital human agents inperforming body movements without supervised training.Given an existing human model and a textual instruction,we prompt the LLM to generate a high-level plan decom-posing the whole motion into consecutive steps, followedby specifying the positions of every body part in each step.We then render the animation by linearly interpolating theselected body part positions across steps.We evaluatethe generated animations from a diverse set of motion in-structions through both automatic and human evaluation,and ﬁnd that LLMs generally struggle to recognize accu-rate body part positions. Speciﬁcally, LLMs struggle withcomplex motions with multiple steps and body parts, andcomplex body parts with more possible positions."
Q3:ポスター3月11日（火） 13:00-14:30   Q会場(1F会議室101AB),Q3-16,A Study on Multi-modal Interaction in Vision Large Language Models,/proceedings/annual_meeting/2025/pdf_dir/Q3-16.pdf,"○◊魏 厚静, 趙 羽風, 石 鈺亭 (JAIST), 井之上 直也 (JAIST/理研)","Vision Large Language Models (VLLMs) usually takeinput as a concatenation of image token embeddingsand text token embeddings and conduct causal modeling.Based on observations, this paper hypothesizes that in-tensive multimodal interactions happen in the mid-to-latelayers. To verify, we apply cosine similarity measurementand norm-based attention analysis. Our experiments indi-cate that in the mid-to-late layers of LM decoder, there isa rise in inter-modal similarity and gradual accumulationin attention allocation to visual tokens, suggesting a four-phase inference dynamics against the LM layers, includingI) Alignment, II) Intra-modal Encoding, III) Inter-modalEncoding, and IV) Output Preparation."
Q3:ポスター3月11日（火） 13:00-14:30   Q会場(1F会議室101AB),Q3-17,Classifying the Relation Between Images and Text on Social Media Using Vision-Language Models,/proceedings/annual_meeting/2025/pdf_dir/Q3-17.pdf,"Edison Marrese-Taylor, ○◊Matiss Rikters (産総研)","Social media websites have had the option of multime-dia uploads for more than a decade now. However, therelation between the text and the posted images is not al-ways unambiguous if there is a relation at all. We explorehow multilingual vision-language models tackle the task ofimage-text relation prediction in diﬀerent languages, andprepare dedicated balanced benchmark data sets from Twit-ter posts in Latvian and English. We compare our resultsto previous work and show that the more recently releasedvision-language model checkpoints are becoming increas-ingly capable at this task, but there is still much room forfurther improvement. Experiments with in-context learn-ing outline how further improvements can be achieved."
Q3:ポスター3月11日（火） 13:00-14:30   Q会場(1F会議室101AB),Q3-18,Stable Diffusion を利用したシンボルマーク画像の生成,/proceedings/annual_meeting/2025/pdf_dir/Q3-18.pdf,"○藤本 竜也, 竹内 孔一 (岡山大)",デザイン会社などで多くのデザイン画像が蓄積されている一方で，近年のStable Diﬀusion1）をはじめとするDiﬀusion モデル[1] を利用した言語から画像を生成する研究が発展している．本研究では既存のデザインデータを利用することで，目的に応じた新たなデザイン画像を生成する手法について研究する．第一段階として本稿では，デザイン画像として，シンボルマークに注目し，Diﬀusion モデルにシンボルマークと関連するテキストを学習させた場合の画像の出力についてどの程度反映されているかを明らかにする．約770 件程度のシンボルマークデータを学習させた結果，学習したデータの画像に近い絵を出力するようになったが，一方で，現段階ではデザイン画像として利用できない点があることを明らかにする．
Q3:ポスター3月11日（火） 13:00-14:30   Q会場(1F会議室101AB),Q3-19,動画データと画像キャプション生成を用いた音とテキストペアの自動生成,/proceedings/annual_meeting/2025/pdf_dir/Q3-19.pdf,"○石川 裕地 (LINEヤフー/慶應大), 齋藤 主裕 (LINEヤフー), 青木 義満 (慶應大)","本研究では, 動画データと画像キャプション生成モデルを活用した, 音とテキストのペアデータの自動生成手法を提案する. 提案手法は3 段階で構成される. まず, 画像キャプション生成モデルを用いて動画のフレームごとにキャプションを生成する. 次に,これらのキャプションの選択/統合により動画全体を説明するキャプションを作成する. 最後に, 生成されたキャプションと音データのペアに対して, CLAPによる類似度計算を用いてフィルタリングを行うことで, 高品質な音とテキストのペアを自動的に生成する. ClothoV2 とAudioCaps を用いたlanguage-basedaudio retrieval タスクでの評価実験では, 提案手法で生成したデータによる学習が, 人手でアノテーションされたデータと同等の性能を達成することを確認した."
Q3:ポスター3月11日（火） 13:00-14:30   Q会場(1F会議室101AB),Q3-20,Open-source Human Evaluation Framework for Video-to-Text and Video-to-Audio Systems,/proceedings/annual_meeting/2025/pdf_dir/Q3-20.pdf,"○◊Goran Topic (産総研), Graham Neubig (CMU), Katsuhito Sudoh (奈良女子大), Yuki Saito (東大), Shinnosuke Takamichi, Ryosuke Matsushita (慶應大), Kota Iura (東大), Hiroya Takamura, Tatsuya Ishigaki (産総研)","We present a framework that streamlines the preparationof human evaluation process for text or audio automaticallygenerated from video. In such evaluation tasks evaluatorsoften assess the generated text or audio while watching avideo. Consequently, preparing for these evaluations canbe highly resource-intensive because the process typicallyinvolves several steps cutting a video and audio segments,synthesizing speech with text-to-speech tools, merging au-dio and video, and developing a user interface for crowd-sourcing annotation collection. Our framework automatesthese steps, reducing the researchers’ workload."
Q3:ポスター3月11日（火） 13:00-14:30   Q会場(1F会議室101AB),Q3-21,日本語小論文自動採点システムに関する画像データの活用,/proceedings/annual_meeting/2025/pdf_dir/Q3-21.pdf,"○森本 仁, 竹内 孔一 (岡山大)",本研究では，テキストの答案データと同時に画像の答案データを入力として利用した場合の自動採点システムの効果について議論する．テキスト特徴量と画像特徴量を直接分類層に入力するモデルとLLaVA モデルの二つのモデルを作成し，BERT のみを利用したモデルとの比較実験を行った．その結果，文法能力について評価を行っている文書力については画像を取り込むことで一部の課題において評価精度が向上した．また画像データによるモデルの性能向上の原因として答案の長さの影響が示唆される実験結果を得た．
Q3:ポスター3月11日（火） 13:00-14:30   Q会場(1F会議室101AB),Q3-22,Paper2Poster: LLMを用いた学術ポスターの生成,/proceedings/annual_meeting/2025/pdf_dir/Q3-22.pdf,"○増田 大河 (中部大/オムロンサイニックエックス), 田中 翔平, 平澤 寅庄, 牛久 祥孝 (オムロンサイニックエックス)",学術ポスターは文章と図表を組み合わせて研究内容をまとめたポスターであり，論文の概要を短時間で理解するのに効果的なフォーマットである．従来の学術ポスターの自動生成に関する研究は主にレイアウトの生成を目的としており，コンテンツも含めた生成は行っていない．そこで本研究では，学術ポスターに含まれる文章や図表，レイアウトをLLMを用いて段階的に予測することで，学術ポスター全体を生成するPaper2Poster システムを構築した．定量的および定性的な評価結果より，構築したシステムは整列されたオーバーラップのない，視覚性に優れたポスターを生成可能であることがわかった．
Q3:ポスター3月11日（火） 13:00-14:30   Q会場(1F会議室101AB),Q3-23,llm-jp-eval-mm: 日本語視覚言語モデルの自動評価基盤,/proceedings/annual_meeting/2025/pdf_dir/Q3-23.pdf,"○前田 航希 (科学大/NII), 杉浦 一瑳 (京大/NII), 小田 悠介, 栗田 修平 (NII), 岡崎 直観 (科学大/NII)",視覚言語モデル（VLM）の研究は急速に進展しているが，日本語の視覚言語（V&L）タスクにおける評価環境は未だ十分に整備されていない．その結果，日本語評価データセットは散逸し，網羅的な性能評価をすることは困難な状態にあった．本研究では，日本語性能に関する複数のマルチモーダル課題を統一した環境で評価するためのツールキットllm-jp-eval-mm を提案する．本ツールキットは既存の6 つの日本語マルチモーダル課題を統合し，モデル出力を複数の指標で一貫して評価するベンチマーク基盤である．本稿はllm-jp-eval-mm の構築と継続的な開発のための設計概要を述べ，公開されている
Q3:ポスター3月11日（火） 13:00-14:30   Q会場(1F会議室101AB),Q3-24,動画キャプション生成におけるマルチモーダル LLM のハルシネーション分析,/proceedings/annual_meeting/2025/pdf_dir/Q3-24.pdf,"○仲田 勝太, 近藤 雅芳 (LINEヤフー)",本研究は、動画キャプション生成タスクにおけるマルチモーダルLLM のハルシネーションの分析を行う。また、ハルシネーション分析に向けて、モデル生成文に対する誤り区間のスパンとそのスパンの修正を付与した新しいデータセットを構築した。分析は言語情報と視覚情報の２つの観点から行い、誤りパターンの分析や動画の明るさや動きといった視覚的要因との関連性に注目した分析を行う。分析結果から、モデルの生成文は入力動画の視覚情報よりもマルチモーダルLLM のDecoder の影響を強く受けた文表現となることや、動画の明るさが大きいほどハルシネーションが生じやすい傾向にあることなどが分かった。
Q3:ポスター3月11日（火） 13:00-14:30   Q会場(1F会議室101AB),Q3-25,VLMによるソフトウェア図表の理解に関する予備調査,/proceedings/annual_meeting/2025/pdf_dir/Q3-25.pdf,"○高橋 舞衣, 小原 有以, 中澤 初穂 (日本女子大), 秋信 有花, 倉林 利行 (NTT), 倉光 君郎 (日本女子大)",近年，ソフトウェア開発においてLLM の活用が注目されている．しかし，視覚的な情報を扱えないLLM にテキストのみで開発における複雑な情報を正確に伝えるのは難しい．一方，ソフトウェア開発現場では，要件定義や設計を効率的に行うために，UML ダイアグラムなどの視覚的情報が広く利用されてきた．視覚的情報を活用することで，テキスト主体のLLM の限界を補い，より実用的な支援が期待できる．そのため，視覚的情報とテキストを統合理解するVLM の導入が求められる．しかし，現状のVLM がソフトウェア開発における図表をどの程度理解できるのかは不明である．本研究では，VLMのソフトウェア開発における図表理解能力の調査を目的として，これらの図表に特化したベンチマーク「JSWEMU」を開発した．本論文では，JSWEMU を用いた調査結果について述べる．
A4:NLPモデルの評価・安全性・信頼性(4)3月11日（火） 14:50-16:20   A会場(2Fコンベンションホール1+2),A4-1,大規模言語モデルのための日本語安全性境界テスト,/proceedings/annual_meeting/2025/pdf_dir/A4-1.pdf,"○黒澤 友哉, 高山 隼矢, 綿岡 晃輝, 小林 滉河 (SB Intuitions), 浅原 正幸 (国語研/総研大), 西内 沙恵 (北教大)",大規模言語モデル(LLM) における倫理観の調整は、有用性とのトレードオフを伴う。過剰に安全性を優先したLLM では、無害なプロンプトに対して応答を拒否する事例が確認されており、このような境界領域の分析や評価は、安全性強化において重要である。しかし、日本語においてこうした過剰な拒否がどのような条件下で発生するのかについては、体系的な調査や評価手法が十分に確立されていない。本研究では、LLM にとって安全性と有用性の境界付近に位置するケースを網羅的に整理し、各ケースに対するモデルの応答を評価する「日本語安全性境界テスト」を提案する。本データセットを用いて
A4:NLPモデルの評価・安全性・信頼性(4)3月11日（火） 14:50-16:20   A会場(2Fコンベンションホール1+2),A4-2,SIPeN: パーソナルナラティブから構築された尺度推意ベンチマーク,/proceedings/annual_meeting/2025/pdf_dir/A4-2.pdf,"○佐野 朗人, 土井 智暉, 綿引 周, 谷中 瞳 (東大)","心の理論とは, 他者の心の状態や意図を理解する能力である. 近年, 大規模言語モデル（LLM）の発展に伴い, その能力を評価するための分析が進められている. その中でも, 尺度表現に対して聞き手が文字通りの意味を超えた推論を行う「尺度推意」は注目される課題の一つである. しかし, これまでの研究では, 自然なテキストに基づく評価は十分に行われていなかった. そこで本研究では, 尺度推意に関する自然なテキストデータセットを構築し, LLM の尺度推意の推論能力を評価する. 結果から, GPT-4o, Llama"
A4:NLPモデルの評価・安全性・信頼性(4)3月11日（火） 14:50-16:20   A会場(2Fコンベンションホール1+2),A4-3,敵対的事例に対する日本語処理モデルの頑健性向上の試み,/proceedings/annual_meeting/2025/pdf_dir/A4-3.pdf,"○秋本 一樹, 森本 文哉, 小野 智司 (鹿大)",深層ニューラルネットワーク（Deep NeuralNetwork: DNN）は，微小な変更が加えられた入力データである敵対的事例（Adversarial Examples: AE）を誤認識してしまう脆弱性が存在する．日本語処理用のDNN も同様の脆弱性が存在し，このような脆弱性は，DNN を実世界の課題に応用する上で重大な障害となり得る．本研究では，AE に対する日本語処理モデルの頑健性向上を目的とし，日本語に特化した再攻撃による敵対的防御手法を提案する．実験により，提案手法が通常事例の分類精度を維持しつつ，AE の矯正を行えることを確認した．
A4:NLPモデルの評価・安全性・信頼性(4)3月11日（火） 14:50-16:20   A会場(2Fコンベンションホール1+2),A4-4,大規模言語モデルにおける社会的バイアスの抑制と文化的常識の理解のトレードオフの分析,/proceedings/annual_meeting/2025/pdf_dir/A4-4.pdf,"○山本 泰成, 九門 涼真 (東大), Danushka Bollegala (UOL), 谷中 瞳 (東大)",社会的バイアスと文化的常識はどちらも社会に根付いた規範や価値観の理解に関するものであり，密接に関わる．これまで，大規模言語モデルの持つ社会的バイアスの抑制手法において，モデルの他の側面への影響は一般的な能力を測るタスクで評価されてきた．しかし，より関連が深い問題である文化的常識への影響については考慮されていない．本研究ではモデルが持つ社会的バイアスと文化的常識の両方を評価するデータセットを提案する．実験ではプロンプトによる社会的バイアス抑制手法が与える，文化的常識に基づく推論性能への影響を検証する．実験の結果，モデルの社会的バイアスの抑制と文化的常識理解タスクの性能低下には相関が見られた．注意: 本論文には差別的な表現が一部含まれます．
A4:NLPモデルの評価・安全性・信頼性(4)3月11日（火） 14:50-16:20   A会場(2Fコンベンションホール1+2),A4-5,コーパスの逆蒸留,/proceedings/annual_meeting/2025/pdf_dir/A4-5.pdf,"○盧 慧敏 (東大), 磯沼 大 (東大/エディンバラ大/NII), 森 純一郎 (東大/理研), 坂田 一郎 (東大)",本稿では、学習データ蒸留を逆向きに適用する学習データの逆蒸留を導入し、大規模言語モデルへの応用について議論する。学習データの逆蒸留では、ある学習データがもたらすモデルの変化と逆の変化をもたらす学習データを生成する。例えば有害な文章を含むコーパスを逆蒸留することで、モデルから有害な表現を忘却させる学習データが得られる。本稿では、一般的なコーパスに適用可能な、非常に軽量・単純な逆蒸留手法を導入し、モデルの有害性除去を例にその有効性を検証した。逆蒸留された文章が、有害性を除去するための学習データとして機能することを、様々なモデルを通じて示した。
A4:NLPモデルの評価・安全性・信頼性(4)3月11日（火） 14:50-16:20   A会場(2Fコンベンションホール1+2),A4-6,大規模言語モデルの法廷通訳への導入可能性の検証,/proceedings/annual_meeting/2025/pdf_dir/A4-6.pdf,"○山岸 聖子, 神藤 駿介 (東大), 宮尾 祐介 (東大/NII)",外国人被告人が公正な裁判を受ける権利を保障するためには法廷通訳人の存在が必要不可欠であるが、その人数は年々減少傾向にあり、また、国家資格が存在しないため通訳の質の保証の問題も抱えている。本研究では、大規模言語モデルを用いた法廷通訳並びにチェック・インタープリターの実現可能性を検証する。法廷通訳能力の検証のためのデータセットの作成および評価基準の策定を行い、3 種類の機械翻訳システムの検証を行った。実験の結果、特にGPT-4o による訳文は法的等価性を高い水準で維持できる一方で、法律用語や疑問文の訳出エラー、日本の司法制度に関する知識の不足といった課題もあることが分かった。
B4:心理言語学・認知モデリング(2)3月11日（火） 14:50-16:20   B会場(1F会議室102),B4-1,アテンションが記憶想起の認知モデルたりうるならば、記憶の表現としては何が妥当か？,/proceedings/annual_meeting/2025/pdf_dir/B4-1.pdf,"○吉田 遼, 磯野 真之介, 梶川 康平, 染谷 大河 (東大), 杉本 侑嗣 (阪大), 大関 洋平 (東大)","近年の計算心理言語学では、アテンションの人間の記憶想起のモデルとしての妥当性が検証されている。しかし、Transformer のアテンションが扱う表現の単位はトークンであるのに対し、伝統的に計算心理言語学では人間の文処理は統語構造の構築を伴うとされてきた。本研究では、統語構造を表現単位として扱うTransformer (Transformer Grammar, TG) のアテンションが、人間の記憶想起のモデルとして妥当なのかを検証する。結果、TG のアテンションはTransformer を上回る読み時間の説明力を達成し、アテンションの記憶想起アルゴリズムとしての妥当性を裏付けるとともに、統語構造を表現単位として想定することの重要性を示した。"
B4:心理言語学・認知モデリング(2)3月11日（火） 14:50-16:20   B会場(1F会議室102),B4-2,大規模マルチモーダル言語モデルによる認知症の言語症状の再現,/proceedings/annual_meeting/2025/pdf_dir/B4-2.pdf,"○山越 貴耀, 青山 龍平 (東大), 荒牧 英治 (NAIST), 大関 洋平 (東大)","認知症の言語症状は患者の予後やQOL を規定するが, その発症メカニズムは未解明である. 近年の言語モデルを用いた研究は, 主に言語表出の分類に重点を置き, 病因を直接的に検討するものは少ない.そこで本研究は言語モデルを生成モデルとして捉え, 単語の出現確率を変化させるパラメータを操作することで, 認知症特有の単語選択や言語構造の再現を試みた. 結果として, 係り受け距離や一部の品詞の頻度においては再現ができた一方, 意味情報量の点においては認知症患者の言語表出とは逆の傾向が得られた. 本研究は言語モデルを用いて認知症患者の言語表出そのものを再現することで, 認知症の言語症状の発症メカニズムの解明につながると期待される."
B4:心理言語学・認知モデリング(2)3月11日（火） 14:50-16:20   B会場(1F会議室102),B4-3,大規模言語モデルによる失語症の単語産出シミュレーション,/proceedings/annual_meeting/2025/pdf_dir/B4-3.pdf,"○森田 早織, 原田 宥都 (東大), 直江 大河, 沖村 宰 (昭和大), 大関 洋平 (東大)",本研究では、日本語生成モデルllm-jp-3-13B-instruct に構造化Pruning を適用し、失語症の言語症状の再現可能性を検証した。結果、高頻度語が低頻度語よりも復唱タスクにおいて高い正答率を示し、失語症者に見られる高頻度語保持の傾向と一致する可能性が示唆された。また、層ごとのPruning が出力に与える影響を目標語と出力語のコサイン類似度にて評価した結果、一部のモデルで目標語との意味的類似性が観察され、意味性錯語に近い現象が確認された。これにより、LLM のPruning が失語症者の発話特徴の再現や回復過程のシミュレーションに応用できる可能性が示された。本研究は、失語症の病態の機序解明やリハビリ手法の開発など、臨床応用できる可能性を示した点で意義深いと考えられる。
B4:心理言語学・認知モデリング(2)3月11日（火） 14:50-16:20   B会場(1F会議室102),B4-4,失語症者向け意思疎通支援者の会話方略の評価,/proceedings/annual_meeting/2025/pdf_dir/B4-4.pdf,"○嶋﨑 百音, 森田 亜由美, 葛西 有代, 木山 幸子 (東北大)",本研究では、失語症者向け意思疎通支援者（以下支援者）と実践経験豊富な言語聴覚士（以下ST）が使用する会話方略を比較し、新たに活動を始める支援者や訓練未経験者が習得しにくい会話態度・技術について検討した。支援者とST のそれぞれが失語症のある方と対面で会話をする様子を録画し、それを成人の日本語母語話者
B4:心理言語学・認知モデリング(2)3月11日（火） 14:50-16:20   B会場(1F会議室102),B4-5,言語モデルの事前学習におけるバリエーションセットの効果,/proceedings/annual_meeting/2025/pdf_dir/B4-5.pdf,"○芳賀 あかり (NAIST), 深津 聡世 (東大), 大羽 未悠 (NAIST), Arianna Bisazza (フローニンゲン大), 大関 洋平 (東大)",近年，子供向けの発話（CDS）が言語モデル（LM）の学習効率を向上させる可能性が示唆されている．しかし，CDS のどの特性がLM の学習に有効であるかは明らかになっていない．本研究では，CDS の一つの特徴であるバリエーションセット（VS）に着目し，VS がLM の学習に与える影響を調査する．具体的には，人工的に作成したVS を含む学習データを用いてGPT-2 の事前学習を行った．その結果，文法の学習と自然言語理解において，学習データ中のVS の存在がモデルの性能向上に貢献する可能性を示した．これらの結果から，VS がLM の学習効率向上に有益であることが示唆される一方，効果の詳細を解明するためのさらなる調査が必要である．
B4:心理言語学・認知モデリング(2)3月11日（火） 14:50-16:20   B会場(1F会議室102),B4-6,作業記憶の発達的特性が言語獲得の臨界期を形成する,/proceedings/annual_meeting/2025/pdf_dir/B4-6.pdf,"○三田 雅人 (東大/サイバーエージェント), 吉田 遼, 深津 聡世, 大関 洋平 (東大)","大規模言語モデル（LLM）は汎用的な言語能力を持つが，言語獲得効率では人間と大きな乖離がある．本研究では，人間が特定の時期において言語獲得が特に効率的に進むとされる臨界期における作業記憶の発達的特性を言語モデルに組み込む手法を提案した．提案手法では，学習初期に“作業記憶” を制限し, 学習が進むにつれて指数関数的に制限を緩和する仕組みを導入する．文法評価ベンチマークで性能を評価した結果，提案手法は従来手法を上回る性能を示し，特に，局所的な規則性と文全体の複雑な関係を含む文法項目で顕著な改善が見られた．これらの知見は，データ効率の高いLLM 設計の新たな指針を提供するだけでなく，人間の言語獲得における臨界期仮説を支持する重要な間接証拠となる．"
C4:マルチモーダル(2)3月11日（火） 14:50-16:20   C会場(1F会議室103),C4-1,早期うつ状態検出のためのマルチモーダル対話データセットに基づくうつ状態検出モデルの性能評価,/proceedings/annual_meeting/2025/pdf_dir/C4-1.pdf,"○柏原 功太郎, 高鍋 俊樹 (徳島大), 木内 敬太 (JOHAS), 梅原 英裕, 入澤 航史, 中瀧 理仁, 沼田 周助, 康 シン, 吉田 稔, 松本 和幸 (徳島大)","ストレスや不安によるうつ病が世界的に増加しており, 日本でも深刻な問題となっている. しかし, カウンセラーや精神科医の不足により早期発見が困難である. 本研究では, 我々の研究グループで構築しているカウンセリング面談時の言語・音声・動画・心拍及びアンケートデータから成るデータセットを用いて, 最新のMamba ベースのマルチモーダルうつ状態検出モデルの学習・評価を行った. その結果, 既存の大規模データセットを用いた事前学習と本データセットでの微調整が, モデル性能の向上に効果的であることが分かった."
C4:マルチモーダル(2)3月11日（火） 14:50-16:20   C会場(1F会議室103),C4-2,A Survey of MultiModal Large Language Models,/proceedings/annual_meeting/2025/pdf_dir/C4-2.pdf,"○◊Yahan Yu (京大), Duzhen Zhang (MBZUAI), Chenhui Chu (京大)","In recent years, MultiModal Large Language Models(MM-LLMs) have undergone substantial advancements,augmenting oﬀ-the-shelf LLMs to support MM inputs oroutputs via cost-eﬀective training strategies. In this paper,we provide a survey aimed at facilitating further researchon MM-LLMs. We outline general design formulationsfor model architecture. Furthermore, we review the perfor-mance of selected MM-LLMs on mainstream benchmarksand explore future directions. More latest developments inthis ﬁeld are provided in a real-time tracking website.1）Wehope that this survey contributes to the ongoing advance-ment of the MM-LLMs domain."
C4:マルチモーダル(2)3月11日（火） 14:50-16:20   C会場(1F会議室103),C4-3,VLMを用いたドメイン特化生成画像の定量評価,/proceedings/annual_meeting/2025/pdf_dir/C4-3.pdf,"○岡部 健太, 遠藤 隆夫, 石上 将太郎, 中村 光貴, 仁平 雅也, 乙村 浩太郎, 羽藤 淳平 (三菱電機)",視覚言語モデル（VLM）の進歩に伴い，画像品質評価においてVLMを用いることが注目されている．また，製造業では製品の外観検査において異常画像の数が少ないため精度の高い異常検知モデルの開発が難しく，異常画像を生成できるドメイン特化画像生成AI の需要が高い．そこで本研究ではVLM を用いてドメイン特化生成画像の定量評価を行い，その妥当性を検証した．VLM により生成画像を定量評価し，既存評価値や官能評価値との相関を分析した結果，特に形状，色，テクスチャの観点でVLM によるドメイン特化生成画像の定量評価の可能性を示した．また，参照画像や生成画像同士の相対評価を行うことで，精度の高い評価が可能となることを示唆した．
C4:マルチモーダル(2)3月11日（火） 14:50-16:20   C会場(1F会議室103),C4-4,画像言語モデルにおけるハルシネーションの発生とVisual Attention精度の関係の調査,/proceedings/annual_meeting/2025/pdf_dir/C4-4.pdf,"○富田 雅代, 林 克彦, 金子 知適 (東大)",画像言語モデルは、与えられた画像と矛盾する出力を生成することが報告されている。この現象はハルシネーションと呼ばれ、画像言語モデルの信用を損ない、普及を阻害する要因となっている。しかし、ハルシネーションの発生と、画像言語モデルがテキスト生成時に画像の適切な領域へ注目しているかどうかは関連すると予想されるが、データでは示されていない。本研究では、ハルシネーションの有無に関する評価指標であるPOPE を用い、画像内に実際に写っている物体と写っていない物体を対象として、ハルシネーションの発生と画像内の注目領域との関係を検証する。
C4:マルチモーダル(2)3月11日（火） 14:50-16:20   C会場(1F会議室103),C4-5,マルチモーダル大規模言語モデルにおける工業製品画像の認識性能調査,/proceedings/annual_meeting/2025/pdf_dir/C4-5.pdf,"○遠藤 隆夫, 岡部 健太, 石上 将太郎, 中村 光貴, 仁平 雅也, 乙村 浩太郎, 羽藤 淳平 (三菱電機)",VLM の工業製品画像に対する認識性能を調査するため，MVTec-AD データセットに含まれる15 種類の工業製品画像を使いVQA タスクを実施した．実験では，VLM に被写体とその状態に対する質問と回答の選択肢を入力し，VLM の回答の再現率を評価した．その際，参考画像を与える場合と与えない場合の二通りを評価した．被写体に関する質問では，参考画像を与えなくても高い再現率となる製品があることや，参考画像を与えることで再現率が上昇する製品があることを確認した．一方で，参考画像を与えることでかえって再現率が低下する製品も存在した．被写体の状態に関しては，参考画像を与えることで回答の再現率は上昇する傾向があるが，全体的には被写体を回答することに比べ再現率は低いことを確認した．
C4:マルチモーダル(2)3月11日（火） 14:50-16:20   C会場(1F会議室103),C4-6,オープンLLMによる翻訳を活用した日本語CLIPの開発,/proceedings/annual_meeting/2025/pdf_dir/C4-6.pdf,"○杉浦 一瑳 (京大/NII), 栗田 修平, 小田 悠介 (NII), 河原 大輔 (早大/NII), 岡崎 直観 (科学大/NII)","CLIP は視覚言語モデルのコンポーネントとして採用される事例が増えており, 重要性が増している. しかし, オープンな日本語画像・テキスト対データセットは不足しており, モデル開発の障壁となっている. 本研究では, オープンLLM を用いた機械翻訳により, 20 億事例の日本語画像・テキスト対データセットを構築し, 日本語CLIP を学習した. 学習済みモデルの性能を, 7 つの評価データセットを用いて評価した結果, 平均スコアが同程度のモデルサイズにおいて高水準であった一方, 日本文化に関するタスクの性能が低いことがわかった. 学習済みモデル1）2）, 学習データセット3）, 翻訳ツール4）, 評価コード5）は公開する."
D4:テーマセッション2: 人とAIの共生に向けた対話システム・言語使用の研究(3)3月11日（火） 14:50-16:20   D会場(1F会議室107),D4-1,Improving an Assistive Robot's Conversations using Large-Language Model-driven Episodic Memory,/proceedings/annual_meeting/2025/pdf_dir/D4-1.pdf,"○◊Angel Fernando Garcia Contreras (理研), Wen-Yu Chang (台湾大), 河野 誠也 (理研), Yun-Nun Cheng (台湾大), 吉野 幸一郎 (理研)","Robotic cognition is a field that in recent times hasmade strides in developing more comprehensive and help-ful embodied agents. One topic in the field that remainschallenging is that of long-term memory, particularly life-long learning in real-world environments, where a robotmust process large amounts of multimodal, potentially in-complete, frequently uncertain information in or near real-time. Our team has encountered such a challenge as wedevelop Indy, a companion robot that aims to interact andlearn from complex, human-centric environments. Our at-tempt at tackling these challenges is a tiered framework in-spired by cognitive psychology, in which relevant and use-ful knowledge is compiled and retained for progressivelylonger time spans while incidental observations are ‘‘for-gotten’’ using a decay mechanism also inspired by cogni-tive psychology studies. In this work, we show a proof ofconcept for a ‘‘Narrative Memory,’’ in which Indy storesepisodic memory of its conversations with users as first-person dialog summaries and salient observations; these‘‘narrative memories’’ are ‘‘forgotten’’ through progres-sively shorter summarization.We use Large-LanguageModels (LLMs) to generate such memories and sum-maries, while also demonstrating their use in conversationthrough an LLM-driven dialogue demo in which Indy can‘‘recall’’ its past conversation topics."
D4:テーマセッション2: 人とAIの共生に向けた対話システム・言語使用の研究(3)3月11日（火） 14:50-16:20   D会場(1F会議室107),D4-2,多面的なユーザ意欲を考慮したセールス対話データセットおよび対話システムの構築と評価,/proceedings/annual_meeting/2025/pdf_dir/D4-2.pdf,"○邊土名 朝飛, 馬場 惇, 佐藤 志貴 (サイバーエージェント), 赤間 怜奈 (東北大)",購買意欲を向上させるセールス対話システムを実現するためには多面的なユーザの意欲を考慮したデータセットが必要だが、既存データセットにはシステムの想定運用環境で収集された信頼性の高いユーザの意欲に関するデータが含まれていない。本研究では、想定運用環境に基づいた対話データ収集環境を開発し、3 種類のユーザ意欲データを含む日本語セールス対話データセットを構築した。ユーザ評価実験では、発話レベルでユーザの意欲を考慮し、さらにデータセット分析で得られたセールス対話戦略の知見を組み込むことが対話システムによる対話成功率の向上につながることが示唆された。§ github.com/CyberAgentAILab/salestalk-dataset
D4:テーマセッション2: 人とAIの共生に向けた対話システム・言語使用の研究(3)3月11日（火） 14:50-16:20   D会場(1F会議室107),D4-3,対話システムが共有する第三者情報に対するユーザの興味度推定モデルの構築,/proceedings/annual_meeting/2025/pdf_dir/D4-3.pdf,"○金山 凜吾, 三野 星弥, 石黒 浩, 吉川 雄一郎 (阪大)",継続的にユーザと関わる非タスク指向型対話システム実現のため，対話中にシステムが第三者情報をうわさとして共有する手法が注目されている．この手法によりシステムへの満足度を向上させるためには，第三者情報を共有する際に，ユーザにとってより興味深い内容を選択することが重要であると考えられる．本研究では，ユーザにとって興味度の高い情報を共有する対話システム実現の第一歩として，様々な第三者情報に対するユーザの興味度を推定するモデルの構築を目指す．我々は，独自に作成した第三者情報の興味度データセット1）を用いて，GPT-4o をファインチューニングし，また，推定精度を高めるために多段階推定手法，ユーザ属性を考慮する手法を組み合わせることで，第三者情報についての興味度の推定精度をベースモデルよりも45.4%向上させたモデルを構築した．
D4:テーマセッション2: 人とAIの共生に向けた対話システム・言語使用の研究(3)3月11日（火） 14:50-16:20   D会場(1F会議室107),D4-4,大規模言語モデルによるポライトネス理論の検証,/proceedings/annual_meeting/2025/pdf_dir/D4-4.pdf,"○高橋 哲朗 (鹿児島大), 宇佐美 まゆみ (東京外大)",社会科学の分野で研究の蓄積があるポライトネス理論の検証を目的とし，対話コーパス中の発話における発話の丁寧さや，話者間の距離，力関係，発話内容の相手への負荷を大規模言語モデルにより推定した．推定結果を用いてフェイス侵害度と丁寧さを比較したところ実験に用いた120 対話のうち100 対話で有意な相関が見られ，これらの対話においてはポライトネス理論が示す通りの結果を確認できた．
D4:テーマセッション2: 人とAIの共生に向けた対話システム・言語使用の研究(3)3月11日（火） 14:50-16:20   D会場(1F会議室107),D4-5,心理臨床のカウンセラーと対話システムの比較：支援における「個別化の原則」に基づく予備的検討,/proceedings/annual_meeting/2025/pdf_dir/D4-5.pdf,○長岡 千賀 (追大),本研究は，支援の場で重視される「個別化の原則」の観点から，心理臨床のカウンセラーとChatGPT の共通点と相違点を予備的に検討した．熟練カウンセラーは主訴に関する専門的見立ての材料となる情報だけでなく，クライエントの価値観や特性などの個人特有の情報も重視する傾向があり，個別化の原則を高度に実践していることが推察された．一方，ChatGPT は，専門的見立ての材料となる情報を一貫して選択したが，個人特有の情報は選択せず，個別化の原則の点で課題があった．本結果に基づき，対話システム設計の方向性について考察した．
E4:テーマセッション6: 人文学と言語処理(4)3月11日（火） 14:50-16:20   E会場(1F会議室108),E4-1,線形判別分析の PU 学習による朝日歌壇短歌の分析,/proceedings/annual_meeting/2025/pdf_dir/E4-1.pdf,"○加藤 真大 (東大/みずほ第一フィナンシャルテクノロジー), 浦川 通, 田口 雄哉, 新妻 巧朗, 田森 秀明 (朝日新聞社), 羽根田 賢和, 坂口 慶祐 (東北大), 持橋 大地 (統数研)",本研究では，朝日歌壇に掲載されている短歌の特徴を，Fisher の線形判別分析を用いて調査する．どのような短歌が朝日歌壇に掲載されているのかを調査するために，比較の対象として生成モデルによって作成された短歌を用意する．生成短歌には，もし朝日歌壇に投稿されていたら掲載されるような短歌(正例) から，掲載されないような短歌(負例) まで，多様な短歌が幅広く含まれている．こうした朝日歌壇短歌と生成短歌に対して，本研究では従来の線形判別分析をPU 学習の枠組みに拡張した手法を提案し，朝日歌壇短歌を正例データ，生成短歌を正例と負例が混在するラベルなしデータとみなして，これらが混在するPU 学習の枠組みで分析を行った．
E4:テーマセッション6: 人文学と言語処理(4)3月11日（火） 14:50-16:20   E会場(1F会議室108),E4-2,データドリブンな文章構造と情報伝達の抽出手法,/proceedings/annual_meeting/2025/pdf_dir/E4-2.pdf,"○本那 真一, 村山 太一, 松井 暉 (横国大)",文章構造は，読者の注意喚起や興味喚起，理解・記憶の効率など，文章を評価する要素に大きな影響を与えるにもかかわらず，文章構造と評価との関係は明らかでない．本稿では，小説，Wikipedia 記事，学術論文，映画字幕といった多様な媒体を対象に，文章構造と評価の関係を定量的に分析した．具体的には，意味依存度の低い特徴量を抽出し，文章中の構造を捉え，評価に与える影響を検証した．その結果，評価が高い文章には特定の構造が顕著に見られることが明らかとなり，情報提示の順序や関係性が読者の評価に与える影響が確認された．これにより，効果的な文章作成や情報提示の設計において，媒体ごとの構造や転換タイミングを考慮する重要性を示すことができた．
E4:テーマセッション6: 人文学と言語処理(4)3月11日（火） 14:50-16:20   E会場(1F会議室108),E4-3,古事類苑の知識グラフ化と言語リソースとしての活用,/proceedings/annual_meeting/2025/pdf_dir/E4-3.pdf,"○上松 大輝 (総研大), 武田 英明 (NII), 山田 奨治 (日文研), 相田 満 (日本女子大)",本研究では，明治期に編纂された百科史料事典である「古事類苑」を知識グラフ化した．さらに，記載された事物やことがら，引用・参照される史料との関係性を元に，古事類苑の言語リソース，およびその基盤として活用方法を提案する．古事類苑は，類書の構造をもとに編纂されており，日本の和歌集や物語といった史料群を体系的に知ることのできる書物を目指して作成された．そこで，古事類苑を知識グラフ化し，さまざまな引用書と語の関係や，現代語との接続を行うことで，明治期に設定された語の分類，および古代から江戸時代までの書物との関連性を扱うことで，言語リソースとして古事類苑を利用可能とする．
E4:テーマセッション6: 人文学と言語処理(4)3月11日（火） 14:50-16:20   E会場(1F会議室108),E4-4,エイゼンシュテインのモンタージュに含まれる要素,/proceedings/annual_meeting/2025/pdf_dir/E4-4.pdf,○高橋 速巳 (カシェウェブレト),エイゼンシュテイン（1898 - 1948）がモンタージュについて述べているものの中に、「同じ」「類似」という要素が入っているかどうかを個別に判定した.調査は「モンタージュ」(1937)、「モンタージュ１
P4:ポスター3月11日（火） 14:50-16:20   P会場(2Fコンベンションホール3+4),P4-1,Bayesian Linear Mixed Model を用いた単語習得時期推定,/proceedings/annual_meeting/2025/pdf_dir/P4-1.pdf,○浅原 正幸 (国語研/総研大),本研究では『分類語彙表』全項目について単語習得時期を大規模クラウドソーシング調査で収集し、Bayesian Linear Mixed Model でモデリングを行った。同データはhttps://github.com/masayu-a/WLSP-SchoolGrade にて公開した。
P4:ポスター3月11日（火） 14:50-16:20   P会場(2Fコンベンションホール3+4),P4-2,大規模言語モデルにおける語彙関数知識の類推推論による検討,/proceedings/annual_meeting/2025/pdf_dir/P4-2.pdf,"楊 宇軒, ○郭 凱 (早大), 河野 優輝 (旭川工業高専), ルパージュ イヴ (早大)",本研究の目的は、意味・テキスト理論で定義されている語彙関数が、大規模言語モデルにおいてどの程度習得されているかを評価することである。複数のオープンソース大規模言語モデルを対象に、特定の語彙関数に関連するデータセットを用いたタスクを実行し、それらの正確率を統計的に分析した。実験結果から、大規模言語モデルは異なる語彙関数に対して正確率に明確な差があることを示した。このことは、モデルが異なる意味関係を理解する能力に違いがあることを示唆している。また、大規模言語モデルのサイズと正確率には強い相関関係が見られることも明らかになった。
P4:ポスター3月11日（火） 14:50-16:20   P会場(2Fコンベンションホール3+4),P4-3,ニューラル単語アライメントに基づく言い換え知識獲得,/proceedings/annual_meeting/2025/pdf_dir/P4-3.pdf,"○近藤 里咲, 梶原 智之, 二宮 崇 (愛媛大)",本研究では，ニューラル単語アライメントを用いて言い換え辞書の品質を改善する．大規模な言い換え知識獲得には，対訳コーパス上での単語アライメントに基づくBilingual Pivoting と呼ばれる手法が用いられてきた．そのため，Bilingual Pivoting で得られる言い換えの品質は単語アライメントの品質に依存する．既存の言い換え辞書は，統計的な単語アライメントに基づくBilingual Pivoting によって構築されており，単語の意味を考慮せずに言い換えを抽出しているため，獲得できる言い換えの品質に改善の余地がある．本研究では，ニューラル単語アライメントに基づくBilingual Pivoting を用いて，より高品質な言い換え知識獲得に取り組む．評価実験の結果，本研究で構築した言い換え辞書が適合率と再現率の両方で既存の日本語言い換え辞書を上回った．
P4:ポスター3月11日（火） 14:50-16:20   P会場(2Fコンベンションホール3+4),P4-4,日本語の関係節におけるWeak Crossover現象の非構造的要因を制御した経験的検証,/proceedings/annual_meeting/2025/pdf_dir/P4-4.pdf,"○福島 遥 (お茶大), Daniel Plesniak (SNU), 戸次 大介 (お茶大)",本研究では，Language Faculty Science の手法を基に，日本語の関係節におけるWeak Crossover 現象に関する仮説の検証を行った．英語での同様の検証では，非構造的要因を排除しても，関係節のWeakCrossover 構文における照応的解釈が容認されるという結果が得られた．しかし，英語の語順により，その結果が構造的要因と先行関係のどちらに依るものか不明であった．本研究では，日本語の語順を使用することで，関係節におけるWeak Crossover 構文おける照応的解釈が容認されるのは構造的要因に依るものである可能性が高いことが示された．
P4:ポスター3月11日（火） 14:50-16:20   P会場(2Fコンベンションホール3+4),P4-5,"Dispersion Measures as Predictors of Lexical Decision Time, Word Familiarity, and Lexical Complexity",/proceedings/annual_meeting/2025/pdf_dir/P4-5.pdf,"○Adam Nohejl, 渡辺 太郎 (NAIST)","Various measures of dispersion have been proposed topaint a fuller picture of a word’s distribution in a corpus,but only little has been done to validate them externally. Weevaluate a wide range of dispersion measures as predictorsof lexical decision time, word familiarity, and lexical com-plexity in ﬁve diverse languages. We ﬁnd that the logarithmof range is not only a better predictor than log-frequencyacross all tasks and languages, but that it is also the mostpowerful additional variable to log-frequency, consistentlyoutperforming the more complex dispersion measures. Wediscuss the eﬀects of corpus part granularity and logarith-mic transformation, shedding light on contradictory resultsof previous studies."
P4:ポスター3月11日（火） 14:50-16:20   P会場(2Fコンベンションホール3+4),P4-6,"In search of efficient, parsing-free encodings of word structure: efficacy comparison among n-grams, skippy n-grams and extended skippy n-grams against on noun classification tasks",/proceedings/annual_meeting/2025/pdf_dir/P4-6.pdf,○黒田 航 (杏林大),"This study explores eﬃcient, parsing-free methods forencoding word structure by comparing regular 𝑛-grams,skippy 𝑛-grams, and extended skippy 𝑛-grams in the con-text of inﬂectional classiﬁcation tasks for noun gender,plurality, and case. The classiﬁcation was tested on thenouns of four languages: Czech, French, German, andIrish. While the outcomes were mixed and complex, theﬁndings suggest that extended skippy 𝑛-grams (with orwithout boundary marking) outperform skippy 𝑛-grams,and skippy 𝑛-grams perform better than regular 𝑛-grams interms of classiﬁcation eﬃciency. This study provides evi-dence that (extended) skippy 𝑛-grams oﬀer a more eﬀectiveapproach for encoding word structure."
P4:ポスター3月11日（火） 14:50-16:20   P会場(2Fコンベンションホール3+4),P4-7,認知負荷の最適化戦略としての自由語順と項省略,/proceedings/annual_meeting/2025/pdf_dir/P4-7.pdf,"○梶川 康平, 磯野 真之介 (東大/国語研), 窪田 悠介 (国語研), 大関 洋平 (東大)",自由語順と項省略という統語現象には相関関係がみられる。つまり、言語ごとに、両方の現象が観察されるか、どちらも観察されないか、という傾向がある。では、なぜそのような文法相関が存在するのだろうか。本研究では、自由語順と項省略がみられる日本語に注目し、処理の効率性がこれらの特徴を形作っているのか検証する。具体的には、日本語のコーパスから、自由語順、項省略、またはその両方がないバージョンを作成し、現実のコーパスと比較する。その結果、自由語順かつ項省略が存在する言語は、記憶と予測の負荷を抑制する点で有利だと示された。
P4:ポスター3月11日（火） 14:50-16:20   P会場(2Fコンベンションホール3+4),P4-8,固有名詞の音象徴の機械学習による検討ーポケモンの名前を材料にしてー,/proceedings/annual_meeting/2025/pdf_dir/P4-8.pdf,"○新田 直弘, 久野 雅樹 (電通大)","音が特定のイメージを喚起する現象を音象徴という. 本研究では, 機械学習を用いて音象徴の分析を行うことを目的とした. 具体的には, 日本語のポケモン名を材料に, モデルを作成し, 進化前後の分類予測を行った. また, 作成したモデルにおける各音韻に対する重要度を分析した. その結果, 一定の性能で音象徴性を予測できることが確認された. さらに, 音韻の重要度の分析により, 従来から音象徴に影響を与えるとされる音韻がモデルに反映されていることが明らかになった一方で, 既存研究では注目されていなかった音韻も何らかの影響を及ぼしている可能性が示唆された."
P4:ポスター3月11日（火） 14:50-16:20   P会場(2Fコンベンションホール3+4),P4-9,認知言語学的イメージスキーマの生成と解釈における大規模言語モデルと画像生成モデルの評価,/proceedings/annual_meeting/2025/pdf_dir/P4-9.pdf,"○本田 恭平 (ブリヂストン), 松﨑 孝介, 吉田 遥音 (東北大), 坂口 慶祐 (東北大/理研)",イメージスキーマとは認知言語学において、認知プロセスに繰り返し現れるパターンを表現する図である。しかしこのパターンは人間が同定する必要があるため、全てを網羅的に発見することは困難であった。本研究では英語の動詞を対象に、大規模言語モデル（LLM）と画像生成モデルを用いたイメージスキーマの生成を行った。評価の結果、画像生成モデルでは生成が困難であったが、LLM はLaTeX（TikZ）のコードとして、人間とLLM 双方にとって解釈性の高いイメージスキーマを生成できることが示された。これはLLM を用いたイメージスキーマの網羅的発見の可能性を示唆するものである。
P4:ポスター3月11日（火） 14:50-16:20   P会場(2Fコンベンションホール3+4),P4-10,自閉スペクトラム症の眼球運動による言語モデルのファインチューニング,/proceedings/annual_meeting/2025/pdf_dir/P4-10.pdf,"○前田 ありさ, 大関 洋平 (東大)",自閉スペクトラム症（ASD）は、定型発達の人とは異なるコミュニケーションの取り方や行動パターンで特徴付けられる発達障害であり、文処理に困難が伴うことが多い。本研究では、ASD の文処理を理解し支援するために、ASD の人の文処理データを用いて言語モデルをファインチューニングするアプローチを提案する。このアプローチにより、ASD の人々の文処理の特徴を反映したモデルの構築が行われ、ASD の統語論処理能力に関する理解の深化や、ASD の人々の読解ニーズに応じた支援ツールの実現に向けた可能性が示唆された。
P4:ポスター3月11日（火） 14:50-16:20   P会場(2Fコンベンションホール3+4),P4-11,LLMはASD小児と定型発達小児が作成したストーリーを識別できるか？,/proceedings/annual_meeting/2025/pdf_dir/P4-11.pdf,"○河野 真有香, 平尾 悠太朗, Monica Perusquía-Hernández, 内山 英昭, 上垣外 英剛, 清川 清 (NAIST)",ASD の小児の言語や事物の認識を理解することは，彼らに対する支援の適切性の評価に重要である．当事者やその家族を対象とした研究や生物学的研究のほかに，工学的観点からヒトの模倣可能性が注目されているLLM を活用した研究がある．我々はこれらを組み合わせてASD の小児における言語認知メカニズムの解明を目指す．そのために，LLMに対してASD の小児のペルソナを与え，LLM にASD 様の振る舞いを再現させることを目指す．本稿では，LLM にASD の小児と定型発達の小児のストーリーを識別する能力があるかを調査した結果を報告する．ASD の小児が作ったストーリーを回答するという5 択のQA タスクにより，現状のLLMによる識別精度は22%であることを明らかにした．
P4:ポスター3月11日（火） 14:50-16:20   P会場(2Fコンベンションホール3+4),P4-12,社会的承認によって定義された心があるAI：評価方法と有効性の基礎検討,/proceedings/annual_meeting/2025/pdf_dir/P4-12.pdf,"○飯田 愛結, 大澤 正彦 (日大)","「""それ""であると認められることをもって、""それ""の定義を満たす」とする社会的承認という方法で定義された「心があるAI」の実現を目指す．そして人とAI 自身が「心がある」ことを認めるAI のつくりかたを考える．本論文では，社会的承認による定義やこの場合の評価方法の実現性，作成する人工物の有効性を議論する端緒を形成することを目的に，簡単な発話応答に対する評価を実施した．実験ではダニエルデネットの提唱する「設計スタンス」「意図スタンス」の考え方に基づく，設計発話/応答と意図発話/応答の組み合わせを作成し印象を調べた．"
P4:ポスター3月11日（火） 14:50-16:20   P会場(2Fコンベンションホール3+4),P4-13,埋め込みベクトルを用いた動詞の意味の粒度分析と共起関係,/proceedings/annual_meeting/2025/pdf_dir/P4-13.pdf,○森下 裕三 (桃山学院大),本研究では，埋め込みベクトルと頻度情報を基に移動動詞の粒度を定量化し、それと着点との共起傾向を検証する。これまでの研究では，移動事象における着点志向性が認知的に優位であり，言語にも反映されることが示されてきた。しかし，着点と共起しやすい動詞については主観的な議論にとどまっていた。本研究では，英語の移動動詞を対象に，COCA から抽出した用例を基に埋め込みベクトルを生成し、その分散の平均値と頻度から粒度を算出する手法を提案する。
P4:ポスター3月11日（火） 14:50-16:20   P会場(2Fコンベンションホール3+4),P4-14,アジア地域における英語学習者の英語使用の特徴,/proceedings/annual_meeting/2025/pdf_dir/P4-14.pdf,"○藤野 沙也加, 久野 雅樹 (電通大)",本研究では，アジア地域の英語学習者が書いたエッセイを対象に，各地域特有の言語使用の特徴を明らかにすることを目的とした．ICNALEコーパスの中級レベル（B1_1 およびB1_2）の「大学生のアルバイト」に関するエッセイデータを用い，TF-IDF でベクトル化したデータに基づきロジスティック回帰モデルで地域分類を実行した．モデルの正解率は0.74 であり，混同行列と使用単語の寄与度の分析から，各地域特有の語彙傾向が確認された．これは，文化的・教育的背景が特徴に影響を与えることを示している．
P4:ポスター3月11日（火） 14:50-16:20   P会場(2Fコンベンションホール3+4),P4-15,行為要求発話の修辞機能分析－親子会話におけるやり取りに着目して－,/proceedings/annual_meeting/2025/pdf_dir/P4-15.pdf,"○田中 弥生, 居關 友里子 (国語研)",談話分析手法の一つである「修辞機能分析」は，発話機能の分類と，主語や主題の分類と述部の時制の分類の組み合わせから修辞機能と脱文脈度を特定するものである．本研究は親子会話の発話に付与された談話行為情報のうち行為要求に分類されている発話の修辞機能を確認して，修辞機能分析と談話行為情報との関係を明らかにすることを試みた．その結果，典型的な行為要求の修辞機能だけでなく，間接的な表現がさまざまな修辞機能として用いられており，修辞機能分析の分類法によってこれらの観察ができることが明らかになった．
P4:ポスター3月11日（火） 14:50-16:20   P会場(2Fコンベンションホール3+4),P4-16,フレーム意味論に基づく言及先情報を含むSNS投稿の事実忠実度のアノテーション,/proceedings/annual_meeting/2025/pdf_dir/P4-16.pdf,"○遠田 哲史, 吉永 直樹, 豊田 正史 (東大)",SNS 投稿には他の投稿や外部サイトの情報に対して言及するものがあるが，言及先の情報が必ずしも投稿内に忠実に記述されるとは限らない．このような情報の変容は偽・誤情報の蔓延に繋がるため，投稿に含まれる事実表現が言及先に忠実であることを自動的に確認する手法の開発が大きな課題となっている．本研究では，SNS 上の情報伝播時における事実表現の累積的な改変の解明に向けて，フレーム意味論に基づいた自動要約システムのアノテーション枠組みを応用し，SNS 投稿内に含まれる事実表現に関する誤りの種類の分類を行う．データセットとしてニュース記事に言及する日本語X 投稿を人手でアノテーションし，分析を行う．結果として，全体の約1/3 に事実忠実度の観点での誤りが認められた．
P4:ポスター3月11日（火） 14:50-16:20   P会場(2Fコンベンションホール3+4),P4-17,大規模言語モデルとISAアプローチ,/proceedings/annual_meeting/2025/pdf_dir/P4-17.pdf,"○荒井 柚月, 津川 翔 (筑波大)","人間中心主義的に展開されてきた言語の哲学は、ChatGPT（OpenAI）、Claude（Anthropic）といった人間に比肩する言語的能力を持つとされる大規模言語モデル（Large Language Models, LLMs）の出現によって、脱人間中心主義化を迫られている。従来はその基礎的意味論として分布意味論があてがわれてきたLLM であるが、現在では、LLM の基礎的意味論として分布意味論以外の基礎的意味論を探る研究が続けられている。本発表は、言語の表象性という観点から、言語モデルに最適な基礎的意味論としてロバート・ブランダムの推論的意味論を提案し、推論的意味論の反表象主義性や論理的表出主義性が、LLM の性質や振る舞いを解釈する上で有用であることを示す。"
P4:ポスター3月11日（火） 14:50-16:20   P会場(2Fコンベンションホール3+4),P4-18,系列ラベリングを用いた日本語の比喩表現抽出,/proceedings/annual_meeting/2025/pdf_dir/P4-18.pdf,"○Ganbat Naranbuuvei, 尾崎 太亮, 古宮 嘉那子 (農工大), 浅原 正幸 (国語研/総研大)",本研究では、系列ラベリングの手法を用いて日本語の比喩表現をスパンレベルで抽出した。モデルにはBERT を使用し、コーパスにはBCCWJ-Metaphorコーパスを用いた。比喩表現一般を抽出するモデルと比喩表現の4 つの種類である結合比喩、文脈比喩、換喩、提喩それぞれを抽出するモデルの2 種類を作成した。さらに、各モデルの性能を評価し、エラー分析を行った。これにより、日本語の比喩表現の自動抽出とその課題を明らかにする。
P4:ポスター3月11日（火） 14:50-16:20   P会場(2Fコンベンションホール3+4),P4-19,BERT ベクトルを用いたオノマトペ由来の新動詞の検出,/proceedings/annual_meeting/2025/pdf_dir/P4-19.pdf,"○古宮 嘉那子, 宇野 良子 (農工大), 浅原 正幸 (国語研/総研大)",本稿では、BERT ベクトルを用いてオノマトペ候補の分析を行う。国語研日本語ウェブコーパスから
P4:ポスター3月11日（火） 14:50-16:20   P会場(2Fコンベンションホール3+4),P4-20,LLMのふるまいの理解における理想化された科学モデルの有用性について,/proceedings/annual_meeting/2025/pdf_dir/P4-20.pdf,"○平岡 太郎 (北大), 菅原 朔 (NII)",大規模言語モデル（以下LLM）の行う処理について、どのようにすれば理解可能な説明が与えられるか。LLM では処理のブラックボックス性が指摘されており、ベンチマークによる評価では処理機構が必ずしもわからず、出力の説明性が低い。本論文ではこの点を問題とし、それを解決する手段として科学モデルの概念が有用ではないかと指摘する。その上で、科学モデルが現象の理解をもたらす条件を確認し、どのようにすればLLM の行う処理について理解可能な説明が与えられるかを考察する。
P4:ポスター3月11日（火） 14:50-16:20   P会場(2Fコンベンションホール3+4),P4-21,言語モデルのふるまいと多重実現,/proceedings/annual_meeting/2025/pdf_dir/P4-21.pdf,"○坪井 祥吾 (一橋大), 菅原 朔 (NII)",大規模言語モデルが人間らしい言語的なふるまいを示すようになってきたことを受けて、言語モデルから人間の言語について何らかの示唆を引き出そうとする研究が増えてきている。他方、言語処理のメカニズムが言語モデルと人間とで大きく異なることを根拠に、この手の研究の妥当性が疑問視されることもある。本稿では、この議論の文脈に、科学哲学における「多重実現」という考え方を導入する。本稿は、この考え方を導入することで、この種の研究手法の妥当性を評価する際に考慮するべき、哲学的・概念的な論点を浮き彫りにすることを目指す。
P4:ポスター3月11日（火） 14:50-16:20   P会場(2Fコンベンションホール3+4),P4-22,分類語彙表の基本義を利用した日本語メタファー検出,/proceedings/annual_meeting/2025/pdf_dir/P4-22.pdf,"○ZHU HANG, 古宮 嘉那子 (農工大), 浅原 正幸 (国語研/総研大)",本研究では，分類語彙表の基本義を活用した日本語メタファー検出手法を提案する．メタファーは言語の認知的およびコミュニケーション機能において重要な役割を果たしているが，その自動検出には文脈内での表現の意味理解が必要となる．既存のメタファー検出モデルは主に英語を対象としており，日本語に特化したモデルは限られている．提案手法では，日本語BERT をベースに分類語彙表から得られる基本義情報とその用例文を活用し，対象単語の文脈的な意味と基本義の文脈的な意味を比較することでメタファーを検出する．基本義には，山崎らが作った基本義を利用する．また，手法にはBasicBERT を基本として利用し，基本義の用例はBCCWJ から取得する．本研究では，分類語彙表の基本義を活用した既存手法の日本語への効果的な適用により，日本語の比喩抽出を行った．評価はBCCWJ-Metaphor コーパスを用いた5 分割交差検証により行い，高精度な日本語メタファー検出の実現を目指す．
P4:ポスター3月11日（火） 14:50-16:20   P会場(2Fコンベンションホール3+4),P4-23,言語一般の計測を目指して: サブワードと分散意味論に基づく言語の複雑性計測,/proceedings/annual_meeting/2025/pdf_dir/P4-23.pdf,○中山 拓人 (慶應大),本研究は，「あらゆる言語は等しく複雑である」という，いわゆる言語の等複雑性について，単位形式系列当たりの語義数とその出現確率の偏りを通して，言語の複雑性を計測を試みる．このために，BERT を用いたサブワードへの分割や分散表現を利用している．12 言語1）を対象とし，ランダムサンプリングしたWikipedia の100 記事をデータとして，各言語につき4 回の分析を行った．結果として，全体的には単位形式系列当たりの語義数に大きな差が見られなかった．一方で4 回の分析に渡って，各言語はそれぞれ非常に近い値を示すことが多かった. このことから言語の複雑性は，非常に狭い領域に収ま理ながら，その領域内で各言語が特有の傾向を持つことが示唆される．
P4:ポスター3月11日（火） 14:50-16:20   P会場(2Fコンベンションホール3+4),P4-24,言語研究における科学的理解と言語モデル,/proceedings/annual_meeting/2025/pdf_dir/P4-24.pdf,"○鈴木 陽登 (慶應大), 菅原 朔 (NII)",近年の大規模言語モデルの急速な発展を受けて、言語研究の領域では言語モデルの言語学的・科学的な意義について活発な議論が行われている。しかし、そのような議論において、各々の研究者が（自身がすでに受け入れている）特定の理論的前提に基づいて必ずしもフェアとは言えない主張を展開している場面がしばしば見受けられる。このような背景から、本稿では、言語モデルの科学的理解への貢献を評価する際に考慮すべき要件を、科学哲学における文脈主義の立場を援用しつつ明確化することを目的とする。そして、文脈主義の枠組みに基づき、言語研究における言語モデルの有用性を評価するためには、(1) 理解の対象は何か、(2) 使用する理論は何か、(3) 理論の使用者は誰かの3 点を考慮する必要があると主張する。
P4:ポスター3月11日（火） 14:50-16:20   P会場(2Fコンベンションホール3+4),P4-25,文学批評から大規模言語モデルへ―単語埋め込みの組み換えによる文学テクスト解釈の試み,/proceedings/annual_meeting/2025/pdf_dir/P4-25.pdf,○橋本 健広 (中央大),本研究の目的は，英米文学の分野における文芸批評の客観的分析と大規模言語モデルの分析を結び付ける方策を探ることにある．テクストどうしの影響を調べる影響分析において，BERT の単語埋め込みを使用して，単語埋め込みを組み換えた場合と組み換えない場合の影響の効果を英米文学の影響分析のための評価指標を使用して調べた．単語組み換えに顕著な効果はみられなかったが，主観的な要素を含める文学的読解と自然言語処理を結び付ける方法の一端として有益な試みである． ．
Q4:ポスター3月11日（火） 14:50-16:20   Q会場(1F会議室101AB),Q4-1,Semantic feature engineering for in-context AutoML,/proceedings/annual_meeting/2025/pdf_dir/Q4-1.pdf,"○◊Afonso Lourenço (GECAD, Polytechnic of Porto, Portugal/Fujitsu Laboratory Ltd., Japan), 寛彰 金月, 司睦 田原 (Fujitsu Laboratory Ltd., Japan), Goreti Marreiros (GECAD, Polytechnic of Porto, Portugal)","Machine learning for structured data has lagged be-hind text and image, with current methods remainingapplication-dependent and requiring extensive algorithmselection and hyperparameter tuning. Large tabular models(LTMs) oﬀer a promising solution for context-aware Au-toML by pretraining on diverse tabular datasets. However,scalability remains a challenge due to the quadratic growthof contexts. This paper introduces a novel in-context Au-toML paradigm focused on semantically informed featureengineering, where input data, rather than model parame-ters, are treated as learnable components. By leveragingtask-speciﬁc insights from data card descriptions and his-torical logs, a large language model (LLM) enhances con-text creation for a LTM. Empirical results on ten benchmarkdatasets demonstrate this paradigm delivers competitiveperformance compared to conventional AutoML methods."
Q4:ポスター3月11日（火） 14:50-16:20   Q会場(1F会議室101AB),Q4-2,大規模言語モデルのタスク特化ドメイン適応における知識獲得効率に関する初期検討,/proceedings/annual_meeting/2025/pdf_dir/Q4-2.pdf,"○小林 和馬 (NII/国がん研), 相澤 彰子 (NII)",医療分野は国ごとの制度や慣習の違いが大きく、事前学習済み大規模言語モデルに対してドメイン固有の知識を効率的に習得させる学習戦略が重要となる。本研究では、英日医学翻訳を対象タスクとして設定し、英語の医学用語から適切な日本語の医学用語を想起する能力を、当該タスクにおけるドメイン知識として定義した。これに基づき、医学専門用語の変換精度を定量的に評価するための知識プロービング・ベンチマークを構築した。続いて、Qwen-2.5ファミリーのベースモデルに対して、英日医学対訳コーパスを用いた継続事前学習と教師ありファインチューニングを異なる比率で実施し、ドメイン知識獲得の観点から最適な学習戦略を検証した。
Q4:ポスター3月11日（火） 14:50-16:20   Q会場(1F会議室101AB),Q4-3,Ruri: 日本語に特化した汎用テキスト埋め込みモデル,/proceedings/annual_meeting/2025/pdf_dir/Q4-3.pdf,"○塚越 駿, 笹野 遼平 (名大)",近年，英語や多言語の汎用的なテキスト埋め込みモデルの開発が盛んに行われている．しかし，日本語でのモデル開発の取り組みは限定的であり，その理由としてはデータセットの不足やモデル開発のための知見が少ないことが挙げられる．本稿では，日本語汎用テキスト埋め込みモデルRuri を開発し，その過程について述べる．具体的には，訓練データの不足を補うための大規模言語モデルによる合成データセット構築，対照事前学習によるベースモデルの訓練，そして高品質データを用いた微調整について説明する．構築したテキスト埋め込みモデルRuriは，日本語テキスト埋め込みのベンチマークにおいて既存のモデルを上回る性能を達成した．
Q4:ポスター3月11日（火） 14:50-16:20   Q会場(1F会議室101AB),Q4-4,医療分野に特化した日本語の小規模言語モデルの開発,/proceedings/annual_meeting/2025/pdf_dir/Q4-4.pdf,"○渡辺 翔吾, 連 乃駿, 今岡 幸弘, 飯原 弘二 (国循)",本研究では，日本語の医療分野に特化した小規模言語モデルの開発を行った．日本語に焦点を絞ったテキストクリーニングと形態素解析，教科書相当の品質に分類されたテキストデータ，疾病・薬剤に関する話題についての合成テキストデータを使用し，軽量化に重きをおいた1B の言語モデルの事前学習を実施した．このモデルをベースモデルとして指示ファインチューニングしたモデルをIgakuQA とJMED-LLM を用いて評価を行った．ファインチューニングモデルにおいて，JMED-LLM の8 つの評価指標のうち，6 つのタスクで既存の大規模言語モデルより高いスコアを示した．この結果から，ネットワークや計算資源が限られた環境において，特定の分野に特化した小規模言語モデルの運用が選択肢の１つになり得る可能性が示唆された．
Q4:ポスター3月11日（火） 14:50-16:20   Q会場(1F会議室101AB),Q4-5,疎なパラメータを用いて大規模言語モデルを効率よくFine-Tuneする手法の提案,/proceedings/annual_meeting/2025/pdf_dir/Q4-5.pdf,"○原田 慎太朗, 山崎 智弘, 吉田 尚水 (東芝)","本稿では、疎なパラメータを用いて大規模言語モデルの部分的更新を行なうことで効率よくFine-Tuneする手法を提案する。大規模なコーパスで学習された事前学習済みの言語モデルを特定のタスクやドメインに対してFine-Tune するには、事前学習済みモデルのパラメータを固定し、少量の追加パラメータのみを学習する手法(Parameter-Eﬃcient Fine-Tuning,PEFT) が主流である。しかし、通常のPEFT は学習時の計算リソースを抑える一方でパラメータをすべて更新するため、知識保持および編集が重要なタスクやドメインの性能が劣化したりモデル解釈性が失われたりする問題がある。そこで本稿では、疎なパラメータを用いることで計算リソースを抑えつつ、新たにモデル解釈性も備えた新しいPEFT を提案する。事前学習済みモデルとしてRoBERTa とLlama3-8B に適用することで、言語理解と算術推論ベンチマークで性能が向上すること、およびモデル解釈が可能であることを示す。"
Q4:ポスター3月11日（火） 14:50-16:20   Q会場(1F会議室101AB),Q4-6,LLM事前学習の効率化と性質改善： 埋め込み層および出力層のパラメータ固定による再利用,/proceedings/annual_meeting/2025/pdf_dir/Q4-6.pdf,"○李 宰成, 矢野 一樹, 高橋 良允, 柴田 圭悟, 池田 航 (東北大), 鈴木 潤 (東北大/理研/NII)",LLM の効率的な段階的事前学習法を提案する．提案法では，事前に適切な埋め込み層と出力層のパラメータを獲得し，それを初期値として再利用した上で固定して事前学習をする．この手順を取ることで，標準的な事前学習より計算量およびメモリ要求量を削減可能であることを示す．また，事前に獲得した埋め込み層と出力層の単語ベクトルとしての性能が標準的な事前学習で得られる表現よりも優れており，それがLLM の最終的な性能向上に寄与する可能性があることを示す．
Q4:ポスター3月11日（火） 14:50-16:20   Q会場(1F会議室101AB),Q4-7,LoRAを活用した言語モデルの中間層蒸留,/proceedings/annual_meeting/2025/pdf_dir/Q4-7.pdf,"○鈴木 偉士, 山田 寛章, 徳永 健伸 (科学大)",近年，言語モデルの巨大化により，計算コストが大きく増加したため，性能を保ちつつモデルのパラメータ数を削減する手法が求められている．その一つに知識蒸留があり，中間層蒸留はその一種である．モデルの中間層出力も損失関数の計算に用いる中間層蒸留は有効とされてきたが，線形写像を推論時に用いないため，学習の効果が保証されない問題があった．本研究では，中間層蒸留の線形写像をLoRA のアダプターで代替し，推論時に除かれない線形写像を実現したLoRAILD を提案し，実験を行った．その結果，中間層蒸留の効果に対する否定的な結果を得た．
Q4:ポスター3月11日（火） 14:50-16:20   Q会場(1F会議室101AB),Q4-8,大規模言語モデルを利用したnetlistによる回路生成,/proceedings/annual_meeting/2025/pdf_dir/Q4-8.pdf,"○島田 優斗, 竹内 孔一 (岡山大)",回路設計を行う企業では，すでに設計した回路図が存在する一方で，新たな回路設計の際に，それまでの設計知識を活かした設計は人手により任されている．近年，大規模言語モデル(LLM) は記号列である言語の生成を文脈まで反映した形で実行することが可能になってきている．そこで，本論文ではLLM を利用した回路生成についての第一段階の研究成果を報告する．回路生成には素子間の結合と配置の問題があるため，本稿では素子間の結合に焦点をあて，回路を表現する言葉から素子と素子間の結合をあらわすnetlist を生成させるタスクを設定して回路生成の可能性について小規模な実験を実施した．実験の結果，現段階では生成がむずかしいことを明らかにする．
Q4:ポスター3月11日（火） 14:50-16:20   Q会場(1F会議室101AB),Q4-9,Mixture-of-Expertsの悲観的な統合による頑健な自然言語理解,/proceedings/annual_meeting/2025/pdf_dir/Q4-9.pdf,"○本多 右京 (サイバーエージェント), 岡 達志 (慶應大), 張 培楠, 三田 雅人 (サイバーエージェント)",自然言語理解タスクのデータでは，ショートカットと呼ばれる，ラベルと擬似相関をもつ単純な特徴量が存在することがある．擬似相関はデータ分布の変動に対して頑健でないため，ショートカットへの依存は分布外データでの性能低下につながる．先行研究ではショートカットに依存しないモデルの学習が目標とされてきたが，この学習には実用上大きな困難が伴う．本研究ではこの学習を直接の目標とせず，それぞれ異なる潜在特徴量に基づいて予測するmixture-of-experts モデルをルールにより悲観的に統合することで，頑健に予測する手法を提案する．実験により，実用的な設定において先行研究を上回る分布外性能を示すことを確認した．
Q4:ポスター3月11日（火） 14:50-16:20   Q会場(1F会議室101AB),Q4-10,モデル拡張によるパラメータ効率的な LLM の事前学習,/proceedings/annual_meeting/2025/pdf_dir/Q4-10.pdf,"○矢野 一樹 (東北大), 伊藤 拓海 (東北大/Langsmith), 鈴木 潤 (東北大/理研/NII)",大規模言語モデル（LLM）の事前学習は，モデルパラメータの多さからメモリ要求量の問題に直面する．本稿では，モデル拡張を用いたメモリ効率に優れた事前学習法であるSTEP を提案する．実験結果から，STEP を用いることにより，標準的な事前学習と比較して，最大で53.9%の最大メモリ要求量を削減しながら同等の性能を達成することを確認した．さらに，STEP により訓練されたモデルが，下流タスクに対しても標準的に訓練されたモデルと同等の性能を達成することを示す．
Q4:ポスター3月11日（火） 14:50-16:20   Q会場(1F会議室101AB),Q4-11,大規模言語モデルのためのアライメントデータ合成手法の実験的評価,/proceedings/annual_meeting/2025/pdf_dir/Q4-11.pdf,"○坂本 充生, 陣内 佑, 森村 哲郎, 阿部 拳之, 蟻生 開人 (サイバーエージェント)",アライメントは大規模言語モデル(LLM) の振る舞いを人間の選好に合わせて無害で正確な，バイアスのない応答を生成するようモデルを誘導する手法である．アライメントの効果は選好データセットの質と量に大きく依存することが知られているが，人手による高品質な選好アノテーションを集めることは非常に高価である．そのため，高性能なLLMを用いて選好データを自動生成する手法が広く研究されている．しかしながら先行研究の多くは英語の多量のデータのあるドメインでの評価がほとんどであり，真に合成データが必要な非英語少データドメインにおける合成方法は明らかにされていない．本研究は日本語LLM (CALM3) を用い，日本語のAnswerCarefully データセットを基にデータ合成手法を評価した．人手評価の結果，データ合成を行わない場合および外部の報酬モデルを用いた合成方法と比較して，CALM3 のみを使った合成方法の方が高い性能が得られた．本研究成果は日本語の少データドメインでも選好データの合成が効果的であることを示すものであり，今後の日本語LLM の研究開発に活かされるものであると考えられる．
Q4:ポスター3月11日（火） 14:50-16:20   Q会場(1F会議室101AB),Q4-12,対訳構造の指示調整は言語間転移を促進するのか？,/proceedings/annual_meeting/2025/pdf_dir/Q4-12.pdf,"○佐藤 美唯, 西潟 優羽 (日本女子大), 秋信 有花, 倉林 利行 (NTT), 倉光 君郎 (日本女子大)","多言語LLM や低資源言語LLM の開発において，言語間での事前学習データの不均衡は大きな技術課題である．現状は，英語中心の事前学習データが圧倒的に多い一方、低資源言語のデータ収集や作成は容易ではない．言語間転移は英語で学習した知識を活用して低資源言語の性能を高めることが期待されるが，その発生条件や原理は未解明な部分が多い．本研究では，指示調整を通じて言語間転移を促進させることを目指し，指示文を二言語の対訳構造にした対訳指示調整(Parallel Instruction Fine-Tuning, PIFT)を提案する．PIFT の効果を日本語からのコード生成タスクで調査した結果，単言語の指示文を用いた指示調整と比較して性能が向上することを確認した．"
Q4:ポスター3月11日（火） 14:50-16:20   Q会場(1F会議室101AB),Q4-13,言語構造の数理分析のための代数統計的アプローチ試論,/proceedings/annual_meeting/2025/pdf_dir/Q4-13.pdf,"○前田 晃弘 (JAIST/日本学術振興会), 鳥居 拓馬 (東京電機大), 日髙 昇平 (JAIST)",代数統計は代数幾何と統計の融合領域であり，構造を備えた確率モデルを高次元空間における多様体として捉える新たな視点を提供する．本研究では，言語の確率モデルを文を構成する単語の同時確率分布として定式化し，その確率ベクトルが言語の構造を反映した多様体をなすことを示す．これにより，代数幾何のツールである多項式イデアルを用いて，単語の同時確率を制約する多様体構造から言語の構造を抽出するための新たな手法を検討する．
Q4:ポスター3月11日（火） 14:50-16:20   Q会場(1F会議室101AB),Q4-14,LLM間と問題間の類似度制約を加えたLLMの性能推定,/proceedings/annual_meeting/2025/pdf_dir/Q4-14.pdf,"○田村 拓也, 矢野 太郎, 榎本 昌文, 小山田 昌史 (NEC)",本研究では、LLM が与えられた問題を適切に解けるかを推定するタスクにおいて、推定モデルの学習に含まれない新規のLLM や問題に対しても高精度に推定する手法を提案する。提案手法では、従来の行列分解に基づくアプローチに加えて、問題文の埋め込みやモデルの来歴などの補助情報から得られる類似度を考慮した類似度制約項を損失関数に導入する。その結果、提案手法では学習時に利用した既知のLLM による新規問題の平均的な解決性能の推定において20.2%、新規LLM の既知の問題に対する平均的な性能の推定において15.6%の誤差軽減を達成した。
Q4:ポスター3月11日（火） 14:50-16:20   Q会場(1F会議室101AB),Q4-15,真面目 LLM と不真面目 LLM で推論能力は変わるか？,/proceedings/annual_meeting/2025/pdf_dir/Q4-15.pdf,"○堀尾 海斗, 河原 大輔 (早大)",本研究では、真面目さという性格をLLM に付与した場合のタスク正解率への影響を検証する。手法としては、真面目さ、不真面目さを付与する複数種類のプロンプトを用いる。実験では、日本語の3 種類のタスクを使用して各プロンプトを検証する。実験の結果、真面目さを付与した場合はプロンプトによって正解率が向上することもあれば低下することもあること、不真面目さを付与した場合は基本的に正解率が低下することがわかった。また、正解率に大きな変化を与える言語表現が存在することも判明した。
Q4:ポスター3月11日（火） 14:50-16:20   Q会場(1F会議室101AB),Q4-16,いくつかの意味論的なタスクにおける単一事例規範と対照学習規範の併用,/proceedings/annual_meeting/2025/pdf_dir/Q4-16.pdf,"○小早川 健, 塩田 雄大, 望月 貴裕 (NHK)",いくつかの意味論的なタスクをとりあげ，BERT型モデルに対して対照学習規範を用いた学習の効果を検証する．対照学習規範をBERT に適用した先行研究は，基となるBERT の埋込層に追加されたPooling 層のみを対照学習規範で学習するものが多いのに対して，この報告では，BERT の埋込層も含めた学習を行う．実験によると，対照学習規範は，単一事例規範と併用することによって，性能改善が達成できることがわかった．
Q4:ポスター3月11日（火） 14:50-16:20   Q会場(1F会議室101AB),Q4-17,Padding vs. Packing: 大規模言語モデルのファインチューニングにおける学習効果の検証,/proceedings/annual_meeting/2025/pdf_dir/Q4-17.pdf,"○塩野 大輝 (東北大), 田中 涼太 (東北大/NTT), 宮脇 峻平, 工藤 慧音, 鈴木 潤 (東北大)",大規模言語モデル(LLM) のファインチューニングにおける入力系列の作成時には，1 つのサンプルに[PAD] トークンを最大系列長まで連結するPadding戦略が広く採用される．しかしファインチューニング時には，最大系列長に収まるように複数サンプルを連結し入力系列を作成するPacking 戦略を採用する選択肢も考えられる．このPacking 戦略は，複数のサンプルを連結して入力するので，Padding 戦略と比較して学習効率が高い利点がある．しかし，Packing 戦略が，Padding 戦略を採用した時と同様の学習効果が得られるかどうかは明らかになっていない．本研究では，LLM のファインチューニング段階における，Packing 戦略の学習効果を検証し，特定の学習データに対しては，Padding 戦略で学習した場合と同等の学習効果が得られることを示す．
Q4:ポスター3月11日（火） 14:50-16:20   Q会場(1F会議室101AB),Q4-18,Transformer LLMの内部挙動改善：隠れ状態ベクトルの数値的収束性の向上,/proceedings/annual_meeting/2025/pdf_dir/Q4-18.pdf,"○柴田 圭悟, 高橋 良允, 矢野 一樹, 李 宰成, 池田 航 (東北大), 鈴木 潤 (東北大/理研/NII)",Transformer の事前学習済みモデルでは，各層の予測分布の意味的収束性が示される一方で，隠れ状態ベクトルの数値的収束性が確認されておらず，両者に乖離があることが問題である．本研究では，事前学習済みモデルに自己蒸留を適用し，隠れ状態ベクトルの数値的収束性を改善する．自己蒸留は，同一モデル内で深い層から浅い層へ知識を蒸留し，モデルの性能を維持しながら隠れ状態ベクトルの収束性を高めることが可能である．提案手法により，最終層付近での隠れ状態ベクトルの収束性が向上した．
Q4:ポスター3月11日（火） 14:50-16:20   Q会場(1F会議室101AB),Q4-19,日本語大規模言語モデルの有用性と安全性の両立に向けたチューニング手法の検証,/proceedings/annual_meeting/2025/pdf_dir/Q4-19.pdf,"○勝又 智 (レトリバ), 児玉 貴志 (NII), 宮尾 祐介 (東大/NII)",大規模言語モデルは多様な入力に対しても有用な回答を生成できるが，出力された回答の安全性に関する課題も指摘されている．特に日本語LLM の研究開発では安全性に対する対策がまだ十分には進んでいない．本研究では日本語LLM の安全性向上を目的としたチューニングを行い，特に有用性を損なわずに安全性を向上させる手法について検討する．さらに日本語LLM の安全性を自動で評価するツールを新たに作成し，チューニングによる安全性向上を定量的に検証する．実験では，SupervisedFine-Tuning やDirect Preference Optimization を適切に組み合わせることで，安全性を効果的に向上させられることを確認した．
Q4:ポスター3月11日（火） 14:50-16:20   Q会場(1F会議室101AB),Q4-20,低資源言語のための辞書を用いた言語間語彙転移,/proceedings/annual_meeting/2025/pdf_dir/Q4-20.pdf,"○坂上 温紀, Justin Vasselli, 井手 佑翼, 坂井 優介 (NAIST), Yingtao Tian (Sakana AI), 上垣外 英剛, 渡辺 太郎 (NAIST)",事前学習済みモデルの性能を新たな言語、特に低資源言語に転移させる際、事前学習済みモデルのサブワード埋め込みを用いて目的言語のサブワード埋め込みを初期化する手法が知られている。それらは目的言語のコーパスを用いるが、低資源言語の中には十分なコーパスが存在しない場合が多い。その一方で、多くの言語には対訳辞書が存在している。そこで本研究では、対訳辞書に基づくサブワード埋め込みの初期化の手法を提案する。実験の結果、既存の手法では課題となっていた言語に対して提案手法は有効であることが明らかとなった。
Q4:ポスター3月11日（火） 14:50-16:20   Q会場(1F会議室101AB),Q4-21,情報圧縮を用いた訓練データの重複削減,/proceedings/annual_meeting/2025/pdf_dir/Q4-21.pdf,"○堤田 恭太, 村瀬 文彦, 三谷 陽 (デンソー)",公開されている汎用的なニューラル言語モデルを利用する際，当該タスクやドメインの文書を用いた継続事前学習を行って，下流タスクの精度向上を図ることがある．また，訓練データから重複を除去することで，学習効率が向上することが知られている．そこで本研究では，情報圧縮を用いて訓練データ中の重複を削減する手法を提案する．実データを用いた類似文書検索タスクにて，完全一致を除去するナイーブな手法や，ランダムなデータ選択などと比べて，提案法がより高い検索精度を実現する言語モデルを構築できることを示した．
Q4:ポスター3月11日（火） 14:50-16:20   Q会場(1F会議室101AB),Q4-22,話者スタイル抽出と対話フロー生成に基づく対話データ拡張手法,/proceedings/annual_meeting/2025/pdf_dir/Q4-22.pdf,"○斉 志揚, 稲葉 通将 (電通大)",自然言語処理技術の進展に伴い，対話システムが多様なユーザと対話を行う場面が増加している．しかし，特殊な話者スタイルを示す小規模のユーザグループに対しては，データ不足がシステム性能向上を妨げる要因となっている．本研究では，話者スタイルと対話行為の流れを組み合わせたデータ拡張手法を提案する．大規模言語モデル（Large LanguageModel; LLM）を用いて話者スタイルを抽出し，事前学習済み言語モデル（Pre-trained Language Model;PLM）を活用して対話行為系列を生成することで，その話者に特化した豊かな対話データを生成する．実験により，提案手法が低リソースユーザグループに適応可能な対話システムの開発に寄与することを示した．
Q4:ポスター3月11日（火） 14:50-16:20   Q会場(1F会議室101AB),Q4-23,Jellyfish: データ前処理のためのLLM,/proceedings/annual_meeting/2025/pdf_dir/Q4-23.pdf,"○張 皓辰 (阪大), 董 于洋 (NEC), 肖 川 (阪大), 小山田 昌史 (NEC)","データ分析において不可欠なステップであるデータ前処理（DP）に対して，大規模言語モデル（LLM）の活用が注目を集めている．しかし，既存手法の多くはGPT のAPI に依存しており，プライバシーやコスト面での課題が残されている．本研究では，ローカル環境で実行可能な，Llama3-8B,mistral-7B などのパラメータ規模が小さいLLM にのInstruction-tuning を実施し，代表的なDP タスクにおける性能を包括的に評価した．本実験により，全てのモデルの性能向上が確認され，GPT-3.5/4 に匹敵する処理能力を実証した．この取り組みは，ローカル環境で実行でき，プライバシーとコストを考慮しつつ高性能なDP を実現しうるLLM による実用的な解決策を提案するものである．モデルおよび学習データはhttps://huggingface.co/NECOUDBFM で公開されている．"
Q4:ポスター3月11日（火） 14:50-16:20   Q会場(1F会議室101AB),Q4-24,トークン・次元・層の3つの観点とクロスファインチューンによるBERTモデル冗長性の解明,/proceedings/annual_meeting/2025/pdf_dir/Q4-24.pdf,"○福畠 汐音, 狩野 芳伸 (静大)",特定のタスクのためにBERT モデルをファインチューンする場合、最終層の出力の一部を選択し、新しく作成された全結合層に入力することが一般的に行われる。しかし、最終層のどの部分を選択すべきか、また、層の各次元がどのような情報を保持しているかは、よくわかっていない。本研究では、GLUE タスクに対するBERT のファインチューンを通じて、トークンに対応する最終層のベクトル、Transformer の層、ベクトルの次元について、有効性と冗長性を総合的に調査した。その結果、最終層はどのベクトルでも同等の情報を含むこと、ほとんどのタスクは2-3 次元しか必要としないこと、上位層ではどのTransformer 層でもほとんど差がないことが示された。さらに、異なるタスクで順次ファインチューンを行うクロスファインチューンを実施した。その結果、ファインチューンにより隠れ層が大きく変化すること、複数タスクを同時に学習保持できる冗長性があることが示唆された。
Q4:ポスター3月11日（火） 14:50-16:20   Q会場(1F会議室101AB),Q4-25,Leveraging Sentiment Adjectives in Instruction Tuning of LLMs for Zero-Shot Sentiment Classification,/proceedings/annual_meeting/2025/pdf_dir/Q4-25.pdf,"○◊趙 陽, 村岡 雅康, 吉田 一星, Bishwaranjan Bhattacharjee, 金山 博 (IBM)","Instruction tuning signiﬁcantly improves the perfor-mance of LLMs in tasks such as sentiment classiﬁcation. Inthis work, we propose a simple yet eﬃcient instruction aug-mentation method which does not rely on any actual labeledsentiment instances. With just 240 pseudo-instruction in-stances, the proposed method signiﬁcantly improves thesentiment classiﬁcation performance across several LLMson 12 sentiment benchmark datasets, increasing scores by"
A5:NLPモデルの解釈可能性・分析(1)3月12日（水） 8:30-10:00   A会場(2Fコンベンションホール1+2),A5-1,層の冗長性と層同士の独立性に基づく言語モデルの層交換の成否の特徴づけ,/proceedings/annual_meeting/2025/pdf_dir/A5-1.pdf,"○小林 春斗, 原 知正, 鴨田 豪 (東北大), 横井 祥 (国語研/東北大/理研)",ニューラル言語モデルを一度学習し，後からその層を繋ぎ直すことで，モデルの軽量化や複数のモデルの統合が可能になるという不思議な現象が知られている．本稿では，最も単純な層の繋ぎ変えである隣接層同士の交換の成否が，「層の冗長性」と「層同士の独立性」というふたつの直感的な指標によって特徴づけられることを示す．理論的には，これらの量が十分小さいことが，層同士を交換できることの必要条件になっていることを示した．経験的には，提案指標が学習済みのGPT-2 の層同士の交換しやすさが提案尺度でよく予測できることを確認した．
A5:NLPモデルの解釈可能性・分析(1)3月12日（水） 8:30-10:00   A会場(2Fコンベンションホール1+2),A5-2,束縛変項照応を用いた大規模言語モデルのプロービング,/proceedings/annual_meeting/2025/pdf_dir/A5-2.pdf,"○松岡 大樹, 盧 捷, 小林 純一朗, 川崎 義史, 大関 洋平, 谷中 瞳 (東大)",近年の大規模言語モデル(large language model;LLM) は，人間らしく言語を扱う能力を示しつつある一方で，理論言語学が明らかにしてきた人間の言語機能の普遍的性質を持っているかは明らかでない．本研究は「代名詞の束縛変項照応」という現象に対する構造的な制約に注目し，LLM がこの制約に従うか否かを調査した．実験にあたっては，人間の場合でも判断に揺れや個人差があることを考慮し，統語構造とは関係のない要因を除去する「言語機能科学」の方法論を採用した．実験の結果，非構造的要因がないと考えられる状況においても，LLM は束縛変項照応の構造的制約に従わない判断をする場合があり，人間の言語機能との差異が示唆された．
A5:NLPモデルの解釈可能性・分析(1)3月12日（水） 8:30-10:00   A会場(2Fコンベンションホール1+2),A5-3,"Tracing the Roots of Facts in Multilingual Language Models: Independent, Shared, and Transferred Knowledge",/proceedings/annual_meeting/2025/pdf_dir/A5-3.pdf,"○趙 信, 吉永 直樹, 大葉 大輔 (東大)","Acquiring factual knowledge for language models (LMs)in low-resource languages poses a serious challenge, thusresorting to cross-lingual transfer in multilingual LMs(ML-LMs). In this study, we ask how ML-LMs acquireand represent factual knowledge by conducting multilin-gual factual knowledge probing and a neuron-level investi-gation of ML-LMs. Additionally, we trace the roots of factsback to their source (Wikipedia) to understand how ML-LMs acquire speciﬁc facts. We identiﬁed three patternsin how ML-LMs acquire and represent facts: language-independent, cross-lingual shared, and transferred."
A5:NLPモデルの解釈可能性・分析(1)3月12日（水） 8:30-10:00   A会場(2Fコンベンションホール1+2),A5-4,プロンプトに基づくテキスト埋め込みのタスクによる冗長性の違い,/proceedings/annual_meeting/2025/pdf_dir/A5-4.pdf,"○塚越 駿, 笹野 遼平 (名大)",近年，プロンプトを与えることでタスクごとに適した埋め込み表現を出力する，プロンプトに基づくテキスト埋め込みモデルが高い性能を示している．しかし，これらのモデルはしばしば数千次元に及ぶ巨大な埋め込み表現を出力するため推論コストや保存コストに課題がある．本稿では，分類，クラスタリング，検索という3 種のタスクに対し，事後的にこれらの埋め込みの次元数を削減した場合の性能を調査し，分類・クラスタリングタスクについては次元数を大幅に削除しても性能がほとんど損なわれないことを示す．さらに，固有次元の大きさや等方性を調査することで，大幅な次元削減が可能なタスクに適した埋め込みは冗長性が大きいことを示す．
A5:NLPモデルの解釈可能性・分析(1)3月12日（水） 8:30-10:00   A会場(2Fコンベンションホール1+2),A5-5,定数精度浮動小数点 Transformer Decoder が認識する言語の有限性・余有限性,/proceedings/annual_meeting/2025/pdf_dir/A5-5.pdf,"○根岸 直生 (東北大), 谷口 雅弥 (理研), 坂口 慶祐 (東北大/理研), 乾 健太郎 (MBZUAI/東北大/理研)",Transformer decoder の認識する言語を所属性問題として定義し，softmax 関数および定数精度浮動小数点数を採用した場合，認識する言語は有限言語および余有限言語クラスと一致することを示した．
A5:NLPモデルの解釈可能性・分析(1)3月12日（水） 8:30-10:00   A会場(2Fコンベンションホール1+2),A5-6,知識編集が confidence calibration へ与える影響,/proceedings/annual_meeting/2025/pdf_dir/A5-6.pdf,"○長谷川 遼, 坂井 優介, 上垣外 英剛, 渡辺 太郎 (NAIST)",言語モデルの大規模化が進むにつれ，再学習無しで知識更新が可能な知識編集の需要が高まっている．しかし知識編集は事前学習で獲得したトークン予測確率を事後学習で変化させるため，トークン予測確率と実際の精度が乖離する可能性がある．本研究ではこの問題が実際に起きているか検証するために，知識編集前後でのトークン予測確率と実際の精度の一致度をconﬁdence calibration の観点から計算し比較した．その結果，知識編集によりモデルのconﬁdence calibration が変化すること，特に意味理解が必要なタスクでは精度と比べトークン予測確率を相対的に低下させる傾向があることが分かった．
B5:言語処理応用3月12日（水） 8:30-10:00   B会場(1F会議室102),B5-1,Point-of-Interest 推薦ための少数事例選択,/proceedings/annual_meeting/2025/pdf_dir/B5-1.pdf,"○西田 遼, 川原田 将之, 高村 大也, 大西 正輝, 石垣 達也 (産総研)",本研究では，Point-of-Interest (POI) 推薦タスクのための少数ショット事例選択手法を提案する．POI 推薦はユーザの移動履歴を元に次にユーザが興味を示す地点(POI) を推薦するタスクである．従来，蓄積された過去の移動履歴から予測モデルを教師あり学習する手法が研究されてきた．本研究では，蓄積された移動履歴に含まれる有益な知識をプロンプトに含める少数ショット事例選択手法を提案する．実験より，事例数が制限されている設定において，無作為に事例を選択するベースライン手法よりも提案手法がACC@1 を13.6%向上させることを確認した．
B5:言語処理応用3月12日（水） 8:30-10:00   B会場(1F会議室102),B5-2,関数単位の修正箇所特定によるリポジトリレベルのバグ修正,/proceedings/annual_meeting/2025/pdf_dir/B5-2.pdf,"○近藤 瑞希, 河原 大輔 (早大), 倉林 利行 (NTT)",近年、大規模言語モデル(LLM) のコード生成能力は飛躍的に上昇し、ソフトウェアエンジニアリングタスクをLLM に適用する研究が多く行われている。本研究では、LLM の並列処理能力に着目し、LLMエージェントを用いないリポジトリレベルでのバグ修正手法を提案する。リポジトリ内から修正が必要なファイルと関数を特定し、各関数をLLM で独立に修正し、統合する。これらを複数のモデルを用いてアンサンブルする。SWE-bench Lite を用いた評価の結果、ファイルの検索と関数の特定は高精度だったが、バグ修正の精度は他のシステムと比べて大きな改善は見られなかった。
B5:言語処理応用3月12日（水） 8:30-10:00   B会場(1F会議室102),B5-3,多言語音声転写アプリとAIによる外国語授業の自己分析―Multilingual Voice-to-Text Appの開発,/proceedings/annual_meeting/2025/pdf_dir/B5-3.pdf,"○砂岡 和子 (早大), 徐 勤 (京大)",生成系AI を活用した自動音声認識技術（Automatic Speech Recognition：ASR）は飛躍的に進歩しているが，頻繁に言語コードが切り替わる自然発話（Code-switching：CS）の認識は依然として課題が残る．筆者らは，Whisper large-v3 を用いた多人数CS 発話のテキスト転写技術に基づき，より操作性に優れた多言語対応音声テキスト化アプリ（Multilingual Voice-to-Text App）を開発した．本アプリを使用することで，習得目標言語（Ｌ2）と母語（Ｌ1）が混じる外国語授業の発話を，授業実施者や学習者自身が随時可視化できる．本稿では APP の開発経緯と，日本語と中国語が切り替わる授業発話にAPP を用い，認識精度が向上した結果を示す．さらに，ChatGPT を用いた発話内容の質的分析を通じて，簡便に授業を振り返る手法を提案する．
B5:言語処理応用3月12日（水） 8:30-10:00   B会場(1F会議室102),B5-4,ソフトウェア高速化を対象としたLLMとSLMの言語処理特性,/proceedings/annual_meeting/2025/pdf_dir/B5-4.pdf,"○飯塚 康太, 吉藤 尚生 (フィックスターズ)",大規模言語モデル(LLM) のコスト削減を主な目的として、特定ドメインに特化した小規模言語モデル(SLM) の開発が急速に進んでいる。この論文では、ソースコードの高速化性能を題材としてLLMとSLM を比較し、SLM のコードを壊すリスクが低くなる特性が発揮される事例を示した。また、SLMとLLM を組み合わせることで互いの長所を生かしたコード高速化性能を獲得できることも示した。
B5:言語処理応用3月12日（水） 8:30-10:00   B会場(1F会議室102),B5-5,大規模言語モデルを用いた我が国の対米外交における調書作成支援システム,/proceedings/annual_meeting/2025/pdf_dir/B5-5.pdf,○原田 武夫 (原田武夫国際戦略情報研究所),少子高齢化の続く我が国においては知識伝播と技能伝承の刷新が不可欠である。本研究では外務省において生じているそうした問題状況への対処を図るべく、大規模言語モデル（LLM）と検索拡張生成システム（RAG）を用いた業務支援システムを提案する。具体的には日米外交を念頭に、データセットとして党派色の無い米連邦議会調査局（CRS）によるアジア関連レポートの英文テキストを用いてコーパスを作成し、その調書を日英文で作成、両者の比較を通じての改善案作成を行った。その際、日英文で同一内容の質問を行う中、模範となるべき英文での回答の生成に際し生じる深刻な「幻覚」により、実装に際しての負担増が生じ、課題となることが判明した。
B5:言語処理応用3月12日（水） 8:30-10:00   B会場(1F会議室102),B5-6,ChatGPTを活用した高知県観光支援システムの構築,/proceedings/annual_meeting/2025/pdf_dir/B5-6.pdf,"○廣瀬 水咲, 井佐原 均 (追手門学院大)",本研究は，高知県を対象にChatGPT を活用した観光支援システムを構築し，観光資源の効果的な発信を目指した．土佐弁を活用した対話インターフェースやユーザー条件に基づく観光案内，地域特化型データを活用したリアルタイム情報提供を試みた．その結果，観光案内の有用性が示される一方，情報の正確性や視覚的要素，音声対話機能の課題が明らかになった．本研究は，AI 技術による観光業の可能性と地域振興の新たな方向性を提案するものである．
C5:テキスト生成3月12日（水） 8:30-10:00   C会場(1F会議室103),C5-1,トラッキングデータからのサッカー実況生成,/proceedings/annual_meeting/2025/pdf_dir/C5-1.pdf,"○染谷 大河 (東大/産総研), 石垣 達也, 高村 大也 (産総研)",サッカーの試合の臨場感や興奮を直接的に伝える主要な手段として，アナウンサーなどによる試合中の実況がある．一方で，サッカーの試合実況は専門人材やコスト面での制約が大きく，下位リーグやアマチュア，育成年代といったあらゆるカテゴリーにおいて実施することは容易ではない. そこで，本研究では，サッカーにおける多様なカテゴリの試合に実況を付与することを目指し，試合映像や選手・ボールの位置情報等の情報から自動的に実況を生成する下流タスクを新たに提案する．J リーグの試合映像に対して実況を付与したサッカー実況生成モデル構築のための大規模なデータセットLive FootballCommentary (LFC) を作成した上で，選手・ボールの位置情報データを入力として，大規模言語モデル（LLM）を用いて実況を生成するベースラインモデルを構築し，評価を行なった．
C5:テキスト生成3月12日（水） 8:30-10:00   C会場(1F会議室103),C5-2,拡散モデルを用いたテキスト生成における「崩壊問題」と時刻埋め込みの影響,/proceedings/annual_meeting/2025/pdf_dir/C5-2.pdf,"○野坂 瞭太, 松崎 拓也 (東京理科大)",拡散モデルは，ランダムノイズに対して「ノイズ除去」を繰り返し行うことで徐々に良いサンプルを出力する，生成モデルの一種である．テキスト生成に応用する際の課題として，生成の過程において，ある回数以降のノイズ除去でサンプルの改善に失敗し，生成結果を崩壊させていく現象がある．本研究は，この現象に関して，これまで注目の薄かった時刻の埋め込みに焦点を当て，その影響を調査した．結果として，時刻の埋め込みがこの「崩壊問題」の一因であることを示し，崩壊を抑制する正則化を提案する．
C5:テキスト生成3月12日（水） 8:30-10:00   C会場(1F会議室103),C5-3,製造業で取り扱う実データを対象としたRAGの改善,/proceedings/annual_meeting/2025/pdf_dir/C5-3.pdf,"柴田 健吾, ○梶田 久貴, 杉本 崚, 森田 克明 (三菱重工業)",企業における大規模言語モデルの活用が進む中、社内固有の知識を大規模言語モデルと結び付けるRetrieval Augmented Generation（RAG）は重要な技術である。多くの企業でRAG の改善が試みられているが、製造業でRAG を活用する場合、使用されるドキュメント群の特殊性から、一般的なデータセットで検証されたRAG 改善手法が常に効果を発揮するとは限らない。本研究では、RAG の性能を改善するとされる要素（①テキストの正規化、②ハイブリッド検索、③リランキング、④検索ワードの拡張）について、製造業の設計現場で扱われるドキュメント群に対して、どの要素が効果的であるかを調査した。その結果、テキスト正規化、ハイブリッド検索、リランキングが検索性能向上に寄与した一方、検索ワードの拡張は検索性能向上に寄与しなかった。
C5:テキスト生成3月12日（水） 8:30-10:00   C会場(1F会議室103),C5-4,大規模言語モデルによる時系列行動セグメンテーションの精度向上,/proceedings/annual_meeting/2025/pdf_dir/C5-4.pdf,"○捧 蓮, 曲 佳, 三輪 祥太郎 (三菱電機)","時系列行動セグメンテーションは、映像内の一連の行動を時間軸に沿って認識し、一連の行動を構成する個別行動区間を検出するタスクであり、行動理解・評価や技術習得支援等への応用が期待されている。既存手法では、全体的な時系列の流れを捉えておらず、ラベルの予測精度が課題となっている。本手法では、多種多様なドメインに対する膨大な一般的知識を持つ大規模言語モデルを汎用的な状態遷移モデルとして活用することで、常識的・論理的な行動手順を考慮し、行動認識の精度を向上させる。提案手法の性能をいくつかのビデオデータセット（50Salads, Breakfast）で評価したところ、既存手法を上回る性能を達成した。"
C5:テキスト生成3月12日（水） 8:30-10:00   C会場(1F会議室103),C5-5,ChatGPTを用いた教育的ノベルゲーム,/proceedings/annual_meeting/2025/pdf_dir/C5-5.pdf,"○赤田 直弥, 村田 真樹 (鳥取大)",本研究は，村田[1] によるChatGPT を用いた教育的小説の生成や，宮本ら[2] によるChatGPT によるノベルゲーム自動生成システムを参考にして，教育的ノベルゲームを作成した．ChatGPT を用いたノベルゲームにはDeepGame[3] があるが，DeepGame はユーザ入力による逐次生成であるため，物語の全体像が見えにくい．そのため，初めに物語の全体像をフローチャート形式で生成してから細かい生成を行う．生成の際は，被験者が興味を持つ内容になるように，海外旅行や料理などの物語のテーマを設定する．ノベルゲームの面白さや教育的効果についてアンケートと事前，事後の小テストを用いて被験者実験を行った結果，筆頭著者による被験者実験では興味や一貫性などについて概ね良いという評価になったが，小テストの結果はほぼ変わらなかった．また，物語のテーマによって評価が異なり，海外旅行や料理をテーマにしたものよりも，SF をテーマとしたもののほうが評価が高かった．著者以外の被験者による被験者実験では，被験者によって評価が大きく異なり，特に評価の低かった被験者A は小テストの点数も低かった．被験者A は短時間で物語の途中にあるバッドエンドに辿り着いており，内容を十分に理解できなかったからではないかと考えられる．読むのにかかった時間やシーンの選択で評価が変化すると考えられる．
C5:テキスト生成3月12日（水） 8:30-10:00   C会場(1F会議室103),C5-6,LLM as a Debate Judge: 学習者ディベーターへの自動フィードバック生成,/proceedings/annual_meeting/2025/pdf_dir/C5-6.pdf,"○尾崎 大晟 (大阪公立大), 市野 敬介 (NADE), 松田 拓, 久保 健治 (CoDA), 内藤 昭一 (リコー/東北大), 山口 健史 (東北大), 天野 祥太朗 (大阪公立大), 井之上 直也 (JAIST/理研), 中川 智皓, 新谷 篤彦 (大阪公立大)",本研究は，批判的思考力育成の有効手段とされるディベートにおいて，人的リソースの負担が大きいエキスパートジャッジの役割を，LLM エージェントで代替可能とするシステムを提案する．ディベートエキスパートらと共にマルチLLM エージェントシステム用のディベート評価指標(ジャッジ指標) を新たに設計し，それを元に肯定側へフィードバックを提供するジャッジシステムを構築した．さらに，システムが出力したフィードバックと，エキスパートが作成した模範フィードバックを比較評価する実験を行った．その結果，論点の整理などといった観点ではLLM によるフィードバックが人間エキスパート以上の品質を示した．
D5:テーマセッション5: 言語とコミュニケーションの創発(1)3月12日（水） 8:30-10:00   D会場(1F会議室107),D5-1,構成性の度合いはカオスの縁で最も高くなる ---ESNモデルとTopSim指標を用いたケーススタディ---,/proceedings/annual_meeting/2025/pdf_dir/D5-1.pdf,○上田 亮 (東大),我々には想像もつかないような帰納バイアスにおいて，想像もつかないような記号体系が最適であったかもしれないのに，構成性が言語の必然的な性質であると信じて良いのだろうか？この問いに答えるためには，言語の進化（文化進化）のみならず，人類の進化（生物進化）にも思いを馳せながら，構成性と帰納バイアスの関係を考察する必要がある．事例研究として，Echo State Network モデルがカオスの縁と呼ばれる超パラメタ領域において構成的な（高いTopSim スコアをもつ）記号体系に適合・汎化するバイアスをもつことを実験的に示し，構成的な言語が創発する必然性への傍証を試みる．
D5:テーマセッション5: 言語とコミュニケーションの創発(1)3月12日（水） 8:30-10:00   D会場(1F会議室107),D5-2,メッセージの階層構造を把握するための parsing action がランダムではないのはなぜか？,/proceedings/annual_meeting/2025/pdf_dir/D5-2.pdf,"○加藤 大地, 上田 亮, 宮尾 祐介 (東大)",仮に人間がランダムにparsing action をとる言語理解をしていたならば、どんな階層構造を取っても理解できるような頑健な記号体系が作られていた可能性もあるが、人間のparse 戦略がそうなっていないのはなぜだろうか？実際に、階層的なバイアスを持つモデルによる言語創発の先行研究では、メッセージをランダムにparse する、人間の言語理解と乖離した戦略をとるエージェントのコミュニケーション精度が高くなることが報告された。本研究では、(I) ランダムなparse 戦略では意味の理解が難しくなるような、階層的構造を持つより複雑な入力を用いる、(II) 言語の単語や文字の順序に影響を与えるとされるsurprisal に関する項を目的関数に組み込む、というシンプルで自然な変更を実験設定に加え、ランダムなparse 戦略を取るエージェントのコミュニケーション精度がどうなるか、検証を行った。
D5:テーマセッション5: 言語とコミュニケーションの創発(1)3月12日（水） 8:30-10:00   D会場(1F会議室107),D5-3,音声信号から文字記号を創り出す ―深層ベイズに基づく教師なし表現学習によるアプローチ―,/proceedings/annual_meeting/2025/pdf_dir/D5-3.pdf,"○髙橋 舜 (NAIST), 金崎 朝子 (科学大), 須田 仁志 (産総研), Sakti Sakriani (NAIST)",如何にして対象の音声言語の音声データから，その言語において言語学的に妥当な文字記号の体系を機械に創り出させるか．この問いに答えるべく，本研究では深層ベイズに基づく機械学習手法を提案する．提案手法では，世界の言語の音素数の報告データをもとに，文字記号の種類数の弱情報事前分布を導入する．これにより，従来研究のように，文字記号の種類数に関する事前の仮定に無限や定数を無理に持ち出すことなく，対象言語が持ち得る文字記号の種類数を推定しながら，その言語の文字記号の体系を創出することが可能になる．実験により，提案手法の文字体系と人手で創られた文字体系に，従来手法と比較してより強い対応が示された．
D5:テーマセッション5: 言語とコミュニケーションの創発(1)3月12日（水） 8:30-10:00   D会場(1F会議室107),D5-4,RNNの回帰行列を凍結しても統語構造の獲得は損なわれない,/proceedings/annual_meeting/2025/pdf_dir/D5-4.pdf,"○上田 亮 (東大), 栗林 樹生 (MBZUAI), 神藤 駿介 (東大), 乾 健太郎 (MBZUAI/東北大/理研)",人間と同様の言語能力を達成するために必要十分な構造しか持たないニューラル言語モデルはどのようなものか？可能な限り簡素なニューラル言語モデルを出発点としてこの問いに取り組むべく，本稿はReservoir Computing の基本的なモデルであるEcho State Network（ESN）と呼ばれる回帰型のモデルを再訪し，ESN やそれを少し拡張した言語モデルの能力を検証する．実験の結果，適切な初期化のもとでは埋め込み層と出力層のみ訓練し，回帰行列は凍結したとしても統語構造の獲得が損なわれないことが示唆された．
D5:テーマセッション5: 言語とコミュニケーションの創発(1)3月12日（水） 8:30-10:00   D会場(1F会議室107),D5-5,キャプション生成ゲームを通じた複数の視覚言語モデルのベイズ的統合,/proceedings/annual_meeting/2025/pdf_dir/D5-5.pdf,"○松井 悠太, 山木 良輔 (立命館大), 上田 亮 (東大), 品川 政太朗 (NAIST), 谷口 忠大 (京大)",本研究では，複数の視覚言語モデル（VLM）を記号創発の枠組みで統合する手法である，メトロポリスヘイスティングスキャプション生成ゲーム（MHCG）を提案する．MHCG では，異なるデータで事前学習したVLM エージェント間で画像に対するキャプションを提案・受容・更新するプロセスを通じて，モデル間の知識(本稿では画像に対する言語表現) を統合する．この手法は，既存のモデル統合の手法が持つ推論コストやモデル構造の一致の成約を受けない．実験では，COCO とCC3M でそれぞれ事前学習した２体のエージェントがMHCG を行い，相手のエージェントの学習データに対するキャプション生成性能が向上することを示した．
D5:テーマセッション5: 言語とコミュニケーションの創発(1)3月12日（水） 8:30-10:00   D会場(1F会議室107),D5-6,共通基盤の構築に寄与する認知機能:モジュラー生成モデルによるシミュレーション,/proceedings/annual_meeting/2025/pdf_dir/D5-6.pdf,"○馬場 龍之介, 森田 純哉, 天谷 武琉 (静大), 東中 竜一郎 (NTT), 竹内 勇剛 (静大)",抽象的な物体を指示対象とする共通基盤の構築過程を，シミュレーションにより検討した．利用したモデルは，コミュニケーションの過程を，対象の知覚，イメージ生成，言語生成などのモジュールの組み合わせにより説明する．各モジュールの機能を検討する実験により，(1) 対象知覚の調整に比べ，言語生成の調整が，対話相手との意思疎通の成立に有効であること，(2) イメージ生成は，言語生成の多様化を促進することが明らかになった．この結果は，共通基盤構築に寄与する認知機能の役割を検討するうえで，本研究のアプローチの有効性を示す．
E5:テーマセッション1: 金融・経済ドメインのための言語処理(1)3月12日（水） 8:30-10:00   E会場(1F会議室108),E5-1,決算短信における見通し文と結果文のアラインメント,/proceedings/annual_meeting/2025/pdf_dir/E5-1.pdf,"○平松 悠太 (名大), 小川 泰弘 (名市大), 外山 勝彦 (名大)",企業が公開する決算短信には，事業の結果について述べる文のほかに，将来の業績や事業計画などを見通す文が含まれる．事業の見通しとその結果を比較できれば，企業ごとに見通しの傾向を知ることができる．それにより，投資家は企業について，より正確に予測できる．しかし，投資初心者が決算短信を分析することは容易でない．本研究では，投資初心者の支援のために，時系列に並んだ決算短信の間で，それらに出現する見通し文と結果文をアラインメントする．具体的には，文の類似度や大規模言語モデル(LLM) を単独で用いる手法に加えて，それらを併用する手法を検証する．その結果，LLM を用いる手法が最も有効であることを明らかにした．
E5:テーマセッション1: 金融・経済ドメインのための言語処理(1)3月12日（水） 8:30-10:00   E会場(1F会議室108),E5-2,Decoding Sentiment: Predicting Stock Returns from Japanese 10-K Reports with Advanced Large Language Models,/proceedings/annual_meeting/2025/pdf_dir/E5-2.pdf,"○山崎 高弘 (阪産大), 中筋 萌, 岡田 克彦, 月岡 靖智 (関西学院大)","This study leverages advanced natural language processing techniques and large language models (LLMs)—including ChatGPT, Claude, and Gemini—to extract sentiment from Japanese 10-K reports and predict stock returns. Using a dataset of 11,135 firm-years from Tokyo Stock Exchange-listed companies (2014–2023), we compare LLMs with dictionary-based methods and a DeBERTaV2 model. While traditional approaches show no significant sentiment-return relationship, LLM-derived sentiment reveals a significant negative correlation with future stock performance, challenging the efficient market hypothesis. These findings underscore the transformative potential of LLMs in financial analysis, offering predictive insights undetected by traditional methods."
E5:テーマセッション1: 金融・経済ドメインのための言語処理(1)3月12日（水） 8:30-10:00   E会場(1F会議室108),E5-3,Word-level Polarity is All You Need?: 解釈可能なニューラルネットワークモデルを利用した単語極性変換による効率的な金融センチメント適合,/proceedings/annual_meeting/2025/pdf_dir/E5-3.pdf,○伊藤 友貴 (三井物産),金融分野へのサービス提供時等において，深層学習モデルのドメイン適合実施時において，「計算コスト」や「更新されたパラメータのブラックボックス性」が課題になることがある．特に金融分野では単語レベルでのポジネガが時代やドメインが変わると変化することも多く，本課題は当該分野では重要な課題である．そこでなニューラルネットワークモデルSINN を活用した単語極性変換手法Word-level Polarity Adaptation framework based onSINN (WPAS) を提案する．景気センチメントに関するデータセットを利用した検証の結果，提案手法WPAS により（１）少ないパラメータ数の更新、かつ（２）更新されたパラメータが解釈可能な形で高性能なドメイン適合ができることを実証した．
E5:テーマセッション1: 金融・経済ドメインのための言語処理(1)3月12日（水） 8:30-10:00   E会場(1F会議室108),E5-4,銘柄テキスト情報と銘柄数値情報をハイブリッド活用した企業間類似度の獲得,/proceedings/annual_meeting/2025/pdf_dir/E5-4.pdf,"○平松 賢士 (アイフィスジャパン), 伊藤 友貴 (三井)",出資判断や自社IR 活動，テーマ型投資信託の組成，事業推進時のパートナー選定といった金融実務の場において，類似企業間や競合企業間での比較分析を行うことが多い．ここで，「企業間類似度の算出」に関する有用なのがテキスト情報に対しBERT等を活用することで獲得できる企業埋込表現である．このテキストデータをベースとする埋込表現は有効である一方，経済・金融分野においては株価や売上の推移やセグメント別売上等の数値データや株のや特定投資株式を始めとする株式保有情報等，企業間類似度を測る上で有用と考えられる数値データも多く存在し，これらの金融数値データとテキストデータを組み合わせることでより有用な「企業間類似度」を算出することが期待される．そこで，本研究では，銘柄テキスト情報だけでなく，セグメント別売上や株価時系列データ，株式保有情報も活用した「テキスト情報」と「数値情報」をハイブリッドに活用した企業間類似度を提案する．
E5:テーマセッション1: 金融・経済ドメインのための言語処理(1)3月12日（水） 8:30-10:00   E会場(1F会議室108),E5-5,バリューモデルを活用したサステナビリティ情報抽出： LLMにおける未抽出情報の検証,/proceedings/annual_meeting/2025/pdf_dir/E5-5.pdf,"中尾 悠利子 (関大), 石野 亜耶 (広島経済大), 國部 克彦 (神戸大), ○須貝 フィリップ (同志社大)","近年, 拡大するESG 投資に対し, 従来の評価基準における開示の有無だけでは不十分という課題を解決すべく, バリューモデルは81 の明確な目標を設定し企業のサステナビリティ活動を評価する枠組みを提示している.本稿では, バリューモデルの168 のサブゴールうち従業員向け42 サブゴールを対象に, 大規模言語モデル（LLM）を用いた情報抽出を検証した.具体的には, 企業のサステナビリティレポートトに対し「従業員のメンタルヘルス施策」などの定量および定性情報を抽出するプロンプトを設計し, LLM のツールのひとつであるChatPDF からの回答を人手で検証したところ, 報告書の表のレイアウトや類義語の違いなどに起因して未抽出情報率が企業ごとに20～40%台と大きく異なることが示された.この結果は, LLM 活用の際, レポート側のレイアウトや抽出に適した類義語のプロンプト設計が重要であることを示している."
E5:テーマセッション1: 金融・経済ドメインのための言語処理(1)3月12日（水） 8:30-10:00   E会場(1F会議室108),E5-6,エネルギー関連コモディティ先物市場におけるベージュブックテキストの実証分析,/proceedings/annual_meeting/2025/pdf_dir/E5-6.pdf,"○市川 佳彦 (Insight Edge), 高野 海斗 (野村アセット), 中川 慧 (野村アセット/OMU)",本研究は，エネルギー関連のコモディティ先物市場におけるベージュブック情報の影響を分析する．ベージュブックは，地域経済の景況感や多様なトピックを含むテキスト情報を持つ．ベージュブックが様々な資産に影響を与えることが実証されているが，本研究では，まず，ベージュブックの発表が市場に影響を与えるかを分析する．次に，ベージュブックのどのセンチメントやトピックが影響を与えるかを検証する．結果，一部のエネルギー関連のコモディティがベージュブックの情報に特に敏感に反応することが示された．
P5:ポスター3月12日（水） 8:30-10:00   P会場(2Fコンベンションホール3+4),P5-1,読みにくい日本語文に対する係り受け解析・語順整序・読点挿入の同時実行とその評価,/proceedings/annual_meeting/2025/pdf_dir/P5-1.pdf,"○荒木 駿介, 大野 誠寛 (東京電機大), 松原 茂樹 (名大)",日本語において，語順や読点の使用法は比較的自由に書き手に任されるが，実際には選好が存在しているため，意味は伝わるものの読みにくい文が作成されることがある．本稿では，推敲支援のための要素技術として，Shift-Reduce アルゴリズムを拡張した，日本語文に対する係り受け解析・語順整序・読点挿入の同時実行手法を提案する．提案手法では，従来手法にビームサーチを組み込み，深層学習モデルとしてRoBERTa を使用することにより，精度向上を試みる．また，逐次実行手法との比較を行い，同時実行することの有効性を検証する．
P5:ポスター3月12日（水） 8:30-10:00   P会場(2Fコンベンションホール3+4),P5-2,レビュー情報を用いた LLM による観光地比較表生成,/proceedings/annual_meeting/2025/pdf_dir/P5-2.pdf,"○辻本 陵 (NAIST), 坪内 孝太, 山下 達雄 (LINEヤフー), 松田 裕貴 (岡山大/NAIST/理研), 諏訪 博彦, 大内 啓樹 (NAIST/理研)",Table Generation は，複数の要素を比較する際に有用な技術である．本研究では，観光地（POI）のレビュー情報を基に観光地間の比較表を自動生成する新しい手法を提案する．レビューから属性-レビューペアを抽出し，それを属性ごとに整理した情報をLLMs に入力することで，客観的要素と主観的要素を含む比較表の生成を可能にした．評価実験では，無作為なレビュー入力やレビューを使用しない手法と比較して，提案手法が優れた比較表を生成できることを確認した．本研究は，観光地選定を支援する実用的なアプローチを提示し，Table Generationタスクに新たな視点を提供するものである．
P5:ポスター3月12日（水） 8:30-10:00   P会場(2Fコンベンションホール3+4),P5-3,Attention スコアの分布類似性を用いた大規模言語モデルの動作効率化および省メモリ化,/proceedings/annual_meeting/2025/pdf_dir/P5-3.pdf,"○谷口 令 (阪大), 肖 川 (阪大/名大), 董 于洋, 小山田 昌史 (NEC), 鬼塚 真 (阪大)",Transformer-デコーダをベースとした大規模言語モデルは、文脈理解・回答における精度の高さから活用が広がっている。近年では長文入力への需要が高まっているが、自己注意処理(Attention) における計算量が入力長の2 乗に比例すること、KV キャッシュのサイズが入力長に比例するという理由により、入力長に対して制限が存在する。本研究ではTransformer 内の各レイヤ・各ヘッドについて注意スコアの分布を調査し、同一レイヤにおいてスコアを共有できるヘッドが存在すること、また各レイヤについてスコアが大きなトークンが共通していることを明らかにした。これを元に自己注意処理の効率化とKV キャッシュの削減を行い、削減前と比較してベンチマークにおける精度低下が限定的であることを確認した。
P5:ポスター3月12日（水） 8:30-10:00   P会場(2Fコンベンションホール3+4),P5-4,意味、言語構造、言語の優位性を考慮した多言語文脈内学習,/proceedings/annual_meeting/2025/pdf_dir/P5-4.pdf,"○金子 正弘, Aji Alham Fikri, Timothy Baldwin (MBZUAI)",多言語大規模言語モデル（MLLM）の文脈内学習（ICL）における事例選択では、意味の一致、言語構造の類似、言語の優位性の3 項目が重要となる。既存研究ではこれら3 項目を総合的にどのように考慮するべきか明らかにされていない。我々は3 項目の指標を再定義し、最適なバランスで事例選択する手法を提案する。実験の結果、既存手法と比較して提案手法が最高性能を達成した。
P5:ポスター3月12日（水） 8:30-10:00   P会場(2Fコンベンションホール3+4),P5-5,二つの時系列データの関係を記述する自然言語文生成手法の実測データ適用への取り組み,/proceedings/annual_meeting/2025/pdf_dir/P5-5.pdf,"○中野 由加子, 小林 一郎 (お茶大)",本研究においては，人工データを用いて二つの時系列データの関係を説明する文生成を行う手法を提案し，実測された時系列データへの適用可能性について検証を行った．具体的には，初めに二つの時系列データの関係を捉えるためTransformer のクロス注意機構を拡張したモデルを用いて，人工的に作成した時系列データの挙動および関係性についての説明文生成の訓練を行う．そしてそのモデルを用いて，実測された時系列データの振る舞いについての説明文生成を行ない，人工データで学習したモデルの実測データへの転移学習の有効性について検証を行った．実測データについての説明文生成の精度は十分に高いものではなかったが，人工データの挙動に近い場合は正しく文生成を行うことが可能であることが確認された．
P5:ポスター3月12日（水） 8:30-10:00   P会場(2Fコンベンションホール3+4),P5-6,ASCII CHALLENGE−LLMは画家になれるか−,/proceedings/annual_meeting/2025/pdf_dir/P5-6.pdf,"○吉田 遥音, 羽根田 賢和 (東北大), 斉藤 いつみ, 坂口 慶祐 (東北大/理研)",アスキーアートはイラストや画像を文字で表現するテキストアートである．文字だけを用いて様々な表現を可能にするアスキーアートは現代社会で広く用いられている一方で，その作成は容易ではない．また既存の生成ツールは画像を機械的に変換するなど柔軟性が低い方法に限定されている．本研究では，自然言語からアスキーアートを生成する手段としてのLLM・LVLM の利用可能性の検証を行った．結果として現行のモデルでは生成が困難だが，アスキーアートに特化したデータセットを用いて学習することで生成可能になる兆しが見えた．
P5:ポスター3月12日（水） 8:30-10:00   P会場(2Fコンベンションホール3+4),P5-7,文法を基いた逐次選択アプローチによるゲーム記述生成,/proceedings/annual_meeting/2025/pdf_dir/P5-7.pdf,"○田中 恒彦, シモセラ エドガー (早大)",本研究は，Game Description Language(GDL) を基にしたゲーム記述生成において，文法的正確性を改善する新しいプロセスを提案する．GDL は多様なゲームを統一的に表現できるドメイン固有言語であり，ゲームデザインの自動化に広く利用されている．本研究では，大規模言語モデル(LLM) を活用し，文法に基づいた生成候補を逐次提示するアプローチを開発した．さらに，部分出力と文法的に妥当な候補を含むデータセットを構築し，LLM を教師ありファインチューニングで学習させた．その結果，提案手法は生成されたゲーム記述の文法的に正確さにおいて従来手法を上回る性能を示した。
P5:ポスター3月12日（水） 8:30-10:00   P会場(2Fコンベンションホール3+4),P5-8,正解保証を伴う思考プロセス付き合成データ生成による日本語大規模言語モデルの数学推論能力向上,/proceedings/annual_meeting/2025/pdf_dir/P5-8.pdf,"○岡田 龍樹, 平川 雅人 (ELYZA), 大葉 大輔 (ELYZA/科学大)","日本語に特化した大規模言語モデル（日本語LLM）の日本語数学能力を改善するには、高品質な学習データを大量に用意することが必要である。本研究では、任意の英語数学問題-回答ペアをシードに、日本語で記述された思考過程付きの数学学習データを、出力の正解を保証しながら半自動で合成する方法を提案した。また、実際に英語数学データに対して提案手法を適用し、約17 万件の学習データを合成した。PRM800K およびGSM8Kの日本語翻訳版を用いた評価では、提案手法により合成された学習データは、日本語LLM (e.g.,Llama-3-ELYZA-JP-8B) の日本語数学推論能力を確かに改善することを示した。その過程で、学習データが日本語で記述されていることの有用性、データ合成時における正解保証の有用性を示した。"
P5:ポスター3月12日（水） 8:30-10:00   P会場(2Fコンベンションホール3+4),P5-9,生成系タスクの自動評価においてチェックリストの使用は有効なのか？,/proceedings/annual_meeting/2025/pdf_dir/P5-9.pdf,"○古橋 萌々香 (東北大/NII), 中山 功太, 児玉 貴志, 菅原 朔 (NII)",生成系タスクにおける大規模言語モデルを用いた自動評価では，評価基準の曖昧さが課題とされている．これに対し，チェックリストにより評価基準を細分化する方法が注目されているが，作成方法の検討はまだ十分でない．本研究では6 つの生成手法でチェックリストを作成し，それに基づいて回答を評価，その有効性を3 種の評価モデルで検証した．その結果，チェックリスト未使用時と比較して一致率が向上したケースは22.6%に留まり，チェックリストの有効性は限定的であった．一方，項目数制限や付加情報の活用が有効であり，小規模評価モデルでも適切なチェックリストを用いることで大規模モデルと同等の評価を行える可能性が示唆された．
P5:ポスター3月12日（水） 8:30-10:00   P会場(2Fコンベンションホール3+4),P5-10,判決書要約文の自動評価,/proceedings/annual_meeting/2025/pdf_dir/P5-10.pdf,"○新保 彰人, 山田 寛章, 徳永 健伸 (科学大)",一般の文書要約で使われているROUGE などの自動評価指標は判決書自動要約タスクでも使われている．しかし既存の自動評価指標では判決書要約文に不可欠な要素が，要約文に含まれているかを評価することができない．本研究では，判決書要約文に特化した評価ルーブリックを策定し，それに基づいて法律の専門家による人手評価を行う．そして，その評価データを利用して判決書要約文に特化した自動評価器を構築する．構築した評価器をカッパ係数で評価し，自動評価器と正解データとの一致度が人手評価者の間の一致度を部分的に上回ることを示す．
P5:ポスター3月12日（水） 8:30-10:00   P会場(2Fコンベンションホール3+4),P5-11,クエリ対応の事前要約を伴う大規模言語モデルによる企業事業概要生成,/proceedings/annual_meeting/2025/pdf_dir/P5-11.pdf,"○田村 光太郎 (Uzabase,Inc)",企業の事業・財務の内容を把握することは、投資や経営の意思決定などビジネスにおいて、さまざまな場面で必要となる。一つの情報を多角的かつ高品質な情報として整理する必要があるが、実際には、多種多様なフォーマットで書かれた開示資料や公開情報などの読取りには、専門的な知識が必要となることもあり、人手で行うことに大きなコストがかかる。本研究では、有価証券報告書や決算説明会の書き起こしなど、これらの企業情報を一定の形式に整理し、事業の概要を説明する文を生成することを試みる。その生成の方式として、多種多様なテキストの特徴や文章量を均すために、テキストを事前に要約し、RAG を行うことで、生成される概要文の品質を高めることを行った。
P5:ポスター3月12日（水） 8:30-10:00   P会場(2Fコンベンションホール3+4),P5-12,医療事故・ヒヤリハットに関する要因・対策案生成ベンチマークの提案,/proceedings/annual_meeting/2025/pdf_dir/P5-12.pdf,"○長谷山 優菜 (北大), 伊藤 友貴 (三井物産), 坂地 泰紀, 野田 五十樹 (北大)",医療現場での利活用の需要が高まる中，医療事故が起こった際，その原因を突き止め，迅速に対策を講じるための大規模言語モデルは有用だと考えられる．医療現場で利用可能な大規模言語モデルを考えるうえで，その能力を評価するベンチマークは必要不可欠だが，現状は十分とは言えない．このような背景のもと，本研究では，日本医療機能評価機構による医療事故情報収集等事業によって収集，提供されている事故・ヒヤリハット事例のデータからデータセットを構築し，医療事故の内容から，背景・要因，改善策の生成を評価するためのベンチマークを提案する．
P5:ポスター3月12日（水） 8:30-10:00   P会場(2Fコンベンションホール3+4),P5-13,大規模音声認識モデルに基づく韻律・言語情報を考慮した音声感情認識,/proceedings/annual_meeting/2025/pdf_dir/P5-13.pdf,"○福田 りょう, 叶 高朋, 安藤 厚志, 小川 厚徳 (NTT)",本研究では、大規模音声認識モデルであるWhisperに基づく音声感情認識手法を提案する。近年盛んに研究が行われている、事前学習済み音声エンコーダに基づく音声感情認識手法では、言語的な情報を十分に考慮することができなかった。そこで多量のデータ・複数の音声言語処理タスクで事前学習されたWhisper のデコーダを用いることで、言語情報も考慮した感情認識手法の実現を目指した。また、音声認識や性別認識といったサブタスクのトークンを含めた単一系列をデコーダで生成するマルチタスク学習手法を提案した。
P5:ポスター3月12日（水） 8:30-10:00   P会場(2Fコンベンションホール3+4),P5-14,合成単語データを用いた低コスト高品質な音声認識のドメイン適応,/proceedings/annual_meeting/2025/pdf_dir/P5-14.pdf,"○小松 秀輔, 大西 一誉 (mocomoco/NAIST/理研), 田中 康紀, 金 道鉉 (mocomoco/NAIST), 吉野 幸一郎 (科学大/理研/NAIST)",深層学習により高い性能を発揮している汎用音声認識モデルは，ドメインに適応した出力を行うにはファインチューニングによる追加学習を必要としている．先行研究では大規模言語モデルと制御音声合成を用いたデータ拡張による音声認識モデルのファインチューニング手法が提案されているが，コストと未知語の学習の面で課題が残る．本研究では単語のみの制御音声合成を結合した音声データを用いた低コストかつ，高品質なファインチューニング手法を提案する．実験では既存手法と比較して，提案手法によるファインチューニングは1/3 程度の学習コストでより多くの未知語を学習することができることを示した．
P5:ポスター3月12日（水） 8:30-10:00   P会場(2Fコンベンションホール3+4),P5-15,タスク指向音声対話における大規模言語モデルを活用した柔軟な発話終了検知の検討,/proceedings/annual_meeting/2025/pdf_dir/P5-15.pdf,"○大竹 真太, 東 佑樹, 杉山 雅和 (AI Shift)","音声対話システムにおいて発話終了検知は, ユーザ意図の正確な理解とスムーズな対話の実現に不可欠である. 従来の沈黙時間ベースの手法は頑健だが,発話末尾での不必要な待機による応答遅延がユーザ体験を損なう. 発話の意味的な内容を考慮するアプローチは, よりスムーズな発話終了検知を実現できる可能性がある一方で, 特定のドメインや発話スタイルに依存してしまい, 汎用性に乏しいという課題がある. そこで, 本稿ではタスク指向対話において, 大規模言語モデル（LLM）の文脈理解能力を活用することで, 柔軟かつ高速な発話終了検知を実現する新しい手法を提案する. 社内で収集した電話音声データを用いて検知の遅延時間を評価し, ベースラインよりも約37.8%短縮できた."
P5:ポスター3月12日（水） 8:30-10:00   P会場(2Fコンベンションホール3+4),P5-16,Emotion-aware Speech-to-text Translation with Generative Error Correction,/proceedings/annual_meeting/2025/pdf_dir/P5-16.pdf,"○◊Zhengdong Yang, Chenhui Chu (京大)","This paper explores emotion-aware speech-to-text trans-lation (ST) using generative error correction (GER) bylarge language models (LLMs). Despite recent advance-ments in ST, the impact of the emotional content has beenoverlooked. First, we enhance the translation of emotionalspeech by adopting the GER paradigm: Finetuned an LLMto generate the translation based on the decoded 𝑁-besthypotheses. Next, we combine the emotion labels into theLLM ﬁnetuning process to enable the model to considerthe emotion content. Experiments show that GER and theintegration of emotion labels are eﬀective on the English-Japanese language pair. This research lays the foundationfor more sophisticated models that consider emotional nu-ances in speech."
P5:ポスター3月12日（水） 8:30-10:00   P会場(2Fコンベンションホール3+4),P5-17,音声認識出力の曖昧性を考慮したMulti-task End-to-end音声翻訳と曖昧性の高い音声入力に対する頑健性の分析,/proceedings/annual_meeting/2025/pdf_dir/P5-17.pdf,"○胡 尤佳 (NAIST), 須藤 克仁 (奈良女子大/NAIST), 中村 哲 (CUHK/NAIST), Sakriani Sakti (NAIST)",音声翻訳は原言語の音声を目的言語の音声やテキストへ変換する技術であり，近年では原言語の音声を直接目的言語のテキストへ翻訳するEnd-to-end音声翻訳の研究が進んでいる．本研究では，より音声認識出力の曖昧性を考慮した損失関数を用いたMulti-task 音声翻訳モデルの学習方法を提案し，Hybrid CTC/Attention loss の仕組みへの適用を試みた．実験と分析により，従来モデルと比較し，提案モデルにおける翻訳性能の向上が見られ，曖昧性をある程度多く含む音声入力に対する頑健性の向上が見られることを確認した．
P5:ポスター3月12日（水） 8:30-10:00   P会場(2Fコンベンションホール3+4),P5-18,対話履歴の LLM 埋め込みを用いた音声合成のスタイル制御,/proceedings/annual_meeting/2025/pdf_dir/P5-18.pdf,"○小島 淳嗣, 藤田 雄介, 水本 智也, 吉川 克正 (SB Intuitions)",対話履歴に基づき、合成音声のスタイルを制御する手法を検討する。対話履歴を考慮するため、提案モデルは、大規模言語モデルによって得られた対話履歴の埋め込みに基づき音声を合成する。実験では、Emotional Speech Database を用いて擬似対話履歴付き音声データセットを作成し、モデルを学習した。実音声と合成音声の発話スタイルの類似度を5段階で主観評価し、提案モデルに対話履歴を入力せずに音声を合成する手法と性能を比較した。その結果、提案手法は3.1 ± 0.18、比較手法は2.3 ± 0.19 となり、対話履歴に基づく発話スタイル制御の有効性が示された。
P5:ポスター3月12日（水） 8:30-10:00   P会場(2Fコンベンションホール3+4),P5-19,音声トークナイズが音声言語モデルの性能に与える影響の調査,/proceedings/annual_meeting/2025/pdf_dir/P5-19.pdf,"○神藤 駿介 (東大), 宮尾 祐介 (東大/NII), 高道 慎之介 (慶應大/東大)",近年，音声言語処理の新たな手法としてTextlessNLP（テキスト資源に頼らず音声資源のみを用いてNLP システムを構築する試み）が注目を集めている．その基盤となる「音声言語モデル」は，音声シグナルを「トークナイズ」して離散表現に変換した上で言語モデルを学習し，音声言語処理の実現を目指すものである．本研究では，計36 通りの音声トークナイズ手法を用いて音声言語モデルを学習して性能を比較し，音声トークナイズが音声言語モデルの性能に与える影響を調査した．実験の結果，音声シグナルを適切な粒度で分節すること，離散化時のクラスタ数を増やすことの有用性が示唆された．
P5:ポスター3月12日（水） 8:30-10:00   P会場(2Fコンベンションホール3+4),P5-20,ReShape Attentionによる音声と言語の基盤モデルの統合,/proceedings/annual_meeting/2025/pdf_dir/P5-20.pdf,"○叶 高朋, 小川 厚徳, デルクロア マーク (NTT), チェン ウィリアム (CMU), 福田 りょう, 松浦 孝平, 芦原 孝典 (NTT), 渡部 晋治 (CMU)","本論文では, 音声翻訳システムにおいて, 音声基盤モデルであるWhisper の分散表現を言語基盤モデルであるLLaMA2 の分散表現と結合するReShapeAttention (RSA) を提案する.RSA は, LLaMA2 のTransformer 層の内部に挿入され, 音声とテキストの分散表現を, 同じ特徴次元のサブベクトルに変形し, 2 つの分散表現間でCross-Attention を実行する.RSA により, LLaMA2 とWhisper の勾配グラフは接続され, 音声翻訳システム全体を入力音声に対して最適化できる. RSA は, Whisper とLLaMA2 を用いたCascade 音声翻訳システムと比較して, BLEU スコアを相対的に8. 5% 向上させた. さらに, RSA は正解の書き起こしが得られる場合においてCascade システムよりも音声翻訳精度を向上させる可能性があることが示された."
P5:ポスター3月12日（水） 8:30-10:00   P会場(2Fコンベンションホール3+4),P5-21,二重分節構造モデルを用いた連続音声からの教師なし音素・単語・文法獲得,/proceedings/annual_meeting/2025/pdf_dir/P5-21.pdf,"○落合 翔馬, 齋藤 一誠, 長野 匡隼, 中村 友昭 (電通大)",人間は二重分節構造を持つ連続音声信号を明確な境界点やラベルなしに音素や単語に分割し，単語の遷移規則を文法として学習することが可能である．音声信号の二重分節構造を学習するモデルを構築することは，人間の言語獲得過程を構成論的に解明するために重要である．そこで本稿では，Gaussian Process Hidden Semi Markov Model(GP-HSMM) とHidden Semi Markov Model (HSMM) を階層的に接続し，連続音声信号から音素，単語と文法を学習することが可能な新しい確率的生成モデルを提案する．提案手法では，各統計モデルのパラメータを相互に更新している．そのため，音素と単語と文法が相互に影響し合った学習を可能とする．実験では，文法学習を含む提案手法が，文法学習をしない従来手法よりも高い精度で連続音声信号を音素と単語に分割・分類できることを示した．また，文法学習が文中の単語数の正確な推定に大きく寄与することを示した．
P5:ポスター3月12日（水） 8:30-10:00   P会場(2Fコンベンションホール3+4),P5-22,大規模言語モデルによるイベント知識グラフからのマルチターンfew-shot実況生成手法の検討,/proceedings/annual_meeting/2025/pdf_dir/P5-22.pdf,"○辻村 有輝, 江上 周作, 浅田 真生, 石垣 達也, 福田 賢一郎, 高村 大也 (産総研)",本研究ではイベント知識グラフからの実況テキスト生成に取り組む．タスク設定はシナリオの進行に合わせて実況を生成できるようマルチターン形式で定義する．グラフ情報はテキスト形式へ変形し，大規模言語モデルを用いてfew-shot プロンプトによる生成を行う．また，我々は既存のイベント知識グラフを備えた動画データセットに対して，日本語の実況音声とテキストを新たに付与することで4 種のデータ形式を備える動画実況データセットを構成し実験に利用した．結果として，詳細なグラフ情報の利用によりBLEU スコアの向上を確認したものの，言語モデルの最大系列長制限のため正解実況で言及されることのある情報の一部は入力中に含められなかった．データセットは一般公開されている．1）
P5:ポスター3月12日（水） 8:30-10:00   P会場(2Fコンベンションホール3+4),P5-23,LLM偽針混入テスト：誤抽出を考慮した情報抽出時の評価フレームワーク,/proceedings/annual_meeting/2025/pdf_dir/P5-23.pdf,"○叶内 晨, 深澤 祐援 (NLPeanuts/ブリングアウト), 角野 為耶 (Axcreator/ブリングアウト), 林 翔太, 小原 正大 (ブリングアウト)",本研究では，大規模言語モデル（LLM）の情報抽出時の評価手法であるNeedle in a Haystack LLM テストをより実践的に拡張したLLM 偽針混入テストを提案する．従来手法はLLM の抽出精度をRecallのみで評価するため，現実の情報抽出で頻出する誤抽出の問題を考慮していない．提案手法では，Precision を評価指標に加えて誤抽出を定量化するとともに，抽出対象と文脈のドメインを一致させ，さらに偽正解情報を混入することで実践により近い誤抽出を評価可能とする．実験の結果，提案手法による現実的な設定下でLLM による誤抽出が増加し，誤抽出を網羅的に評価する必要性が示された．
Q5:ポスター3月12日（水） 8:30-10:00   Q会場(1F会議室101AB),Q5-1,Low-Overhead Disambiguation for Generative Linguistic Steganography via Tokenization Consistency,/proceedings/annual_meeting/2025/pdf_dir/Q5-1.pdf,"○◊Ruiyi Yan, 村脇 有吾 (京大)","Generative linguistic steganography aims at embeddinginformation into natural language texts for covert transmis-sion. However, in most tokenizer-based language modelapproaches, segmentation ambiguity during extraction canresult in errors or extraction failures. Despite several ex-isting countermeasures (or disambiguation) that have beenproposed, none address this issue from the perspective oftokenization consistency. Speciﬁcally, previous methodsexcessively modify candidate pools, compromising imper-ceptibility or embedding capacity. To address it, we pro-pose a stepwise tokenization-veriﬁcation method whichprecisely removes error tokens for each step, ensuring"
Q5:ポスター3月12日（水） 8:30-10:00   Q会場(1F会議室101AB),Q5-2,訓練・推論時の不一致を解消する離散拡散テキスト生成モデル,/proceedings/annual_meeting/2025/pdf_dir/Q5-2.pdf,"○浅田 真生 (産総研), 三輪 誠 (豊田工大/産総研)",本研究では，離散拡散モデルを用いたテキスト生成において生じる訓練時と推論時の不一致に注目し，この問題を解消するため，訓練時の損失計算においてモデルが予測した系列を次ステップの入力として使用する2 ステップ損失計算アプローチと，その確率的スケジューリングを提案する．提案手法を広く使用されている4 つのテキスト生成ベンチマークデータセットにおいて学習・評価した結果，2 ステップ損失計算による離散拡散モデルの性能向上を確認した．
Q5:ポスター3月12日（水） 8:30-10:00   Q会場(1F会議室101AB),Q5-3,Generating Explanations of Stereotypical Biases with Large Language Model,/proceedings/annual_meeting/2025/pdf_dir/Q5-3.pdf,"○◊Yang Liu, Chenhui Chu (京大)","Existing studies investigate stereotypical biases in largelanguage models (LLMs) through the diﬀerence betweenreal-world and counterfactual data. In this case, real-worlddata typically exhibit pro-stereotypical bias, while counter-factual data rewritten by humans exhibit anti-stereotypicalbias.Due to the subjective nature of stereotypical biasjudgment, it is crucial to explain the judgment. In thisstudy, we aim to use LLMs to judge whether a sentenceis pro- or anti-stereotypical and explain the reason for thejudgment. We construct a stereotypical bias explanationdataset for this goal. The experimental results show thatLLMs outperform humans in distinguishing pro- and anti-stereotypical biases. Moreover, our constructed dataset ishighly eﬀective in training smaller language models to gen-erate high-quality explanations. Finally, we ﬁnd that LLMsdiﬀer from human annotations on counterfactual data thanon real-world data."
Q5:ポスター3月12日（水） 8:30-10:00   Q会場(1F会議室101AB),Q5-4,Open Weight LLMs in Out-of-Distribution Setting: Search Ad Title Generation,/proceedings/annual_meeting/2025/pdf_dir/Q5-4.pdf,"○◊Tolmachev Arseny, Foran Joseph, 星野 智紀, 森川 裕介 (HT)","Large Language Models (LLMs) have revolutionized theNLP landscape overnight. However, they still struggle inout-of-distribution (OOD) scenarios. We present a casestudy on the performance of LLMs in the ad title gen-eration task, which represents an OOD scenario. LLMsperform better than we expected. Instruction-tuned mod-els are signiﬁcantly more stable than non-tuned ones. Adistilled Llama 3.2 performs signiﬁcantly worse than thebase Llama 3.1.General chat instruction-tuned modelsyield mixed results compared to non-tuned models."
Q5:ポスター3月12日（水） 8:30-10:00   Q会場(1F会議室101AB),Q5-5,ClaimBrush: 特許審査官の選好を考慮した選好最適化に基づいた特許請求の範囲の自動補正モデル,/proceedings/annual_meeting/2025/pdf_dir/Q5-5.pdf,"○河野 誠也 (理研/NAIST), 野中 尋史 (愛工大), 吉野 幸一郎 (科学大/理研/NAIST)",特許出願における特許請求の範囲の自動補正は，知的財産戦略の観点から極めて重要である。本研究では、データセットと書き換えモデルを含む特許文書の自動補正のための新しいフレームワーク“ClaimBrush” を提案する。具体的には，特許請求の範囲の自動補正モデルを学習・評価するためのデータセットを，特許審査過程における実際の特許請求の範囲の補正事例を大量に収集することによって構築した。構築したデータセットを用いて，大規模言語モデルを微調整することにより，特許請求の範囲の自動補正モデルを構築した。さらに，特許審査官による特許出願の拒絶査定の自動予測結果に基づいた選好最適化を適用することで，提案した特許請求の範囲の自動補正モデルの性能を向上させた。評価実験の結果，提案した特許請求の範囲の自動補正モデルは，経験則に基づいたベースラインや最先端の大規模言語モデルを用いたゼロショット学習手法を凌駕することが示された。さらに，特許審査官による拒絶査定の予測結果に基づいた選好最適化により特許文書の補正性能が向上することを示した。
Q5:ポスター3月12日（水） 8:30-10:00   Q会場(1F会議室101AB),Q5-6,Loss as a Data Introspection Method: Looking into Japanese Advertising Text Generation,/proceedings/annual_meeting/2025/pdf_dir/Q5-6.pdf,"○◊Joseph Foran, Arseny Tolmachev (Hakuhodo Technologies)","This paper presents a case study that examines the dis-tribution of training loss values in a Japanese advertisingtext generation model. Using a LongT5 architecture, weanalyze the characteristics of training examples that exhibitboth high and low loss values. Our ﬁndings reveal severalkey patterns: low-loss examples often contain repetitivephrases and standardized advertising terminology, whilehigh-loss examples tend to feature more complex gram-matical structures and natural language patterns. We alsoidentify potential issues in training data quality and dis-cuss their implications for model performance. We ﬁndthat measuring training loss per example in the trainingdata is a useful diagnostic tool, for better understandingmodel characteristics."
Q5:ポスター3月12日（水） 8:30-10:00   Q会場(1F会議室101AB),Q5-7,タスクベクトル演算を用いた感情表現テキスト生成モデル合成手法,/proceedings/annual_meeting/2025/pdf_dir/Q5-7.pdf,"○天野 椋太, 目良 和也, 黒澤 義明, 竹澤 寿幸 (広島市大)",近年の大規模言語モデル（LLM）を活用した対話システムの飛躍的な発展に伴い，対話システムのパーソナライズへの関心も高まってきている．しかし新たな性格のテキスト生成モデルを表現するには，表現したい感情の強さや混ざり具合に応じたモデルを個別に作らなければならない．本研究では，個別の感情を表現することに特化したモデルを感情ごとに作成し，タスクベクトル演算を用いてモデルを合成することで，感情の強弱や複合感情を表現する手法を提案する．LLM を用いたテキスト評価実験の結果，対象感情の強弱と感情の複合いずれについても生成テキストで表現できていることが確認された．
Q5:ポスター3月12日（水） 8:30-10:00   Q会場(1F会議室101AB),Q5-8,"Disentanglement or Entanglement, which is Better for TST",/proceedings/annual_meeting/2025/pdf_dir/Q5-8.pdf,"○◊徐 勝, 鈴木 良弥, 福本 文代 (山梨大)","With the continuous breakthroughs in the capabilities ofTransformer-based models, NLP research focused on lan-guage style, such as Text Style Transfer (TST), has gradu-ally attracted more attention. Approaches for handling TSTtasks can generally be categorized into two main strategies:disentanglement and entanglement. This paper proposesa method to construct two prompting pipelines based onthese two strategies, utilizing Chain of Thought (CoT) andLarge Language Models (LLMs). We investigate the per-formance of these pipelines on four TST sub-tasks andanalyze their improvements compared to the baseline."
Q5:ポスター3月12日（水） 8:30-10:00   Q会場(1F会議室101AB),Q5-9,自然言語での異常解釈：LLMを用いたAI説明モデルの提案,/proceedings/annual_meeting/2025/pdf_dir/Q5-9.pdf,"○山科 勇輔, 須賀 圭一, 白井 祐典, 市川 佳彦 (Insight Edge)",本研究では、画像異常検モデルと大規模言語モデル（LLM）と組み合わせることで、より解釈しやすくする新しいアプローチを提案する．異常検知は、製造業や医療分野で不可欠であり、迅速かつ正確な判断が求められるが、その出力が抽象的で理解しづらいことがある．そこで画像処理アルゴリズムによって検知された異常を、LLM を用いて自然言語で説明する言語駆動型説明可能AI（Language-DrivenExplainable AI）を提案し、異常検知結果の信頼性と透明性の向上を図るまた、その出力が実業務に有用であるかも検証する．
Q5:ポスター3月12日（水） 8:30-10:00   Q会場(1F会議室101AB),Q5-10,最小ベイズリスク復号におけるバイアスと多様性の分解,/proceedings/annual_meeting/2025/pdf_dir/Q5-10.pdf,"○上垣外 英剛 (NAIST/科学大), 出口 祥之 (NTT), 坂井 優介 (NAIST), 林 克彦 (東大), 渡辺 太郎 (NAIST)",一般的な自然言語生成は、探索空間を制限し出力品質を低下させる貪欲法やビーム探索に依存している。最小ベイズリスク(MBR) 復号は、自動評価尺度とモデルが生成した擬似参照を利用することでこの問題を緩和する。従来研究では、MBR 復号による生成性能の改善を明らかにするための経験的分析が行われ、様々な観察結果が報告されている。その一方で、それらの理論的な背景は不確かである。これに対処するために、本研究ではバイアス-多様性分解の観点からMBR 復号の新しい理論的解釈を提示する。この解釈では、MBR 復号による仮説の品質推定の誤差を、効用関数と人間の評価との近接性を考慮したバイアスと効用関数の品質推定のばらつきを表す多様性の二つの主要な要因に分解する。理論的分析により、バイアスと多様性の両方を同時に改善することの難しさが明らかになり、多様性を高めることによるMBR 復号の性能向上の妥当性が確認された。また、複数のNLP タスクにおける実験により、理論的特性と合致する結果が観測された。
Q5:ポスター3月12日（水） 8:30-10:00   Q会場(1F会議室101AB),Q5-11,Multi-modularizing CodeChainによるコード生成タスクの細分化が精度に与える影響,/proceedings/annual_meeting/2025/pdf_dir/Q5-11.pdf,"○井上 貴之, 鶴岡 慶雅 (東大)",大規模言語モデルによる競技プログラミングのような入力に対し出力が一意に定まるコード生成においては、タスクを小タスクの連続に分割し、それぞれを解決するアプローチが取られている。本研究ではコード内定義関数を利用しタスクの細分化を行うCodeChain と呼ばれる機構について、高難易度の問題における精度向上に向け、関数内関数を利用しさらなる細分化を行うようプロンプトの改修および関数内関数の抽出、評価を追加した。結果、一部のデータ、モデルでは精度の向上が確認できた。
Q5:ポスター3月12日（水） 8:30-10:00   Q会場(1F会議室101AB),Q5-12,GPTを用いた退院サマリの自動生成に関する性能評価について,/proceedings/annual_meeting/2025/pdf_dir/Q5-12.pdf,"○中谷 亮太, 廣淵 亮太, 佐藤 貴俊 (SB), 篠原 恵美子 (東大), 岡本 康宏, 有田 悠人, 有田 隼也, 佐藤 敏紀 (SB), 河添 悦昌, 大江 和彦 (東大)",退院サマリは，退院後の患者のケアを引き継ぐ医療関係者や医療機関に対して，診断結果や入院中の治療に関して正確な情報を共有するのに重要な役割を果たす．その一方で，退院サマリの作成には大量のデータから必要な情報を取捨選択する必要から多くの時間と労力がかかり，多忙な医師にとっては削減したい作業の一つである．本研究では，大規模言語モデルの一つであるGPT を用いて，患者情報及び看護記録等のデータから退院サマリを自動生成することを目指す．具体的には，患者基本情報及び看護記録等から引用元を明らかにしつつ，退院サマリを自動生成し，医師が作成した退院サマリと比較することで，生成された退院サマリの評価を行う．検証の結果，GPT が生成する退院サマリは比較的簡素に生成され，データ全体から満遍なく情報を抽出するセクションに関しては精度が低いことが確認された．
Q5:ポスター3月12日（水） 8:30-10:00   Q会場(1F会議室101AB),Q5-13,大規模言語モデルを用いたソースコードからのドキュメント生成能力調査,/proceedings/annual_meeting/2025/pdf_dir/Q5-13.pdf,"○杉山 咲 (奈良高専), 蒔苗 茉那, 片山 歩希, 坂井 優介 (NAIST), 山口 賢一 (奈良高専), 渡辺 太郎 (NAIST)",ソフトウェアシステムの品質向上には，可読性が高いプログラムが必要不可欠である．特に，処理内容や要素の説明が記述されているコメントやドキュメントは可読性の向上に役立つ．しかし内容の一貫性や明確さ，正確さがの保証が困難であり，高品質なドキュメントの作成には多くの課題がある．またドキュメントが未記載のコード資源も大量に存在しており，コード資源の可用性向上にはドキュメントの整備が必要となる．そこで本稿では，大規模言語モデル(LLM) が可読性の高いドキュメントを生成する能力があるか，Python の関数データからドキュメンテーション文字列であるDocstring をLLM で生成し調査する．複数の観点による分析の結果，LLMは概ね形式的であり可読性が高いDocstring が生成可能な一方で，可読性が低いコードに対しては意図しない書き換えなどを行うことが明らかとなった．
Q5:ポスター3月12日（水） 8:30-10:00   Q会場(1F会議室101AB),Q5-14,自由記述回答から選択肢設問を生成するモデルの構築とMCA参照空間への射影による生成内容の解釈,/proceedings/annual_meeting/2025/pdf_dir/Q5-14.pdf,"○根本 颯汰 (法政大), 土井 智暉 (東大), 花田 智洋 (NICT), 谷中 瞳 (東大), 彌冨 仁 (法政大), 藤本 一男 (NICT/津田塾大)","自由記述回答から選択肢設問の生成はLLM の発展に伴い注目されており, 調査票の改善と回答者や分析者の負担を減らすことができる. 本稿では, データ漏洩のリスクを考慮して, Open-source LLM を組み合わせた自由記述回答から選択肢設問を生成するモデルを構築し, その生成設問を多重対応分析(MCA)による参照空間に射影し, 解釈を行った. 以上を通して, 構築したモデルの機能的有効性を確認した. また, 類似度が高く, 多様性が低いとされる生成設問でもMCA による幾何学的分析によって解釈可能であることを確認できた."
Q5:ポスター3月12日（水） 8:30-10:00   Q会場(1F会議室101AB),Q5-15,情報科学論文の情報量と文章量を維持した自動平易化の試み,/proceedings/annual_meeting/2025/pdf_dir/Q5-15.pdf,"○大西 耕介, 菊池 英明 (早大), 藤倉 将平 (サイシキ)","専門的な文書の平易化は医療分野を対象としたものが多く, 情報科学の分野を対象にしたものは少ない. また, 既存の平易化研究では専門用語の意味を大きく削って平易化を行ったり, 専門用語を非常に長い文章で平易化したりしている. これは論文の情報を全て簡潔に理解するためには適切とは言えない.本研究では情報科学分野の論文を対象に, 専門用語の平易な説明のポップアップを用いて平易化を行うシステムの開発を行った. 目標として, 内容の理解しやすさの改善, 文章量の増加防止, 情報量の保持を掲げた. 内容の理解しやすさの改善は見られなかったが, 先行研究手法と比べ情報量の保持に成功し, 文章量の増加防止は達成した."
Q5:ポスター3月12日（水） 8:30-10:00   Q会場(1F会議室101AB),Q5-16,任意の題目に対する多様な視点の獲得を目的としたラップバトル形式のディベート生成システムの提案,/proceedings/annual_meeting/2025/pdf_dir/Q5-16.pdf,"○三林 亮太 (兵庫県大), 浦川 通 (朝日新聞社), 高梨 大 (Dentsu Lab Tokyo), 諸星 智也 (Think & Craft), 山岸 奏大 (Dentsu Lab Tokyo), 関川 龍宝, 西村 保彦 (Think & Craft), 竹内 祐太 (Dentsu Lab Tokyo), 田森 秀明 (朝日新聞社), 山本 岳洋, 大島 裕明 (兵庫県大)",本研究では，任意の題目に対する多様な視点の獲得を目的とした，ラップバトル形式のディベート生成システムを提案する．意見の対立する即興のディベートを視聴することで，多様な視点を養えることが知られており，これに類似する競技として，即興のラップを通じてお互いの意見を主張するラップバトルがある．本研究では，手動で作成したプロンプトを基にGPT-4o でラップバトル形式のディベートを生成し，その視聴を円滑にするためのデモシステムの作成に取り組んだ．評価は，全国中学・高校ディベート選手権の題目を基に生成したディベート
Q5:ポスター3月12日（水） 8:30-10:00   Q会場(1F会議室101AB),Q5-17,日本語平易化へのTask Arithmeticの応用とその検証,/proceedings/annual_meeting/2025/pdf_dir/Q5-17.pdf,○小西 修平 (NHK),"大規模言語モデルは平易化においても一定の性能を持つことが知られており, 平易化コーパスによる学習を行うことでより高性能な平易化モデルが作成できることが期待できるが, 日本語平易化データセットは質・量ともに十分ではない. この問題を解決するため, モデルの重みの加減算によりモデルの能力を転移する技術であるTask Arithmetic の応用を検討したが, 平易化へ適用した事例は少ない. 本研究では日本語平易化コーパスSJNC を用い, 平易化におけるTask Arithmetic の有効性を検証した. 自動評価の結果スコアの向上が確認され, Task Arithmetic が日本語の平易化に対しても有効である可能性が示された."
Q5:ポスター3月12日（水） 8:30-10:00   Q会場(1F会議室101AB),Q5-18,難解な入力単語を用いた日本語 CommonGen タスクによる LLM の文生成能力評価,/proceedings/annual_meeting/2025/pdf_dir/Q5-18.pdf,"○鈴木 雅人, 新納 浩幸 (茨大)",大規模言語モデル（LLM）の出現により、機械による文生成の能力は大きく向上した．それに伴い、LLM の出現以前に利用されていた文生成能力を測るタスクは現在のLLM の能力を測る指標としては適切なものでなくなってしまったものが多い．その一つに常識推論能力を測るCommonGen がある．本研究では、文生成タスクのCommonGen における入力単語を特定の分野に絞った専門用語にすることで、さらに高い文生成能力を求められるタスクにする試みを行った．更に試験的に作成したデータセットを用いて、LLM による生成文の評価と人手評価を行い、LLM の文生成能力と自動評価の可能性について調査した．
Q5:ポスター3月12日（水） 8:30-10:00   Q会場(1F会議室101AB),Q5-19,係り受け情報と残存文長を考慮した講演テキストへの逐次的な改行挿入,/proceedings/annual_meeting/2025/pdf_dir/Q5-19.pdf,"○高橋 晨成, 大野 誠寛 (東京電機大), 松原 茂樹 (名大)",講演を対象とした字幕生成システムにおいて，講演文特有の長い文が複数行にまたがって表示されると読みやすさが低下するため，適切な位置に改行を挿入し，読みやすい字幕を生成する必要がある．本稿では，読みやすい字幕を生成するための要素技術として，文末を未知とした問題設定において，漸進的係り受け解析結果と残存文長推定結果を考慮した逐次的な改行挿入手法を提案する．
Q5:ポスター3月12日（水） 8:30-10:00   Q会場(1F会議室101AB),Q5-20,Iterative Graph-to-Text Generation with Contextualization for Scientific Abstracts,/proceedings/annual_meeting/2025/pdf_dir/Q5-20.pdf,"○◊Haotong Wang, Liyan Wang, Yves Lepage (早大)","We propose an iterative graph-to-text generation methodto produce coherent scientiﬁc abstracts from paragraph-level knowledge graphs. The method segments the graphsinto smaller, context-speciﬁc components using functionallabels, which guide each generation step and inﬂuence sub-sequent outputs.Experimental results demonstrate thatﬁne-tuning the proposed method enhances the alignmentof Large Language Models (LLMs) with target seman-tics. Moreover, incorporating functional labels and itera-tive generation further improves semantic accuracy, struc-tural clarity, and logical organization, providing a scalablesolution for high-quality abstract generation."
Q5:ポスター3月12日（水） 8:30-10:00   Q会場(1F会議室101AB),Q5-21,テキスト埋め込みからのテキスト復元における予測制御の援用の効果検証,/proceedings/annual_meeting/2025/pdf_dir/Q5-21.pdf,"○三好 優輝, 宮岡 祐弥, 井上 正樹 (慶應大)","テキスト埋め込みから元のテキストを復元する方法を, Vec2Text[1] とは別のアプローチで考えた. そのアプローチは, テキスト生成において予測制御の考えを用いる方法である. 予測制御によるテキスト生成を用いると, Greedy Search によりテキスト生成した場合よりも性能が向上した. 具体的には, 2 つのテキストの内容が一致する割合が最大0.120 だけ向上した."
Q5:ポスター3月12日（水） 8:30-10:00   Q会場(1F会議室101AB),Q5-22,LLMを用いた発話生成のキャラクター性付与におけるプロンプトとファインチューニングの効果比較,/proceedings/annual_meeting/2025/pdf_dir/Q5-22.pdf,"○中路 侑里, 狩野 芳伸 (静大)",LLM による発話生成時にキャラクター性を持たせ一貫したペルソナで会話させることは、人間であるユーザと自然な会話を実現させるうえで重要な要素である. その手法としてプロンプトエンジニアリングやFine-tune があるが、どのような設定の組み合わせが最適かよくわかっていない。本研究では、5 名のキャラクターを対象に、4 種類のLLM を用いて、プロンプトとFine-tune の効果比較を行った。実験の結果、few-shot を中心にプロンプトの有効性を確認したと同時に、実験の範囲では小規模なFine-tune が総合的に良い結果を示した。
Q5:ポスター3月12日（水） 8:30-10:00   Q会場(1F会議室101AB),Q5-23,Faissを用いたデータ拡張によるポジティブテキストリフレーミングの精度向上,/proceedings/annual_meeting/2025/pdf_dir/Q5-23.pdf,"○松田 龍之介, 徐 勝, 福本 文代, 鈴木 良弥 (山梨大)",入力文の意味を保持したまま否定的な感情を肯定的な感情へ変換するポジティブテキストリフレーミング(PTR) タスクは，大規模言語モデルの進展により広く研究されている．PTR タスクでは，事前学習済のモデルを利用し，対象データに併せてファインチューニングする手法が多く提案されている．しかし，PTR タスクにおけるファインチューニングでは，ソース文とターゲット文は同義であり，ソース文は否定を，ターゲット文は肯定を表す大量のパラレルデータが必要であることから，データ不足が問題となることが多い．本研究は，データ拡張手法により生成したパラレルデータを用いることにより，PTR の精度向上を目指す．
Q5:ポスター3月12日（水） 8:30-10:00   Q会場(1F会議室101AB),Q5-24J,日本語ニュース記事要約支援に向けたドメイン特化事前学習済みモデルの構築と活用,/proceedings/annual_meeting/2025/pdf_dir/Q5-24.pdf,"○石原 祥太郎 (日経), 村田 栄樹 (早大), 高橋 寛武, 中間 康文 (独立研究者)",
Q5:ポスター3月12日（水） 8:30-10:00   Q会場(1F会議室101AB),Q5-25J,Bidirectional Transformer Reranker for Grammatical Error Correction,/proceedings/annual_meeting/2025/pdf_dir/Q5-25.pdf,"○◊Ying Zhang (理研), 上垣外 英剛 (NAIST), 奥村 学 (理研/科学大)",
A6:NLPモデルの解釈可能性・分析(2)3月12日（水） 10:20-11:50   A会場(2Fコンベンションホール1+2),A6-1,スパースオートエンコーダーを用いた大規模言語モデルのチェックポイント横断分析,/proceedings/annual_meeting/2025/pdf_dir/A6-1.pdf,"○稲葉 達郎 (京大/NII), 乾 健太郎 (MBZUAI/東北大/理研), 宮尾 祐介 (東大/NII), 大関 洋平 (東大), Benjamin Heinzerling (理研/東北大), 高木 優 (NII)",大規模言語モデルは優れた多言語能力と広範な知識を有するが，これらの能力が内部的に形成される過程は定かでない．本研究ではこの疑問を解明するため，モデルの内部表現に含まれる情報が学習経過に伴いどう変化していくかを分析する．具体的には，モデルのチェックポイント別にスパースオートエンコーダーを学習し，その解釈結果をチェックポイント横断で比較する．実験の結果，大規模言語モデルは言語を個別に学習した後に言語間の対応関係を学習すること，トークンレベルの知識を学習した後に抽象度の高い概念レベルの学習をすることが明らかとなった．
A6:NLPモデルの解釈可能性・分析(2)3月12日（水） 10:20-11:50   A会場(2Fコンベンションホール1+2),A6-2,大規模言語モデルにおいて数値属性間で共有されるスケーリングベクトルの解析とその応用,/proceedings/annual_meeting/2025/pdf_dir/A6-2.pdf,"○峰岸 剛基, 高木 洋羽, 木澤 翔太, 助田 一晟, 谷中 瞳 (東大)",大規模言語モデル（LLM）の利活用が進む一方で，その推論過程や内部表現は不透明である．本研究では，LLM の内部表現における数値属性の構造に着目し，部分的最小二乗法（PLS）を用いたprobingを通じて，異なる属性間で共通する「数値を変調する方向成分（スケーリングベクトル）」の存在を明らかにする．さらに，異なる属性間の交絡は，特定属性への介入操作やfew-shot プロンプティングによる出力に副作用を及ぼすことを実験的に示す．この結果は，LLM の内部表現に対する解釈可能性と実用上の制御手法を結び付け，LLM の出力の公平性や頑健性の研究に貢献しうる示唆を提供する．
A6:NLPモデルの解釈可能性・分析(2)3月12日（水） 10:20-11:50   A会場(2Fコンベンションホール1+2),A6-3,競技クイズにおけるLLMと人間の誤答傾向の分析と比較,/proceedings/annual_meeting/2025/pdf_dir/A6-3.pdf,"○杉浦 尚弥 (名大), 小川 泰弘 (名市大), 外山 勝彦, 山田 康輔, 笹野 遼平 (名大)",本稿では，競技クイズを題材として，問題文や正解1）の特性がLLM と人間の解答の正答率にもたらす影響について調査し，人間とLLM における「難しさ」の違いを明らかにする．人間の正答率が付与されたクイズデータを収集し，クイズの正解のWikipedia エントリが存在するか，正解の文字種が何であるか，問題文中で解答候補が列挙されているか，という3 つの観点で分類する．GPT-4o など6 つのLLM にクイズを解答させ，各観点による分類ごとのLLM と人間の正答率の差を明らかにする．
A6:NLPモデルの解釈可能性・分析(2)3月12日（水） 10:20-11:50   A会場(2Fコンベンションホール1+2),A6-4,専門ドメインを対象とした事前学習データと精度の関係分析,/proceedings/annual_meeting/2025/pdf_dir/A6-4.pdf,"○緒方 陸, 岡野 将大 (八千代エンジニヤリング), 大曽根 宏幸 (インダストリアル・ドリーム), 大久保 順一, 藤井 純一郎 (八千代エンジニヤリング)",大規模言語モデル(LLM)はlong-tail の知識に対して精度が低く，過去には事前学習データに含まれる知識に関する頻度が高いと精度も高くなる関係を示した例がある．一方，実用上はより複雑なタスクを解くことがあり，単純な頻度よりもいかに文脈を捉えるかが重要となる可能性もある．そのための基礎的な分析として，本研究では次の二つを実施した．
A6:NLPモデルの解釈可能性・分析(2)3月12日（水） 10:20-11:50   A会場(2Fコンベンションホール1+2),A6-5,Derivational Probing：言語モデルにおける統語構造構築の解明,/proceedings/annual_meeting/2025/pdf_dir/A6-5.pdf,"○染谷 大河, 吉田 遼, 谷中 瞳, 大関 洋平 (東大)",Transformer ベース言語モデルの内部表現には統語構造が表現されていることが示唆されているが，入力が各層を伝播する中で統語構造が構築される過程は依然として不明確である．本研究では，Transformer ベース言語モデルにおける，統語構造の構築過程を定量的に分析するための新しい手法としてDerivational Probing（派生的プロービング）を提案する．これにより，文の局所的な構造と大域的な構造が，単語表現が各層を伝播する過程でどのように構築されるかを検証することが可能となる．BERT とGPT-2 を用いた実験では，BERT は局所的な構造を構築してから大域的な構造を構築するボトムアップな方法をとるのに対し，GPT-2 は局所的な構造と大域的な構造をよりパラレルに構築する傾向があることが示された．また，主述の一致タスクのケーススタディでは，BERT モデルが最終的に正しい統語構造を導出する場合でも，大域的な構造の構築が行われる層の位置が，タスクのパフォーマンスに影響を与えることが示され，大域的な構造を構築する最適な層の範囲が存在することを示唆した．
A6:NLPモデルの解釈可能性・分析(2)3月12日（水） 10:20-11:50   A会場(2Fコンベンションホール1+2),A6-6,対照損失による追加学習がBERTのファインチューニングにもたらす効果,/proceedings/annual_meeting/2025/pdf_dir/A6-6.pdf,"○竹中 誠 (三菱電機), 瀧 雅人 (立教大)",本研究では，事前学習済みBERT に対する対照損失による追加学習が，下流タスクのファインチューニングに与える影響を実験的に調査する．実験では，事前学習済みBERT と，それをSimCSE で学習したモデルをファインチューニングするときの学習の安定性とモデルの可塑性の二つの観点で分析した．実験の結果，SimCSE で追加学習したモデルでは，( 𝑖) 大きい学習率でのファインチューニングがより安定的になり，(𝑖𝑖) パラメータに関するフィッシャー情報行列の有効ランクが回復することで，モデルの可塑性が向上することがわかった．
B6:知識獲得・情報抽出(1)3月12日（水） 10:20-11:50   B会場(1F会議室102),B6-1,医学生物学文献からのオントロジー構築のためのメンション非依存型情報抽出,/proceedings/annual_meeting/2025/pdf_dir/B6-1.pdf,"○西田 典起 (理研), Oumaima El Khettari (ナント大/理研), Shanshan Liu, Rumana Ferdous Munne, 山縣 友紀 (理研), 古崎 晃司 (阪電通大), Solen Quiniou, Samuel Chaffron (ナント大), 松本 裕治 (理研)",生物学的プロセスなどのエンティティは、医学生物学文献内で常に明示的に言及されているとは限らず、しばしば専門知識の共有を仮定して暗黙的に言及される。本研究では、医学生物学文献からのオントロジー自動構築を目指し、プロセス抽出と文書レベル関係抽出の二段階からなるメンション非依存型情報抽出システムを提案する。提案システムでは、一貫してメンション表現に依存せず、入力文書に対して対象オントロジーに紐づいたプロセスエンティティ集合の抽出とエンティティ間関係の同定を可能にする。新たなベンチマークデータセットを構築し、BERT ベースまたはLLM ベースのメンション非依存型アプローチを提案し、評価と比較を行う。
B6:知識獲得・情報抽出(1)3月12日（水） 10:20-11:50   B会場(1F会議室102),B6-2,情報抽出パイプラインにおけるエラー伝播抑制手法の提案：オーバーサンプリング、フィルタリング指向学習、概念対応,/proceedings/annual_meeting/2025/pdf_dir/B6-2.pdf,"○西田 典起, Shanshan Liu, Rumana Ferdous Munne, 徳永 なるみ, 山縣 友紀 (理研), 古崎 晃司 (大阪電気通信大), 松本 裕治 (理研)",本研究では、情報抽出パイプラインにおけるエラー伝播問題を軽減するための方法を提案する。エンティティの偽陰性問題(抽出漏れ) に対して、「オーバーサンプリング」を導入する。また、エンティティの偽陽性問題(過剰抽出) に対しては、「フィルタリング指向学習」を提案する。さらに、エンティティ曖昧性解消による間違った概念とメンションの紐づけの文書レベル関係抽出に対する影響を軽減するために、「概念対応」を導入する。複数ドメインのデータセットを用いた実験の結果、提案手法によって、情報抽出パイプラインのエラー伝播に対するロバスト性が向上することを確認した。
B6:知識獲得・情報抽出(1)3月12日（水） 10:20-11:50   B会場(1F会議室102),B6-3,多様な言い換え生成と自己学習手法の統合による大規模言語モデルへの新規知識の追加学習,/proceedings/annual_meeting/2025/pdf_dir/B6-3.pdf,"○山本 貴之, 河原 大輔 (早大)",大規模言語モデル（LLM）に、新たな知識を追加学習によって取り込むことは、いまだ困難なタスクと言われている。近年はRAG のように外部情報を参照する手法が注目されているが、この手法においては、LLM 内部に蓄積された膨大な知識と新たな情報を統合し、高度な推論を行うことは依然として難しい。本研究では、LLM が自己学習を行う手法や、DPO（Direct Preference Optimization）による選好最適化手法から着想を得て、LLM に新規知識を効果的に埋め込む枠組みを提案し、その有効性を検証する。
B6:知識獲得・情報抽出(1)3月12日（水） 10:20-11:50   B会場(1F会議室102),B6-4,故障解析における事前学習済みSentence-DeBERTaによる拡張ナレッジグラフとクエリ分解を用いたGraphRAG,/proceedings/annual_meeting/2025/pdf_dir/B6-4.pdf,"○小島 湧太 (東大), 坂地 泰紀 (北大), 鈴木 雅弘 (東大), 中村 格士, 坂田 大晃, 関 和也, 勅使河原 優, 山下 雅己 (いすゞ), 青山 和浩 (東大)","熟練から若手エンジニアへの故障解析の知識継承は自動車業界喫緊の課題である. 故障に関する文書は非構造的でデータ量が多いため, そのままでは活用が困難である. このような文書をデータの構造化に優れるナレッジグラフ(KG) に変換することは有効であるが, 依然として理解が難しい.GraphRAG は, KG と大規模言語モデル(LLM) によるRAG (Retrieval-Augmented Generation) であり, KG 自体の理解を深めることも期待される.既存のKG を用いたGraphRAG に必要な処理を調査するため, 本稿ではLLM と継続事前学習済みSentence-DeBERTa で拡張した既存のKG と, クエリの分解に焦点を当てたEdgeGraphRAG を提案する.独自のデータセット構築と自動評価により, 現時点での有効性の検討と既存のKG を用いた際の課題を論じる."
B6:知識獲得・情報抽出(1)3月12日（水） 10:20-11:50   B会場(1F会議室102),B6-5,法令文の可読性向上のための定義規定・略称規定における文型定義及びパターンベースの正式名称・略称抽出手法,/proceedings/annual_meeting/2025/pdf_dir/B6-5.pdf,"○北野 尚樹 (筑波大), 西山 大輝 (科学大/理研)",法令文では定義規定・略称規定が頻繁に使用されている（例：新型インフルエンザ等対策の推進を図るため、内閣に、新型インフルエンザ等対策推進会議（以下「会議」という。）を置く。）．これらの規定文は複雑になりやすく，読者の混乱や負担を生じさせうる．そこで本研究では，既存法では不十分であった定義規定・略称規定に関する文型を導入し，これに基づき正式名称と略称のペアを抽出するパターンベースの手法を提案する．結果，提案法は複雑な構造や文型に対応し，既存の手法や大規模言語モデルとの比較で高い精度を達成した．また，今後の法令解析研究の促進のために，実験で使用した正式名称と略称のペアのデータセットを公開する．
B6:知識獲得・情報抽出(1)3月12日（水） 10:20-11:50   B会場(1F会議室102),B6-6,学術情報のテキスト解析と生成 AI を用いた専門用語抽出,/proceedings/annual_meeting/2025/pdf_dir/B6-6.pdf,"庄 金鳴 (九産大), 張 馨雲 (九産大/早大), ○成 凱 (九産大)",学術情報の電子化・大規模化に伴い，学術データが大量に蓄積され，学術ビッグデータと呼ばれるようになっている．学術ビッグデータの解析は，専門分野の動向を把握・予測し，新しい課題を開拓することが期待されている．しかし，専門性の高い学術情報を解析するにはその分野の特有な表現（専門用語やトピック）を抽出することが難しいとされている．本発表では，学術情報の自然言語解析による用語抽出を検証しつつ，複数生成AI の統合による専門用語抽出を考案し，実験による評価結果を報告する．
C6:教育応用3月12日（水） 10:20-11:50   C会場(1F会議室103),C6-1,Evaluating the Impact of Continual Pre-Training on Japanese Essay Scoring Tasks,/proceedings/annual_meeting/2025/pdf_dir/C6-1.pdf,"○◊Boago Okgetheng, Koichi Takeuchi (岡山大)","This paper investigates whether continually pre-trainingLarge Language Models on domain-speciﬁc reference textscan improve performance in Japanese Automated EssayScoring tasks.We use a dataset covering multiple es-say prompts related to four thematic areas― Globaliza-tion, Natural Science, Critical Thinking, and East AsianEconomics.Each essay is scored on a ﬁve-point scalefor Comprehensiveness. Models undergo two conﬁgura-tions: (1) direct ﬁne-tuning on the scored essays, and (2)an additional continual pre-training phase using domain-speciﬁc texts prior to ﬁne-tuning. Our ﬁndings indicatethat most models beneﬁt from this extra training, as ev-idenced by improvements in evaluation metrics such asthe F1 Score, Quadratic Weighted Kappa, Accuracy, andRoot Mean Squared Error. These results underscore theimportance of domain adaptation for more accurate essayscoring."
C6:教育応用3月12日（水） 10:20-11:50   C会場(1F会議室103),C6-2,強化学習に基づくデータ選別を通した問題横断型小論文自動採点の精度向上,/proceedings/annual_meeting/2025/pdf_dir/C6-2.pdf,"○柴田 拓海, 宇都 雅輝 (電通大)",近年，小論文自動採点タスクの一つとして問題横断型自動採点が注目されている．しかし従来の問題横断型自動採点では様々な問題に対する採点済み小論文データを全て訓練に利用するため，目的の問題の自動採点に悪影響を与えうるデータまで訓練に利用される可能性がある．この問題を解決するために本研究では，訓練データの価値を評価し，モデル学習に悪影響を及ぼす可能性のあるデータを除外することでその採点精度を向上させる手法を提案する．
C6:教育応用3月12日（水） 10:20-11:50   C会場(1F会議室103),C6-3,難易度調整可能な多枝選択式読解問題自動生成手法とDirect Preference Optimizationによる難易度調整精度の向上,/proceedings/annual_meeting/2025/pdf_dir/C6-3.pdf,"○富川 雄斗, 宇都 雅輝 (電通大)",近年，深層学習を用いて任意の難易度で読解問題を生成できる技術が提案されている．しかし，従来手法は，読解対象文中から答えを抜き出して回答する形式の問題のみを対象としており，教育現場で広く使われている多肢選択式問題を生成できない．加えて，従来手法では訓練データ中の問題の単語列に対する尤度を最大化するように深層学習モデルを訓練しており，難易度調整精度を直接最適化していないため，難易度調整精度に改善の余地が残る．そこで本研究では，自己回帰型の深層学習モデルを用いた難易度調整可能な多枝選択式問題生成手法を開発するとともに，Direct Preference Optimization により難易度調整精度を最大化する訓練手法を提案する．
C6:教育応用3月12日（水） 10:20-11:50   C会場(1F会議室103),C6-4,LLM を用いた質問生成による児童の作文の詳述化支援の検討,/proceedings/annual_meeting/2025/pdf_dir/C6-4.pdf,"○横野 光 (明星大), 成家 雅史 (相模女子大), 宮城 信 (富山大)",小学校の作文教育における内容に関する指導では出来事の具体的な描写を促すといったことが行われる．しかし，児童にとっては具体的なイメージがわかず詳述化が困難となることもある．これに対し，作文に内容に対する質問を児童に行うことで修正の指針を示すことができると考えられるが，多くの児童の作文に対し質問を考えることは教師にとって大きな負荷となる．そこで本研究では，内容の詳述化のための質問生成に大規模言語モデルが利用できるかについて，小学生に対して行った調査に基づき検討を行った．
C6:教育応用3月12日（水） 10:20-11:50   C会場(1F会議室103),C6-5,Elaborative Text Simplification via Target Estimation using Large Language Models,/proceedings/annual_meeting/2025/pdf_dir/C6-5.pdf,"○Martyna Gruszka, 荒瀬 由紀 (科学大)","Text simpliﬁcation is widely believed to enhancecomprehension for non-native readers, and has, there-fore, been the focus of extensive research. However,conventional text simpliﬁcation often involves remov-ing a considerable amount of complex content, whichmay reduce valuable information and potentially limitopportunities to engage with challenging concepts. Inthis work, we speciﬁcally address the needs of lan-guage learners by focusing on elaborative text simpli-ﬁcation, a process involving content addition, such asproviding speciﬁc explanations and clariﬁcations thatcould make a text comprehensible within its context.We introduce a novel data-driven approach for guidedelaboration generation, demonstrating that explicitlyspecifying elaboration targets leads to improved per-formance."
C6:教育応用3月12日（水） 10:20-11:50   C会場(1F会議室103),C6-6,言語指標を用いた日本語文章の難易度の可視化と教育への応用,/proceedings/annual_meeting/2025/pdf_dir/C6-6.pdf,"○劉 婧怡, 内田 諭 (九大)",本研究は，日本語学習者向けの文章の難易度判定の可視化と日本語能力試験（JLPT）との対応付けを行うものである．別の研究で提案した分類精度が88.0%の35 の言語指標集合を基に，難易度を文字語彙，文構造，談話構造の3 観点から捉え，それぞれリッジ回帰モデルを構築し，スコアを可視化した．JLPT の読解文章を用いて提案手法を検証した結果，提案モデルは全体的に判定精度が高く，観点別の難易度スコアを科学的根拠に基づいて提示できる点で，大規模言語モデルを用いた判定手法に対して優位性を示した．さらに，日本語教育における難易度と教育枠組みの関連性を明らかにするため，一般の日本語文章とJLPT の読解文章における観点別難易度の相対位置を可視化した．これらの成果は学習者のレベルに合わせた読解教材の作成・開発に貢献することが期待される．
D6:テーマセッション5: 言語とコミュニケーションの創発(2)3月12日（水） 10:20-11:50   D会場(1F会議室107),D6-1,二者関係の概念化に基づく構文交替の文化進化,/proceedings/annual_meeting/2025/pdf_dir/D6-1.pdf,"○岩村 入吹, 橋本 敬 (JAIST)",進化言語学は，動物コミュニケーションシステムと比較しながら，人間言語の普遍的性質や文法一般の起源・進化・創発を説明しようとする．中には，同世代内でのコミュニケーションや，親の発話と子の学習が繰り返す世代間継承を対象とした文化進化研究がある．本研究では，同一状況を言語使用者の概念化によって表現の仕方を変える構文交替現象が世代間継承で創発する条件をシミュレーションにより示す．ここでは親が事象を概念化して発話し，子が概念化された意味を推論し発話と事象の関係を学習する状況を世代間継承と見做す．推論成功の確率が非常に高い場合のみ構文交替が生じた．
D6:テーマセッション5: 言語とコミュニケーションの創発(2)3月12日（水） 10:20-11:50   D会場(1F会議室107),D6-2,変分ベイズ名付けゲームに基づく多エージェントによる記号創発の評価,/proceedings/annual_meeting/2025/pdf_dir/D6-2.pdf,"○福岡 慶太, 長野 匡隼, 中村 友昭 (電通大), 谷口 彰 (立命館大), 谷口 忠大 (京大/立命館大)",記号創発現象をモデル化するために，複数のエージェントが同じ対象を観測し，それを表現する共有されたサインを推論する，集合的予測符号化仮説が提唱されている．その推論方法として，我々は変分ベイズ法に基づく手法を提案し，複数のエージェント間で共有されたサインが形成可能であることを示している．変分ベイズ法は一般的にサンプリングを用いた手法に比べて学習効率が高いことが知られている．本稿では，1 エージェントが得る観測データのみでは正確な名付けが困難な設定や，エージェント数・データ数を増加させた設定を用いて，サンプリングを用いた従来手法との比較実験を行った．実験の結果，従来手法に比べて，より難しい課題に対しても学習が可能であり，大規模な設定でも収束性が高いことが確認された．
D6:テーマセッション5: 言語とコミュニケーションの創発(2)3月12日（水） 10:20-11:50   D会場(1F会議室107),D6-3,Vector Quantizationに基づく離散系列の発話による分散型深層モデルの提案,/proceedings/annual_meeting/2025/pdf_dir/D6-3.pdf,"○三好 遼 (フリー), 栗田 修平 (NII)",近年，記号創発ロボティクスでは，ベイズ脳仮説を始めとした統合情報理論に基づいたマルチモーダル処理や環境との相互作用による概念獲得などの様々な研究が進んでいる．中でも言語創発は，近年注目の研究であり，分散的ベイズ学習によるコミュニケーションモデルが提案されている．そこで本提案手法では，深層モデルへの応用を検討するため，ベクトル量子化を拡張したVQCom-VAE を提案し，実験にてコミュニケーションによる相手の発話から予測画像の生成が可能であることを示した．
D6:テーマセッション5: 言語とコミュニケーションの創発(2)3月12日（水） 10:20-11:50   D会場(1F会議室107),D6-4,AIは人間らしく話ができるか：ロボットと仲良くなるために,/proceedings/annual_meeting/2025/pdf_dir/D6-4.pdf,"○川原 功司 (名外大), 大道 麻由, 高橋 英之 (阪大)",ロボットが人間と遜色なく会話できるかという問題は，人工知能研究における大きな課題の一つである．本稿では，人間とロボットが快適に会話ができるかというプロジェクトで得られた報告を元に，人間とロボットの会話の特性の違いを明らかにする．特に，ロボットは会話を遂行する際に自分の誤りを修正する能力がなく，これが会話分析における他者修復という観点から分析することが可能であり，軌道修正をする力の有無が現在の人工知能と人間の会話を分ける大きな違いであると主張する．
D6:テーマセッション5: 言語とコミュニケーションの創発(2)3月12日（水） 10:20-11:50   D会場(1F会議室107),D6-5,音素の合成性を仮定した連続信号をサインとした分散的ベイズ推論に基づく記号創発,/proceedings/annual_meeting/2025/pdf_dir/D6-5.pdf,"○齋藤 一誠, 劉 智優, 長野 匡隼, 中村 友昭 (電通大), 谷口 彰 (立命館大), 谷口 忠大 (京大)",エージェント間のコミュニケーションを通して共有されるサインを創り出すことができる記号創発モデルが提案されている．これまでの研究ではサインの生成・認識能力の学習過程はモデル化されていなかった．そこで我々はこれまでに連続信号をサインとして用いた記号創発モデルを提案した．その手法では，複数の音素を組み合わせて単語を構成する音素の合成性を導入した連続信号から，エージェント間で対象を表現するサインを学習する．本稿ではその手法の比較・評価を行った．実験では，各エージェントは同一の物体を観測し，その物体を表現する物体の潜在表現と，それを表現するサインである連続信号を，コミュニケーションによって推論する．提案手法がエージェント間で高い一致率かつ高い精度で物体を表現するサインを学習可能であることを示した．
E6:テーマセッション1: 金融・経済ドメインのための言語処理(2)3月12日（水） 10:20-11:50   E会場(1F会議室108),E6-1,金融分野に特化した複数ターン日本語生成ベンチマークの構築,/proceedings/annual_meeting/2025/pdf_dir/E6-1.pdf,"○平野 正徳, 今城 健太郎 (PFN)",大規模言語モデル(LLM) の発展に伴い、様々な分野において性能を評価する取り組みが必要となってきている。本研究では、金融分野においてLLMの生成の良さ測るための日本語生成ベンチマークpfmt-bench-ﬁn-ja を提案した。pfmt-bench-ﬁn-ja は、MT-bench に対応するような金融分野に特化した複数ターンの日本語生成ベンチマークであり、12 カテゴリー、360 問のベンチマークを新たに構築した。評価にあたっては、GPT-4o-mini をLLM-as-a-judgeとして用いて、10 段階評価でスコア計測をすることとした。実験として、複数のLLM に対してベンチマークを計測し、その結果を比較検討した。その結果、pfmt-bench-ﬁn-ja が一定レベルでLLM の性能評価を行うことができることが示された。構築したベンチマークはGithub より利用可能である。
E6:テーマセッション1: 金融・経済ドメインのための言語処理(2)3月12日（水） 10:20-11:50   E会場(1F会議室108),E6-2,大規模言語モデルを用いた有価証券報告書の表質問応答,/proceedings/annual_meeting/2025/pdf_dir/E6-2.pdf,"○司 龍, 張 引, 王 小天, 宇津呂 武仁 (筑波大)",本論文の目的は，有価証券報告書の表から情報を抽出するタスク（NTCIR-18 U4 Task）に参加するためのシステムの構築である．NTCIR-18 U4 タスクは，表検索サブタスクと表質問応答サブタスクに分けられる．本研究は，表質問応答サブタスクに注目した．表質問応答サブタスクでは，多くの自然言語処理タスクで優れた結果を示している最先端の大規模言語モデル（LLM）を利用し，既存の事前学習済みのモデルを上回り，最高の性能を達成することが期待される．
E6:テーマセッション1: 金融・経済ドメインのための言語処理(2)3月12日（水） 10:20-11:50   E会場(1F会議室108),E6-3,東京証券取引所におけるティックサイズ変更に関するパブリックコメントの影響分析,/proceedings/annual_meeting/2025/pdf_dir/E6-3.pdf,○丸山 博之 (拓殖大),ティックサイズとは、投資家が注文を行うときに出す注文価格に関する変更可能な単位のことを表す。証券取引所がティックサイズを変更するのには、流動性を高めて、自社の取引所に投資家を呼び込無ことを目的としている。ティックサイズに関してはかず多くの研究があるが概ね流動性の改善が見られているが、東京証券取引所が２０１３年に実施した変更では流動性の悪化が一部で見られた。そこで、本研究では、ティックサイズ変更に関連したパブリックコメントを活用して、売買高の予測モデルの作成を行うことを目的とする。
E6:テーマセッション1: 金融・経済ドメインのための言語処理(2)3月12日（水） 10:20-11:50   E会場(1F会議室108),E6-4,株式掲示板テキストを活用したリターン予測における独立成分分析を利用した解釈性の向上,/proceedings/annual_meeting/2025/pdf_dir/E6-4.pdf,"○中島 秀太, 欅 惇志, 渡部 敏明, 小町 守 (一橋大)",本研究では，テキストデータを用いた株価のリターン予測タスクにおいて，独立成分分析(ICA) を適用することで解釈性の向上を目指す．近年，リターン（株価の変化率）の新たな予測変数として，テキストデータから得られる埋め込み表現が注目されている．ただし，テキストの埋め込み表現の各次元を変数として用いる手法では，個別の埋め込み次元を解釈することは困難である．そこで，本研究では，埋め込み表現に対してICA を適用することで，株価の変動の解釈可能性を向上させることを目的とする．実験の結果，意味的に解釈可能な複数のトピックが抽出され，これらのトピックは株価変動と関連性を示すことが確認された．
E6:テーマセッション1: 金融・経済ドメインのための言語処理(2)3月12日（水） 10:20-11:50   E会場(1F会議室108),E6-5,独立成分分析とFisherの線形判別による内閣府景気ウォッチャー調査データの分析,/proceedings/annual_meeting/2025/pdf_dir/E6-5.pdf,"○椎名 唯圭, 加藤 真大, 井口 亮 (みずほFT)",内閣府の景気動向調査である景気ウォッチャー調査では，さまざまな職業の人々による現在および将来の経済状況に関する評価が判断根拠テキストとともに公表されている．本研究では，この景気ウォッチャー調査データをテキスト埋め込みの手法で数値データに変換し，景気判断に影響を及ぼす要因を定量的に分析する．テキスト埋め込みは解釈が難しいことで知られているが，本研究では独立成分分析とFisher の線形判別分析を組み合わせることで，高次元のテキスト埋め込みデータを解釈可能な低次元データに変換することで，人々の景気判断に寄与しているテキストの要素について調査する．
E6:テーマセッション1: 金融・経済ドメインのための言語処理(2)3月12日（水） 10:20-11:50   E会場(1F会議室108),E6-6,株価変動要因情報を手がかりとする株価変動記事生成へのLLMの適用,/proceedings/annual_meeting/2025/pdf_dir/E6-6.pdf,"○西田 隼輔, 宇津呂 武仁 (筑波大)",株価変動に関する記事は，変動の要因を分析する点で有用であるが，人手で作成するには手間と時間がかかるため，十分な量が存在していない. 本研究では，大規模言語モデル(LLM) を用いて記事を自動生成する手法を提案する．日々の株価変動率ランキングに基づく日本語データセット“JFinSR” を構築し，記事と株価変動要因に関する情報を収集した．このデータセットを用いたfew-shot 学習により，株価変動要因から高品質な記事を生成する手法を実現し，zero-shot より優れた性能を達成した。
P6:ポスター3月12日（水） 10:20-11:50   P会場(2Fコンベンションホール3+4),P6-1,質的研究の自動化:患者自由記述テキストからの潜在的トピックの発見,/proceedings/annual_meeting/2025/pdf_dir/P6-1.pdf,"○橋本 清斗, 清水 聖司, 工藤 紀子 (NAIST), 矢田 竣太郎 (筑波大), 若宮 翔子 (NAIST), 江本 駿, 西村 由希子 (ASrid), 荒牧 英治 (NAIST)",医学研究における自由記述テキストデータは，患者・家族や医療従事者の声を直接反映し，新たな知見の発見や意思決定，施策立案において重要な役割を果たす．しかし，これらのデータを対象とした質的データ分析は，膨大な人的労力を要する. 本研究では，希少・難治性疾患患者が新型コロナウイルス感染症の流行期間中に経験した困難を分析対象とし，大規模言語モデル（Large Language Model; LLM）を活用して質的データ分析の自動化を試みた．具体的には，患者・家族の自由記述テキストの各文に対してタグを生成し，タグ間の類似性に基づいて段階的に統合を行う手法を提案した．結果として，提案手法は分析時間を大幅に削減しつつ，人手による分析結果との一定の一致を示した．本研究の成果は，LLM を活用することで，自由記述テキストの効率的な分析手法の実現に向けた基盤を構築するものである．
P6:ポスター3月12日（水） 10:20-11:50   P会場(2Fコンベンションホール3+4),P6-2,言語処理学会を外部から調査するための共著者ネットワークを用いた発表予稿の自動地図作成の試み,/proceedings/annual_meeting/2025/pdf_dir/P6-2.pdf,"○中原 龍一, 竹内 孔一 (岡山大), 片岡 裕雄, 品川 政太朗 (SB Intuitions), 高橋 康 (NEC), 笠井 聡 (新潟医療福祉大), 長谷井 嬢, 二川 摩周 (岡山大), 大戸 彰三 (両備システムズ), 加藤 直人, 鎌倉 英嗣 (旭化成ファーマ)",大規模言語モデルや基盤モデルの出現に伴い、医療AI 領域においても言語処理技術の重要性がますます高まっている。その結果、外部の研究者や企業関係者による言語処理学会に対する網羅的調査のニーズという新しい課題が生まれている。 我々はこの問題を「知識が少ないドメイン外研究者による、学会の網羅的調査」という新しいタスクとして提案する。また、その解決手法として全論文の共著関係を利用した共著ネットワーク地図の有用性を検討したので報告する。
P6:ポスター3月12日（水） 10:20-11:50   P会場(2Fコンベンションホール3+4),P6-3,記号的知識蒸留における敵対的学習の利用とその評価,/proceedings/annual_meeting/2025/pdf_dir/P6-3.pdf,"○日浦 隆博 (NAIST/理研), 河野 誠也 (理研/NAIST), Angel Garcia Contreras (理研), 吉野 幸一郎 (科学大/理研/NAIST)",大規模言語モデル（LLM）は多くの自然言語処理タスクで顕著な性能を実現しているが，知識推論のようなタスクでは依然として性能に課題があり，知識トリプルを用いた適応により知識間の関係性を明示的に学習させるアプローチが注目されている．大規模・高精度な学習用トリプルの獲得に有効なのが記号的知識蒸留である．これはLLM の持つ膨大な知識をトリプルとして出力し，知識推論モデルの学習に使用する手法である．この手法ではトリプルの一部に人手評価を行い，フィルタモデルの学習を行っている．本研究では，敵対的な学習を導入することにより，人手評価を必要としない，自動的な記号的知識蒸留を実現する手法を提案し評価する．
P6:ポスター3月12日（水） 10:20-11:50   P会場(2Fコンベンションホール3+4),P6-4,言語モデルの外部知識獲得に関する高速化と小説プロットによる性能評価,/proceedings/annual_meeting/2025/pdf_dir/P6-4.pdf,"○近藤 碧, 小田 幹雄 (久留米高専)",大規模言語モデル（LLM）をサービスに組み込むとき，外部知識の獲得および推論速度，推論精度は重要である．そこで，本研究では，LLM の推論速度を向上させるために，Hybrid-RAG を改善した外部知識の獲得手法を提案する．従来手法においては，グラフデータベースとベクトルデータベースを並列に接続していたが，提案手法では，各々を直列に接続することにより効率的な外部知識検索を実現した．また，実験において，小説プロットを外部知識として導入したときの性能評価を行った．その結果，従来手法と比較して推論速度が向上することがわかった．
P6:ポスター3月12日（水） 10:20-11:50   P会場(2Fコンベンションホール3+4),P6-5,尤度最大化に基づく自然言語による多段推論過程の抽出への取り組み,/proceedings/annual_meeting/2025/pdf_dir/P6-5.pdf,"○張 辰聖子 (お茶大), 持橋 大地 (統数研), 小林 一郎 (お茶大)",ヒトが行うような自然言語による推論では，観測した事象を言語で表現することで認識を行い，その事象に関する知識を取り込んだ推論を多段に繰り返していくことにより最終的な帰結となる自然言語文を生成していると考える．本研究では，自然言語文入力に対して知識を介在させ，新たな自然言語文を生成する形で結論を導くための多段の多岐にわたる推論過程過程の中から，自然言語文を生成する際の尤度を最大化する過程を抽出する手法を提案する．実験には多段推論のデータセットであるMuSiQueを利用した．結果として，提案手法はチャンスレベルを上回る性能であることを検証した．
P6:ポスター3月12日（水） 10:20-11:50   P会場(2Fコンベンションホール3+4),P6-6,Anchoring を行う生成的関係抽出,/proceedings/annual_meeting/2025/pdf_dir/P6-6.pdf,"○広田 航, 高橋 洸丞 (ストックマーク), Benjamin Heinzerling (理研/東北大), Qin Dai (東北大), 近江 崇宏 (ストックマーク), 乾 健太郎 (MBZUAI/東北大/理研)","生成的言語モデルを用いた関係抽出(生成的関係抽出) によって関係抽出の精度は大きく向上したが,再現率が依然低いという問題がある. この問題に対し, 本論文では任意の生成的関係抽出に適用できる新手法Anchoring を提案する. Anchoring はあらかじめ3 つ組(head, relation , tail) のhead の候補となるスパン(anchor) を抽出し, 各anchor に対して個別に生成的関係抽出を行う手法である. 評価実験では複数の関係抽出データセットにおいてAnchoring が精度および再現率が向上させることを示した上で, 特にhead およびtail の抽出性能の向上に寄与すること,および文の主題でないhead, tail に対しても頑健性が高まることを示す."
P6:ポスター3月12日（水） 10:20-11:50   P会場(2Fコンベンションホール3+4),P6-7,Zero-shot Entity Recognition for Polymer Biodegradability Information: GPT-4o on PolyBD,/proceedings/annual_meeting/2025/pdf_dir/P6-7.pdf,"○◊Shanshan Liu, Masashi Ishii (理研), Yuji Matsumoto (物材機構)","To investigate polymer biodegradability information ex-traction, we constructed PolyBD, a manually annotateddataset containing entity annotations of 100 journal ar-ticles.We evaluated the performance of GPT-4o insentence-level entity recognition under a zero-shot settingon PolyBD. While GPT-4o achieved strong overall results,its performance diﬀered markedly between nested entities(those contained within other entities) and non-nested enti-ties (all others). Speciﬁcally, it achieved a recall of 78% fornested entities but only 56% for non-nested entities. Theseresults underscore both the capabilities and limitations ofadvanced large language models in addressing real-worldextraction tasks."
P6:ポスター3月12日（水） 10:20-11:50   P会場(2Fコンベンションホール3+4),P6-8,From NLI to Classification: Entailment Learning for Low-Resource Text Classification,/proceedings/annual_meeting/2025/pdf_dir/P6-8.pdf,"○◊Rumana Ferdous Munne, Noriki Nishida, Shanshan Liu, Narumi Tokunaga, Yuki Yamagata (理研), Kouji Kozaki (阪電通大), Yuji Matsumoto (理研)","In real-world scenarios, text classiﬁcation often facesthe challenge of limited labeled data, especially for rare oremerging classes. Traditional methods struggle in thesesituations, requiring new approaches that can generalizeto unseen or sparsely annotated classes. This challenge isparticularly common in the biomedical ﬁeld, where datais expensive to annotate, and new diseases and treatmentsfrequently emerge.This paper proposes an entailment-based framework for zero and few-shot text classiﬁcationby reframing the task as a natural language inference (NLI)problem. Leveraging pre-trained language models, the ap-proach infers labels for unseen classes without additionalﬁne-tuning. For few-shot scenarios, minimal task-speciﬁcﬁne-tuning signiﬁcantly enhances performance. Our ﬁnd-ings highlight the potential of entailment-based learning asa versatile and eﬀective paradigm for text classiﬁcation inlow-resource environments."
P6:ポスター3月12日（水） 10:20-11:50   P会場(2Fコンベンションホール3+4),P6-9,大規模言語モデルを用いた生成による企業の業種体系の拡張,/proceedings/annual_meeting/2025/pdf_dir/P6-9.pdf,"○山岸 駿秀, 貞光 九月 (マネーフォワード)",企業情報の分析のために，各企業の各事業に適切な業種を割り当てることは重要である．このとき，既存の業種体系に合致しない事業内容があるため，業種体系を適宜拡張して使う必要がある．本研究では，LLM を用いて既存の業種体系にない業種名称を生成し，業種体系を拡張する．ただし，生成された業種には不要な名称が含まれる．不要な名称を削減する手法として，LLM への生成制約，既存業種にある名称のフィルタリング，生成業種間で類似した名称のクラスタリングを提案し，効果を検証する．
P6:ポスター3月12日（水） 10:20-11:50   P会場(2Fコンベンションホール3+4),P6-10,質問応答によるメールからの送信者情報抽出,/proceedings/annual_meeting/2025/pdf_dir/P6-10.pdf,"○大田尾 匠, 橋本 航 (Sansan)",本研究では、効率的なメール管理のために、メールから送信者情報(氏名・会社名・部署・役職) を抽出する重要性に着目し、送信者のメールヘッダとメール本文を入力として、質問応答によって送信者情報を抽出する手法を提案する。実験では、Transformer をベースとした複数の言語モデルの性能を比較した。結果として、モデルのアーキテクチャによって抽出性能が高い項目が異なること、GPT-4oは正解が存在しない場合も誤抽出する傾向があるがEncoder-only モデルより性能が高いこと、入力長による性能低下はモデルや抽出項目によって違った傾向があることがわかった。
P6:ポスター3月12日（水） 10:20-11:50   P会場(2Fコンベンションホール3+4),P6-11,複数データセットで情報を共有する固有表現抽出,/proceedings/annual_meeting/2025/pdf_dir/P6-11.pdf,"○大井 拓, 三輪 誠 (豊田工大)",本研究では，複数のデータセットにおけるラベル付けの違いを効果的にモデル化し，複数データセットで学習を行うために，条件付き変分オートエンコーダ（Conditional Variational Autoencoder;CVAE）をスパンベースの固有表現抽出（NamedEntity Recognition; NER）モデルに統合する先行研究からエンコーダの変更と条件ベクトルの学習を行う．実験では，複数の生物医学データセットを用いた学習を行い，BioRED データセットでの評価で提案手法の有効性を示し，性能向上を確認した．
P6:ポスター3月12日（水） 10:20-11:50   P会場(2Fコンベンションホール3+4),P6-12,文献からの有機合成手順の自動抽出と専門家によるその結果の編集作業を支援する枠組み,/proceedings/annual_meeting/2025/pdf_dir/P6-12.pdf,"○町 光二郎, 秋山 世治, 長田 裕也, 吉岡 真治 (北大)",文献から有機合成手順を自動抽出するために、ルールベースの手法や生成系大規模言語モデル（GLLM）を用いた方法が提案されている。しかし、自動抽出の結果が正しいとは限らないため、再現性や安全性の観点から、専門家による結果の確認と修正作業は必要不可欠である。本稿では、我々が提案した、専門家による確認と修正作業を支援するための枠組みについて紹介する。本枠組みでは、意味役割を用いた有機合成手順のアノテーションを行うことで視覚的に確認作業を支援し、ルールベースとGLLM ベースの2 種類の性質の異なるシステムの出力を候補として提示することで修正作業を支援する。
P6:ポスター3月12日（水） 10:20-11:50   P会場(2Fコンベンションホール3+4),P6-13,コミュニティ特有のハッシュタグ空間を考慮したマルチラベル候補生成器を用いる二段階推薦,/proceedings/annual_meeting/2025/pdf_dir/P6-13.pdf,○深澤 祐援 (コミューン),"近年, 顧客とのエンゲージメントを生む施策としてコミュニティの重要性や価値が増しており, コミューン株式会社が提供する“Commune” のようにクライアントごとに個別のコミュニティを提供するサービスが注目されている. このようなコミュニティ提供は顧客体験の向上に寄与する一方で, 例としてハッシュタグ推薦タスクにおいては, 各コミュニティが異なるハッシュタグ空間を持つため新たな課題をもたらす. 本研究では, 単一のモデルで複数のコミュニティに対するハッシュタグ推薦を可能にするべくマルチラベル分類モデルを用いた二段階推薦を提案する. 提案手法は実験の結果, NDCG@10 で"
P6:ポスター3月12日（水） 10:20-11:50   P会場(2Fコンベンションホール3+4),P6-14,自己修正に基づく固有表現抽出モデルの指示学習,/proceedings/annual_meeting/2025/pdf_dir/P6-14.pdf,"○高橋 拓誠, 谷口 友紀, 大熊 智子 (旭化成)",固有表現抽出における過抽出やラベルの認識誤りは，典型的な性能低下の要因であり，大規模言語モデルにおいても頻出する課題である．本稿では，固有表現抽出を学習する過程で，抽出エラーを自己修正(Self-Correction) するための指示学習を提案する．本研究における自己修正の学習は，固有表現抽出の教師データのみ参照し，抽出エラーの検証や修正に関する追加アノテーションを必要としない．化学分野の特許を対象とした固有表現抽出において，自己修正に基づく指示学習を導入することで，固有表現の抽出エラーを大幅に抑制できることを示した．
P6:ポスター3月12日（水） 10:20-11:50   P会場(2Fコンベンションホール3+4),P6-15,複数エンティティがまとめて記述される可能性を考慮したWikipedia記事のクラス分類,/proceedings/annual_meeting/2025/pdf_dir/P6-15.pdf,"○鈴木 希望, 吉岡 真治 (北大)",Wikipedia の情報に基づいて、構造化した知識を抽出する研究は多く行われているが、基本的には、Wikipedia の記事が一つのエンティティについて述べていることを前提としている。しかし、実際のWikipedia の記事には、小説を原作としたような映画のように、元の創作物からの派生的なエンティティがまとめて記載されることが多い。本研究では、そのような複数エンティティが記述されている可能性を考慮した中で、Wikipedia 記事のクラス分類を行う方法を提案するとともに、森羅のデータを用いて本手法の性質について議論する。
P6:ポスター3月12日（水） 10:20-11:50   P会場(2Fコンベンションホール3+4),P6-16,大規模言語モデルの Zero-Shot トリプル抽出性能の評価,/proceedings/annual_meeting/2025/pdf_dir/P6-16.pdf,"○乙村 浩太郎, 中村 光佑, 金井 美岬, 羽藤 淳平 (三菱電機)","昨今の大規模言語モデルの発達の恩恵により, 大量の文章から自動でトリプルを抽出することにより知識グラフを構築する方法が現実的になっている.しかし, これまでの大規模言語モデルによるトリプル抽出の評価は一般ドメインのデータに注目するものが多く, 企業内部でのユースケースにおいても同程度の性能が発揮できるかは未知数であった. そこで本稿では, 企業内での活用が想定される文献から作成したトリプル抽出タスクの評価用データセットによって, 5 種類の大規模言語モデルのzero-shot トリプル抽出の性能を評価した. 結果, 抽出性能はF1スコアが最高で約0.16 であり,LLM によるトリプル自動抽出の企業内活用には精度面に課題があることが確認された. また誤答ケースの分析の結果, 性能向上のためには, 学習データの構築や知識グラフスキーマ・オントロジーを活用した手法が必要であることが示唆された."
P6:ポスター3月12日（水） 10:20-11:50   P会場(2Fコンベンションホール3+4),P6-17,検索クエリログを用いない自然な質問のマイニングの検討,/proceedings/annual_meeting/2025/pdf_dir/P6-17.pdf,"○大村 和正, 石原 祥太郎 (日経)",情報欲求に起因して自然発生する質問（自然な質問）のマイニングには様々な応用がある．しかし，素朴なマイニング源として考えられる検索クエリログは一般利用可能でない場合が多い．本研究では，検索クエリログの代わりにテキスト生成モデルを用いた自然な質問のマイニング手法を提案する．具体的にはまず，情報欲求の対象を指定し，これに関する質問の観点をテキスト生成モデルに予測させる．次に，大規模言語モデルを用いて情報欲求の対象と予測された質問の観点を表す2 つのキーワードから自然言語の質問文を生成する．実験の結果，検索クエリログを用いない自然な質問のマイニングができる可能性を示唆した．
P6:ポスター3月12日（水） 10:20-11:50   P会場(2Fコンベンションホール3+4),P6-18,LLM から抽出した日本文化知識のデータベース構築と活用,/proceedings/annual_meeting/2025/pdf_dir/P6-18.pdf,"○大橋 巧, 彌冨 仁 (法政大)","大規模言語モデル（LLM）は自然言語処理で高い性能を示す一方，多様な文化的背景への対応には課題がある．本研究では，日本語コーパスで学習されたLLM を活用することで，日本文化知識データベースNINJA を構築した．NINJA は，既存の文化知識データベースMANGO が持つ日本文化に関するデータと同数の4,597 件生成し比較した結果，データの多様性を示す指標であるSelf-BLUE が0.787 から0.350 に改善した．さらに，日本の文化的背景への理解が必要な常識道徳推論タスクに対して，NINJA を外部情報として組み込んだRAG（RetrievalAugmented Generation）システムを構築し，日本文化に即した推論における有用性を検証した．"
P6:ポスター3月12日（水） 10:20-11:50   P会場(2Fコンベンションホール3+4),P6-19,日本語継続事前学習モデルを対象とした暗記の定量化,/proceedings/annual_meeting/2025/pdf_dir/P6-19.pdf,"○高橋 寛武 (独立研究者), 石原 祥太郎 (日経)",大規模言語モデルによる訓練データの暗記の懸念に注目が集まる一方，非英語や産業界のコーパスを用いる条件下での分析は十分に進んでいない．そこで本研究では，日本語特化の大規模言語モデル構築で一般的な継続事前学習に着目し，訓練データに対する暗記の定量化に取り組む．具体的には，Llama 3に対してWikipedia と日本語ニュースメディア「日経電子版」の記事データを用い，2 種類の継続事前学習モデルを構築・分析した．実験では英語の実証的知見と同様，学習が進むごとに暗記量が増える傾向が観測された．この傾向は日経電子版の場合により明確で，一般的でない産業界のコーパスを用いる際の懸念が示唆された．
P6:ポスター3月12日（水） 10:20-11:50   P会場(2Fコンベンションホール3+4),P6-20,災害時のソーシャルメディアを対象とした場所参照表現の抽出における過去事例の適用,/proceedings/annual_meeting/2025/pdf_dir/P6-20.pdf,"○六瀬 聡宏, 宇津 圭祐, 内田 理 (東海大)",場所参照表現を抽出するタスクについて，次の設定を検証した．災害発生直後のソーシャルメディアを対象とし，過去の災害時に流通した投稿で学習したモデルの利用可能性を検証する．国内で発生した
P6:ポスター3月12日（水） 10:20-11:50   P会場(2Fコンベンションホール3+4),P6-21,LLMを用いたクロールデータからの人物略歴文抽出,/proceedings/annual_meeting/2025/pdf_dir/P6-21.pdf,"○中野 佑哉, 猪野 麻巳子, 二葉 知泰, 丸山 翼, 岸本 耀平, 永井 隆広 (LINEヤフー)",複数Web サイトに点在する人物の略歴文を収集し，Web 検索結果に表示することで，検索サービスのユーザ体験向上が期待できる．しかし，略歴文収集に係る作業は，人間が行った場合においても難易度が高く，大規模な略歴文収集には大きなコストがかかる．そこで，本研究では，LLM を用いて，クロールデータから人物の略歴情報と関連するWebサイトを自動的に紐付け，引用形式を保ったまま略歴文を抽出するタスクを提案し，手法の有効性について検討する．
P6:ポスター3月12日（水） 10:20-11:50   P会場(2Fコンベンションホール3+4),P6-22,URL引用の要否判定において学習データの品質とドメインが与える影響の分析,/proceedings/annual_meeting/2025/pdf_dir/P6-22.pdf,"○和田 和浩 (名大), 角掛 正弥 (日立), 松原 茂樹 (名大)",研究活動において研究データの適切な引用は論文の信頼性のための重要な要素である．URL を参照識別子として研究データを引用すること（URL 引用）が多いが，これを対象とする引用要否判定にはデータセットの品質が低いことや分野が限定されているといった課題がある．本研究では，より高精度なOCR を用いて高品質な複数の分野からなるデータセットを作成し，学習データの品質とドメインの違いがURL 引用の要否判定の性能に与える影響を分析した．実験の結果，高品質なデータセットを用いることでモデルのF 値が14.1%向上することを示した．また，異なるドメイン間でも高い性能を維持できることを明らかにした．
P6:ポスター3月12日（水） 10:20-11:50   P会場(2Fコンベンションホール3+4),P6-23,時相論理を用いた物語のエンティティ状態検索,/proceedings/annual_meeting/2025/pdf_dir/P6-23.pdf,"○佐藤 浩輔, 頼 展韜 (バンダイナムコ)",近年大規模化しているゲームやアニメ、映画、漫画などといった物語を扱うコンテンツにおいて、物語およびその設定に関わる知識をどのように整備・運用するかが課題になっている。本研究では、物語の制作・監修を容易にするために動的に変化する物語世界内のエンティティの状態に関わる事実を検索する手法を提案する。具体的には①LLM によって物語テキストから情報抽出・構造化を行い、②時相論理を用いて検索を行う。提案手法を単純な構造を持つ物語に適用し、簡易的に評価を行った。
P6:ポスター3月12日（水） 10:20-11:50   P会場(2Fコンベンションホール3+4),P6-24J,シソーラスの階層的構造を利用した弱教師あり固有表現抽出,/proceedings/annual_meeting/2025/pdf_dir/P6-24.pdf,"○芝原 隆善 (理研), 山田 育矢 (理研/Studio Ousia), 西田 典起, 寺西 裕紀 (理研), 古崎 晃司 (理研/阪電通大), 松本 裕治 (理研)",
P6:ポスター3月12日（水） 10:20-11:50   P会場(2Fコンベンションホール3+4),P6-25J,未知の知識に対する事前学習済み言語モデルが持つ推論能力の調査,/proceedings/annual_meeting/2025/pdf_dir/P6-25.pdf,"○坂井 優介, 上垣外 英剛 (NAIST), 林 克彦 (東大), 渡辺 太郎 (NAIST)",
Q6:ポスター3月12日（水） 10:20-11:50   Q会場(1F会議室101AB),Q6-1,行動分類のためのコーパス構築と行動分析への応用,/proceedings/annual_meeting/2025/pdf_dir/Q6-1.pdf,"○中岡 明義, 若宮 翔子, 荒牧 英治 (NAIST)",日常生活における行動の理解は，社会学，経済学や疫学などで重要な課題である．ソーシャルメディアの普及に伴い，人々の日々の行動に関わるテキストデータが蓄積されるようになり，行動分析のための材料として注目されている．本研究では，総務省統計局の社会生活基本調査で用いられている20 種類の行動を基に日常生活における行動を定義した．これらの行動を「LIFE STORY」データセットにアノテーションし，公開可能なコーパスを構築した．このコーパスを用いて分類モデルを構築し，分類性能を評価した．さらに，構築したモデルを用いてCovid-19 前後のエピソードから抽出した行動を定量的に分析し，コーパスの有用性を検証した．
Q6:ポスター3月12日（水） 10:20-11:50   Q会場(1F会議室101AB),Q6-2,JAMSE：日本語LLM評価用の高品質な少サンプル日本語ベンチマークの作成および評価−GENIAC LLM開発コンペティションからの知見−,/proceedings/annual_meeting/2025/pdf_dir/Q6-2.pdf,"○山崎 友大 (京大), 谷口 仁慈 (琉大), 山際 愛実 (三重大), 原田 憲旺, 小島 武, 岩澤 有祐, 松尾 豊 (東大)",日本語LLM の開発が盛んな一方，日本語評価ベンチマークの数や質は十分でない．また，既存のベンチマークはサンプル数が多く，評価コストが高いという問題がある．本稿では，高品質かつ少サンプルな評価用日本語ベンチマークJAMSE を提案する．JAMSE は，7 つのベンチマークから構成されており，1 ベンチマークあたり100 サンプルである．そのため，日本語LLM の言語理解能力と生成能力を低コストで評価することができる．国内外の継続学習モデルやGENIAC コンペティションで開発されたモデルで評価を行ったところ，Nejumi LeaderboardNeo による評価結果と強い相関が確認された．1）
Q6:ポスター3月12日（水） 10:20-11:50   Q会場(1F会議室101AB),Q6-3,複数のLLMを用いた法令QAタスクのGround Truth Curation,/proceedings/annual_meeting/2025/pdf_dir/Q6-3.pdf,"○植松 幸生 (デジタル庁/東京理科大), 大杉 直也 (デジタル庁)",本論文では，専門家が作成した法令に関するQAの四者択一問題とそのGround Truth に対して，複数の大規模言語モデル(LLM) を用いて検証することで，Ground Truth に誤りがあることを発見した．発見する方式としては，Ground Truth を与えない状態で，3 種類の異なるファウンデーションモデルのLLM に0-shot の設定で回答させた．生成された回答からmajority voting などの方法で結果を統合し，すべてのLLM の答えが一致しない問題を抽出したのち，再度専門家に確認を依頼し，一部問題でGround Truth が誤っていることを突き止めた．
Q6:ポスター3月12日（水） 10:20-11:50   Q会場(1F会議室101AB),Q6-4,キャッチコピー共同作成対話コーパスにおける第三者評価と自己評価の関係分析,/proceedings/annual_meeting/2025/pdf_dir/Q6-4.pdf,"○周 旭琳, 市川 拓茉, 東中 竜一郎 (名大)",我々は，先行研究において，人間同士が対話しながらキャッチコピーを共同で作成する対話システムの構築を目的としてキャッチコピー共同作成対話コーパスを構築してきた．しかし，作成されたキャッチコピーについて，第三者による評価が行われておらず，共同作業の内容と作成された成果物の質の関係が不明確であった．そこで，本研究ではコーパスに含まれるキャッチコピーに対して第三者評価を付与し，共同作業の内容と作成された成果物の質の関係を明らかにし，それを踏まえ，キャッチコピーを共同で作成する対話システムが持つべき指針について考察する．
Q6:ポスター3月12日（水） 10:20-11:50   Q会場(1F会議室101AB),Q6-5,Enhancing the JNLI Dataset and Evaluating Model Performance on Improved Data,/proceedings/annual_meeting/2025/pdf_dir/Q6-5.pdf,"○◊梁 俊, 藤本 博昭, 福寄 雅洋 (富士通)","The Japanese Natural Language Inference (JNLI) datasetis a valuable resource for NLI research. However, we foundit contains inconsistencies and lacks structural diversity.This paper presents a two-pronged approach to addressthese limitations: A rigorous correction of errors and thecreation of a new, expanded dataset with diverse sentencestructures. We detail our iterative correction methodology,leveraging Large Language Model (LLM) predictions andmanual review. The new dataset introduces variations insentence type (noun, verb, adjective/quantiﬁer), enrichingthe data.Furthermore, we evaluate the performance ofour internally created LLM model Takane on the original,corrected, and newly created JNLI datasets, demonstratingsuperior performance compared to existing state-of-the-artmodels."
Q6:ポスター3月12日（水） 10:20-11:50   Q会場(1F会議室101AB),Q6-6,データペーパー:各都道府県が提供する農業関係オープンデータ,/proceedings/annual_meeting/2025/pdf_dir/Q6-6.pdf,"大友 将宏 (農研機構), 石原 潤一 (北大), ○橋本 祥, 桂樹 哲雄 (農研機構), 二宮 芳継 (筑波大), 小林 暁雄, 坂地 泰紀, 川村 隆浩 (農研機構)",我が国の農業においては、農林水産省が国の政策の策定と実施を担う一方、実務的な管理・指導は都道府県と農業協同組合（農協）が中心となって実施している。各組織は、栽培技術、病害虫防除方法、農業者の経営形態に関する情報など、地域特性に応じた情報を集約し、ウェブサイト等を通じて公開している。本研究では、各組織と交渉して公開・非公開を問わずデータの収集を進めている。収集したデータは、各提供元のオープン・クローズ戦略に準拠しつつ、組織内で有効活用できるようなAI モデルを構築するための知識源として使用している。本稿では、これらの収集されたデータのうち、公開データの収集状況について報告する。
Q6:ポスター3月12日（水） 10:20-11:50   Q会場(1F会議室101AB),Q6-7,オーダーメイド対話管理：商用チャットボットに向けた対話管理学習データ自動作成,/proceedings/annual_meeting/2025/pdf_dir/Q6-7.pdf,○馬 春鵬 (Megagon Labs),ツール拡張言語モデルを用いた対話管理エージェントは流行しているが、既存ベンチマークデータは実際のビジネスタスクと乖離があり、商用チャットボットに使えない。本研究で提案するデータ作成手法ではデータ作成者が与えた必要最小限の情報に基づいて、要望に沿った大量で高品質なデータを自動的に生成してオーダーメイド対話管理を実現した。作成されたデータは学習データとして対話管理エージェントの学習や改良に使える。
Q6:ポスター3月12日（水） 10:20-11:50   Q会場(1F会議室101AB),Q6-8,日本語文章の可読性評価のための項省略判断モデル,/proceedings/annual_meeting/2025/pdf_dir/Q6-8.pdf,"○久保田 智天 (東北大), 石月 由紀子 (フリー), 松林 優一郎 (東北大/理研)",本研究では，日本語の書き手が行う述語の項省略の適切さを，読み手側の視点に立った際に適切に指摘できるかという新しいタスクの設計を検討する．この設定は，項省略の可否を第三者の指摘に基づいて学ぶ学習支援システムの開発を見据えたものである．この問題設定を精緻に検討するために，我々は，読者側が得られる情報のみを用いて項省略の不自然さを指摘できるかについて，判断の要因になりうる複数の観点に基づく質問の回答をアノテーションするデータを作成し，結果を詳細に分析する．分析の結果，我々の設定した省略判断の観点の組み合わせによって，読み手の実際の省略判断を高い割合で説明できることが示された．
Q6:ポスター3月12日（水） 10:20-11:50   Q会場(1F会議室101AB),Q6-9,日本語によるコード生成能力の正確な評価に向けて,/proceedings/annual_meeting/2025/pdf_dir/Q6-9.pdf,"○種口 暁人 (東北大), 藤井 諒, 森下 睦 (フューチャー/東北大), 鈴木 潤 (東北大/理研/NII)",近年，ソースコード生成などのタスクにも大規模言語モデルを活用する動きが活発化している．しかし，日本語を用いたコード生成ベンチマークは限定的であり，特にPython 以外のプログラミング言語を用いた高品質なデータセットは存在しないことから，正確な評価はできていない．本稿では，既存のデータセットを拡張し，高品質な日本語タスク説明文を伴う，複数のプログラミング言語のコード生成評価ベンチマークJMultiPL-E を構築した．実験により，日本語での継続事前学習が日本語を用いたコード生成において効果的であることの示唆を得た．
Q6:ポスター3月12日（水） 10:20-11:50   Q会場(1F会議室101AB),Q6-10,否定理解能力を評価するための日本語言語推論データセットの構築,/proceedings/annual_meeting/2025/pdf_dir/Q6-10.pdf,"○吉田 朝飛, 加藤 芳秀 (名大), 小川 泰弘 (名市大), 松原 茂樹 (名大)",言語モデルが否定を理解する能力を評価するための様々な英語データセットが構築されているが，日本語においては，そのようなデータセットを構築する取り組みは限られている．本研究では，否定理解能力を評価するための日本語言語推論データセットJNLI-Neg を構築する．さらにJNLI-Neg を用いて既存の言語モデルを評価し，それらの否定理解能力の現状と課題を明らかにする．
Q6:ポスター3月12日（水） 10:20-11:50   Q会場(1F会議室101AB),Q6-11,日本語自然言語処理リポジトリに対する研究分野マルチラベルの付与,/proceedings/annual_meeting/2025/pdf_dir/Q6-11.pdf,"○池田 大志, Quan HoangDanh, 長野 紘士朗, 早田 啓介 (コニカミノルタ)",本研究では，日本語自然言語処理に関連する484件のGitHub リポジトリを対象とし，合計1537 件の研究分野マルチラベルを付与したデータセットを構築した．本データセットは，README ファイル，PDF ドキュメント，スクリーンショット画像など，複数形式のマルチモーダルデータを入力とすることでラベルを予測できるように設計されている．実験の結果，本データセットが日本語言語資源の効率的な検索に寄与することを示す．
Q6:ポスター3月12日（水） 10:20-11:50   Q会場(1F会議室101AB),Q6-12,ルーブリックに基づいたタグを付与した日本語小論文データの構築と自動採点への効果,/proceedings/annual_meeting/2025/pdf_dir/Q6-12.pdf,"○成岡 智也, 竹内 孔一 (岡山大)",本研究では，小論文にルーブリックに基づいたアノテーションを行い，そのデータを用いて小論文自動採点を行う方法を提案する．ルーブリックの評価部分に対応した小論文の文書内構造の情報を，小論文にタグをつけるという形でアノテーションを行った．そうして得られるタグを小論文と同時にトークン化し，採点モデルにスコアを予測させ，小論文のみでの自動採点と比較することで，提案手法の有効性を明らかにした．
Q6:ポスター3月12日（水） 10:20-11:50   Q会場(1F会議室101AB),Q6-13,BCCWJ-MEG：日本語脳磁図データの構築,/proceedings/annual_meeting/2025/pdf_dir/Q6-13.pdf,"○杉本 侑嗣 (阪大), 吉田 遼 (東大), 鄭 嫣婷, 菅野 彰剛, 小泉 政利 (東北大), 大関 洋平 (東大)","近年の自然言語処理の成功を受け、神経科学の分野でも自然言語処理との融合的アプローチが急速に発展している。このアプローチにおいては、言語モデルの評価に応用可能な「自然な刺激文に基づく脳活動データセット」が必要不可欠であるが、2025年現在、日本語を対象としたものは存在していない。本研究では、日本語を対象とした新たな脳磁図(Magnetoencephalography, MEG) データセットであるBCCWJ-MEG を構築する。BCCWJ-MEG は、41 名の日本語母語話者が、新聞記事20 件（229 文・1642 文節）を読んでいる際のMEG データを含む。さらに、我々は、ケーススタディとして、アーキテクチャの異なる複数の言語モデルをBCCWJ-MEG を用いて評価し、(i) 自己注意あり言語モデルが自己注意なし言語モデルよりも脳活動をよりよく説明すること、および(ii) 脳活動をよりよく説明するモデルが工学的性能が高いとは限らないということを確かめた。"
Q6:ポスター3月12日（水） 10:20-11:50   Q会場(1F会議室101AB),Q6-14,大規模視覚言語モデルの質感知覚能力の分析,/proceedings/annual_meeting/2025/pdf_dir/Q6-14.pdf,"○松田 陵佑, 塩野 大輝 (東北大), Ana Brassard (理研/東北大), 鈴木 潤 (東北大/理研/NII)",本研究では，「質感」に焦点を当て，大規模視覚言語モデル（LVLM）の質感知覚能力を調査し，さらにLVLM と人間との間の質感知覚の整合性を分析することを目的とする．はじめに画像内の物体に対して人間が知覚する質感語を人手で収集した．次に，収集した質感語をもとに，LVLM が適切な質感語を選択できるか評価する分類タスクを設計し，LVLMと人間の正解率を算出した．また，LVLM に質感語を生成させ，その出力を人間が評価する生成タスクも実施した．最終的には，分類タスクの正解率が高いLVLM は，生成タスクにおいても高いスコアを示すことを確認し，分類タスクが，LVLM の質感知覚能力の評価だけでなく，人間知覚の整合性まで簡易に評価できる可能性があることを示す．
Q6:ポスター3月12日（水） 10:20-11:50   Q会場(1F会議室101AB),Q6-15,Wikidataに基づく大規模ジオコーディングデータセット,/proceedings/annual_meeting/2025/pdf_dir/Q6-15.pdf,"○中谷 響 (NAIST), 安井 雄一郎, 若本 亮佑, 石井 昌之 (日経), 大内 啓樹 (NAIST/理研), 渡辺 太郎 (NAIST)",本稿では，場所を表す言語表現（メンション）を地理データベースの適切なエントリと紐付け，地理座標（緯度・経度）を出力するモデルのための大規模データセットを構築した．具体的には，Wikipediaの各記事に出現するメンションと紐づけられているWikidata のエントリを収集することによって自動構築した．実際に構築したデータセットで学習したモデルは，異なるドメインのデータに対しても高精度で解析可能であることを示す．
Q6:ポスター3月12日（水） 10:20-11:50   Q会場(1F会議室101AB),Q6-16,根拠に基づいたレビュー生成のための LLM を用いた自動アノテーションの検討,/proceedings/annual_meeting/2025/pdf_dir/Q6-16.pdf,"○田中 翔平, 平澤 寅庄, 牛久 祥孝 (オムロンサイニックエックス)",本研究では論文の内容を根拠としてレビューを生成可能なモデルを構築することを目指す．この目的を達成する一つの方法として，学習データのレビューが論文のどの部分に基づいているかという情報を活用することが考えられるが，こうした情報を含むデータセットを人手で作成することはコストがかかる．そこで本論文では，レビューと論文の結びつきや論文の内容を正確に反映したレビュー文をLLM を用いて自動でアノテーションすることを検討した．評価結果より，現在のLLM はレビューと論文の結びつきをある程度の精度で予測することができ，論文の内容を正確に反映したレビュー文を高い精度で選択できることがわかった．
Q6:ポスター3月12日（水） 10:20-11:50   Q会場(1F会議室101AB),Q6-17,Towards Automated Detection of Hype in Biomedical Research,/proceedings/annual_meeting/2025/pdf_dir/Q6-17.pdf,"○◊Bojan Batalo, Erica K. Shimomoto (産総研), Neil Millar (筑波大)","The use of promotional language (’hype’) in biomedicalresearch is increasing. Examples include adjectives such asgroundbreaking, unparalleled, novel and innovative. Suchlanguage can undermine objective evaluation of evidence,impede development of research and erode trust in science.In this pilot study, we show that (1) formalizing annotationguidelines may help humans reliably annotate such adjec-tives as ’hype’ or ’not hype’, and (2) that using an annotateddataset following the guidelines to train machine learningmodels yields promising results for automatic detection ofpromotional language."
Q6:ポスター3月12日（水） 10:20-11:50   Q会場(1F会議室101AB),Q6-18,FaithCAMERA: 広告文生成タスクのための忠実性を担保した評価データセットの構築,/proceedings/annual_meeting/2025/pdf_dir/Q6-18.pdf,"○加藤 明彦, 三田 雅人, 村上 聡一朗, 本多 右京, 星野 翔, 張 培楠 (サイバーエージェント)",広告文生成(ad text generation [ATG]) において、望ましい広告文は、入力に忠実であると同時に、潜在顧客にアピールする重要な情報を含む、すなわち、情報性に優れている。既存の評価データであるCAMERA [1] は、広告制作者が作成した参照文からなり、情報性の評価に適している。しかし、これらの参照文には入力に忠実でない情報が含まれていることが多く、ATG の研究を推進する上で顕著な障害となっている。そこで本研究では広告制作者と協力してCAMERA の参照文を修正し、忠実性を保証した新たなATG の評価データセット(FaithCAMERA) 1）を構築した。また、既存の忠実性向上手法が、忠実性を維持しながら情報性に優れた広告文を生成できるかどうかを評価した。
Q6:ポスター3月12日（水） 10:20-11:50   Q会場(1F会議室101AB),Q6-19,Towards Formalizing Socratic Questions for Explainable Socratic Question Generation,/proceedings/annual_meeting/2025/pdf_dir/Q6-19.pdf,"○◊Surawat Pothong (JAIST), Paul Reisert (Beyond Reason), Naoya Inoue (JAIST), Machi Shimmei, Wenzhi Wang, Shoichi Naito (東北大), Jungmin Choi (理研), Kentaro Inui (MBZUAI)","Socratic questioning (SQ) is an eﬀective strategy for fos-tering critical thinking. One of the key requirements for us-ing SQs in educational settings is maintaining transparencyand logical alignment with the content.For generatingpedagogically appropriate SQs, we explore a logic-basedtemplate approach by ﬁrst leveraging argumentative com-ponents. We conduct an annotation on top of argument-SQ pairs and achieve moderate inter-annotator agreement(Cohen’s Kappa: 0.49) and 84% for annotating SQ compo-nents. We analyze areas of disagreement, oﬀering insightsfor curating a template set. This work lays a foundationfor advancing template-based Natural Language QuestionGeneration methods and improving model transparency."
Q6:ポスター3月12日（水） 10:20-11:50   Q会場(1F会議室101AB),Q6-20,whole-NWJC: 『国語研日本語ウェブコーパス』全データ,/proceedings/annual_meeting/2025/pdf_dir/Q6-20.pdf,○浅原 正幸 (国語研/総研大),本稿では、『国語研日本語ウェブコーパス』（NINJAL Web Japanese Corpus: NWJC）の全データ（whole-NWJC）について概説する。本データは、国立国語研究所との共同研究を通じて利用できる。
Q6:ポスター3月12日（水） 10:20-11:50   Q会場(1F会議室101AB),Q6-21,パラ言語情報に着目したSpeech-to-Text対話ベンチマークデータセットの提案,/proceedings/annual_meeting/2025/pdf_dir/Q6-21.pdf,"○中畔 彪雅 (NAIST/理研), 河野 誠也 (理研/NAIST), Canasai Kruengkrai, Angel Garcia Contreras (理研), 千葉 祐弥, 杉山 弘晃 (NTT), 吉野 幸一郎 (科学大/理研/NAIST)",同じ発話文でもパラ言語情報が異なれば，与える意図やニュアンスが異なる．音声対話システムが持つこれらパラ言語情報処理能力を測るため，パラ言語情報の特に感情に着目したSpeech-to-Text 対話ベンチマーク「paraling-data」を提案する．同じ発話文にパラ言語情報のみが異なる発話を収集し，それぞれのニュアンスに対応する応答を収集した．また，テキスト対話システムとSpeech-to-Text 対話システムを構築し，感情ラベル予測を補助タスクとした対話応答生成を学習し評価した．
Q6:ポスター3月12日（水） 10:20-11:50   Q会場(1F会議室101AB),Q6-22,ソーシャルメディアテキストを用いた摂食障害の文化差比較,/proceedings/annual_meeting/2025/pdf_dir/Q6-22.pdf,"○栗生 紗希帆 (NAIST), Dayeon Kim, Hyuk-Yoon Kwon (SNU), 若宮 翔子, 荒牧 英治 (NAIST)",日本と韓国の肥満率は，先進国の中でワースト1位，2 位である．過度なやせは摂食障害をもたらすことがある．摂食障害は，身体面，心理面，行動面への治療が必要であり，数ヶ月から数年の時間を要するといわれている．本研究では，日本と韓国を対象に，摂食障害とダイエットのソーシャルメディアテキストを収集し，分類した．そして，摂食障害やダイエットに関連する言語的特徴は，文化間（日本と韓国）でどのように異なるのかを調査した．結果としては，日本と韓国による言語的な文化差がみられ，2 言語のテキストを活用した方が性能が僅かに向上した．
Q6:ポスター3月12日（水） 10:20-11:50   Q会場(1F会議室101AB),Q6-23,LLM を用いたキーワードに基づく文書分類ためのデータ拡張の試みと評価,/proceedings/annual_meeting/2025/pdf_dir/Q6-23.pdf,"○小野寺 優, 新納 浩幸 (茨大)",大規模言語モデル(LLM) の高い文生成能力を活かすことで，データ拡張(Data Augmentation) による分類モデルの性能改善が期待できる．しかし，この手法でニュース記事の分類のような多値分類において精度を向上させた研究はまだ少ない．本研究では，ニュース記事を対象としてLLM が生成したデータを訓練データに水増しすることで，分類精度が改善されるかを検証した．カテゴリーのキーワードを与えて新たな文書を生成するアプローチを試みたが，このアプローチでは精度が低下することが確認できた．また，拡張したデータの埋め込み表現を分析することで，元となる訓練データと異なる分布のデータが生成され，分類の際のノイズとなっていることが明らかになった．
Q6:ポスター3月12日（水） 10:20-11:50   Q会場(1F会議室101AB),Q6-24,時事情報に関する日本語QAベンチマーク『ニュースQ』,/proceedings/annual_meeting/2025/pdf_dir/Q6-24.pdf,"○植木 快, 川畑 輝, 田口 雄哉, 新妻 巧朗, 浦川 通, 田森 秀明 (朝日新聞社), 岡崎 直観 (科学大), 乾 健太郎 (MBZUAI/東北大/理研)",近年，大規模言語モデル（LLM）の性能は飛躍的に向上しているが，ハルシネーションと呼ばれる，誤情報を生成してしまう問題が知られており，生成主体のLLM が持つ知識の信頼性や事実性を測定することは重要である．特に，時事に関する誤情報は，ユーザーの実生活における意思決定や行動に直接的な影響を与えるリスクが大きい．そこで本研究では，様々なジャンルのニュースをもとに作成された，時事的知識を日本語で問うベンチマーク『ニュースQ』1）を提案する．主要なLLM のベンチマーク正答率を算出したところ，高品質な日本語コーパスを事前学習する重要性が示唆されるとともに，よりパラメータサイズの大きいモデルの方が時事的な知識をより正確に把握している傾向が確認された．
Q6:ポスター3月12日（水） 10:20-11:50   Q会場(1F会議室101AB),Q6-25,意思決定を指標とする生成テキスト評価：アマチュアと専門家への影響分析,/proceedings/annual_meeting/2025/pdf_dir/Q6-25.pdf,"○高柳 剛弘 (東大/産総研), 高村 大也 (産総研), 和泉 潔 (東大), Chung-Chi Chen (産総研)",本研究では，LLM が生成するテキストが読者の意思決定にどのような影響を及ぼすかを検討し，特にアマチュアと専門家という二種類の受け手に焦点を当てる．実験の結果，GPT-4 が生成する分析はアマチュアと専門家の双方の判断を動かす説得力を有していることが示唆された．さらに，生成テキストを文法，説得力，論理的一貫性，有用性といった観点から評価したところ，これらの多次元評価スコアと，実際に読者が下す意思決定との間に高い相関があることが確認された．このことから，LLM が生成するテキストは人間の意思決定を左右し得る潜在力とリスクを併せ持つこと，そして読者の意思決定を生成テキストの評価指標として活用することが有効である可能性が示唆された．
A7:NLPモデルの解釈可能性・分析(3)3月12日（水） 13:00-14:30   A会場(2Fコンベンションホール1+2),A7-1,What Language Do Japanese-specialized Large Language Models Think in?,/proceedings/annual_meeting/2025/pdf_dir/A7-1.pdf,"○◊鐘 承志, 程 飛 (京大), 劉 倩瑩 (NII), 江 俊锋 (東大), 万 振, 褚 晨翚, 村脇 有吾 (京大), 黒橋 禎夫 (京大/NII)","In this study, we investigate whether large language mod-els (LLMs) trained with substantial Japanese data exhibithigher probabilities for Japanese in their intermediate lay-ers when projected onto the vocabulary space (a.k.a la-tent languages). Focusing on Llama2 (English-centric),Swallow (continued in Japanese), and LLM-jp (balancedEnglish-Japanese), we ﬁnd Llama2 relies mainly on En-glish, while Swallow and LLM-jp use both Japanese andEnglish as latent languages. Moreover, input and target lan-guages both inﬂuence the probability distribution betweenlatent languages."
A7:NLPモデルの解釈可能性・分析(3)3月12日（水） 13:00-14:30   A会場(2Fコンベンションホール1+2),A7-2,埋め込み表現の独立成分の言語内・言語間一貫性の分析,/proceedings/annual_meeting/2025/pdf_dir/A7-2.pdf,"○飯森 栄治 (東大), 松田 孟留, 谷中 瞳 (東大/理研)","単語埋め込みは単語を多次元の実数ベクトルとして表現し，データとして解析しやすくする一方で，その数値の解釈が難しい．独立成分分析（Independent Component Analysis, ICA）を用い，埋め込みから独立した主要な特徴を抽出することで，より明確な意味軸を生成し，言語間で普遍的な意味軸が存在する可能性がある．しかし，言語内および言語間における独立成分の一貫性は，これまで十分に検証されてこなかった．そこで，本研究では，一つの言語内と複数言語間の両面から，意味軸の一貫性を調査した．まず，言語内の一貫性を調べるために，ICA アルゴリズムを複数回実行して得られた結果をクラスタリングし，意味軸の再現性に着目した．次に，統計検定を用いてこれらの軸の対応関係を検証することで，言語間の一貫性を統計的に評価した．この研究は統計的手法を適用し，意味軸の信頼性と普遍性を担保するための手法を確立した．"
A7:NLPモデルの解釈可能性・分析(3)3月12日（水） 13:00-14:30   A会場(2Fコンベンションホール1+2),A7-3,構成的汎化におけるTransformerの内部機序の分析,/proceedings/annual_meeting/2025/pdf_dir/A7-3.pdf,"○九門 涼真, 谷中 瞳 (東大)",ニューラルモデルの構成的汎化能力は，人間のような言語能力の実現に向けた重要な課題の一つである．既存研究は，モデルの出力に着目して構成的汎化能力を評価しており，モデルの構成的汎化における内部機序は明らかでない．そこで本研究では，構成的汎化に寄与するサブネットワークの探索とモデルの統語的特徴の活用に関する因果分析を行い，Transformer の内部機序を分析する．実験結果からTransformer は構成的汎化において統語的特徴に一定程度依存することが示された．一方で，モデル全体よりも優れた汎化性能を持つサブネットワークは，統語的特徴を用いた構成的な解法に加え，非構成的な解法にも依存することも示された．
A7:NLPモデルの解釈可能性・分析(3)3月12日（水） 13:00-14:30   A会場(2Fコンベンションホール1+2),A7-4,大規模言語モデルにおけるIn-context Learningの推論回路,/proceedings/annual_meeting/2025/pdf_dir/A7-4.pdf,"○◊趙 羽風, 加藤 万理子, 坂井 吉弘 (JAIST), 井之上 直也 (JAIST/理研)",In-context Learning (ICL) は，言語モデルにおける新たな少数ショット学習パラダイムとして注目されているが，その内在的メカニズムは十分に解明されていない. 本研究では，ICL の推論ダイナミクスを
A7:NLPモデルの解釈可能性・分析(3)3月12日（水） 13:00-14:30   A会場(2Fコンベンションホール1+2),A7-5,LM は日本の時系列構造をどうエンコードするか,/proceedings/annual_meeting/2025/pdf_dir/A7-5.pdf,"○佐々木 睦史, 鴨田 豪, 高橋 良允 (東北大), Benjamin Heinzerling (理研/東北大), 坂口 慶祐 (東北大/理研)",LM の西洋の人物の内部表象に時系列的な方向が存在することが観察されている．では，和暦という独自の暦法体系を持つ日本の人物の内部表象はどのような構造を持つだろうか．本研究では江戸から平成までのLM 内部での時代表現を別々に取り出し，時代間の方向と位置を比較することで日本の時系列構造を調べた．実験の結果，LM 内部では，日本の時代間の方向はバラバラに表現されるが，時代間の位置は江戸から平成まで単調な順番に配置されることが示された．また，本研究で提案する時系列構造を同一平面で可視化する方法を用いて，日本の時系列構造を簡単な図に示すことができた．
A7:NLPモデルの解釈可能性・分析(3)3月12日（水） 13:00-14:30   A会場(2Fコンベンションホール1+2),A7-6,大規模言語モデルにおけるペルソナの役割と内部動作の理解,/proceedings/annual_meeting/2025/pdf_dir/A7-6.pdf,"○尾崎 慎太郎 (NAIST/NII), 平岡 達也 (MBZUAI), 大竹 啓永 (NAIST/NII), 大内 啓樹 (NAIST/理研), 渡辺 太郎 (NAIST), 宮尾 祐介 (東大/NII), 大関 洋平 (東大), 高木 優 (NII)","大規模言語モデルが特定のペルソナ（人格）として振る舞うとき, モデルはどの程度“本心から” ペルソナという仮面を被っているのだろうか. 本研究では, 表層的には指示されたペルソナとして振る舞えているモデルが, その内部では異なる思考をしているという仮説を立て, モデルの内部表現から出力までの思考の一貫性を検証する. 訓練データ・チェックポイントが異なる複数のモデルについて, 内部表現一貫性評価のために我々が提案した新たな尺度で評価した結果, ペルソナを付与することでモデルの内部表現の一貫性が向上する事がわかった. 一方で,モデル構築過程での内部表現の一貫性向上には限界があることも示され, より出力と内部表現が一貫したモデルを作る方策の必要性が示唆された."
B7:知識獲得・情報抽出(2)3月12日（水） 13:00-14:30   B会場(1F会議室102),B7-1,大規模言語モデルベースの日本語固有表現抽出におけるSelf-ReflectionとFew-Shot学習による精度改善,/proceedings/annual_meeting/2025/pdf_dir/B7-1.pdf,○久保田 崇文 (カカクコム),本研究では，大規模言語モデル（Large Language Model: LLM）を活用した日本語固有表現抽出 （Named Entity Recognition: NER）の精度向上手法としてSelf-Reflection の有効性を検証した．Self-Reflection は，モデルが自身のタスク結果を評価し，反省点を考慮した再試行を行うことで精度を向上させる枠組みである．GPT-4o を対象とした実験では，Few-Shot 学習と組み合わせることでF1-Scoreが1.6 ポイント向上した．しかし，一部の条件下では精度の低下や評価結果の不正確性が観察され，今後はFew-Shot 設計の最適化が課題となる．本研究の結果は，LLM ベースの日本語NER 精度向上の指針として，実応用への貢献が期待される．
B7:知識獲得・情報抽出(2)3月12日（水） 13:00-14:30   B会場(1F会議室102),B7-2,階層的ナレッジグラフを用いた事故事例文書の述語中心の構造化手法,/proceedings/annual_meeting/2025/pdf_dir/B7-2.pdf,"○林 瑛勲, 森 辰則 (横国大)",本研究では、事故事例文書に含まれる事象を階層的ナレッジグラフ(KG) として構造化する手法を提案する。まず、KG のレイヤ構造を定義し、失敗知識データベース[1] を対象に自動取得システムを実装した。その結果、生成されたKG の有用性を確認するとともに、応用可能性を検討した。開発したシステムはGitHub にて公開している1）。
B7:知識獲得・情報抽出(2)3月12日（水） 13:00-14:30   B会場(1F会議室102),B7-3,国会が告示する改正民法における新旧対応の整合性の検証,/proceedings/annual_meeting/2025/pdf_dir/B7-3.pdf,"○前原 太陽, 竹中 要一 (関大), 佐野 智也 (名大)",法律の改正は国会にて、改正する条や改正内容が告示されるため、新旧対応に関しても国会の告示が正しいと考えられている。しかし、国会が告示した新旧対応の妥当性についての検証がされることは少ない。本研究では国会が告示した法律の新旧対応の妥当性を検証する。検証対象は昭和22 年に改正された民法の家族法とし、「対応する条文の有無を推定」「対応する条文の推定」の2 段階に分けて推定を実施する。推定結果を法学的な視点を用いて考察する。
B7:知識獲得・情報抽出(2)3月12日（水） 13:00-14:30   B会場(1F会議室102),B7-4,多言語での判例事実概要からの法的関係性のグラフ可視化,/proceedings/annual_meeting/2025/pdf_dir/B7-4.pdf,"○大南 英理 (NAIST), 宮西 大樹 (東大), 前田 航希 (科学大/NII), 栗田 修平 (NII)",裁判官による判決作成では，争点の事実に関連する法律を解釈し事実を当てはめて結論を導く．他方モデルによる判例予測では，法律領域の精度向上とAI の信頼性観点での推論過程の明確化が課題である．本研究では，どのように法律解釈を行ったかを可視化し，モデルが法律解釈を学習することでドメイン知識を向上させるため，EU 法判例を用いて判例内の事実の法的関連性のグラフ生成タスクであるLegalViz を提案する．更に，グラフ構造と法律内容の双方を考慮したグラフ可視化評価を行うため評価手法を提案する．実験では，学習したモデルがFew-shot 設定のGPT モデルの性能を上回ることから提案データセットの有効性を示した．
B7:知識獲得・情報抽出(2)3月12日（水） 13:00-14:30   B会場(1F会議室102),B7-5,技術観点の自動検出による技術動向マップ自動生成,/proceedings/annual_meeting/2025/pdf_dir/B7-5.pdf,"○蜂須賀 笙太, 任 晶, 福田 悟志, 難波 英嗣, 庄司 裕子 (中央大)",本研究は、技術分野における動向把握の効率化と精度向上を目的としている。従来の技術動向分析手法は、専門家の評価に依存し、高コストであるとともに迅速性や説明可能性に課題を抱えていた。これらの課題を解決するために、本研究では大規模言語モデル（LLM）を活用し、技術観点の自動検出による技術動向マップの構築手法を提案する。本手法により、膨大な技術情報を効率的かつ体系的に整理し、的確な技術動向の分析とその活用を支援する基盤を提供することが可能となる。
B7:知識獲得・情報抽出(2)3月12日（水） 13:00-14:30   B会場(1F会議室102),B7-6,大規模言語モデルを用いた専門用語間の関係性解析,/proceedings/annual_meeting/2025/pdf_dir/B7-6.pdf,"○岩熊 耕平, 難波 英嗣, 福田 悟志 (中央大)",用語間の関係は、情報検索や文書作成など、さまざまなタスクに活用できる重要な情報源である。従来の関係性解析手法として定型表現による抽出があるが、低コストである一方、抽出精度に課題があった。埋め込み表現を用いた教師あり学習による解析手法も提案されているが、多くは汎用的に使用される用語を対象とするデータセットを利用しており、特許などの専門的な文書に含まれる用語の特徴を十分に捉えることが困難である。そこで本研究では、大規模言語モデル（LLM）を活用した専門用語間の関係性解析手法を提案する。特許用語を対象とした英語データセットであるGoogle Patent Phrase Similarity Dataset を利用し、専門用語の文脈的意味を捉えた関係性解析を行う。
C7:音声言語処理3月12日（水） 13:00-14:30   C会場(1F会議室103),C7-1,SOMO: 音声認識出力の可読性向上を目的とした整文手法の提案,/proceedings/annual_meeting/2025/pdf_dir/C7-1.pdf,"○杉野 かおり, 山野 陽祐, 河崎 真琴, 田森 秀明 (朝日新聞社), 岡崎 直観 (科学大), 乾 健太郎 (MBZUAI/東北大/理研)","本研究は, 音声認識出力を可読性の高い形式へと変換する「整文」手法を提案する. 日本速記協会の「発言記録作成標準」を参考に, 語断片の除去や文法,流暢性の向上, 簡潔化までの4 つのステップを定義した. これにより大規模言語モデル（LLM）を用いた整文処理が可能となり, 発言に忠実な書き起こしから, 要点のみをコンパクトにまとめた要約形式まで, 多様な用途に合わせた出力結果が得られる. これにより, 音声認識出力の利活用の可能性を広げることを目指す."
C7:音声言語処理3月12日（水） 13:00-14:30   C会場(1F会議室103),C7-2,音声・音響・音楽を扱うオープン基盤モデルの構築に向けたデータセット策定,/proceedings/annual_meeting/2025/pdf_dir/C7-2.pdf,"○高道 慎之介 (慶應大/東大/産総研), 和田 仰, 小川 諒, 山岡 洸瑛, 中田 亘, 淺井 航平, 関 健太郎, 岡本 悠希, 齋藤 佑樹 (東大), 小川 哲司 (早大/産総研), 猿渡 洋 (東大), 中村 友彦, 深山 覚 (産総研)",本論文では，音声・音響・音楽信号を対象とするオープンな音基盤モデル構築に向けた，データセットの策定結果を報告する．汎用的な音基盤モデルを構築してその知見を共有するには，構築に資するデータセットを再現可能な形で整備すべきである．本論文では，音基盤モデルの満たすべき入出力条件を整理し，策定したデータセットについて分析する．
C7:音声言語処理3月12日（水） 13:00-14:30   C会場(1F会議室103),C7-3,傾聴態度を示す応答の生成における表出可能な応答種類の推定とその利用,/proceedings/annual_meeting/2025/pdf_dir/C7-3.pdf,"○田中 涼雅, 村田 匡輝 (豊田高専)",会話エージェントが人間に代わって語りの聴き手となることが期待されている．聴き手は，語り手に対して相槌などの応答をすることが重要であり，会話エージェントが聴き手として認められるためには，傾聴態度を示す応答（傾聴応答）の生成が望まれる．傾聴応答には複数の種類が存在し，語り手の発話に対する適切なものは必ずしも1 つではない．そのため，発話に適する応答種類を複数推定したうえで，その種類に基づいて応答表現を生成することが望ましい．本論文ではある発話に対して表出可能な応答を複数生成する手法について述べる．語り手の発話に適する応答種類をマルチラベル分類により複数推定，発話と推定結果から応答表現を生成する．実験により，応答種類の推定においてmacro-F1で0.83 を得た．また応答表現の生成において，比較モデルよりDistinct-N の値が向上していたことから，応答種類を利用する有効性を確認した．
C7:音声言語処理3月12日（水） 13:00-14:30   C会場(1F会議室103),C7-4,音声モデルにおけるCritical Period仮説の検証,/proceedings/annual_meeting/2025/pdf_dir/C7-4.pdf,"○古賀 友里愛, 神藤 駿介 (東大), 宮尾 祐介 (東大/NII)",本研究では，自己教師あり学習音声モデル（SSLモデル）の第二言語（L2）獲得過程を，Critical Period（CP）仮説の観点から分析する．L2 獲得におけるCP 仮説とは，人間はL2 への接触開始時期が遅いほど，その習得が困難になるとするものである．CPに注目することは，SSL モデルの学習メカニズムや効率的なL2 学習手法に加え，人間の脳の言語学習の仕組みに関する新たな示唆をも与える可能性がある．実験の結果，SSL モデルではL2 の音韻獲得におけるCP 仮説は成り立たなかったが，早期にL2 の学習を開始したモデルはL1 モノリンガルモデルや初めから2 言語で学習したモデルとは異なる埋め込みを獲得していることが示唆された．
C7:音声言語処理3月12日（水） 13:00-14:30   C会場(1F会議室103),C7-5,日本民謡における旋律と方言アクセントの一致関係の比較分析,/proceedings/annual_meeting/2025/pdf_dir/C7-5.pdf,"○青山 拓生, 河瀬 彰宏, 沈 力 (同志社大)",声調言語や高低アクセント言語を持つ地域を中心に，音楽の旋律と言語の韻律の変化を一致させる傾向が指摘されている．日本においては，とりわけ日本民謡の旋律と言語の韻律の関連が示唆されているものの，具体的な関連を明らかにすることはできておらず，体系的な実証研究が不足していた．本研究では，日本民謡における旋律と方言アクセントとの一致関係を明らかにすることを目的とし，東京，京都，鹿児島の計382 曲を対象に旋律の音程変化とアクセントの高低変化を比較し，一致関係を検証した．その結果，日本民謡の旋律とアクセントの間に地域差を含む一致関係が存在することを明らかにした．
C7:音声言語処理3月12日（水） 13:00-14:30   C会場(1F会議室103),C7-6,量子計算を用いたダイレクトモデル,/proceedings/annual_meeting/2025/pdf_dir/C7-6.pdf,"○三輪 拓真 (NAIST/理研), 小田 悠介 (NII/理研), 河野 誠也 (理研/NAIST), 吉野 幸一郎 (科学大/理研/NAIST)",複数のモジュールでの処理を順次通過するようなタスクでの一般的な実装として，カスケードモデルとEnd-to-End モデルが存在する．カスケードモデルは汎用性が高く，学習データも豊富に存在する一方で，中間出力において情報が一部欠損してしまう．End-to-End モデルは入力から最終出力まで一貫して計算を行うため中間出力における情報欠損が少ないが，既存の訓練データが少なく，学習コストが高い．本研究では両者の課題にアプローチするため，量子計算の性質に着目した．量子計算を用いた量子機械学習モデルをそれぞれ独立に訓練し，推論時のみ回路を結合させることで，量子状態の観測を行わずに中間出力の受け渡しを行う．古典コンピュータに比べて豊富な表現力を持つ量子ビットを中間出力に用いることで，モデル間の情報欠損を抑制する．本研究では対話状態追跡タスクを用いて提案法の検証を行い，今後の課題について考察を示した．
D7:テーマセッション4: 人狼知能：噓を見破り説得する会話ゲームとLLM3月12日（水） 13:00-14:30   D会場(1F会議室107),D7-1,人狼知能コンテスト2024冬季国内大会自然言語部門の概要,/proceedings/annual_meeting/2025/pdf_dir/D7-1.pdf,"○狩野 芳伸, 渡邉 嶺王, 佐橋 優人, 坂根 亜美 (静大), 鳥海 不二夫 (東大), 稲葉 通将 (電通大), 大澤 博隆 (慶應大), 片上 大輔 (工芸大), 大槻 恭士 (山形大), アランニャ クラウス (筑波大), 原田 慧, 伊藤 毅志 (電通大)",狩野芳伸1　渡邉嶺王1　佐橋優人1　坂根亜美1　鳥海不二夫2　稲葉通将3　大澤博隆4　片上大輔5　大槻恭士6　アランニャクラウス7　原田慧8　伊藤毅志9
D7:テーマセッション4: 人狼知能：噓を見破り説得する会話ゲームとLLM3月12日（水） 13:00-14:30   D会場(1F会議室107),D7-2,プレイヤー間の論理的情報を与えたLLMによる人狼ゲーム対話エージェントの構築,/proceedings/annual_meeting/2025/pdf_dir/D7-2.pdf,"○渡邉 嶺王, 狩野 芳伸 (静大)",大規模言語モデルが未だ苦手とする推論などの複雑な問題への対応を目指し、推論が求められる人狼ゲームを題材に、GPT-4 を基盤とした人狼ゲームエージェントを開発し、明示的な論理構造を組み込む手法を提案する。その結果、論理情報を提示する手法は提示しない手法と比較して推論精度が向上し、主観的評価においても優位性が確認された。
D7:テーマセッション4: 人狼知能：噓を見破り説得する会話ゲームとLLM3月12日（水） 13:00-14:30   D会場(1F会議室107),D7-3,大規模言語モデルに基づく人狼ゲームエージェントにおける戦略の自動適応,/proceedings/annual_meeting/2025/pdf_dir/D7-3.pdf,"○中盛 楓也, Yin Jou Huang, Fei Cheng (京大)","本研究では, 人狼エージェントにおいて, 事前に定義された戦略を他者の態度や会話状況に応じて切り替えることで, パフォーマンス向上を図る手法について述べる. 従来のプロンプトエンジニアリングを用いた人狼エージェントでは, あらかじめ有効な戦略を明示的に指定する手法が存在したものの, 状況に応じて変化させるものはなかった. 本研究では, 他者の発言内容や役職の推定結果に基づき, 戦略プロンプトを動的に切り替える手法を提案する. 評価実験では, 従来手法や固定戦略を用いたベースラインと比較し, 勝率の向上を検証する．"
D7:テーマセッション4: 人狼知能：噓を見破り説得する会話ゲームとLLM3月12日（水） 13:00-14:30   D会場(1F会議室107),D7-4,戦略的発話の多様な生成を目指した人狼エージェントの構築,/proceedings/annual_meeting/2025/pdf_dir/D7-4.pdf,"○佐藤 岳大 (明大), 尾崎 慎太郎 (NAIST), 横山 大作 (明大)","不完全情報ゲームである人狼において、大規模言語モデル(Large Language Model, LLM) を利用したエージェントが人間のように戦略的な発話を行うには、会話履歴の情報から状況を把握する等の難しさがある。本研究では、自身が置かれた状況を把握し、状況に適切な発話方針をプロンプトとして与えるエージェントを提案した。この手法により、提案したエージェントは戦略的な発話を多様に出力することが可能になった。また、LLM を単純に適用した場合と比較して、発話が個性的で論理的になっていることを定性評価により示した。"
E7:テーマセッション1: 金融・経済ドメインのための言語処理(3)3月12日（水） 13:00-14:30   E会場(1F会議室108),E7-1,表現の置換による業績要因文の同義文・対義文生成,/proceedings/annual_meeting/2025/pdf_dir/E7-1.pdf,"○小川 紀寧, 酒井 浩之 (成蹊大)",本研究では，決算短信における業績要因文を対象として，文生成にいわゆる大規模言語モデル的手法を使わず，指定の文集合のみを参照して単語・文節の極性を学習し，明示された基準を用いて同義の文や対義の文（意味反転文）を出力する手法を提案した．具体的には，少数の極性提示表現例をもとに，文章中の全文節の極性を自動で算出する．その後，入力文の置換箇所を極性によって定め，置換先の組み合わせ表現を極性や機能語の接続頻度を元に決定し，同義文や対義文の出力を行った．
E7:テーマセッション1: 金融・経済ドメインのための言語処理(3)3月12日（水） 13:00-14:30   E会場(1F会議室108),E7-2,大規模言語モデルを用いたFew-ShotプロンプティングによるJ-REITの投資物件に関する表構造認識,/proceedings/annual_meeting/2025/pdf_dir/E7-2.pdf,"○土井 惟成 (JPX/東大), 田中 麻由梨 (JPX総研)",本研究では，J-REIT の投資物件に関する表から情報を抽出するために，HTML 形式の表をJSON 形式の構造化データに変換する手法として，大規模言語モデルを用いたFew-Shot プロンプティングに基づく手法を提案する．実験の結果，既存のZero-Shotプロンプティングに基づく手法よりも大幅に精度が向上することを示した．特に，同一のJ-REIT の表をサンプルとした場合，変換精度は98.70%に達し，実務への応用可能性を示唆する．
E7:テーマセッション1: 金融・経済ドメインのための言語処理(3)3月12日（水） 13:00-14:30   E会場(1F会議室108),E7-3,取締役推薦理由文を用いた取締役のスキル・マトリックス分類モデルの開発,/proceedings/annual_meeting/2025/pdf_dir/E7-3.pdf,"○山脇 大 (野村アセット/北大), 野中 賢也, 田村 光太郎 (ユーザベース), 高野 海斗 (野村アセット), 中川 慧 (野村アセット/大阪公立大)",株式会社のガバナンスの中核を担う取締役会の構成は、時代の変化に伴い透明性や多様性の確保が求められてきた。近年では、取締役会の機能強化を支える手段としてスキル・マトリックスが注目されている。しかし、その作成は各企業に委ねられ、客観性や標準化の欠如が課題となっている。そこで本研究では、取締役のスキル・マトリックス分類モデルの開発を行う。具体的には企業の公開している取締役推薦理由文からスキルを抽出・データセットを作成し、スキルを定義するとともに，スキル分類を多ラベル問題として定義する。その上で、ラベル不均衡に対応する学習フレームワークを提案し、その有効性を実証した。
E7:テーマセッション1: 金融・経済ドメインのための言語処理(3)3月12日（水） 13:00-14:30   E会場(1F会議室108),E7-4,会計ドメインにおける質問応答のためのLLM を用いた解説ページ順位付け,/proceedings/annual_meeting/2025/pdf_dir/E7-4.pdf,"○飯田 頌平 (弥生), 古俣 槙山, 三田寺 聖, 長谷川 遼, 宇津呂 武仁 (筑波大), 林 友超, 宍戸 里絵 (弥生)",大規模言語モデル（LLM）は幅広い分野で応用が進んでおり，会計ドメインにおいても活用が期待されている．そこで本論文では，弥生株式会社の持つ会計業務に関する質問の解説ページを収集し，検索システム構築および精度評価に用いることのできる弥生QA v1 データセットを構築した．このデータセットを用いて既存のベクトル検索手法の評価を行い，さらにその検索結果をLLM によって順位付けした．この結果，順位付けを実施しない従来手法に比べて正答率の向上が見られ，会計ドメインにおいて有効となる検索手法を示した．
E7:テーマセッション1: 金融・経済ドメインのための言語処理(3)3月12日（水） 13:00-14:30   E会場(1F会議室108),E7-5,金融テキストにおけるセンチメント分析の課題整理,/proceedings/annual_meeting/2025/pdf_dir/E7-5.pdf,○高野 海斗 (野村アセット),大規模言語モデル(LLM) の発展に伴い，資産運用業界においてもLLM への期待が高まっているが，実際には様々な課題が存在する．これまで自然言語処理(NLP) 技術の発展に伴い，金融テキストを対象にしたセンチメント分析も発展してきたが，その変化はセンチメント付与の手法やモデルの切り替わりが中心であり，根本的な課題や問題に対して十分な議論が不足している．そこで本研究では，従来の金融テキストにおけるセンチメント分析の課題とその解決の糸口をいくつか示す．課題を明確に示し，整理することで，金融テキストにおけるセンチメント分析が今後より発展することを期待している．
P7:ポスター3月12日（水） 13:00-14:30   P会場(2Fコンベンションホール3+4),P7-1,対照学習を用いたhallucination検出手法,/proceedings/annual_meeting/2025/pdf_dir/P7-1.pdf,"○山田 美優, 荒瀬 由紀 (科学大)",大規模言語モデル(LLM) は様々な生成タスクで用いられ、高い性能を示すが、一方でhallucination と呼ばれる入力文章と矛盾する情報や入力からは事実性が検証不可能な情報を出力することが問題になっている。様々なhallucination 検出手法が提案されているが、その精度はまだ十分でなく、さらなる改善が求められている。本稿では、hallucination を含む出力が入力文章にない情報や推定困難な情報を含む点に着目する。この特性から入力文章とhallucinationを含む出力ではそれぞれの埋め込み表現が乖離すると仮定し、対照学習を用いてhallucination 検出器を訓練する手法を提案する。実験の結果、提案手法はベースラインよりもhallucination 検出精度を大幅に向上させることが示された。
P7:ポスター3月12日（水） 13:00-14:30   P会場(2Fコンベンションホール3+4),P7-2,科学文書における「間接的」引用についてのハルシネーション検出の評価,/proceedings/annual_meeting/2025/pdf_dir/P7-2.pdf,"○桒原 龍生 (大阪工大), 杉山 弘晃 (NTT), 堂坂 浩二 (秋田県立大), 平 博順 (大阪工大)",近年，科学論文執筆支援技術の研究が進み，科学論文における関連研究セクションの自動生成が試みられている．関連研究セクションの自動生成を構成する技術の一つに，与えられた引用論文と作成対象の論文との関係性を考慮しつつ，引用論文の内容を簡潔に表現した引用文を自動生成する引用文生成技術がある．近年の引用文生成技術では，大規模言語モデル（LLM）が用いられることが増えているが，事実と異なる文章の生成（ハルシネーション）が課題となっている．本研究では，LLM による引用文のハルシネーション検出について，評価用ベンチマークデータを構築し，引用方法の観点から分析を行った．
P7:ポスター3月12日（水） 13:00-14:30   P会場(2Fコンベンションホール3+4),P7-3,大規模言語モデルにおけるICL バイアスの選択的補正,/proceedings/annual_meeting/2025/pdf_dir/P7-3.pdf,"○酒井 祐介, Natthawut Kertkeidkachorn, 白井 清昭 (JAIST)","大規模言語モデルを用いた質問応答システムが広く注目されているが, 生成される回答にはさまざまなバイアスが生じることが指摘されている.本研究では, LLM がIn-Context Learning(ICL) における例示の与え方によって引き起こすバイアスに対し, キャリブレーション手法とRetriever-AugmentedGeneration(RAG) が与える影響を検証する. 特に, 与えたICL 例示によってモデルの予測が大きく変動する問題をICL 依存問題と定義し, それらを選択的に補正するキャリブレーション手法を提案した上で,RAG との併用効果を評価した. 実験の結果, 従来手法よりも効果的にICL によるバイアスを抑制し, 特定条件下では精度でも従来手法を上回ることを確認した."
P7:ポスター3月12日（水） 13:00-14:30   P会場(2Fコンベンションホール3+4),P7-4,SocialStigmaQA-JA: 社会的バイアス評価用日本語データセット,/proceedings/annual_meeting/2025/pdf_dir/P7-4.pdf,"○岩城 諒, 金山 博, 竹内 幹雄, 村岡 雅康, 倉田 岳人 (IBM)",大規模言語モデルの普及に伴い，その出力の安全性を担保することが重要な研究課題として認知されている．本研究では，英語の社会的バイアス評価データセットであるSocialStigmaQA をもとにして日本語の社会的バイアス評価データセットであるSocialStigmaQA-JA を構築する．英語版SocialStigmaQA は米国の文化や法律を背景として構築されたものであるため，日本における社会的バイアスの評価に適するデータセットを構築するためには，単純な翻訳を超える修正が必要である．本稿ではこれらの日本の文化・法律を考慮した修正について詳述する．さらに，構築したSocialStigmaQA-JAを利用して日本語を利用可能な大規模言語モデルの社会的バイアスを評価し，今後の安全性評価の指針について議論する．注意：本論文には不快な表現が一部含まれます．
P7:ポスター3月12日（水） 13:00-14:30   P会場(2Fコンベンションホール3+4),P7-5,PUPPET：タスク性能を維持しながらLLMとして検出されやすくする学習フレームワーク,/proceedings/annual_meeting/2025/pdf_dir/P7-5.pdf,"○齋藤 幸史郎, 小池 隆斗 (科学大), 金子 正弘 (MBZUAI/科学大), 岡崎 直観 (科学大/産総研/NII)",昨今，大規模言語モデル（Large Language Models;LLM）が生成する文を検出する需要が高まっており，代表的な手法の一つに透かし（Watermark）がある．生成文に埋め込まれた透かしトークンを調べることで高性能な検出が可能な一方で，そのトークンはランダムに選択されるため，その生成文の品質やタスク性能に課題がある．そこで，本研究ではLLM のタスク性能を維持したまま，そのLLM の生成文を検出しやすくするフレームワークPUPPET を提案する．具体的には，生成文に対して検出器とタスク評価器の二つから報酬関数を設計し，LLM の強化学習を行う．評価実験の結果，我々のフレームワークで学習したLLM は文書要約タスクにおいてタスク性能を維持したまま，その検出が容易（再現率6pt 向上）となったことを確認した．
P7:ポスター3月12日（水） 13:00-14:30   P会場(2Fコンベンションホール3+4),P7-6,日本語を対象としたLLMの大規模人手評価,/proceedings/annual_meeting/2025/pdf_dir/P7-6.pdf,"○井之上 直也 (いちから/JAIST), 安藤 まや, 後藤 美知子, 関根 聡 (いちから), 中山 功太, 宮尾 祐介 (NII)",大規模言語モデル（LLM）の評価は，LLM による自動評価が主流となっているが，自動評価には多くの課題が存在し，LLM の評価方法論そのものにおいて決定的な解は未だ得られていない．本研究では，今後のLLM 評価に関する研究を支援することを目的として，484 件の日本語プロンプトに対する
P7:ポスター3月12日（水） 13:00-14:30   P会場(2Fコンベンションホール3+4),P7-7,chakoshi: カテゴリのカスタマイズが可能な日本語に強いLLM向けガードレール,/proceedings/annual_meeting/2025/pdf_dir/P7-7.pdf,"○新井 一博, 松井 遼太, 深山 健司, 山本 雄大, 杉本 海人, 岩瀬 義昌 (NTT)",本研究では，日本語特有のニュアンスに対応したLLM 向けのガードレールモデルである「chakoshi」を開発し，その有効性を検証した．chakoshi は，複数のオープンデータセットを再編成し，独自の学習データセットでファインチューニングした，軽量なLLM である．gemma-2-9b-it をベースとしたchakoshiモデルは，複数のテストデータセットにおけるF1スコアで平均0.92 以上を達成し，既存のモデルと比較して高い性能を示した．さらに，防ぎたい話題を自然言語でカスタマイズできる機能を実装し，実験によってその有効性を確認した．
P7:ポスター3月12日（水） 13:00-14:30   P会場(2Fコンベンションホール3+4),P7-8,アライメントが大規模言語モデルの数値バイアスに与える影響,/proceedings/annual_meeting/2025/pdf_dir/P7-8.pdf,"○佐藤 郁子, 金 輝燦 (都立大), 陳 宙斯 (一橋大), 三田 雅人 (サイバーエージェント/都立大), 小町 守 (一橋大)",大規模言語モデル（LLM）を評価者として用いる“LLM-as-a-judge” は，機械翻訳品質推定（MTQE）をはじめとする，多くの評価タスクで効果を示している．しかし，指示チューニングや強化学習によってアライメントされたLLM では，特定の評価スコアを頻繁に生成する数値バイアスが確認されている．この現象は，アライメントにより出力の多様性が減少するという既存の知見と一致しており，多様性の欠如は評価スコアの偏りを引き起こす可能性がある．その結果，入力の微細な変化に対する評価の頑健性が損なわれる懸念がある．本研究では，LLMのアライメントが数値バイアスおよびタスク性能に与える影響を調査する．
P7:ポスター3月12日（水） 13:00-14:30   P会場(2Fコンベンションホール3+4),P7-9,"人間と LLM の ""面白さ"" の感性は一致するのか？",/proceedings/annual_meeting/2025/pdf_dir/P7-9.pdf,"○坂部 立 (一橋大), 金 輝燦 (都立大), 小町 守 (一橋大)",計算機によるユーモアの研究は，対話システムなどの自然言語処理ツールの高度化に不可欠とされている一方で，大規模言語モデル(Large LanguageModel; LLM) のユーモア生成や評価に関してはまだ十分に検討されていない．本研究では，図1 のように大喜利を題材として新たに高品質な日本語の大喜利データセットを構築し，LLM の大喜利生成能力と大喜利評価能力を検証した．
P7:ポスター3月12日（水） 13:00-14:30   P会場(2Fコンベンションホール3+4),P7-10,大規模言語モデルの文生成確率を用いた教師なし品質推定,/proceedings/annual_meeting/2025/pdf_dir/P7-10.pdf,"○樽本 空宙, 梶原 智之, 二宮 崇 (愛媛大)",本研究では，言語生成タスクにおける参照なし自動評価の改善のために，大規模言語モデルの文生成確率に基づく教師なし品質推定の手法を提案する．生成文の品質推定は主に機械翻訳タスクを対象に取り組まれており，先行研究では対訳コーパスで訓練したTransformer やmBART に基づく品質推定が提案されている．先行研究の系列変換モデルよりも大規模なデータで事前訓練した大規模言語モデルは，高性能な品質推定と様々なタスクへの応用が期待できる．機械翻訳およびテキスト平易化における品質推定に関する評価実験の結果，提案手法は機械翻訳では多資源言語対において既存手法の性能を上回り，テキスト平易化では一部の教師あり品質推定の性能を上回ることを確認した．
P7:ポスター3月12日（水） 13:00-14:30   P会場(2Fコンベンションホール3+4),P7-11,大規模言語モデルの多言語社会的バイアス抑制における単言語ラベル付きデータの役割,/proceedings/annual_meeting/2025/pdf_dir/P7-11.pdf,"○大葉 大輔 (科学大/ELYZA), 金子 正弘 (MBZUAI/科学大), Danushka Bollegala (リバプール大), 岡崎 直観 (科学大/NII)",大規模言語モデル(LLM) を多言語対応するためには、あらゆる入力言語において社会的バイアスを抑制することが求められるが、全言語を対象としたラベル付き学習・評価データを整備するのは容易ではない。本研究では、非英語言語へのバイアス抑制における英語のラベル付きデータが担う役割を検証する。日本語を含むアジア圏言語を対象とした評価実験では、英語のラベル付きデータを学習データとして単に流用するだけでは、多言語バイアス抑制効果は限定的であることを示す。追加分析と併せて、ラベル付き学習データが対象言語の表層や文化を反映したものであることの必要性を示唆する。注意: 本論文には不快な表現が一部含まれます。
P7:ポスター3月12日（水） 13:00-14:30   P会場(2Fコンベンションホール3+4),P7-12,多言語大規模言語モデルにおける英語指示文と対象言語指示文の公平な比較,/proceedings/annual_meeting/2025/pdf_dir/P7-12.pdf,"○榎本 大晟, 金 輝燦 (都立大), 陳 宙斯, 小町 守 (一橋大)",多言語大規模言語モデルでタスクを解く際，非英語のデータを扱う場合であっても，英語指示文が対象言語指示文より効果的である傾向が報告されている．しかし，それらの研究では英語から翻訳されたデータセットや指示文が用いられていることが多く，翻訳特有のバイアス（Translationese）が指示文の言語間の公平な比較を妨げている可能性がある．この問題に対して，本研究ではTranslationese の影響を排除し，指示文の公平な比較を実現する．結果として，先行研究と異なり，どちらの指示文がより効果的であるかはタスクや分類ラベルによって異なることを示す．また，各指示文を用いる際の生成テキストの特徴や活性化ニューロンの違いを分析する．
P7:ポスター3月12日（水） 13:00-14:30   P会場(2Fコンベンションホール3+4),P7-13,日本語大規模言語モデルの事前訓練過程における下流タスク性能の網羅的な分析,/proceedings/annual_meeting/2025/pdf_dir/P7-13.pdf,"○西田 悠人, 小田 悠介 (NAIST/NII), Namgi Han (東大), 高木 優 (NII), 宮尾 祐介 (東大/NII)",大規模言語モデル(LLM) は目覚ましい発展を遂げているが，その高い性能がどのように獲得されていくのかについての理解は不十分である．本稿では，日本語を多く含む大規模テキストを用いて学習されたLLM-jp-3 モデルを対象に，様々なモデルサイズ・下流タスクにおけるモデルの学習過程を分析し，日本語LLM の内部メカニズムの洞察を深める．分析の結果，LLM の学習過程の下流タスクのスコアの軌跡は，タスクの種類によっていくつかの典型的なパターンに分類できることが示唆された．
P7:ポスター3月12日（水） 13:00-14:30   P会場(2Fコンベンションホール3+4),P7-14,SelfCheckGPTはコード生成におけるハルシネーションを検知できるか,/proceedings/annual_meeting/2025/pdf_dir/P7-14.pdf,"○伊東 和香, 小原 有以, 佐藤 美唯 (日本女子大), 秋信 有花, 倉林 利行 (NTT), 倉光 君郎 (日本女子大)","大規模言語モデル(Large Language Model, LLM) によるコード生成は，ソフトウェア開発の効率化に寄与する技術として注目されている．しかしLLM の出力にはハルシネーションを含むことが問題となる．ハルシネーションを含む出力コードはエラーを引き起こす可能性があるため，事前にハルシネーションを検知することが重要である．本研究では，自然言語におけるハルシネーション検知手法であるSelfCheckGPT をコード生成に適用する．一般的なコード生成の評価手法である実行ベース評価と，SelfCheckGPT によるコードの評価を比較することで，両者の関連性を確認する．実行ベース評価と比較した結果，特にBLEU，ROUGE-L，EditSim を利用したSelfCheckGPT による評価において，実行ベース評価との関連性が見られた．"
P7:ポスター3月12日（水） 13:00-14:30   P会場(2Fコンベンションホール3+4),P7-15,日本語LLMに含まれる交差バイアスと有害性の評価に向けて,/proceedings/annual_meeting/2025/pdf_dir/P7-15.pdf,"○谷中 瞳, Sunjin Oh (東大), Xinqi He (立教大), Namgi Han, Jie Lu, 九門 涼真 (東大), 松岡 佑磨, 渡部 和彦 (ソフトバンク), 板津 木綿子 (東大)",LLM の社会的バイアスの評価において，個々の社会的属性だけでなく，複数の属性の組み合わせからなる交差バイアスを社会問題の事例に基づいて評価することの重要性が指摘されている．本研究では，QA タスクでLLM の交差バイアスを評価する日本語ベンチマークinter-JBBQ を構築する．inter-JBBQを用いてGPT-4o とSwallow を分析した結果，同じ問題でも属性の組み合わせによって回答に変動があり，曖昧な問題に対しGPT-4o はSwallow と比較して答えられないと回答する傾向が強化されていた．一方，曖昧性を解消した問題ではSwallow の正答率がGPT-4o の正答率を上回る場合も観測された．注意：本論文には不快な表現が一部含まれます．
P7:ポスター3月12日（水） 13:00-14:30   P会場(2Fコンベンションホール3+4),P7-16,日付入りLLM文書翻訳評価用データセット,/proceedings/annual_meeting/2025/pdf_dir/P7-16.pdf,"○岩月 憲一, 根石 将人 (みらい翻訳)",大規模言語モデル（LLM）による翻訳の評価に際し，評価に用いるデータがLLM の事前学習データに含まれている場合，適切な評価ができない。本研究では，この問題を回避するために，頻繁に更新されるニュース系のリソースを利用して，英日の文書翻訳評価用データセットを構築した。本データセットは公開されており，不定期に更新される予定である。また，利用者が自ら更新できるよう，データ構築に用いたソースコードも合わせて公開する。
P7:ポスター3月12日（水） 13:00-14:30   P会場(2Fコンベンションホール3+4),P7-17,Constructing Open-source Large Language Model Evaluator for Japanese,/proceedings/annual_meeting/2025/pdf_dir/P7-17.pdf,"○◊孫 一坤, 八幡 早紀子, 程 飛, 村脇 有吾, 褚 晨翚 (京大), 黒橋 禎夫 (京大/NII)","Evaluating the performance of large language models(LLMs) remains a crucial research topic, and conductinga comprehensive and accurate evaluation of LLM perfor-mance eﬃciently is challenging.This challenge is par-ticularly acute for non-English languages. GPT-4-basedautomated evaluation has proven eﬀective, demonstratinghigh consistency with human preference. However, GPT-"
P7:ポスター3月12日（水） 13:00-14:30   P会場(2Fコンベンションホール3+4),P7-18,Jailbreakにより生成したフェイクニュースの危険度評価,/proceedings/annual_meeting/2025/pdf_dir/P7-18.pdf,"○島田 比奈理 (科学大), 金子 正弘 (MBZUAI), 岡崎 直観 (科学大/産総研/NII)",悪意を持つユーザーにより大規模言語モデル(Large Language Model: LLM) がJailbreak 手法により攻撃され，虚偽情報の生成に悪用されることでフェイクニュースの拡散につながる懸念が高まっている．LLM の安全性を高めるには様々な攻撃に対する頑健性の評価が不可欠だが，フェイクニュースにおいてJailbreak 手法の脅威に関するデータセットや評価指標は確立されていない．本稿では，フェイクニュース生成のJailbreak に関するベンチマークを構築し，LLM の頑健性や出力されたフェイクニュースの評価を実施した．その結果から，Jailbreak 攻撃の成功確率とフェイクニュースの評価指標では攻撃手法ごとに異なる傾向が見られ，Jailbreak 手法の評価においてLLM が出力した内容まで精査する必要があることが明らかになった．
P7:ポスター3月12日（水） 13:00-14:30   P会場(2Fコンベンションホール3+4),P7-19,大規模言語モデルの事前学習用コーパスにおける要配慮個人情報の検出,/proceedings/annual_meeting/2025/pdf_dir/P7-19.pdf,"○源 怜維 (早大), 小田 悠介 (LLMC), 河原 大輔 (早大/LLMC)",法的に取得が制限される要配慮個人情報は，大規模言語モデル（LLM）の構築に必要な大規模な事前学習用コーパスに含まれる可能性があり，その検出とフィルタリングは重要な課題である．本研究では，文章内の要配慮個人情報を検出するために，要配慮個人情報データセットを構築し，機械学習モデルを学習させた．その結果，要配慮個人情報のジャンルと関係する情報を高速に検出する判定器を構築できた．
P7:ポスター3月12日（水） 13:00-14:30   P会場(2Fコンベンションホール3+4),P7-20,大規模言語モデルが持つ抽象推論能力の分析,/proceedings/annual_meeting/2025/pdf_dir/P7-20.pdf,"○清野 輝風 (東北大), 青木 洋一, 斉藤 いつみ, 坂口 慶祐 (東北大/理研)",人工知能が高度な汎化能力を持つためには，少数の例からパターンを抽出し，新しい入力に適用する抽象推論能力の向上が重要である．しかしながら，既存の大規模言語モデルは未だ十分な抽象推論能力を有しておらず，その能力について詳細な分析が必要である．本稿ではこれらの能力を評価する代表的なデータセットであるARC（Abstraction andReasoning Corpus）についてfew-shot 学習を通して実際に解かせ，ARC の各タスクに必要な処理を能力ごとに分解し分類した上で，能力ごとの精度を分析することで大規模言語モデルの抽象推論能力を詳細に評価する．
P7:ポスター3月12日（水） 13:00-14:30   P会場(2Fコンベンションホール3+4),P7-21,生成AIのための農業データセット構築とモデル評価,/proceedings/annual_meeting/2025/pdf_dir/P7-21.pdf,"○板倉 亮真, 坂地 泰紀, 野田 五十樹 (北大), 小林 暁雄, 大友 将宏, 石原 潤一, 桂樹 哲雄 (農研機構)",農業の栽培技術や取り組みは、国内の各自治体や公共団体、農協、その他の民間企業などがそれぞれ独自に取りまとめたデータがそれぞれのサイト上などから公開されている。しかしながら、これらの知識は機械可読な形式で提供されていることは稀で、現状の生成AI などでうまく活用できているとは言い難い。本研究では、そのようなデータから、AI で利用しやすい形のデータセットとして、インストラクション形式でのデータの半自動構築を行う手法を提案する。また、既存の生成AI がこれらのウェブ上のデータに含まれる知識をどの程度学習しているかについても検証を行った。
P7:ポスター3月12日（水） 13:00-14:30   P会場(2Fコンベンションホール3+4),P7-22,組織を超えたLLM学習データの目的外利用を防げるか？,/proceedings/annual_meeting/2025/pdf_dir/P7-22.pdf,"○相馬 菜生, 小林 美結, 宮田 侑佳, 倉光 君郎 (日本女子大)","高性能な大規模言語モデル（Large Language Model,LLM）の開発には，高品質な学習データの収集が不可欠である．しかし，データ収集には多くの課題が伴い，データ提供者とモデル開発者が異なるケースでは，組織間でのデータ共有が避けられない場合がある．この共有プロセスにおいて，データの不適切な利用や漏洩リスクは重大な課題となる．そのため，データに適切な保護処理を施し，LLM の学習以外での利用を防ぐことが必要不可欠となる．同時に，保護されたデータを用いて構築したLLM において，モデル性能が大幅に低下しないことも求められる．本研究では，保護処理を施したデータを学習データとして使用した場合におけるLLM への影響を，特にコード生成能力を指標として評価する．"
P7:ポスター3月12日（水） 13:00-14:30   P会場(2Fコンベンションホール3+4),P7-23,人間が書いた文章を対象としたHallucination検出ベンチマークの構築と評価,/proceedings/annual_meeting/2025/pdf_dir/P7-23.pdf,"○岩本 和真 (香川大), 大村 和正, 石原 祥太郎 (日経)",文章の内容的な誤りを正す校閲は，文章の質を担保するために重要な工程である．本研究では，大規模言語モデル(LLM) を活用した校閲支援の実現に向け，人間が書いた文章に生じるHallucination の特徴を分析し，LLM の校閲能力を評価するベンチマークを構築する．新聞の訂正記事を用いた分析では，漢字誤変換や数字の桁のずれといった，人間が書いた文章ならではの特徴があるとわかった．分析結果をもとに人間が起こしやすいHallucination を含む文章を自動生成しLLM を評価した結果，LLM にとって校閲は困難なタスクであることを確認した．
P7:ポスター3月12日（水） 13:00-14:30   P会場(2Fコンベンションホール3+4),P7-24,大規模言語モデルの利用におけるプライバシー保護の新たな視点,/proceedings/annual_meeting/2025/pdf_dir/P7-24.pdf,"○髙田 雅之, 玉井 睦 (セコム)",ChatGPT の登場により，対話型生成AI システムに対する期待が高まっている．一方で，LLM が組み込まれたAI システムの利用にはプライバシーリスクが伴う．LLM のプライバシー保護研究は，学習データやモデルに含まれる個人のプライバシーリスクに関する対策が主流であり，AI システム利用時のプライバシーリスクに関する検討は十分でない．本稿では，LLM の生成結果が利用者に出力される状況におけるプライバシーリスクとその低減の重要性を述べ，そのリスクに対するプライバシー保護の既存研究を示すとともに，今後研究すべき領域について提案する．
P7:ポスター3月12日（水） 13:00-14:30   P会場(2Fコンベンションホール3+4),P7-25,ダイアグラム理解に向けた大規模視覚言語モデルの内部表現の分析,/proceedings/annual_meeting/2025/pdf_dir/P7-25.pdf,"○吉田 遥音, 工藤 慧音, 青木 洋一 (東北大), 田中 涼太 (東北大/NTT), 斉藤 いつみ, 坂口 慶祐, 乾 健太郎 (東北大)",ダイアグラムを理解できるAI モデルの実現は，学習支援や情報処理の効率化において重要である．しかし，画像理解タスクで顕著な成果を上げている大規模視覚言語モデル（LVLM）であっても，ダイアグラムのような抽象的かつ構造的な画像の理解には限界がある．本研究では，LVLM がダイアグラムのどのような視覚情報を認識しているか，またそれらの情報をどのように保持しているかを明らかにするため，画像エンコーダおよびLLM の隠れ状態を用いてプロービングを行った．その結果，ノードの色や形，エッジの色や有無の情報はどの層でも10次元程度の低次元の線形部分空間に保持されていたが，エッジの向きの情報は10 次元程度の低次元空間には保持されていなかった．また，パッチ単位のプロービングにより，ノードやエッジが描かれていない背景の隠れ状態に，複数のノードやエッジの情報がまとめて保持されていることが示唆された．
Q7:ポスター3月12日（水） 13:00-14:30   Q会場(1F会議室101AB),Q7-1,構造化知識 RAG・文書ベース RAG を段階的に利用したマルチホップ QA に対する LLM の精度向上,/proceedings/annual_meeting/2025/pdf_dir/Q7-1.pdf,"○石井 愛 (理研/BIPROGY), 井之上 直也 (JAIST/理研), 鈴木 久美, 関根 聡 (理研)",大規模言語モデル（LLM）のハルシネーション（事実と矛盾する情報生成の課題）に対し，構造化・非構造化知識源を用いたRetrieval-AugmentedGeneration（RAG）の比較分析を行う．マルチホップQA データセットを用いて，構造化知識ベース，文書ベースのRAG およびLLM のみによる回答を段階的に組み合わせる手法により，各知識源の特性を活かした回答生成の有効性を実証する．
Q7:ポスター3月12日（水） 13:00-14:30   Q会場(1F会議室101AB),Q7-2,法律分野の統合引用グラフを活用した質問応答の実現,/proceedings/annual_meeting/2025/pdf_dir/Q7-2.pdf,"○丸山 拓海, 稲垣 有二 (弁コム)",法律実務においては，法令や判例に加え，専門書籍やガイドラインなど，多様な情報源の関係性を総合的に把握することが不可欠である．しかし，これまでの研究は主に法令や判例間の関係性に焦点を当てており，書籍やガイドラインとの連携については十分に検討されていなかった．本研究では，これらすべての情報源を包括的に結びつける大規模な引用グラフを構築し，その実務的有用性を検証した．その結果，質問応答タスクにおいて，本引用グラフを活用することで，適切な法令・判例の選出が可能となっただけでなく，法的な正確性を保ちながら，人手で作成した回答よりも好ましい回答を生成できることが明らかとなった．
Q7:ポスター3月12日（水） 13:00-14:30   Q会場(1F会議室101AB),Q7-3,軽量LLMを用いた規則適合判定,/proceedings/annual_meeting/2025/pdf_dir/Q7-3.pdf,"○矢野 大地 (大阪工大), 小林 一郎 (お茶大), 平 博順 (大阪工大)",自律型ロボットと人間が共生し，自動運転車が公道を走行する世の中では，それらの行動が，人間があらかじめ定めた法律や規則に沿ったものであるか説明できる高精度な規則適合判定が重要である．また，セキュリティの側面から，ローカル環境での規則適合判定技術の精度向上も重要である．本研究では，普通自動車免許学科試験問題を題材とし，現在比較的高精度とされる軽量LLM を用い、判定理由も出力可能な規則適合判定をローカル環境で行い，規則適合判定の特徴などについて分析を行った． その結果，論理推論能力による出力の影響が大きいことや，「正」「誤」の判定能力に偏りがあることがわかった．
Q7:ポスター3月12日（水） 13:00-14:30   Q会場(1F会議室101AB),Q7-4,ハンセン病回復者の語り部の証言記録に対する質問応答システム構築に向けたベクトル検索精度の検証,/proceedings/annual_meeting/2025/pdf_dir/Q7-4.pdf,"○孝壽 真治, 竹内 孔一 (岡山大)",ハンセン病回復者の語り部との対話を通した人権学習は，自身の考えや価値観を見つめ直す対話型体験学習として重要である．しかし，語り部の高齢化やハンセン病を取り巻く環境などの背景から，次世代の語り部への記憶の継承が難しい．本研究では，語り部の実体験や記憶を後世に継承するために，ハンセン病回復者の語り部との対話による対話型体験学習の効果を再現できる質問応答システムの構築を目指す．本論文においては，質問応答システム構築の事前実験として，証言記録のテキストにベクトル検索を適用した場合の精度を検証する．実験の結果，GLuCoSE-base-ja-v2 が最も高い性能を発揮した．
Q7:ポスター3月12日（水） 13:00-14:30   Q会場(1F会議室101AB),Q7-5,RAGの生成器におけるSLMの利用,/proceedings/annual_meeting/2025/pdf_dir/Q7-5.pdf,"○阿部 晃弥, 新納 浩幸 (茨大)",LLM に外部知識を統合する手法であるRAG は，情報を検索する「検索器」と，その情報を基に回答を生成する「生成器」から構成されることが一般的である．本研究の目的は，検索器の能力が十分高い場合，SLM を生成器として用いてもRAG が有効に機能するかを検証することである．実験では，JQaRA データセットを用いたQA タスクを実施し，検索器が常に正解文書を検索できるという理想的な条件を仮定した．その結果，検索器の性能が高い場合でも，生成器として性能の高いモデルを使用する方が全体の回答精度が向上することが示された．また，生成器の機構に関して，複数のSLM をアンサンブルとして組み合わせることで，全体の正解率を大幅に向上させる可能性が示された．
Q7:ポスター3月12日（水） 13:00-14:30   Q会場(1F会議室101AB),Q7-6,Sentence-BERTによる分散表現を用いたベストアンサーの推定,/proceedings/annual_meeting/2025/pdf_dir/Q7-6.pdf,"○間宮 壮太, 市川 治 (滋賀大)",本研究では、Yahoo!知恵袋に投稿された質問と回答文を対象とし、Sentence-BERT で得た文ベクトルをLightGBM で学習することでベストアンサー予測するモデルを構築した。回答のみより質問文＋回答文を併用した方が高精度となり、人間の予測精度を上回る結果を得た。一方でカテゴリ別分析では、恋愛や政治といった正解が定まらない領域で精度が低く、質問者の主観や好みがBA 選定に大きく影響する傾向が示唆された。
Q7:ポスター3月12日（水） 13:00-14:30   Q会場(1F会議室101AB),Q7-7,OCRを利用したRAGにおけるPDF文書内のタイトルや表の利用,/proceedings/annual_meeting/2025/pdf_dir/Q7-7.pdf,"○蒲原 悠登, 竹内 孔一 (岡山大)",本論文では，大量かつ複雑な構造を持ったPDF 文書を扱う際に，Retrieval- Augmented Generation (RAG)の利用において，OCR ライブラリsurya1）を利用したチャンキング手法を提案する。surya を用いてタイトルや表を自動判定し，それぞれの構造に応じた処理を適用することで精度の向上を目指す．学内事務手続きPDF を用いたRAG による質問応答実験では，単純なテキスト分割と比べてBLEU およびROUGE 各種指標で高い性能を示した．その際特に表領域の処理の効果が確認された．
Q7:ポスター3月12日（水） 13:00-14:30   Q会場(1F会議室101AB),Q7-8,SQL AgentとマルチモーダルLLMを用いた文書内の表に対する質問応答システム,/proceedings/annual_meeting/2025/pdf_dir/Q7-8.pdf,"○青栁 直人, 森田 祐介 (みずほ第一FT)",多くの文書は表が含まれているため，質問応答において文書内の表に対する質問に正確に回答することは重要である．本研究では，回答の根拠となる表の検索と表に対する推論を必要とする質問応答タスクに取り組んだ．まず，従来手法の比較実験を行い，SQL Agent の回答性能が良いこと，SQL Agent に表画像を入力に加えた手法(SQL Agent-V) が表記揺れに対して頑健である可能性が示唆された．表記揺れに対する頑健性を向上させるために，LangGraphを利用してSQL Agent とSQL Agent-V を質問に応じて動的に切り替える手法を提案し，表記揺れを発生させたデータセットで実験を行うことで提案手法の有効性を確認した．
Q7:ポスター3月12日（水） 13:00-14:30   Q会場(1F会議室101AB),Q7-9,適応型負例選択を用いた対照学習による回答検索,/proceedings/annual_meeting/2025/pdf_dir/Q7-9.pdf,○伊東 秀夫 (リコー),質問応答におけるRAG では，質問文と回答が必ずしも類似関係にないため，回答を含む文脈（チャンク）が検索できない場合がある．我々はこの問題を，質問文から回答をピンポイントに検索する機能（回答検索）を用いて従来の検索結果をリランキングすることで解決する．具体的には生成言語モデルによる質問文のエンコード結果から得られる質問ベクトルを検索キーとし，同じく検索対象のエンコード結果から得られるベクトル列に対し最大内積検索（MIPS）を行う．これらベクトルは次トークン予測用に最適化されているため，MIPS 用に変換する必要がある．このベクトル変換の対照学習を効果的にするため，適応型負例選択と呼ぶ提案手法を用いる．実験では，回答検索によるリランキングにより一貫して検索精度が向上した．
Q7:ポスター3月12日（水） 13:00-14:30   Q会場(1F会議室101AB),Q7-10,Extraction and Generation Tasks with Knowledge-aware Text-to-Text Transfer Transformer,/proceedings/annual_meeting/2025/pdf_dir/Q7-10.pdf,"○◊Mohammad Golam Sohrab (産総研), Makoto Miwa (産総研/豊田工大)","We introduce knowledge-aware transfer learning with atext-to-text transfer transformer (KAT5) by leveraging atext-to-text transfer transformer (T5) in the Wikipedia do-main. In standard transfer learning like T5, a model is ﬁrstpre-trained on an unsupervised data task with a languagemodel objective before ﬁne-tuning it on a downstreamtask.In this work, we align large-scale alignments be-tween Wikipedia abstract and Wikidata triples to facilitateour pre-training KAT5 model. Experiment result showsthat KAT5 can match or outperform several downstreamtasks, including question answering, entity and relationextraction, summarization and machine translation."
Q7:ポスター3月12日（水） 13:00-14:30   Q会場(1F会議室101AB),Q7-11,トップダウン手続きを応用したLLM Agentのプランニングの試み,/proceedings/annual_meeting/2025/pdf_dir/Q7-11.pdf,"○村上 夏輝, 加賀屋 智之, 黄瀬 輝 (パナソニック コネクト)",LLM の著しい成果により，LLM を用いたエージェント(LLM Agent) 研究が近年増加しており，エージェントに重要なプランニングにLLM が用いられる研究が特に多い．本研究は，認知心理学や論理学から着想を得て，人間の問題解決能力を模倣するフレームワークを提案する．具体的には，複雑なゴールに対して，ルールに沿って，下位の簡単なサブゴールに木構造的に分解していく．評価実験の結果，既存手法と比較して提案手法によるプランニングのステップ数が少なくなることを示した．
Q7:ポスター3月12日（水） 13:00-14:30   Q会場(1F会議室101AB),Q7-12,介護支援システム:CPRASの開発,/proceedings/annual_meeting/2025/pdf_dir/Q7-12.pdf,"○阿部 貴駿, 中島 陽子, 本間 宏利 (釧路高専), Michal Ptaszynski, 桝井 文人 (北見工大), 秋葉 友良 (豊橋技科大)","令和5 年度の介護労働安定センターの調査[1] によると, 介護施設において29 歳以下の若い介護職員が離職率が高く, これは新人職員の指導が十分でないことが原因と考えられている. 特に, 利用者の困りごとへの対応に苦慮することが多いという問題がある. このような問題を解決するため, 本研究ではPython とFlask を用いて困りごとに対する適切な対応方法候補を提示するWeb アプリケーションの開発を行った. これにより, 作業効率の向上および離職率の低減に貢献が期待できる."
Q7:ポスター3月12日（水） 13:00-14:30   Q会場(1F会議室101AB),Q7-13,実世界対話における参照関係の統合的解析,/proceedings/annual_meeting/2025/pdf_dir/Q7-13.pdf,"○稲積 駿 (NAIST/理研), 植田 暢大 (京大), 吉野 幸一郎 (科学大/理研/NAIST)",本研究では，実世界における日本語対話の曖昧性解消を目的として，マルチモーダル参照解析の性能向上に寄与する要素を検討し，またモデルに組み込む．具体的には，メンション間およびメンション・物体間の参照関係を統合的に解析するフレームワークを提案する．実験では，共参照解析や照応解析といったメンション間の学習がメンション・物体間の解析に与える利得を明らかにした．
Q7:ポスター3月12日（水） 13:00-14:30   Q会場(1F会議室101AB),Q7-14,PDF 形式の農業技術文書を用いた表構造認識ベンチマーク TOITA,/proceedings/annual_meeting/2025/pdf_dir/Q7-14.pdf,"○阿部 瑞稀, 杉山 陽菜乃, 中村 彩乃, 前多 陸玖, 坂口 遥哉, 佐藤 栄作, 木村 泰知 (小樽商大)",本研究では，農業の技術継承にも用いられる長崎県農林業基準技術の文書を基に，各ツールの表構造認識の精度を検証するための正解データセットを作成し，さらに評価ベンチマークであるTechnical Obtainment and Interpretation of Tables inAgricultural document (TOITA) を構築した．
Q7:ポスター3月12日（水） 13:00-14:30   Q会場(1F会議室101AB),Q7-15,ユーザ属性を考慮した検索拡張生成による学部教育課程相談チャットボット,/proceedings/annual_meeting/2025/pdf_dir/Q7-15.pdf,"○竹内 新, 目良 和也, 梶山 朋子 (広島市大)",本研究では，ユーザ属性を考慮した検索拡張生成（RAG）を活用し，学部教育課程に関する質問に応答するチャットボットを構築した．本提案では，学部や入学年度などのユーザ属性に基づき，外部DBに含まれる全ドキュメントからユーザ属性に合ったドキュメント群を抽出する．そしてこのドキュメント群から質問に適合するパッセージ集合を生成し，質問とともにLLM に入力することで，質問への回答を生成する．提案手法により生成した回答は，全ドキュメントから生成した適合パッセージ集合による回答と比べて，質問内容に関係のない記載を含まない高評価の回答であることを確認した．
Q7:ポスター3月12日（水） 13:00-14:30   Q会場(1F会議室101AB),Q7-16,LLM埋め込みと遷移確率予測を利用した実店舗内顧客行動シミュレーション,/proceedings/annual_meeting/2025/pdf_dir/Q7-16.pdf,"○宮本 遼人 (早大), 春日 瑛 (サイバーエージェント)",実店舗での顧客行動シミュレーションは物理的な制約やコストから難しく，WEB のようなA/B テストが不可能なため需要が高い．本研究では顧客の店内行動をシミュレートするフレームワークLISSを提案する．店内をエリア区分し，隣接する棚や商品，滞在時間をLLM で埋め込み化することで，新商品の追加やレイアウト変更が購入率や滞在時間に与える影響を推定する．手法は過去の店舗行動ログを用いて学習し，変更時の行動変化を推論する．EZOHUB TOKYO における実データを用いて商品追加や配置変更の影響，情報拡張による推論安定化，柔軟な条件の設定が可能であることを確認した．実運用向けの推論アプリケーションも開発した．
Q7:ポスター3月12日（水） 13:00-14:30   Q会場(1F会議室101AB),Q7-17,広告画像ランキングによる視覚言語モデルの評価,/proceedings/annual_meeting/2025/pdf_dir/Q7-17.pdf,"○大竹 啓永 (NAIST), 張 培楠 (サイバーエージェント), 坂井 優介 (NAIST), 三田 雅人 (サイバーエージェント), 大内 啓樹 (NAIST/サイバーエージェント), 渡辺 太郎 (NAIST)",視覚言語モデルは高い画像認識能力を有しており、広告画像理解への応用に注目が集まっている。しかし、既存研究は広告画像単体を対象にしたものに限られている。そのため広告される対象である商材との関係を捉えた広告画像への視覚言語モデルの理解能力は明らかにすることで、自動生成された広告の推薦システム開発の支援に繋がる。そこで本研究では、モデルと人間との解釈の相関を測る評価用フレームワークを広告分野へ応用することでこの能力を明らかにする。実験結果より、視覚言語モデルは広告画像のランキング生成において関係性を十分に考慮できない場合が多かったが、一部のモデルで購買意欲を刺激するという観点を与えた場合に商材と広告画像の関係性を考慮し、ランキングに変化をもたらす可能性が示唆された。
Q7:ポスター3月12日（水） 13:00-14:30   Q会場(1F会議室101AB),Q7-18,北海道十勝地域における農業政策と営農活動の課題分析の試み,/proceedings/annual_meeting/2025/pdf_dir/Q7-18.pdf,"○坂口 遥哉, 木村 泰知 (小樽商大), 河野 洋一, 東 陽介 (帯畜大)",本研究では，北海道十勝管内の自治体を対象とし，現地調査に基づき特定された課題と議会会議録を対象とした農政政策に関する議論分析を組み合わせることによって，農業政策と営農活動に関する課題の体系的な分析を行う．
Q7:ポスター3月12日（水） 13:00-14:30   Q会場(1F会議室101AB),Q7-19,拡張現実を用いた歩行型音声対話エージェント,/proceedings/annual_meeting/2025/pdf_dir/Q7-19.pdf,"○前土佐 勇仁, 南 泰浩 (電通大)",本研究は，仮想エージェントと歩行しながら対話する音声対話システムを提案する．AR グラスなどの持ち運びのしやすい端末に実装し，仮想エージェントと自由に移動しながらの対話を目指す．対話文生成では仮想エージェントの発話内容，動作内容の順で生成する．対話中にユーザと仮想エージェントの歩行軌道を記録した結果，仮想エージェントがユーザと横並びで対話できる事が確認された．
Q7:ポスター3月12日（水） 13:00-14:30   Q会場(1F会議室101AB),Q7-20,農林業基準技術に含まれる表を対象としたPDF から CSV へ変換する際の課題分析,/proceedings/annual_meeting/2025/pdf_dir/Q7-20.pdf,"○杉山 陽菜乃, 阿部 瑞稀, 中村 彩乃, 前多 陸玖, 坂口 遥哉, 佐藤 栄作, 木村 泰知 (小樽商大), 小林 暁雄, 大友 将宏, 石原 潤一, 桂樹 哲雄, 川村 隆浩 (農研機構)",内閣府「研究開発とSociety 5.0 との橋渡しプログラム（BRIDGE）」の農林水産省課題「AI 農業社会実装プロジェクト」では，国内農業知識を学習させたLLM の開発を進めている．これを実現するには，国内に散在する農業に関するデータを収集し，機械可読な形式へ変換する必要がある．本研究では，多くの都道府県から公開されている農業基準技術に関する文書を対象とし，そこに含まれている，人手で作成された経営類型や技術体系や作業別労働時間などの表から適切な形式でのデータの抽出を目的とする．本稿では，その基礎的な分析として，PDF 形式の表をCSV 形式に変換する際に生じる課題を明らかにした．
Q7:ポスター3月12日（水） 13:00-14:30   Q会場(1F会議室101AB),Q7-21,新型コロナワクチンをめぐるTwitter上の話題変化：テキスト精読と頻出単語分析による仮説構築とその検証,/proceedings/annual_meeting/2025/pdf_dir/Q7-21.pdf,"○武富 有香, 須田 永遠 (NII), 中山 悠理 (東大), 宇野 毅明 (NII), 橋本 隆子 (千葉商科大), 豊田 正史, 吉永 直樹 (東大), 喜連川 優 (東大/ROIS), 小林 亮太 (東大)",新型コロナワクチン接種期間中の人々の考えや関心の変化を知るために，「ワクチン」を含む日本語の全ツイート(1.1 億件)を分析した．先行研究では大きな世論のダイナミクスを捉えることに成功したが，本研究ではツイートのより詳細な内容とその時間変化を明らかにすることを目的とした．まずLDA トピックモデルを用いて15 の主要トピックを特定し，トピックの内容を人手で意味解釈して4 つの主要なテーマに分類した．次に月毎の頻出単語分析と約
Q7:ポスター3月12日（水） 13:00-14:30   Q会場(1F会議室101AB),Q7-22,農林業基準技術文書を対象としたPDF解析ツールの表構造認識の性能評価,/proceedings/annual_meeting/2025/pdf_dir/Q7-22.pdf,"○中村 彩乃, 杉山 陽菜乃, 阿部 瑞稀, 前多 陸玖, 坂口 遥哉, 佐藤 栄作, 木村 泰知 (小樽商大)",本研究では，PDF 文書から表データを正確に抽出することを目的とし，主に農業分野で利用される技術文書を対象に主要企業の表抽出ツールを評価する．既存研究が指摘する固定レイアウト構造の課題を考慮し，複雑な表レイアウトや多言語への対応を踏まえて，表構造認識ベンチマークTOITA を用いて性能を比較することで，その有用性を明らかにする．
Q7:ポスター3月12日（水） 13:00-14:30   Q会場(1F会議室101AB),Q7-23J,クイズコンペティションの結果分析から見た日本語質問応答の到達点と課題,/proceedings/annual_meeting/2025/pdf_dir/Q7-23.pdf,"○有山 知希 (東北大), 鈴木 潤 (東北大/理研), 鈴木 正敏 (Studio Ousia), 田中 涼太 (NTT/東北大), 赤間 怜奈 (東北大/理研), 西田 京介 (NTT)",
Q7:ポスター3月12日（水） 13:00-14:30   Q会場(1F会議室101AB),Q7-24J,NAIST Simultaneous Interpretation Corpus: Development and Analyses of Data from Interpreters of Different Levels,/proceedings/annual_meeting/2025/pdf_dir/Q7-24.pdf,"○Kosuke Doi (NAIST), Katsuhito Sudoh (NAIST/奈良女子大), Satoshi Nakamura (NAIST/CUHK-Shenzhen)",
A8:NLPモデルの解釈可能性・分析(4)3月13日（木） 8:30-10:00   A会場(2Fコンベンションホール1+2),A8-1,似た単語の知識ニューロンは似た形成過程を経る,/proceedings/annual_meeting/2025/pdf_dir/A8-1.pdf,"○有山 知希 (東北大/理研), Benjamin Heinzerling (理研/東北大), 穀田 一真 (東北大/理研), 乾 健太郎 (MBZUAI/東北大/理研)",近年，言語モデルの高い性能を実現している仕組みを理解すべく様々な研究が行われているが，これらの研究の中には事前学習によって得られたモデルパラメータを“ニューロン” と見立て，入出力やタスク性能との関連を調べているものがある．本研究では，ニューロンとモデルの学習過程との関係に焦点を当て，ある単語に反応するニューロンが学習中にどのように形成されるのかを，その単語が持つ意味の側面と合わせて分析した．その結果，ある単語のニューロンの形成過程は，その単語と意味的に同類関係にある単語のニューロンの形成過程と類似する傾向が観察された．また，同類関係にある単語間では形成後のニューロンも共通する傾向が見られた．
A8:NLPモデルの解釈可能性・分析(4)3月13日（木） 8:30-10:00   A会場(2Fコンベンションホール1+2),A8-2,多角的な評価から大規模言語モデルにおける事実知識の想起の要因分析,/proceedings/annual_meeting/2025/pdf_dir/A8-2.pdf,"○趙 信, 吉永 直樹, 大葉 大輔 (東大)",大規模言語モデル(LLM) は膨大なテキストから学習され，実世界の知識を内包する一方で，幻覚など知識の運用に問題があることが知られている．そのため，LLM の知識評価を行うことが重要である．本研究では，多様なプロンプトを持つデータセットMyriadLAMA を構築し，それを用いた知識評価フレームワークBELIEF を提案する．In-contextlearning (ICL) を用いて，LLM が有する知識を精度，一貫性，信頼性の観点から多角的な評価を可能にする．実験では，パラメタ数，事前学習コーパス，指示学習の有無などが異なる複数のLLM を対象に知識評価を行い，LLM における事実知識の想起において重要な要素を明らかにする．
A8:NLPモデルの解釈可能性・分析(4)3月13日（木） 8:30-10:00   A会場(2Fコンベンションホール1+2),A8-3,心理測定テストに関するLLMのメタ知識の検証,/proceedings/annual_meeting/2025/pdf_dir/A8-3.pdf,"○山本 有起 (京大), Arjav Singh (IITM), Yin Jou Huang, Chenhui Chu, 村脇 有吾 (京大)",大規模言語モデル(LLM) に対する心理測定テストにおいて、LLM に内在するメタ知識が測定結果に与える影響を検証するため、ビッグファイブ理論に基づくIPIP-NEO に関するケーススタディを行う。本論文では、LLM に対するIPIP-NEO テストの実施、LLM の訓練時におけるIPIP-NEO データセットの混入の検証、LLM のIPIP-NEO に関するメタ知識の理解度の検証を行う。検証した3 種のモデルに関して、性格の指示に対する敏感さが明らかになり、データセットの混入も確認された。また、3 種のモデルのメタ知識への理解度の傾向が確認された。
A8:NLPモデルの解釈可能性・分析(4)3月13日（木） 8:30-10:00   A会場(2Fコンベンションホール1+2),A8-4,日本向けにファインチューニングされた中国系大規模言語モデルに北京の検閲は残るか？,/proceedings/annual_meeting/2025/pdf_dir/A8-4.pdf,"○伊藤 亜聖 (東大), 高口 康太 (フリー)",先行研究によれば中国系大規模言語モデル(LLM)には政治的に敏感な問題に回答しないように検閲的なファインチューニングが施されている。本稿は中国系LLM をベースに日本市場向けにファインチューニングされたLLM を対象に、簡体字中国語の敏感質問への反応を検証した。合計4 モデルを評価した結果、敏感質問への回答回避比率はベースとなった中国系LLM よりも大幅に低く、ファインチューニングにより検閲的特徴がかなりの程度解消されていることが分かった。ただし一部には回答回避や検閲の形跡が残っていた。日本語での利用では影響は軽微だと考えられるが、それでも元モデルへの介入を十分に認識したうえで取り扱う必要がある。
A8:NLPモデルの解釈可能性・分析(4)3月13日（木） 8:30-10:00   A会場(2Fコンベンションホール1+2),A8-5,大規模言語モデルは日本語・中国語の状態パーフェクトを理解できるか?,/proceedings/annual_meeting/2025/pdf_dir/A8-5.pdf,"○盧 捷, 金 杜, 柴田 行輝, 土井 智暉, 染谷 大河, 谷中 瞳 (東大)",近年，大規模言語モデル(Large Language Model，LLM) は様々な言語理解タスクで高精度を達成しつつある．しかし，LLM が文中に現れる事象間の時間関係をどの程度理解できているのかについては，十分に研究が進められていない. 本研究では，「パーフェクト相」の一種である「状態パーフェクト」に注目して自然言語推論（Natural Language Inference，NLI）データセットを構築し，LLM の日本語・中国語の状態パーフェクトが表す複数の時点の関係性を正確に把握しているかについて分析を行った. 実験の結果，日本語・中国語の状態パーフェクトの表す意味について，LLM の判断は一貫しておらず，人間の判断と一致していない傾向を明らかにした.
A8:NLPモデルの解釈可能性・分析(4)3月13日（木） 8:30-10:00   A会場(2Fコンベンションホール1+2),A8-6,従属節が分断された不可能言語を言語モデルは学習するのか,/proceedings/annual_meeting/2025/pdf_dir/A8-6.pdf,"○指田 昌樹, 鈴木 彩音, 安田 卓矢, 染谷 大河, 谷中 瞳 (東大)",言語モデルの言語獲得能力は人間とどのように異なるかという問いに対して，人間にとって不自然な言語（不可能言語）を人工的に生成し，言語モデルの学習のしやすさを分析した研究がある．先行研究では，GPT-2 モデルにおいて不可能言語は可能言語よりも学習しにくいという結果が報告されているが，言語に共通する性質は単一ではなく，不可能言語についても様々な種類が存在するため，言語モデルがどのような不可能言語においても学習が難しいのかという問題については，依然として多くの疑問が残されている．本研究では，「最下層の従属節は他の節によって分断されない」という言語に共通する性質に着目し，従属節の間に主節の一部を混ぜた不可能言語を作成した．作成した不可能言語を用いてGPT-2 モデルを学習し，可能言語と同様に不可能言語を学習できるかどうか分析を行った．GPT-2 モデルにおいて可能言語と比較して不可能言語の学習は困難であるという結果となり，先行研究と同様の傾向を示した．
B8:言語資源構築3月13日（木） 8:30-10:00   B会場(1F会議室102),B8-1,認知症高齢者の発話意図推定に基づく注意発話検出システムの開発 ―帰宅願望や不安などを特定するコーパス構築―,/proceedings/annual_meeting/2025/pdf_dir/B8-1.pdf,"○有國 開成 (追大), 神崎 享子 (県女), 井佐原 均 (追大)",本研究では、認知症高齢者の「帰宅願望」や「不安」といった注意すべき発話を特定するシステムの構築を目的とした。介護施設で収集した対話データを基に、実データの収集が困難な環境下でも活用可能なデータ拡張手法を活用し、日本語BERT を基盤とした発話意図推定モデルを構築した。特に、ChatGPT(GPT-4o)を用いた疑似データ生成により、少数データクラスのデータ不足を補完し、分類精度の向上を実現した。 評価の結果、疑似データ生成がデータ不足を補う有効な手法である一方、施設特有の文脈や固有表現への完全な対応には最低限の実データが不可欠であることが判明した。本研究は、疑似データ生成を活用したコーパス構築の有効性を示すとともに、施設ごとに適応可能なモデル設計の方向性を示す一助となるものである。
B8:言語資源構築3月13日（木） 8:30-10:00   B会場(1F会議室102),B8-2,多様な客観的解釈を反映した主体性コーパス構築と予備的分析,/proceedings/annual_meeting/2025/pdf_dir/B8-2.pdf,"○林 純子, 伊藤 和浩, 永井 宥之 (NAIST), 矢田 竣太郎 (NAIST/筑波大), 若宮 翔子, 荒牧 英治 (NAIST)",主体性とは「行為を引き起こしているのは自分だ」という行為主体としての自己の感覚を指す．主体性はwell-being やうつ病などと密接に関連しており，文章を通じて主体性をモニタリングすることは非常に重要である．しかし，ある行為の記述に対してどの程度の主体性を認めるかという判定は人によって異なる．本研究ではアノテーションのばらつきを考慮したコーパスを構築し，主体性の多寡を推定するタスクと解釈のばらつきを推定するタスクを実施し予備的分析を行なった．前者のタスクでは高い精度を示したものの，後者のタスクでは課題が残った．主体性という心理学的概念に対して自然言語処理によるアプローチの可能性が示唆された．
B8:言語資源構築3月13日（木） 8:30-10:00   B会場(1F会議室102),B8-3,日本語文平易化のための疑似パラレルコーパス構築,/proceedings/annual_meeting/2025/pdf_dir/B8-3.pdf,"○澤柳 翔太 (名大), 小川 泰弘 (名市大), 外山 勝彦 (名大)","本研究では, 単言語コーパスをもとに日本語文平易化コーパスを疑似的に構築する手法を提案する.日本語文平易化タスクにおいては, 大規模なコーパスの不足が課題である. 本研究では, 単言語コーパスから類似度が高く, かつ難易度が異なる2 文を抽出することにより, 約6 万ペアを含む疑似日本語文平易化コーパスを構築した. また, 構築したコーパスを用いて平易化モデルを構築することにより, コーパスの品質を評価した. その結果, 提案手法の有効性を明らかにした."
B8:言語資源構築3月13日（木） 8:30-10:00   B会場(1F会議室102),B8-4,AdParaphrase: 魅力的な広告表現の分析を目的とした広告文言い換えデータセット,/proceedings/annual_meeting/2025/pdf_dir/B8-4.pdf,"○村上 聡一朗, 張 培楠 (サイバーエージェント), 上垣外 英剛 (NAIST/科学大), 高村 大也, 奥村 学 (科学大)",広告の成功には人々を惹きつける効果的な言葉選びが欠かせない．本研究は広告文の言語表現に焦点を当て，どのような言語的特徴を持つ広告文が好まれるか明らかにすることを目的とし，選好評価データ付きの広告文言い換えデータセットAdParaphraseを提案する．AdParaphrase は広告文の言い換えペアから構成され，選好評価データを含む．これにより人々が魅力的に感じる広告表現の分析が可能となる．実験では広告文の言語的特徴量と選好評価データの関係を分析し，魅力的な広告文の特徴を明らかにした．またこれらの知見や提案データセットを活用し，魅力的な広告文を生成する手法を探求した．
B8:言語資源構築3月13日（木） 8:30-10:00   B会場(1F会議室102),B8-5,プロンプトと複数の音声認識候補による青空文庫振り仮名注釈付き音声コーパスの再構築,/proceedings/annual_meeting/2025/pdf_dir/B8-5.pdf,"○佐藤 文一 (NDL), 吉永 直樹, 豊田 正史 (東大), 喜連川 優 (ROI/東大)",著者らは漢字の読み推定の学習・評価用コーパスとして「青空文庫振り仮名注釈付き音声コーパス」を構築し，2024 年1 月に国立国会図書館NDL ラボから公開している．音声コーパスの構築においては音声と元テキストとの間の対応付けの成功率が最終的なコーパスのサイズに影響を及ぼす．本研究では対応付けの成功率を高めるため，OpenAI のWhisperにおいて，専門用語等の未知語の音声認識を高める目的で使用されるプロンプトを追加し，認識精度の改善を図ることで，コーパスの拡張を試みた．結果として7604 万文字，4617 時間の振り仮名注釈付き音声コーパスの構築に成功した．本コーパスは近日の公開を予定している．
B8:言語資源構築3月13日（木） 8:30-10:00   B会場(1F会議室102),B8-6,Sketch2Diagram: 視覚的指示を入力とするダイアグラム生成,/proceedings/annual_meeting/2025/pdf_dir/B8-6.pdf,"○斉藤 いつみ (東北大/理研), 吉田 遥音 (東北大), 坂口 慶祐 (東北大/理研)",スケッチ画像を理解してベクター形式のダイアグラムを生成するためのベンチマークデータセットSkeTikZ を提案する1）．SkeTikZ は，人手で作成したスケッチ画像とTikZ 形式のダイアグラムがペアになった初めてのデータセットである．さらに，画像を理解してTikZ 形式のダイアグラムを生成可能なマルチモーダルモデルImgTikZ を提案する．ImgTikZ は，コード生成に特化した大規模言語モデルと画像エンコーダを活用したモデルであり，実験によって7B 規模のモデルサイズながらGPT-4o に匹敵するダイアグラム生成能力を有することを確認した．また，スケッチ作成のツールによって画像認識の難易度が大きく変わることを確認した．
C8:NLPのための効率的/低リソース手法3月13日（木） 8:30-10:00   C会場(1F会議室103),C8-1,リザバー計算に触発された軽量型Transformer の提案：パラメタ共有を用いた計算の効率化と性能評価,/proceedings/annual_meeting/2025/pdf_dir/C8-1.pdf,"○中村 仁 (阪大), 加藤 万理子 (JAIST), 黒岩 蒼太郎 (未来大), 崎野 也真人 (日産), 田中 剛平 (名工大), 山下 洋史, 鈴木 秀幸, 白坂 将 (阪大)",近年，Transformer は多様なNLP タスクで卓越した性能を示す一方，大規模化による計算資源コストの増大が深刻な課題となっている．本研究では，リザバー計算の仕組みに着想し，Transformer のEncoderをなすEncoder ブロックの大部分を固定層（リザバー層），残余ブロックを学習層とすると同時に，固定層・学習層それぞれにおける層間完全パラメタ共有を組み合わせた軽量アーキテクチャを提案する．提案手法により，学習パラメタと更新コストを大幅に削減した．独英翻訳タスクでは，15%超のパラメタ削減にもかかわらずBLEU スコアを約28 に維持し，学習収束レートをを考慮した性能指標においても従来手法を上回る性能を示した．さらに，本アーキテクチャは離散力学系として解釈でき，高次元非線形変換の再帰的適用によって翻訳に有効な特徴が獲得される可能性を示唆する．本成果は，NLP と非線形ダイナミクスの結節点として新たな視点を提供するものであり，言語モデルにおける情報表現の理解や省メモリ設計に寄与することが期待される．
C8:NLPのための効率的/低リソース手法3月13日（木） 8:30-10:00   C会場(1F会議室103),C8-2,生成文の短縮による言語モデルの計算量削減,/proceedings/annual_meeting/2025/pdf_dir/C8-2.pdf,"○海野 圭矢, 内田 真人 (早大)",言語モデルの計算量削減を目的とした従来の手法は，1 トークンあたりの計算コストを削減することに焦点を当ててきた．本研究では，文章生成にかかるコストが生成トークン数にも影響されることに注目し，言語モデルの生成文を短縮することで計算量を削減する方法を検討する．これを実現する学習方法として，文章全体に長さに応じた報酬を与える強化学習と短い文章を誘発するトークンを正解データとする教師あり学習の2 つを検証する．さらに，生成文の短縮率と性能の関係を調査することで，生成文の短縮が言語モデルの性能にどのように影響するかを示す．Phi-3-mini，Zamba2-2.7B における実験の結果，強化学習と教師あり学習の両手法において生成文の短縮に成功した．また，5%以下の性能低下のもとでは，Phi-3-mini は約15%～20%，Zamba2-2.7Bは約30%の短縮が可能であることが示された．
C8:NLPのための効率的/低リソース手法3月13日（木） 8:30-10:00   C会場(1F会議室103),C8-3,合成データと能動学習を用いた大規模言語モデルへの効率的な知識定着,/proceedings/annual_meeting/2025/pdf_dir/C8-3.pdf,"○角谷 あおい (エル・ティー・エス), 河越 淳 (日立システムズ)","近年，大規模言語モデル（LLM）は膨大なWebデータを活用することで性能を大幅に向上させている．しかし，実務適用においては，ドメイン固有の知識をモデル内部へ定着させる必要があり，これに対して多様な手法が提案されてきた．また，単一の事実をモデルに確実に学習させるためには，多角的な文脈や表現を100～1,000 回程度提示する必要があることが報告されているが，そのようなドメインデータを十分に収集・整理するには多大なコストや制約が伴う．本研究では，LLM に対する新たな知識定着を実現する継続事前学習に対して，複数の合成データ生成手法を適用し，効率的な知識獲得方法を検証した．さらに，能動学習を用いたデータセット削減手法を組み合わせることで，知識定着をより効率化する方法を検討した．実験の結果，事実ベースの合成データ生成手法によって多様な合成データを準備することで，単純な言い換え手法と比較して学習回数を69 ％削減しつつ，モデル内部への知識定着が可能であることが明らかとなった．一方で，能動学習手法による学習効率化は，合成データを用いる環境下では期待した性能改善を示さなかった．"
C8:NLPのための効率的/低リソース手法3月13日（木） 8:30-10:00   C会場(1F会議室103),C8-4,モデル拡張を用いた段階的事前学習によるモデル系列の効率的な構築,/proceedings/annual_meeting/2025/pdf_dir/C8-4.pdf,"○矢野 一樹 (東北大), 高瀬 翔 (東北大/SB Intuitions), 小林 颯介 (東北大), 清野 舜 (SB Intuitions), 鈴木 潤 (東北大)",大規模言語モデルの実応用では，7B，13B，70Bといったパラメータ数の異なる複数のモデル（モデル系列）を提供することが一般的である．モデル系列の構築は，素朴には各サイズのモデルを個別に構築する必要があり，計算コストは加算的に増加する．本研究では，小さなモデルから段階的に学習を進め，サイズを拡張させながら，モデル系列を構築する手法を提案する．実験では，提案手法が計算コストを削減しつつ，個別にモデル系列を学習する場合と比較して同等以上の性能を達成できることを示す．
C8:NLPのための効率的/低リソース手法3月13日（木） 8:30-10:00   C会場(1F会議室103),C8-5,Gated Recurrent Unitの簡略化と学習型Bloom Filterへの影響,/proceedings/annual_meeting/2025/pdf_dir/C8-5.pdf,"○大西 雄真, 西田 拳 (北大), 林 克彦 (東大), 上垣外 英剛 (NAIST)",機械学習とBloom Filter (BF) を組み合わせることで，BF のメモリ使用量や計算効率を向上させるLearned Bloom Filter (LBF) が注目を集めている．BFとしての特性上，LBF で採用する機械学習モデルは軽量かつ計算効率に優れていることが求められるが，系列データに対するLBF において，どのような機械学習モデルを採用すれば良いかはまだ十分に議論されていない．本研究では，系列データに対するLBF の機械学習モデルとして，Gated RecurrentUnit (GRU) を考える．また，その構造の簡略化も検討し，それがLBF の性能に与える影響を調査する．
C8:NLPのための効率的/低リソース手法3月13日（木） 8:30-10:00   C会場(1F会議室103),C8-6,MCMCを用いた前提検索によるLLMの仮説推論能力の強化,/proceedings/annual_meeting/2025/pdf_dir/C8-6.pdf,"○Wang Yuanyi, 小林 一郎 (お茶大)",本稿では，大規模言語モデル（LLMs）の推論能力，特に仮説推論能力を向上させるため，モンテカルロ・マルコフ連鎖（MCMC）を活用した新しいアルゴリズムパイプラインをを提案する．観察を最も適切に説明する仮説と，それを支持する関連前提を効率的かつ計算コストを抑えて探索するため，完全教師なしのMCMC アルゴリズムを導入した．本手法は，関連性の高い前提の順序を優先することで，LLMs における正当な仮説を効果的に構築し，生成文の精度と前提知識の再現率の向上を確認し，仮説推論能力を向上させることを実証している．
D8:対話(1)3月13日（木） 8:30-10:00   D会場(1F会議室107),D8-1,話者特性に基づくターンテイキング速度の分析,/proceedings/annual_meeting/2025/pdf_dir/D8-1.pdf,"○大西 一誉, 大中 緋慧 (NAIST/理研), 吉野 幸一郎 (NAIST/理研/科学大)",本研究では，対話時のターンテイキングにおけるターン速度の違いとその要因を明らかにするため，話者の役割，関係性，性格特性に着目し分析を行った．その結果，ターン速度は話者の役割や関係性，個人特性に大きく依存することが確認された．初学者と専門家間の対話では，初学者が発話の準備に時間を要するためターン速度が遅くなる傾向が確認された．また，友人同士の会話では沈黙が許容されやすく，初対面に比べてターン速度が遅い結果が得られた．さらに，BIG5 の性格特性において，開放性，協調性，勤勉性および神経症傾向がターン速度に影響を与えることが明らかになった．
D8:対話(1)3月13日（木） 8:30-10:00   D会場(1F会議室107),D8-2,性格特性による感情誘導の効果検証,/proceedings/annual_meeting/2025/pdf_dir/D8-2.pdf,"○船迫 龍之介, 當間 愛晃 (琉大)",ユーザーをポジティブな感情に誘導する対話システムのパーソナライズを目指し，性格特性による感情誘導効果の違いを検証した．ビッグファイブの性格特性ごとに高低特性を持つ10 種の擬似ユーザーエージェントを構築し，感情誘導実験を行なった結果，外向性，開放性，誠実性，調和性が高い場合，または神経症傾向が低い場合に，ポジティブな感情誘導効果が高まる可能性が示唆された．本研究は，性格特性を考慮した感情誘導対話システムの設計に向けた基礎的知見を提供する．
D8:対話(1)3月13日（木） 8:30-10:00   D会場(1F会議室107),D8-3,実インタラクション映像から構築したマルチモーダルモデルを用いた人とロボットのインタラクションにおける異常検出,/proceedings/annual_meeting/2025/pdf_dir/D8-3.pdf,"○望月 翔太, 山下 紗苗 (名大), 星牟禮 健也, 馬場 惇 (サイバーエージェント), 窪田 智徳, 小川 浩平, 東中 竜一郎 (名大)",本研究では，人とロボットのインタラクションにおいて生じる異常を自動で検出するモデルを構築することを目的とし，データセットの作成および異常検出モデルの構築を行った．具体的には，人とロボットのインタラクションに問題が生じた際に人間が介入する複数人同時対話の枠組みにおいて収集されたインタラクション映像に対して，正常か異常かを人手でアノテーションすることでデータセットを作成した．そして，作成したデータセットを用いて分類モデルを学習することで異常検出モデルを構築した．さらに，複数人同時対話の枠組みを検証する実証実験を実施し，モデルの検出結果をアラートとして提示することがオペレータの介入に有用であることを確認した．
D8:対話(1)3月13日（木） 8:30-10:00   D会場(1F会議室107),D8-4,大規模言語モデルを用いた対話品質評価に関する調査,/proceedings/annual_meeting/2025/pdf_dir/D8-4.pdf,"○赤間 怜奈, 鈴木 潤 (東北大/理研)",高度な言語理解能力に加えて人間的な感性をも備えつつある高性能大規模言語モデルを、人手評価の代替手段として活用することに関する議論が近年広がりを見せている。しかし、大規模言語モデルによる人手評価の代替については、いまだ現行技術の限界や致命的な課題など未解明の側面も多く、言語やタスク横断的に広く知見を収集することが重要な段階にある。本研究は、日本語を対象として、対話データの品質評価における大規模言語モデルの活用について経験的な知見を提供するものである。評価軸や回答形式が異なる複数の評価設定において、モデルの評価性能や動作傾向がどのように変動するかを定性的および定量的に調査し、結果を報告する。
D8:対話(1)3月13日（木） 8:30-10:00   D会場(1F会議室107),D8-5,回答単位を小説登場人物とする大規模言語モデルベース発話者分類,/proceedings/annual_meeting/2025/pdf_dir/D8-5.pdf,"○古俣 槙山, 長谷川 遼 (筑波大), 銭本 友樹 (名大), 宇津呂 武仁 (筑波大)",小説中の発話文の発話者がどの登場人物かを分類する発話者分類タスクは，小説や登場人物の分析において重要なタスクである．英語・中国語小説を対象とした発話者分類では深層学習モデルを用いた手法の有効性が確認されているが，日本語小説に対する先行研究では主に規則を用いた手法が検討されている．そこで本論文では，日本語小説を対象とした発話者分類タスクに大規模言語モデル(GPT-4o，Gemini，Claude) を適用した際の性能評価を行う．評価用データとして，複数のウェブ小説に発話者情報をアノテーションしたデータを用いる．本論文では，大規模言語モデルを用いて「小説登場人物名リスト作成」・「発話文への発話者対応付け」という二段階の処理を行い，小説登場人物を回答単位とした発話者の推論を行う．この結果，どの大規模言語モデルにおいても正答率が85%を超え，日本語小説を対象とした発話者分類における大規模言語モデルの利用が効果的であることを示した．
D8:対話(1)3月13日（木） 8:30-10:00   D会場(1F会議室107),D8-6,日本語Full-duplex音声対話システムの試作,/proceedings/annual_meeting/2025/pdf_dir/D8-6.pdf,"○大橋 厚元, 飯塚 慎也, 姜 菁菁, 東中 竜一郎 (名大)",人間同士の対話における発話のオーバーラップや相槌など，同時双方向的な特徴をモデル化できるfull-duplex 音声対話システムは，近年注目を集めている．しかし日本語においては，full-duplex 音声対話システムはほとんど見られず，full-duplex 音声対話システムの開発に関する知見は不足している．本研究では，英語における主要なfull-duplex 音声対話システムであるMoshi をベースとすることで，日本語で利用可能な最初のfull-duplex 音声対話システムを試作し，公開する．1）
E8:テーマセッション3: 認知・脳と自然言語処理(1)3月13日（木） 8:30-10:00   E会場(1F会議室108),E8-1,混合物の強さの度合,/proceedings/annual_meeting/2025/pdf_dir/E8-1.pdf,○高橋 速巳 (カシェウェブレト),小説を読んでいる途中で「何かについての印象が強化される」と言うことは適切だろうか. その何かというものが出来事等の混合物であり単純に一語で表されてはいないというときにはどうだろうか.小説においては、「強化」というものは単独では終わらずに、さらにその「強化」されたものの影響を受け得る別の項に働きかけ、その項において変形や価値的な反転が生じる.本稿では「出来事の混合物についての心象の強度」が関わる先行研究を取り上げる. ドゥルーズ「差異と反復」(1968) において「強度」「巻き込み」という概念、ドゥルーズとガタリ（以下DG とする）の共著「ミル・プラトー」(1980) において「表現の形式と内容の形式の相互性、交錯性」を概観する.また実験科学の知見に少し触れる.
E8:テーマセッション3: 認知・脳と自然言語処理(1)3月13日（木） 8:30-10:00   E会場(1F会議室108),E8-2,大規模言語モデルは他者の心をシミュレートしているか,/proceedings/annual_meeting/2025/pdf_dir/E8-2.pdf,"○青木 洸士郎, 河原 大輔 (早大)",心の理論は，他者の心的状態を推測する能力であり，人間の社会的相互作用において重要な役割を果たす．近年，大規模言語モデル（LLM）が人間と同等の心の理論の能力を示すことが報告されているが，そのメカニズムはまだ十分に解明されていない．本研究では，LLM の内部表現を解析することで，心の理論のメカニズムに関する理論的枠組の一つであるシミュレーション説のLLM における妥当性を検証する．実験の結果，LLM におけるシミュレーション説に対して肯定的な証拠は得られなかったが，解釈可能性の研究で広く用いられる介入の限界を明らかにし，LLM における心の理論のメカニズムに関する今後の研究の方向性を提供する．
E8:テーマセッション3: 認知・脳と自然言語処理(1)3月13日（木） 8:30-10:00   E会場(1F会議室108),E8-3,大規模視覚言語モデルは錯視を理解しているか,/proceedings/annual_meeting/2025/pdf_dir/E8-3.pdf,"○篠崎 大河 (慶應大/東大), 土井 智暉 (東大), 綿引 周 (NICT/阪大/北大), 西田 知史, 谷中 瞳 (東大)",錯視画像とは，その実際の特徴と見かけの特徴が異なるような画像のことである．大規模視覚言語モデル(Large Vision-Language Model: LVLM) に関して，その錯視画像の認識能力を評価する研究が近年行われている．先行研究においては，実験の結果により，LVLM は錯視に騙されやすい，あるいは人間と同様の騙され方をすると考えられている．しかし，先行研究は錯視に関する重要な区別を見落としているため，その実験結果に曖昧さを残している．本研究では，可能な限り曖昧さを排した手法を提案し，それを用いてLVLM の錯視認識能力を評価する．実験の結果，LVLM は一見して錯視を理解しているように思われるものの，実際には錯視に関する一般的な知識から回答しており，錯視を視覚的に正しく認識しているわけではないことが示唆される．
E8:テーマセッション3: 認知・脳と自然言語処理(1)3月13日（木） 8:30-10:00   E会場(1F会議室108),E8-4,大規模言語モデルを用いた言語刺激下の脳内意味表象解読,/proceedings/annual_meeting/2025/pdf_dir/E8-4.pdf,"○佐藤 杏奈, 小林 一郎 (お茶大)",脳情報解読技術は，神経活動を解釈して思考や感情を再現する手法として注目されている．Tang ら(2023) [1] は，fMRI データを使用した，言語モデルを生成モデルとして活用する新たな解読手法を提案した．本研究はその拡張として，先行研究で用いられたGPT モデルに加え3 種類の言語モデルを導入し，精度比較を行った．結果として，高い解読精度には，使用する言語モデルが脳活動の予測に優れていることだけでなく，言語モデルが生成するテキストの種類も重要である可能性を明らかにした．
E8:テーマセッション3: 認知・脳と自然言語処理(1)3月13日（木） 8:30-10:00   E会場(1F会議室108),E8-5,Improving Zero-Shot Machine Translation with Fixed Prefix Pair Bootstrapping,/proceedings/annual_meeting/2025/pdf_dir/E8-5.pdf,"○◊Van-Hien Tran, Raj Dabre, Hour Kaing, 田中 英輝, 内山 将夫 (NICT)","Zero-shot in-context learning allows large languagemodels (LLMs) to perform tasks using only instructions,yet calibration issues often limit their performance in zero-shot machine translation (MT). These issues result in prob-lems like hallucinations and oﬀ-target translations, reduc-ing output quality. This paper introduces ﬁxed preﬁx pairbootstrapping, a method that enhances zero-shot MT byinitializing translations with a correct bilingual preﬁx pair,guiding the model to produce accurate target-language out-puts from the start. Evaluation across four model architec-tures and translation directions shows consistent, substan-tial improvements, highlighting this simple yet eﬀectiveapproach for advancing zero-shot MT performance."
E8:テーマセッション3: 認知・脳と自然言語処理(1)3月13日（木） 8:30-10:00   E会場(1F会議室108),E8-6,記述文選択タスクによる大規模視覚言語モデルのアモーダル補完能力の評価,/proceedings/annual_meeting/2025/pdf_dir/E8-6.pdf,"○綿引 周, 土井 智暉 (東大), 篠崎 大河 (慶應大), 西田 知史 (NICT/阪大/北大), 新川 拓哉 (神戸大), 宮原 克典 (北大), 谷中 瞳 (東大)","本研究ではアモーダル補完(amodal completion:AC) と呼ばれる現象に着目して大規模視覚言語モデル(Large vision language model; LVLM) の視覚的認識能力を評価した. ベンチマークの構築に上位オントロジーの一つであるBasic Formal Ontology(BFO) を利用することでより体系的な評価を試みた. 実験の結果, 特に規模の大きなLVLM は全般的に人間に近いAC 能力をもつものの，人間と比較して，その能力には補完される対象の種類によってばらつきがあることが確認された．またLLaVA-NeXT モデルの一部については，基盤言語モデルのパラメータ数が大きくなっているにも関わらず正答率の低下が見られた. この結果は知覚動詞を適切に理解するという課題は基盤言語モデルのパラメータサイズを単純に増やすだけでは克服できない可能性を示している."
P8:ポスター3月13日（木） 8:30-10:00   P会場(2Fコンベンションホール3+4),P8-1,検索付き拡張生成におけるハイパーパラメータとプロンプトの同時最適化,/proceedings/annual_meeting/2025/pdf_dir/P8-1.pdf,"○鈴木 海渡, 水野 尚人, 柳瀬 利彦, 佐藤 元紀 (PFN)",Retrieval-augmented generation（RAG）は，コーパスからの情報検索を活用することにより，大規模言語モデル（LLM）の性能を大幅に向上させる．RAG の性能は，RAG パイプラインにおけるハイパーパラメータと，LLM に与えるプロンプトに大きく依存する．本研究で提案するUniOptRAG フレームワークでは，単変量最適化アルゴリズムを組み合わせることで，ハイパーパラメータとプロンプトを同時に最適化する．この同時最適化によっていずれか一方のみを最適化する場合の性能を上回り，既存研究でファインチューニングや高度な推論パイプラインを用いた場合と同等の性能を達成することを示す．
P8:ポスター3月13日（木） 8:30-10:00   P会場(2Fコンベンションホール3+4),P8-2,事業セグメントに着目した有価証券報告書からの文脈抽出とキーワード生成による類似企業検索,/proceedings/annual_meeting/2025/pdf_dir/P8-2.pdf,"○國吉 房貴, 井本 稔也 (JDD)",事業セグメントに着目した類似企業の特定は，ポートフォリオの構築や，資産価格や債券金利の適切な設定など金融機関の主要業務に関わる重要な課題とされている．類似企業の特定は，各社の事業セグメントに基づき異なる粒度で各企業に独自のカテゴリーを割り当てた業種分類に基づいて行われる．しかし，複数の業種にまたがる事業をもつ企業の場合，ひとつの企業に複数の業種を割り当てることができないため，類似企業を適切に特定することが困難である．そこで本研究では，有価証券報告書で報告された事業セグメントの記述よりキーワードを抽出し，その周辺のコンテキストを含めてベクトル化することで，多様な意味や潜在的な文脈を抽出する手法と，大規模言語モデルの内部知識に基づき企業の一般的な業種イメージをキーワードとして表現する手法を組み合わせるハイブリッド検索手法を提案した．これにより，従来の業種分類では困難だった，事業セグメントを考慮した類似企業検索を実現した．評価実験により，業種抽出性能と株式投資のリターン相関の評価において，提案モデルがベースラインモデルを上回る性能を示した．
P8:ポスター3月13日（木） 8:30-10:00   P会場(2Fコンベンションホール3+4),P8-3,事故事例文書絞り込み検索システムの構築,/proceedings/annual_meeting/2025/pdf_dir/P8-3.pdf,"○福岡 康大, 大八木 悠聖, 喜多 俊介, 深草 理貴, 森 辰則 (横国大), 伊藤 拓海, 小野寺 理恵 (IHI)",本研究では、事故・不具合問い合わせの解析・類似事例の検索・回答文の生成といった作業を自動で行うシステムの実現を目指しており、本稿では、現場からの問い合わせに対し、企業に蓄積されている文書から目的の類似事例を得るための絞り込み手法を提案する。製造業の企業における現場からの問い合わせは抽象的であるため、問い合わせ意図を検索結果に反映することが難しく、1 度の問い合わせで目的の類似事例文書を得ることは難しい。そのため、本稿では、現場利用者の情報要求に応じた類似事例文書を得るために、事故事例文書の絞り込みを行うシステムを構築することを目的とし、問い合わせ文からの問い合わせ意図推定、システムが能動的に行う質問に対してユーザが回答文を入力するやり取りの中でのスロットフィリング、スロットフィリングで得られた情報をもとにリランキングを行い絞り込みを行う手法を提案する。また、提案手法の有効性を検証するために、提案手法を扱うシステムを作成し評価実験を行った。抽象的な問い合わせ文を入力とし、提示する質問に回答していくことで、正解文書が初期の検索結果でのランクよりも上位にリランキングされることを確認した。
P8:ポスター3月13日（木） 8:30-10:00   P会場(2Fコンベンションホール3+4),P8-4,Wikipedia記事の内容と閲覧時間帯の関係の統計的分析,/proceedings/annual_meeting/2025/pdf_dir/P8-4.pdf,"○吉井 健敏 (D2C), 持橋 大地 (統数研)",インターネット上には様々なコンテンツが溢れていて、ユーザはライフサイクルに沿ってそれらを利用する。メディアは閲覧数に応じた収益を獲得するため、コンテンツとユーザの時間特性を把握し閲覧数を増大させることは重要なビジネステーマである。本研究ではWikipedia の記事内容と閲覧ログを用いて、内容とユーザの興味の時間特性を明らかにする手法を提案する。最初に内容が類似するWikipedia 記事は閲覧される時間帯が類似することを示す。次に独立成分分析を利用して異なるユーザグループの時間特性を抽出し、それらが直感的なライフサイクルと一致することを確認する。これまでの議論から記事内容と閲覧傾向に密接な関係があることが期待できるため、最後にニューラルネットを使って記事内容から閲覧傾向を直接予測できることを示す。本研究はWikipedia の記事について注目しているがシンプルな手法ゆえ、閲覧ログが取得可能なあらゆるコンテンツで適応可能である。
P8:ポスター3月13日（木） 8:30-10:00   P会場(2Fコンベンションホール3+4),P8-5,表記ゆれが文埋め込みモデルに及ぼす影響についての考察,/proceedings/annual_meeting/2025/pdf_dir/P8-5.pdf,"○佐々木 峻, 山本 大輝 (アクロクエストテクノロジー)",近年のRAG (Retrieval-Augmented Generation) や検索システムでは，文埋め込みを用いた検索手法が注目されている．従来はキーワード一致に基づくTF-IDF ベースの検索が主流であったが，大規模事前学習モデルの発達に伴い，文埋め込みを用いた検索が盛んに使用されるようになった．しかしながら，文埋め込みがキーワードベースの検索に対して，どのような利点や欠点を持つかはまだ十分に明らかになっていない．特に日本語検索においては，多様な表記ゆれが検索精度に影響を与える一因となる．そこで本研究では，単語レベルの表記ゆれをクエリに与えた際，どのように文埋め込みベースの検索精度が変化するのかを検証する．実験では，JMTEB ベンチマークのうちJAQKET およびJaGovFaqs-22k を用いて，同義語辞書によるクエリ変換を実施し、変換前後のクエリを使用した場合の検索精度への影響を分析した．さらに，文埋め込みに同義語を拡張したクエリ手法も提案し，その有効性を検証する．
P8:ポスター3月13日（木） 8:30-10:00   P会場(2Fコンベンションホール3+4),P8-6,IterKey: LLMを用いた反復的キーワード生成による検索拡張生成の最適化,/proceedings/annual_meeting/2025/pdf_dir/P8-6.pdf,"○林 和樹, 上垣外 英剛 (NAIST), 幸田 慎也 (TDSE), 渡辺 太郎 (NAIST)",本論文では，LLM を活用し，疎検索を用いた検索拡張生成（RAG）を最適化する，反復的キーワード生成手法IterKey を提案する．IterKey は，キーワード生成，回答生成，回答検証の3 つの構成から成り，すべてLLM によって実行し，RAG の処理全体の最適化を目指す．この手法により，質問応答タスクにおいて，検索なしの手法やBM25 を用いたRAG と比較して精度が5 ％から20 ％向上し，密検索モデルを用いたRAG や先行研究と同等の性能を達成した．IterKey は，価値あるキーワードを生成しながら，解釈可能性を維持し，LLM による反復的なキーワード洗練と自己検証を通じてRAG 全体を最適化する可能性を示す新たな疎検索手法である．
P8:ポスター3月13日（木） 8:30-10:00   P会場(2Fコンベンションホール3+4),P8-7,文対モデリングのための言い換えに基づく対照学習,/proceedings/annual_meeting/2025/pdf_dir/P8-7.pdf,"○杉山 誠治, 近藤 里咲, 梶原 智之, 二宮 崇 (愛媛大)",本研究では，文対モデリングタスクの性能改善のために，事前学習済みマスク言語モデルに対する追加事前学習の手法を提案する．マスク言語モデリングによる事前学習は，意味的に近い文の埋め込み同士を埋め込み空間上で必ずしも近づけるようには設計されていない．そこで提案手法では，事前学習済みマスク言語モデルに対して，言い換え文対の文埋め込みを近づける対照学習を適用し，文対モデリングの性能改善を目指す．対照学習の先行研究で標準的に使用される自然言語推論コーパスは，英語以外の言語では大規模に利用できない課題があるが，本手法では生コーパスと言い換え辞書から低コストに対照学習のための学習データを構築できる．4 種類の文対モデリングタスクにおける実験の結果，英日の両言語において提案手法の有効性を確認できた．
P8:ポスター3月13日（木） 8:30-10:00   P会場(2Fコンベンションホール3+4),P8-8,大規模言語モデルを用いた学術論文検索におけるブーリアン型検索クエリ作成の支援,/proceedings/annual_meeting/2025/pdf_dir/P8-8.pdf,○福田 悟志 (中央大),本論文では，学術論文検索におけるブーリアン型検索クエリの考案を支援するシステムを提案する．大規模言語モデルを活用し，「AND 結合」「OR 結合」「クエリ置換」「クエリ削除」の4 つの操作パターンに基づくクエリ推薦と，その推薦理由を提示することで，ユーザが効率的にクエリを修正できる機能を提供する．本システムは少量のアノテーションデータを利用しており，ユーザの負担を抑えつつ柔軟なクエリ推薦を実現する．実験では，これらの操作パターンに基づくクエリ推薦において検索結果の再現率を向上させる語を提示できることを示した．
P8:ポスター3月13日（木） 8:30-10:00   P会場(2Fコンベンションホール3+4),P8-9,特定ドメイン向けローカル検索用のサジェスト提示に向けた分析,/proceedings/annual_meeting/2025/pdf_dir/P8-9.pdf,"○鈴木 琴音, 岩本 和真, 安藤 一秋 (香川大)",検索システムの支援の1 つであるサジェスト機能は，膨大な検索ログを利用して実装されているため，ローカル文書を対象とした検索システムに転用できない．この課題を解決するために，本研究では，検索対象文書内の単語類似性に基づくサジェスト機能について検討する．本稿では，事前分析として，Wikipedia データで学習されたWord2Vec モデルと，検索対象文書集合の特定ドメインデータで追加学習したWord2Vec モデルを用いて，特定ドメインデータの追加学習による単語ベクトルの分布や類似性の変化を定量・定性的に分析する．分析の結果，追加学習したモデルは，特定ドメインにおける語彙の関係性を捉えられており，検索対象文書のドメイン特性を活かしたサジェスト機能の実現可能性を確認した．
P8:ポスター3月13日（木） 8:30-10:00   P会場(2Fコンベンションホール3+4),P8-10,地方議会会議録検索システム「ぎ～みるv2」の概要,/proceedings/annual_meeting/2025/pdf_dir/P8-10.pdf,"○乙武 北斗 (福岡大), 高丸 圭一 (宇都宮共和大), 内田 ゆず (北海学園大), 木村 泰知 (小樽商大)",乙武北斗1　高丸圭一2　内田ゆず3　木村泰知4
P8:ポスター3月13日（木） 8:30-10:00   P会場(2Fコンベンションホール3+4),P8-11,クリックログと小規模高品質データを併用したEコマースクエリ意図分類モデルの精度向上,/proceedings/annual_meeting/2025/pdf_dir/P8-11.pdf,"○田爪 聡, 伊奈 拓郎, 馬緤 美穂, 石原 敬大, 鍜治 伸裕 (LINEヤフー)",本研究では，E コマースにおけるクエリ意図分類の精度向上を目的とする．提案手法では，クリックログを利用して大規模なデータセットを構築し，それを人手ラベルデータで補完する方法を採用した．さらに，これらのデータを統合的に活用することで，モデルを段階的に学習させる新しいアプローチを提案する．実験の結果，クリックログによる大規模データセットを信頼性の高い小規模な人手データで補完することで，従来手法を上回る分類性能を示した．
P8:ポスター3月13日（木） 8:30-10:00   P会場(2Fコンベンションホール3+4),P8-12,Sentence-BERT による，レコメンドへのユーザー意図の反映,/proceedings/annual_meeting/2025/pdf_dir/P8-12.pdf,"○青井 孝史, 久保田 崇文 (カカクコム)",本論文では，株式会社カカクコムが運営する求人ボックスを題材として，大規模で更新頻度が高い検索サービスにおける高性能なレコメンドシステムの設計方針を提示する．文ベクトルを生成するのに適した深層学習モデルSentence-BERT を用いて，閲覧履歴からユーザーを表現するベクトルを作成することで，パーソナライズされた推薦を可能にする．さらにItem2vecの思想を応用したファインチューニングを行うことで，文章の意味のみならずユーザーの意図をベクトル表現に反映することが可能になる．
P8:ポスター3月13日（木） 8:30-10:00   P会場(2Fコンベンションホール3+4),P8-13,ベクトル検索におけるテキスト構造化の効果分析,/proceedings/annual_meeting/2025/pdf_dir/P8-13.pdf,"○梶川 怜恩 (シェルパ/愛媛大), 神田 峻介, 赤部 晃一 (シェルパ), 小田 悠介 (シェルパ/NII)",ベクトル検索において，検索対象のテキスト同士の特徴が異なる状況で同じ埋め込みモデルを用いると，埋め込み空間上で離れた位置に写像されてしまうために正しく検索できなくなる問題がある．本研究ではこの問題に対し，構造面でのテキスト間の相違を事前に緩和することで検索精度を改善できる，という仮説の下，検索対象のテキストに対して事前に指定したフォーマットに基づいた構造化を行う．実験的分析の結果，提案手法を適用しない場合と比べて，検索精度が改善することを確認した．加えて，構造化によってテキストに含まれる特徴量を解釈可能な情報として抽出し，検索に有用な特徴量を特定できるという異なる利点についても分析した．
P8:ポスター3月13日（木） 8:30-10:00   P会場(2Fコンベンションホール3+4),P8-14,企業法務向け日本語文書検索評価データセットの構築と分析,/proceedings/annual_meeting/2025/pdf_dir/P8-14.pdf,"○菅原 祐太, 丸山 拓海, 西野 裕貴, 稲垣 有二 (弁護士ドットコム)",本研究では，日本語検索拡張生成（RAG）システムの性能評価と改善を目的とした企業法務向け評価データセットを構築する．構築した評価データセットを用いて既存モデルの性能検証とエラー分析を行う．一般ドメインの評価データセットでの性能評価結果と異なることを示し，特定のドメインに特化した評価データセットを作成することの重要性を明らかにする．さらに，より信頼性の高い評価データセットの確立のため，評価データの収集方法の違いがモデルの性能評価結果に与える影響について追加検証を実施する．
P8:ポスター3月13日（木） 8:30-10:00   P会場(2Fコンベンションホール3+4),P8-15,逆プロンプトを用いたコールドスタート推薦,/proceedings/annual_meeting/2025/pdf_dir/P8-15.pdf,○草野 元紀 (NEC),本研究では、新商品などの教師データに該当商品がなくて予測が困難になるコールドスタート推薦に取り組む。この問題に取り組むために、従来は商品名やカテゴリーといった補助情報を用いる推薦システムが提案されていたが、十分な量の訓練データが必要であった。近年では、大規模言語モデル（LLM）を用いることで教師データなしにコールドスタート問題を解けるようになったが、運用時のコスト面に課題があった。本論文では、LLM をデータ拡張機として活用し、教師データ収集とコスト効率の両課題を解消するRevAug を提案する。RevAugのアイディアは、ユーザがその商品を好きかどうかを予測させる従来の推薦プロンプトを、ユーザが好きそうな商品を生成させるプロンプトに変換し、それにより得られる出力を擬似サンプルとして学習データに活用したことである。4 つの実データを用いた数値実験では、RevAug は少ない教師データで高い推薦精度を達成し、LLM の処理時間と利用料金を大幅に削減した。
P8:ポスター3月13日（木） 8:30-10:00   P会場(2Fコンベンションホール3+4),P8-16,芸能人への感想を表すX上のポスト集約およびウェブ検索・RAGによるその理由の集約,/proceedings/annual_meeting/2025/pdf_dir/P8-16.pdf,"○横山 響, 土田 陸斗, 宇津呂 武仁 (筑波大)",本研究は，芸能人のファンが，芸能人に関連する事柄についての情報探索を行いやすくすることを目的とする．X から特定の芸能人に関するポストを収集し，大規模言語モデル(LLM) であるChatGPT を活用して，芸能人の評価対象とそれに関連する感想のペアを抽出する．これらをキーワードとして使用し，上位30 件のウェブページから感想の背景にある理由を探る．この理由の収集・集約では，ChatGPTに検索拡張生成(RAG) の枠組みを適用し，収集したウェブページの内容を参照情報として活用する．人手で作成した評価対象と感想のペア，および理由のデータを参照として評価を行った結果，提案手法が高い精度を達成することが明らかになった．
P8:ポスター3月13日（木） 8:30-10:00   P会場(2Fコンベンションホール3+4),P8-17,ユーザ行動ログに基づくクエリ理解のための検索クエリ埋め込み,/proceedings/annual_meeting/2025/pdf_dir/P8-17.pdf,"○西川 荘介, 平子 潤, 鍜治 伸裕, 渡邉 幸暉, 浅野 広樹, 山城 颯太, 佐野 峻平 (LINEヤフー)","検索クエリの意図をよく反映した埋め込み表現は, 検索エンジンの様々なクエリ理解(Query Under-standing, QU) タスクに活用できる. しかし, 検索クエリは短く表層形の変化が生じやすいため, 既存手法では意図を十分に捉えられない. 本研究ではユーザ行動ログから抽出した, 検索意図が類似するクエリペアを正例とする対照学習手法を提案する. このペアは表層形の類似性に依らず意図が類似するため,表層形の差異に頑健でクエリに内在する意図を的確に捉える埋め込みモデルを実現できる. 提案モデルは複数のQU タスク評価でRuri やSimCSE などの最先端テキスト埋め込みモデルを大幅に上回った."
P8:ポスター3月13日（木） 8:30-10:00   P会場(2Fコンベンションホール3+4),P8-18,論文を対象とした RAG システムにおける質問分類に基づく動的検索,/proceedings/annual_meeting/2025/pdf_dir/P8-18.pdf,"○大平 颯人 (一橋大), 佐藤 郁子 (都立大), 真鍋 章, 谷本 恒野, 原 慎大 (富士電機), 小町 守 (一橋大)",本研究では，企業内で蓄積される論文形式の技報の効率的な活用を目的とし，RAG（Retrieval-Augmented Generation）システムにおける質問分類に基づく動的検索手法を提案する．技報は，技術的な知見や情報を記録した重要な資産である一方，必要な情報を迅速かつ正確に検索することが課題となっている．本手法では技報に関するQA データに質問分類のラベルを付与したデータセットを構築し，質問分類に応じて検索戦略を動的に調整することで，応答精度の向上と応答速度の維持を実現する．
P8:ポスター3月13日（木） 8:30-10:00   P会場(2Fコンベンションホール3+4),P8-19,文書埋め込みとクラスタリングを組み合わせたトピック分析手法の提案,/proceedings/annual_meeting/2025/pdf_dir/P8-19.pdf,"○藤田 葵, 中山 悠理, 山本 泰智, 小林 亮太 (東大)",トピック分析とは，文書群を内容によってグループに分類する技術であり、大規模テキストデータの分析に有用である．トピック分析の代表的手法としてLDA (Latent Dirichlet Allocation) があり，政治学，文献計量学，ソーシャルメディア分析などの分野へ応用されてきた．一方，LDA を単語数が少ない文書に適用すると，人間が解釈しやすい分類結果を得ることが難しいという問題があった．本研究では，文書埋め込みとクラスタリングを組み合わせたトピック分析手法を提案する．4 つのデータセットを分析した結果，既存手法に比べ，提案手法はより人間に近いトピック分類を行うことが示された．
P8:ポスター3月13日（木） 8:30-10:00   P会場(2Fコンベンションホール3+4),P8-20,SoftMatcha: 大規模コーパス検索のための柔らかくも高速なパターンマッチャー,/proceedings/annual_meeting/2025/pdf_dir/P8-20.pdf,"○出口 祥之 (NAIST), 鴨田 豪 (東北大), 松下 祐介 (京大), 田口 智大 (ノートルダム大), 末永 幸平, 和賀 正樹 (京大), 横井 祥 (国語研/東北大/理研)",用例や言語現象をコーパスから素早く探し出すgrep などのパターン検索は，コーパスと人間をつなぐための基本的で重要な道具である．しかし，既存の文字列一致に基づくパターン検索では，表記揺れや類義語といった表層の変化を捉えることは難しい．文埋め込みを用いた密ベクトル検索も注目を集めており，意味的に粗く類似したテキストを検索できるが，具体的なクエリの出現位置の特定や列挙といった操作は困難である．本研究では，単語埋め込みを用いた柔らかいパターンマッチャーSoftMatcha を提案する．提案法は，転置索引を拡張したアルゴリズムを用いており，巨大コーパスに対して柔らかくも高速な検索・列挙をおこなうことができる．コーパス中の有害事例の列挙や，形態論的に複雑な特徴を持つ言語に対する用例検索を通して，SoftMatcha の有用性を実験的にも確認した∗．
P8:ポスター3月13日（木） 8:30-10:00   P会場(2Fコンベンションホール3+4),P8-21,Bi-encoder と 𝑘NN の組み合わせによる職務記述書に書かれた文のスキルマッピング,/proceedings/annual_meeting/2025/pdf_dir/P8-21.pdf,○牧野 拓哉 (Megagon Labs),スキルマッピングは職務記述書や履歴書中の文で言及されるオントロジーで定義されたスキルを特定する作業であり労働市場の分析に不可欠である．詳細な分析に必要な細分化されたスキルが付与された学習データを人手で構築するのは高いコストなため既存研究はLarge Language Model (LLM) が生成した合成データがbi-encoder の学習に用いる．合成データを活用したさらなる精度改善のため，提案手法(𝑘NNBE) は推論時に学習に利用したラベル付き合成文を𝑘-nearest neighbor (𝑘NN) によって取得し入力文との類似度をbi-encoder のスコアに加える．実験により𝑘NNBE はbi-encoder の精度改善，さらに既存の最高精度を示すLLM でスキルをリランキングする手法と比較して高いスループットを維持しながら精度改善を確認した．
P8:ポスター3月13日（木） 8:30-10:00   P会場(2Fコンベンションホール3+4),P8-22,学術情報推薦におけるグラフ構造の有効性検証,/proceedings/annual_meeting/2025/pdf_dir/P8-22.pdf,"○長尾 浩良, 桂井 麻里衣 (同志社大)",研究者への情報推薦は論文調査や関連研究者の探索に有用である．個々の研究者の業績一覧が入手可能な場合，そのコンテンツ情報を各人の専門興味のモデル化に用いることができる．一方，共著者情報が適切に整備されている場合，研究者や論文をノードとしたグラフ構造に基づくモデル化手法を採用できる．近年はこのようなグラフベース手法が注目を集めているが，コンテンツ情報のみでのモデル化手法と同一条件下で比較した例は未だ報告されていない．本論文では，学術情報推薦をグラフ内のリンク予測問題とみなし，これら二種類の手法を比較する．実験方法を情報推薦の観点から再設計した結果，コンテンツベース手法がグラフベース手法より高い性能を示した．また，リンク予測の観点での推薦性能と推薦結果の意外性はトレードオフの関係にあることが示唆された．
P8:ポスター3月13日（木） 8:30-10:00   P会場(2Fコンベンションホール3+4),P8-23,インストラクションと複数タスクを利用した日本語向け分散表現モデルの構築,/proceedings/annual_meeting/2025/pdf_dir/P8-23.pdf,"○勝又 智, 木村 大翼, 西鳥羽 二郎 (レトリバ)",Information Retrieval を始め，様々な用途で分散表現を用いた研究や製品が開発されており，高性能な分散表現モデルへの需要は日々高まっている．本研究では，日本語の多様なタスクに対して効果的な分散表現作成モデルを構築した．作成したモデルの検証結果から，学習データとして様々なタスクのデータが分散表現モデルの学習に効果的なこと，英語に関するデータが日本語向け分散表現に効果があることが確認できた．
Q8:ポスター3月13日（木） 8:30-10:00   Q会場(1F会議室101AB),Q8-1,言語モデルを用いたパラメータ異常検出： 複数パラメータの組み合わせに対する異常,/proceedings/annual_meeting/2025/pdf_dir/Q8-1.pdf,"○内田 博規 (九工大), 富永 圭太郎, 板井 秀樹 (PSD), 李 玉潔, 中藤 良久 (九工大)",本研究では、テキスト内に含まれる複数のパラメータの組み合わせに基づく異常を検出する手法に関する実験結果を報告する。これまでの研究では、BertMaskedLM 手法が高い有効性を持つことが示されている。しかし、先行研究ではモデルを1 から学習させており、既存の学習済みモデルを用いて追加学習を行う方が精度向上が期待できると予測可能である。そこで、本研究では、先行研究で提案された改善手法による結果と、有名な学習済みBERT モデルを比較、さらに学習済みBERT モデルに同様の改善手法を適用した場合の結果を調査する。
Q8:ポスター3月13日（木） 8:30-10:00   Q会場(1F会議室101AB),Q8-2,マイクロドメインに向けたLLM における知識活用方法の検討,/proceedings/annual_meeting/2025/pdf_dir/Q8-2.pdf,"○角掛 正弥, 是枝 祐太, 薛 雅文, 住吉 貴志, 永塚 光一, 友成 光, 山田 喬, 十河 泰弘 (日立)",大規模言語モデル（LLM）の業務活用では業務に必要な独自知識をLLM が扱う必要がある．個別の業務・製品の知識をLLM に活用させる方法としてRAG が主流であるが，複数の業務・製品が複雑な知識体系を持つ小規模なマイクロドメインを形成する場合に有効な知識活用方法は明らかでない．本研究はJP1 というミドルウェア製品を対象ドメインとし，追加学習とRAG を併用したマイクロドメイン特化の有効性を検証する．追加学習ではデータ合成によりデータの量・多様性を補強する．多肢選択問題から成るJP1 の資格認定試験で評価した結果，マイクロドメイン特化により正答率が向上し，最難関の試験では合格点（70%）に達した．
Q8:ポスター3月13日（木） 8:30-10:00   Q会場(1F会議室101AB),Q8-3,継続事前学習によるLLMの知識獲得,/proceedings/annual_meeting/2025/pdf_dir/Q8-3.pdf,"○高橋 洸丞, 近江 崇宏, 有馬 幸介 (ストックマーク), Benjamin Heinzerling (理研/東北大), Qin Dai (東北大), 乾 健太郎 (MBZUAI/東北大/理研)",継続学習は、モデルが新しい情報を取り入れつつ、既存の知識を保持する能力を向上させる技術であり、本研究では大規模言語モデル（LLM）における継続学習を通じた知識の埋め込みの手法について検討する。本研究では、LLM に特定のドメインデータの知識を覚えさせるために、継続学習時に対象ドメインデータから作成した複数のNLP タスクを混ぜ、さらに指示学習時においても、ドメイン特化した指示データで学習を行う。QA タスクによる実験の結果、人手評価において、対象のドメインで指示学習データを作ったモデルが最も正答率が高く、ドメイン特化させる場合は指示学習データもドメイン特化させる方がよいと考えられる。また本研究では、継続学習時のコンテキスト長が与えるQA タスクの性能変化についても調査した。
Q8:ポスター3月13日（木） 8:30-10:00   Q会場(1F会議室101AB),Q8-4,利用手法の類似性に着目した学術論文推薦手法の提案,/proceedings/annual_meeting/2025/pdf_dir/Q8-4.pdf,"○YANG QI (電通大), 成松 宏美 (NTT), 南 泰浩 (電通大)",学術論文数の急増により，論文推薦システムの重要性が高まっている．特に，「背景」「手法」「結果」といった観点のうち，どの観点が類似するかを示すことは，利用者の負担削減に有効である．これに対して，従来は要旨内の各文を観点に分類し，各観点類似度をもとに推薦理由を提示する手法がとられていた. しかし，これまで「手法」が類似している論文に対する推薦精度が低かった．本研究では，要旨内の「手法」の類似性に着目した新たな推薦手法を提案する．具体的には，要旨から分野情報を抽出し，分野情報を表す単語の埋め込みを調整することで，「手法」が類似している論文の推薦精度を向上させる．ベンチマークデータで提案手法を評価した結果，従来手法を上回る精度を示した．
Q8:ポスター3月13日（木） 8:30-10:00   Q会場(1F会議室101AB),Q8-5,日本語バイト符号化マスク言語モデルの開発と分析,/proceedings/annual_meeting/2025/pdf_dir/Q8-5.pdf,"○工藤 慧音 (東北大/理研), 鴨田 豪, 塩野 大輝 (東北大), 鈴木 潤 (東北大/理研/NII)",バイト符号化を用いた日本語マスク言語モデルの開発における知見と学習したモデルの分析結果について報告する．本論文前半では，モデルアーキテクチャ・学習戦略の探索を行い，大規模言語モデルで用いられるアーキテクチャは，バイト単位マスク言語モデル構築時においても有効であること，マスク率は50%が最適であることを確認した．後半では，学習したバイト単位マスク言語モデルの表層的な類似に対する頑健性及びモデル内部での複合化過程を分析した．学習したバイト単位マスク言語モデルは，表層的な類似に対して頑健であり，モデル内部での複合化はモデルの初期及び最終層付近で行われていることを確認した．
Q8:ポスター3月13日（木） 8:30-10:00   Q会場(1F会議室101AB),Q8-6,日独民法における自動対応付け手法の比較とfine-tuningの実装,/proceedings/annual_meeting/2025/pdf_dir/Q8-6.pdf,"○髙橋 寿記, 中村 誠 (工科大)","日本法と外国法において，類似条文の対応付けに一定の需要がある．先行研究 [1] では日本とドイツの民法の自動対応付けが行われた．しかし，対応付けできない条文も多く, 高い評価は得られなかった．本研究では先行研究 [1] の対応付け手法と評価手法を見直し， fine-tuning の実装を行った．実験により，本研究で行った類似条文の自動対応付け手法が先行研究 [1] の手法を上回った．また，fine-tuning を実装することでさらに高い評価を得ることを確認した．"
Q8:ポスター3月13日（木） 8:30-10:00   Q会場(1F会議室101AB),Q8-7,LLM の学術ドメイン適応のための合成データに基づく統合フレームワーク,/proceedings/annual_meeting/2025/pdf_dir/Q8-7.pdf,"○小川 隼斗 (早大), 河原 大輔 (早大/NII), 相澤 彰子 (NII)",大規模言語モデル（LLM）の様々な分野での応用が広がる中，専門知識を要する学術ドメインでの活用は難しい課題である．特に，日本語の学術ドメインにおけるLLM の開発は未だ発展途上である．本研究では，LLM が生成したQA データを活用し，学習と自動評価を統合したフレームワークを提案する．まず，学術論文を対象とした合成データセットを作成する．次に，そのデータセットを用いてLLMをチューニングし，学術的な文脈での質問応答能力を強化する．さらに，LLM による自動評価手法により開発したモデルの性能と有効性を検証する．
Q8:ポスター3月13日（木） 8:30-10:00   Q会場(1F会議室101AB),Q8-8,法令文解析に適した事前学習モデルの構築,/proceedings/annual_meeting/2025/pdf_dir/Q8-8.pdf,"○渋谷 太朗, 中村 誠 (新潟工科大)",比較法学研究を推進するために日本法と外国法の類似条項を対応付ける研究が行われている．その手法の一つに汎用言語モデルであるBERT が使われている [1]．これにより，事前学習とfine-tuning の組み合わせでEnd-to-end 学習を可能とする．法令分野の事前学習モデルは既にいくつかある [2，7]が，判例など法令以外の文書もコーパスに含まれており，法令のみをコーパスとしたBERT モデルは存在せず，高精度な法令解析を行うには，法令のみをコーパスとしたBERT モデルが必要となる．したがって，本研究の目的は，日本の法令文解析に適した事前学習モデルを構築することである．法令のみをコーパスとした事前学習モデルを二通り作成し，各モデルの言語理解能力，外国法対応付け能力をテストした．結果として，F1 値で東北大学が発表した，日本語汎用事前学習モデル（以降，東北大BERTi）を上回る性能を示した．
Q8:ポスター3月13日（木） 8:30-10:00   Q会場(1F会議室101AB),Q8-9,モデルマージを用いたLLM翻訳における破滅的忘却の抑制,/proceedings/annual_meeting/2025/pdf_dir/Q8-9.pdf,"○岩川 光一, Zhu Haocheng, 鈴木 潤 (東北大), 永田 昌明 (NTT)",本稿では翻訳能力を向上させるデータを用いて継続事前学習を行ったモデルを対象に，モデルマージを用いて破滅的忘却を抑制する方法について検討する．継続事前学習前後のモデルをマージすることにより，一般的タスク能力の忘却を抑えつつ，翻訳能力をベースモデルよりも向上させられることを示す．さらに，モデルマージの手法間の比較や，各マージ手法のパラメータ設定による結果の変化についても調査を行い，今後の研究の方向性を示す．
Q8:ポスター3月13日（木） 8:30-10:00   Q会場(1F会議室101AB),Q8-10,LLM推定ラベルと弱教師あり学習による反復的アノテーション更新,/proceedings/annual_meeting/2025/pdf_dir/Q8-10.pdf,"○浅野 輝 (東大/理研), 小津野 将 (OSX), 馬場 雪乃 (東大)",本研究では、大規模言語モデル（LLM）による初期アノテーションと、弱教師あり学習の一種であるRobust Unlabeled-Unlabeled Learning を組み合わせた反復的な学習フレームワークを提案する。従来、専門領域や大規模データセットにおけるテキスト分類では、アノテーションコストとラベルノイズが精度向上の大きな障壁となっていた。本手法ではまずLLM を用いて未ラベルデータに対し擬似ラベルを一括付与し、正例比率が相対的に高いコーパスと低いコーパスを疑似正例・負例として構築する。次にRobust UU Learning を適用することで、LLM が付与したノイズを含むラベルにも頑健な分類器を学習し、その分類器で再度データをラベリングする手順を複数回繰り返す。これにより、初期アノテーションの誤りを段階的に削減し、高精度な分類器を獲得できることを実験的に確認した。また、本手法により、GPT-4o などの言語モデルの性能を上回る成果を得られることも示した。
Q8:ポスター3月13日（木） 8:30-10:00   Q会場(1F会議室101AB),Q8-11,Flashback: 深層系列処理モデルのメモリ効率化・高速化のための記憶機構,/proceedings/annual_meeting/2025/pdf_dir/Q8-11.pdf,○関井 大気 (サイバーエージェント),本稿では，従来研究におけるRNN ベースの深層系列処理モデルの持つ課題，（1）記憶の劣化，（2）不正確な勾配の逆伝搬，（3）次トークン予測に対する親和性，の3 点を同時に解決するDNN 記憶機構の実現に取り組む．具体的には，課題1～2 に対処するため，記憶領域に保存されて以降，別の時刻の隠れ状態で上書きされるまで，記憶が保存時の値の恒等写像として完全に保持されるFlashback 特性を定義し，その性質を満たすFlashback 機構を提案する．また課題3 に対して，次トークン予測が可能な方式で，Flashback 機構を従来のTransformersとMamba それぞれに組み込んだアーキテクチャを提案する．実験では，多様なテキストデータを含むThe Pile データセットを学習に用いて，従来手法へのFlashback 機構の導入による常識推論精度，処理速度，メモリ使用量のトレードオフを評価することで，Flashback 特性の有効性を検証した．
Q8:ポスター3月13日（木） 8:30-10:00   Q会場(1F会議室101AB),Q8-12,SvMoE: MoE ルータの教師あり学習,/proceedings/annual_meeting/2025/pdf_dir/Q8-12.pdf,"○村田 栄樹, 河原 大輔 (早大)","Mixture-of-Experts はそのパラメタ数に対して計算コストが小さく, 大規模言語モデルの実用に向けて重要な技術である. しかし, エキスパートを選択するルーティングでは選択が偏り, 効率的なパラメタの利用が難しいという問題がある. それに対して, エキスパート選択を均一にする追加損失が使われるが言語モデル性能に干渉することがわかっている. 本研究では, TF-IDF を教師信号とした教師あり学習でMixture-of-Experts のルーティングを訓練することを提案する. ケーススタディとして法律へのドメイン特化を扱い, 追加損失なしの提案手法は追加損失を使用するベースラインに比肩する結果を得た."
Q8:ポスター3月13日（木） 8:30-10:00   Q会場(1F会議室101AB),Q8-13,日本語の包括的な指示追従性データセットの構築,/proceedings/annual_meeting/2025/pdf_dir/Q8-13.pdf,"○堀尾 海斗, 福田 創, 小川 隼斗, 鈴江 万碧, 織田 宥楽 (早大), 河原 大輔 (早大/いちから), 関根 聡, 安藤 まや (いちから)",大規模言語モデル(LLM) は急速な発展により、幅広い知識を保有し、多種多様な応答が可能になっている。LLM の知識や言語能力の評価にはGLUEやMMLU などのデータセットが存在し、JGLUE などの日本語データセットも構築されている。LLMの生成評価の観点は、これら以外に、人間の指示に対して追従しているかという点がある。しかし、指示追従性を評価する為の日本語データセットは存在するものの、カバーする範囲が狭い。本研究では、日本語の包括的な指示追従性データセットを構築する。さらに、構築したデータセットを評価ベンチマークとして、既存のLLM の指示追従性を評価する実験を行う。構築したデータセットはichikara-instruction2 データに含まれる形で提供予定である。
Q8:ポスター3月13日（木） 8:30-10:00   Q会場(1F会議室101AB),Q8-14,LLMを用いた日本語学習者支援,/proceedings/annual_meeting/2025/pdf_dir/Q8-14.pdf,"○亀田 隆雅, 馬 青 (龍谷大)",生成AI 技術の著しい進歩により、これを活用した製品やサービスが数多く登場している。本研究では、生成AI の一種であるLLM を用いて日本語学習者を支援するため、架空の日本での生活をシミュレーションするゲームを開発している。このゲームでは、動的な対話を可能にするLLM を登場人物として活用し、学習者に現実に近い会話練習を提供する。さらに、LLM の特性を活かして、学習者ごとにパーソナライズされた会話体験を実現し、日本語学習の効率と効果を高めることを目指している。
Q8:ポスター3月13日（木） 8:30-10:00   Q会場(1F会議室101AB),Q8-15,Sparse Autoencoders as a Tool for Steering the Output Language of Large Language Models,/proceedings/annual_meeting/2025/pdf_dir/Q8-15.pdf,"○◊Sebastian Zwirner, Wentao Hu, 青木 洸士郎, 河原 大輔 (早大)","Recent advancements in Sparse Autoencoders (SAEs)have uncovered insightful features in large language models(LLMs). In this study, we identify language-speciﬁc SAEfeatures, which are predominantly found in the later layersof the LLM. Using these features, we steer the output lan-guage of an LLM. In an experiment based on a translationtask, our method achieves a 49% accuracy in generating thedesired target language, outperforming a previous methodusing individual language neurons for steering. This workdemonstrates the potential for SAE features for languagesteering."
Q8:ポスター3月13日（木） 8:30-10:00   Q会場(1F会議室101AB),Q8-16,日本語 VLM 構築に向けた合成データのフィルタリングの検討,/proceedings/annual_meeting/2025/pdf_dir/Q8-16.pdf,"○大島 遼祐 (早大/SB Intuitions), 小澤 圭右, 品川 政太朗, 鈴木 哲平 (SB Intuitions)",Vision-Language Model の学習に必要なVisual In-struction Tuning データセットは、コストの観点から主に人手ではなくデータ合成によって作成される。合成データの利用における課題は、合成時に発生する不適切な合成データを取り除く上での正確性と、時間的効率性である。本稿では、CLIP およびVLMas a judge を用いたフィルタリングの正確性と効率性について検証する。実験の結果、VLM as a judge は正確性が17.3%高いがCLIP の方が62 倍高速に動作すること、これら手法の併用によりVLM as a judge単体に比べ正確性を損なうことなく36%高速にフィルタリング可能なことがわかった。
Q8:ポスター3月13日（木） 8:30-10:00   Q会場(1F会議室101AB),Q8-17,文脈内学習におけるデモの親和性と多様性の提案,/proceedings/annual_meeting/2025/pdf_dir/Q8-17.pdf,"○加藤 万理子, 趙 羽風, 坂井 吉弘 (JAIST), 井之上 直也 (JAIST/理研)","文脈内学習(In-Context Learning; ICL) において, デモンストレーション(デモ) の選択はタスク性能に大きな影響を与える. 既存研究ではデモの選択手順については研究されているが, 選択基準であるデモの性質は十分に調べられていない. 本研究では, デモの「親和性」と「多様性」という2 つの性質を新たに提案し, その内の親和性が性質が複数のモデルおよびデータセットにおいてデモ選択に望ましい性質であることを示した. さらに, 既存手法で選ばれたデモが, 2 つの性質のタスク性能を向上させる方向へ集約していることを示し, デモ選択とタスク性能のメカニズム解明への示唆を得た."
Q8:ポスター3月13日（木） 8:30-10:00   Q会場(1F会議室101AB),Q8-18,新聞ドメインにおける大規模言語モデルの継続事前学習と下流タスクデータ量の関係,/proceedings/annual_meeting/2025/pdf_dir/Q8-18.pdf,"○岸波 洋介, 藤井 諒, 森下 睦 (フューチャー)",近年の大規模言語モデル(LLM) の発展により，様々なドメインに特化したLLM の研究が進んでいる．ドメイン特化LLM を下流タスクに用いる場合，タスクのラベル付きデータで教師ありファインチューニングする前に，そのドメインの知識獲得を目指し，特定ドメインの生テキストを用いた継続事前学習が先行して行われることがある．しかしながら下流タスクのデータ量に着目した継続事前学習の有効性については不明な点が多い．本研究では新聞ドメインにおける見出し生成タスクを対象に，ドメイン特化を目的とする継続事前学習と下流タスクのデータ量が性能に与える影響を分析する．分析の結果，下流タスクのデータ量が極めて少ない状況では継続事前学習の効果が大きい可能性が示唆された．
Q8:ポスター3月13日（木） 8:30-10:00   Q会場(1F会議室101AB),Q8-19,確率的丸めを用いた言語モデルの量子化を意識した学習,/proceedings/annual_meeting/2025/pdf_dir/Q8-19.pdf,"○趙 開顔 (東大), 田原 司睦, 小林 健一, 本田 巧, 山崎 雅文 (富士通), 鶴岡 慶雅 (東大)",近年、大規模言語モデル(LLMs) の各パラメータの重みを二値や三値に量子化することで、推論時のメモリ使用量を大幅に削減できることが報告されている。しかし、これらのモデルの学習には依然として多くのメモリが必要である。その理由の一つは、これらのモデルを学習する際に、Straight-ThroughEstimator (STE) に必要な、(量子化されていない) 高精度の重み行列を保持する必要があるからである。そこで本研究では、学習時のメモリ使用量を削減するため、バックプロパゲーションにおいてSTE を用いずに、量子化された低精度の重み行列を直接更新することを試みる。具体的には、確率的丸めを利用することで、低ビットの重みを用いる際に生じる情報の損失を防ぐ。LLaMA 構造の言語モデルを用いた実験の結果、低精度の重みのみでの学習が可能であることが明らかになった。
Q8:ポスター3月13日（木） 8:30-10:00   Q会場(1F会議室101AB),Q8-20,大規模言語モデルによるテキスト平易化のための意味的類似性と表層的非類似性に基づくパラレルコーパスフィルタリング,/proceedings/annual_meeting/2025/pdf_dir/Q8-20.pdf,"○前川 大輔, 梶原 智之, 二宮 崇 (愛媛大)",大規模言語モデルは小規模なファインチューニングで高い性能を発揮できると他のタスクで報告されているが，テキスト平易化タスクにおいて必要なデータ量は未知である．本研究では，テキスト平易化のためのパラレルコーパスフィルタリングの手法を提案し，大規模言語モデルのファインチューニングに必要なデータ量を削減する．日本語における実験の結果，テキスト平易化のタスク遂行能力は16～
Q8:ポスター3月13日（木） 8:30-10:00   Q会場(1F会議室101AB),Q8-21,模倣学習による大規模言語モデルの指示チューニング,/proceedings/annual_meeting/2025/pdf_dir/Q8-21.pdf,"○Youmi Ma (科学大), 水木 栄, 藤井 一喜, 中村 泰士, 大井 聖也 (科学大/産総研), 島田 比奈理, 塩谷 泰平, 齋藤 幸史郎, 前田 航希 (科学大), 服部 翔 (科学大/産総研), 岡本 拓己, 石田 茂樹 (科学大), 横田 理央 (科学大/産総研/NII), 高村 大也 (産総研), 岡崎 直観 (科学大/産総研/NII)",指示チューニングを効率的に行う手段として，高性能な大規模言語モデル（LLM）の挙動を模倣する手法が注目を集めている．既存研究ではGPT-4を模倣した学習が主流であるが，ライセンスの制限が厳しいうえ，汎用的な知見が得られにくい．本稿では複数のオープンなLLM を模倣先とし，模倣学習の有効性を検証する．実験結果により，Llama-3.1-Swallow-8B-v0.1 にGemma-2-27B-IT の模倣学習をさせることで，13B 以下のモデルの中でトップクラスの性能を達成した．また，性能は高いものの模倣学習の効果が限定的なLLM や，模倣学習で習得しにくい能力の存在を明らかにした．
Q8:ポスター3月13日（木） 8:30-10:00   Q会場(1F会議室101AB),Q8-22,少量ショットに対する大規模言語モデル（LLM）を用いた人工データ生成による精度向上の試み,/proceedings/annual_meeting/2025/pdf_dir/Q8-22.pdf,"○山本 大輝, 佐々木 峻 (アクロクエストテクノロジー)",近年，大規模言語モデル（Large Language Model：LLM）の発展により，質問応答や文書生成をはじめとする多様な自然言語処理タスクで高い精度が実現されている．従来のBERT やロジスティック回帰と比較して，LLM はより優れた性能を示しているが，その学習および推論には大量のGPU リソースを必要とするため，業務での安定運用には高額なコストが伴う．一方で，BERT やロジスティック回帰などの従来手法を利用することで，運用コストを削減しながらも一定の性能を維持する方法が考えられる．しかし，分析に必要な十分なデータを集められない事例も多く，これがモデルの性能向上を妨げる要因となる．本研究では，LLM を利用して学習データを人工的に生成する手法に着目し，文書分類タスクにおける軽量モデルの精度向上に寄与するかを検討した．実験の結果，参照なし文書生成プロンプトが最も効果的であり，軽量なモデルでも精度向上が可能であることを確認した．
Q8:ポスター3月13日（木） 8:30-10:00   Q会場(1F会議室101AB),Q8-23,量子化 bit 幅の異なる基盤モデルに対する Adapter の転移性を活用した Low-Rank Adaptation,/proceedings/annual_meeting/2025/pdf_dir/Q8-23.pdf,"○神田 悠斗, 波多野 賢治 (同志社大)",大規模言語モデルは，重みの勾配や最適化状態を保持するため，推論時よりも訓練時に要求されるGPU メモリ量が多いことが知られている．したがって，例えば同一の計算資源上で基盤モデルの訓練と推論を行う際には，基盤モデルのサイズは訓練時の資源制約から決定されるため，推論時にはGPUメモリの余剰が発生する．本研究ではこの推論時のメモリの余剰に着目し，これを活用してLoRA モデルの性能を向上させる新たな量子化-LoRA フレームワークとして，Post LoRA Restoration（PLR）を提案する．評価実験の結果，訓練時の計算コストはそのままに，PLR による最大12 倍の精度向上が確認できた．
Q8:ポスター3月13日（木） 8:30-10:00   Q会場(1F会議室101AB),Q8-24,連合学習におけるLoRAの統合数と精度の関係の検証,/proceedings/annual_meeting/2025/pdf_dir/Q8-24.pdf,"○尹 子旗, 村田 栄樹, 河原 大輔 (早大)",本研究では、大規模言語モデル（LLM）の連合学習におけるLoRA の統合数がモデル性能に与える影響について検証する。LLM に基づく連合学習の多くは、複数のクライアントがローカルデータを用いてLoRA を学習し、その重みを統合することでグローバルモデルを構築する。しかし、LoRA の統合数が増加するにつれ、モデル性能の低下が予想されるため、その定量的評価と原因の解析が必要である。本研究では、データ分布が同一であることを仮定し、テキスト要約タスクおよび数学的推論タスクを対象に実験する。その結果、LoRA の統合数が増加するにつれてモデル性能が低下する傾向が観察された。特に数学的推論タスクでは、統合数の増加によって正解率が顕著に低下した。これらの結果は、従来の統合手法であるFedAvg がLoRA 重みの統合において性能劣化を招くことを示しており、統合手法の改善が求められることを示唆する。
Q8:ポスター3月13日（木） 8:30-10:00   Q会場(1F会議室101AB),Q8-25J,Weighted Asymmetric Loss for Multi-Label Text Classification on Imbalanced Data,/proceedings/annual_meeting/2025/pdf_dir/Q8-25.pdf,"○安田 有希, 宮﨑 太郎 (NHK), 後藤 淳 (N財団)",
A9:機械翻訳(1)3月13日（木） 10:20-11:50   A会場(2Fコンベンションホール1+2),A9-1,段落単位の対訳データによる大規模言語モデルの翻訳精度向上,/proceedings/annual_meeting/2025/pdf_dir/A9-1.pdf,"○近藤 海夏斗, 宇津呂 武仁 (筑波大), 永田 昌明 (NTT)",大規模言語モデルは，自然言語処理タスクで優れた性能を発揮しているが，翻訳タスクではモデルサイズや訓練手法による性能差が見られる．本研究では，段落単位の対訳データを活用した継続事前訓練およびSupervised ﬁne-tuning が翻訳精度に与える効果を検証した．Llama-3 ベースのモデルを用いて英日・日英翻訳を評価した結果．段落単位の対訳データを継続事前訓練とSupervised Fine-Tuning の両方で利用することで最も高い精度が得られた。また，推論時に段落全体を一括で翻訳する方法が有効であることを確認した．
A9:機械翻訳(1)3月13日（木） 10:20-11:50   A会場(2Fコンベンションホール1+2),A9-2,対訳単語の対偶を考慮した文パターンの選択とNMTの効果,/proceedings/annual_meeting/2025/pdf_dir/A9-2.pdf,○村上 仁一 (鳥取大),パターン翻訳は，古典的な機械翻訳の方法である．従来，文パターンは，人手で作成される．しかし，簡単な文パターンは，単語辞書を利用して，自動的に作成可能である．そして，NMT において翻訳精度を向上させるため，学習データに文パターンを加える方法がある．しかし，翻訳精度は，ほとんど向上しない．この原因として，文パターンの作成方法に問題があると考えた．そこで，対訳単語の対偶を考慮して文パターンを選択して，学習データに加えた．作成したNMT の翻訳精度を評価したところ，文パターンの選択前と比較すると大幅に向上した．
A9:機械翻訳(1)3月13日（木） 10:20-11:50   A会場(2Fコンベンションホール1+2),A9-3,特許請求項翻訳における単語対応に基づく節分割モデルの有効性,/proceedings/annual_meeting/2025/pdf_dir/A9-3.pdf,"○西村 柾人, 宇津呂 武仁 (筑波大), 永田 昌明 (NTT)",特許請求項は特許範囲を規定する重要部分だが，その長さや独特の書式が原因でNMT モデルでは訳抜けや繰り返しといった誤訳を引き起こしやすい．本論文では，この課題を解決するために，節分割モデルを用いた分割統治翻訳手法を提案する．翻訳元文を節分割モデルを用いて節に分割し，それぞれの節を節翻訳モデルで翻訳，その後並び替え・編集モデルで最終的な翻訳文を生成する．さらに，節分割モデルと節翻訳モデルを訓練するための節単位の対訳コーパスを，単語対応情報をもとに文単位の対訳コーパスから作成する手法を提案する．実験では，提案手法が通常のモデルをBLEU で上回り，訳抜けや繰り返しの改善を確認した．
A9:機械翻訳(1)3月13日（木） 10:20-11:50   A会場(2Fコンベンションホール1+2),A9-4,ニューラル機械翻訳のモデルレベル双方向学習における単言語データの活用,/proceedings/annual_meeting/2025/pdf_dir/A9-4.pdf,"○加藤 龍兵, 秋葉 友良, 塚田 元 (豊橋技科大)",双方向学習はタスク対の入出力の対称性を利用して，各タスクのモデル性能を相互的に高める手法である．機械翻訳分野でも，双方向学習は翻訳性能の向上や単言語データを使ったドメイン適応など幅広く応用されている．一方，双方向学習を単一モデルで行うモデルレベル双方向学習では単言語データの活用例が少ない．そこで本研究ではモデルレベル双方向学習での単言語データの利用法を提案する．具体的には，単言語データを用いる補助タスクおよび主タスクである翻訳と補助タスクとを併用するための訓練フレームワークを提案しドメイン適応実験で有効性を示す．
A9:機械翻訳(1)3月13日（木） 10:20-11:50   A会場(2Fコンベンションホール1+2),A9-5,対訳文のみを用いた翻訳と言い換えのマルチタスク学習における翻訳精度,/proceedings/annual_meeting/2025/pdf_dir/A9-5.pdf,"○名村 太一, 村上 仁一 (鳥取大)",機械翻訳の問題として学習データの対訳文不足がある．この問題への対策として単言語データを用いたデータ拡張などが行われている．提案手法は日本語と英語の対訳文から英日対・日英対・日日対・英英対の対訳を作成する．そしてそれぞれを英日翻訳，日英翻訳，日本語言い換え，英語言い換えタスクとしてマルチタスク学習を行う．提案手法の特徴としてアーキテクチャの変更，単言語データを用意する必要がない．実験の結果，自動評価と人手評価でベースラインを上回った．
A9:機械翻訳(1)3月13日（木） 10:20-11:50   A会場(2Fコンベンションホール1+2),A9-6,事例ベース意思決定理論に基づく復号,/proceedings/annual_meeting/2025/pdf_dir/A9-6.pdf,○出口 祥之 (NTT),最小ベイズリスク（minimum Bayes risk; MBR）復号は、出力候補の中から品質の期待値を最大化する仮説を選択する復号法であり、従来の最大事後確率復号よりも高品質なテキストを出力する。しかし、MBR 復号の出力は、テキスト生成モデルが生成するサンプルに依存するため、生成モデルの学習が不十分なドメインにおいては、ドメインの知識や情報を反映したテキストを出力することは難しい。この課題に対処するため、本研究では、ドメインデータを利用した事例ベース意思決定理論に基づく復号を提案する。独英ドメイン翻訳実験より、提案法は、最大事後確率復号よりも高品質なテキストを出力でき、また、MBR 復号と組み合わせることで、MBR復号よりもドメインに特化した高品質なテキストを出力できることを確認した。
B9:語彙資源・辞書3月13日（木） 10:20-11:50   B会場(1F会議室102),B9-1,ダイエット口コミデータセットにおけるダイエット食品およびダイエット飲料に関する語彙解析,/proceedings/annual_meeting/2025/pdf_dir/B9-1.pdf,○大塚 敬義 (目白短大),ダイエットカフェ株式会社から国立情報学研究所（NII）を通じて研究者に提供されているデータセットである「ダイエット口コミデータセット」の貸与を受けた。合計約19 万9 千件の口コミから成る当該データセットのうち，ダイエットドリンク約４万3千件，ダイエット食品約8 千件について，出現する単語の共起ネットワーク図を作成したので報告する。
B9:語彙資源・辞書3月13日（木） 10:20-11:50   B会場(1F会議室102),B9-2,JMED-DICT: 大規模医療用語辞書の構築,/proceedings/annual_meeting/2025/pdf_dir/B9-2.pdf,"○永井 宥之, 西山 智弘, 大槻 優佳, 藤牧 貴子, 川端 京子, 工藤 紀子 (NAIST), 山崎 由佳, 白石 暖哉 (京大), 梶原 智之 (愛媛大), 進藤 裕之 (MatBrain), 河添 悦昌, 今井 健 (東大), 矢田 竣太郎 (NAIST/筑波大), 若宮 翔子, 荒牧 英治 (NAIST)",70 万語超を収録した大規模医療用語辞書JMED-DICT の構築方法およびメンテナンスについて報告する．JMED-DICT は，LLM をはじめとして計算機によって利用されることを想定した，医療用語間の対応関係を保持する辞書である．本稿では，本辞書の仕様，データ構築の手法，メンテナンス方法を紹介する．また，メンテナンスの効率化のために開発した各種ツールおよび，本辞書を利用した応用例であるAPI についても併せて述べる．
B9:語彙資源・辞書3月13日（木） 10:20-11:50   B会場(1F会議室102),B9-3,大規模言語モデルを活用した大規模医療用語辞書メンテナンスの効率化,/proceedings/annual_meeting/2025/pdf_dir/B9-3.pdf,"○大槻 優佳 (NAIST), 矢田 竣太郎 (NAIST/筑波大), 西山 智弘, 工藤 紀子, 川端 京子, 藤牧 貴子, 永井 宥之, 若宮 翔子, 荒牧 英治 (NAIST)",自然言語処理において，最も早くから利用されてきたリソースが辞書である．辞書は多様なタスクに有用であるが，構築やメンテナンスに要するコストが課題である．我々は，辞書データへの人手の修正履歴を活用し，未修正の用語に対して修正を自動提案するシステムを構築することで，質を担保しつつ低コストでメンテナンスが可能になると考えた．本研究では，構築中の50 万語を超える大規模医療辞書において，医療用語のメタデータを自動修正する手法を提案する．実験では，専門的な医学知識を必要とする遺伝子バイオマーカの表記ゆれの修正性能を検証した結果を報告する．本手法は，多くの辞書メンテナンス負担軽減に貢献するものである．
B9:語彙資源・辞書3月13日（木） 10:20-11:50   B会場(1F会議室102),B9-4,関西方言を対象とした形態素解析用辞書の拡張,/proceedings/annual_meeting/2025/pdf_dir/B9-4.pdf,"○小木曽 智信 (国語研/総研大), 尹 熙洙 (総研大/国語研), 王 竣磊 (国語研/東大), 岡田 純子 (国語研)",現代語用のUniDic をベースとして関西方言を対象とした形態素解析用の辞書「関西弁UniDic」の拡張を行い、方言特有の見出し語の追加、特に機能語の品詞や活用形の整備を行った。また、短単位データとして整備した関西方言用の学習用コーパスを大幅に充実させ、これらのデータを用いてMeCab 用の辞書を作成した。さらに、各種の学習用コーパスを組み合わせて解析精度の検証を行った。これにより従来より高い精度で、広域の関西方言の会話書き起こしテキストを解析することを可能にした。
B9:語彙資源・辞書3月13日（木） 10:20-11:50   B会場(1F会議室102),B9-5,『子ども版日本語日常会話コーパス』モニター版の構築,/proceedings/annual_meeting/2025/pdf_dir/B9-5.pdf,"○小磯 花絵 (国語研), 石本 祐一 (ものつくり大/国語研), 居關 友里子, 江口 典子, 柏野 和佳子, 川端 良子, 田中 真理子, 田中 弥生, 西川 賢哉 (国語研)",国立国語研究所共同研究プロジェクト「多世代会話コーパスに基づく話し言葉の総合的研究」では、子どもを中心とする多様な場面における多様な相手との会話を対象とする『子ども版日本語日常会話コーパス』（CEJC-Child）の構築を2022 年度から進めている。これは、2022 年3 月に公開した『日本語日常会話コーパス』で不足する子どものデータを補充するために計画したものである。収録対象は8 世帯12 名の子どもであり、100 時間規模のコーパスを構築するが、このうち50 時間のデータを2025 年3月にモニター公開する。本稿ではCEJC-Child モニター版の特徴について報告する。
B9:語彙資源・辞書3月13日（木） 10:20-11:50   B会場(1F会議室102),B9-6,留学生向け看護語彙リスト作成のためのコーパス構築における課題 -『系統看護学講座』シリーズ３巻のパイロットスタディから-,/proceedings/annual_meeting/2025/pdf_dir/B9-6.pdf,"○山元 一晃 (金城学大), 浅川 翔子 (慈恵医大), 稲田 朋晃 (十文字大), 岩間 裕司 (防医大), 土屋 ともえ (国福大)",看護留学生への支援に活用できる語彙リストを作成するためのコーパス構築のパイロットスタディについて発表する.まず，全70 巻の『系統看護学講座』シリーズのうち３巻を文字化し，語彙の多様性や，品詞・語種の観点から留学生が直面しうる困難について検討した.その結果，名詞が多いこと，漢語や外来語が多いことなどから，母語や背景によっては難しく感じることが示唆された.その後，本パイロットスタディを踏まえ，コーパス構築を前提とした整形作業において考慮すべきことについて検討した.教科書という特性上，コラムや練習問題などが入り組んでおり，学習の必要性や語彙の特徴の過大評価の可能性などを踏まえ，今後の整形の方針を述べた.
C9:情報検索・テキストマイニング3月13日（木） 10:20-11:50   C会場(1F会議室103),C9-1,RAGによる芸能人の話題集約及びその経歴の良否判定,/proceedings/annual_meeting/2025/pdf_dir/C9-1.pdf,"○土田 陸斗, 横山 響, 宇津呂 武仁 (筑波大)",本論文の目的は，先行研究[9] の情報探索の問題点の解決と，大規模言語モデルによる良否判定の能否を判明させることである．その手法として，まずウェブページの芸能人に関する記事から対象の芸能人に言及している文を収集する．この際，記事を全て人が確認することは困難であるため，その収集を大規模言語モデルのChatGPT で行う．次に，集めた文章をChatGPT によって内容でカテゴリ分けし，カテゴリ名を付ける．ここで付けた名前を芸能人の観点と呼ぶことにする．この芸能人の観点について，先行研究[9] の手法との対応付けや，大規模言語モデルによる経歴の良否判定を行う．
C9:情報検索・テキストマイニング3月13日（木） 10:20-11:50   C会場(1F会議室103),C9-2,抽象度が高いクエリによるアンケートデータの設問検索,/proceedings/annual_meeting/2025/pdf_dir/C9-2.pdf,"○田中 稔也, 熊谷 雄介, 藤井 遼 (博報堂DYホールディングス)",膨大なアンケートデータから，分析目的に合致する設問を検索する作業は，マーケターにとって手間と時間がかかる工程の一つである．この作業工程をユーザのクエリ入力による設問検索で効率化することを提案する．このとき，クエリの意味や内容が抽象的であってもユーザが望む設問を検索することを目指す．本研究では，アンケートデータ設問検索タスクに取り組む．それに伴い，マーケターのアノテーションによる設問検索データセットを構築した．複数の手法を用いた設問検索実験の結果，文から直接埋め込み表現を取得しクエリとの類似度を求める手法が高い精度を示した．また，設問検索特有の課題が明らかとなった．
C9:情報検索・テキストマイニング3月13日（木） 10:20-11:50   C会場(1F会議室103),C9-3,k近傍事例に基づく埋め込み表現のドメイン適応と検索への応用,/proceedings/annual_meeting/2025/pdf_dir/C9-3.pdf,"○五藤 巧 (NAIST), 堤田 恭太, 村瀬 文彦, 三谷 陽 (デンソー), 渡辺 太郎 (NAIST)",特定ドメインを対象とする検索タスクにおいて埋め込みモデルのドメイン適応は重要であるが，対象とするドメインの種類数が膨大な場合には追加学習による方法を適用するのは難しい．本研究では，ニューラルモデルに基づく密ベクトル検索において，モデルを追加学習することなくドメイン適応させる方法を提案する．具体的には，ドメイン適応先の単言語コーパスからクエリのk 近傍事例を計算して，近傍事例の埋め込み表現を統合した表現によってクエリの表現を調整する．実験では，独自に収集するデータを用いた故障事例検索タスクにおいて，提案法により検索性能が向上すること，また検索結果が解釈性の向上につながることを示す．
C9:情報検索・テキストマイニング3月13日（木） 10:20-11:50   C会場(1F会議室103),C9-4,VDocRAG: 視覚的文書に対する検索拡張生成,/proceedings/annual_meeting/2025/pdf_dir/C9-4.pdf,"○田中 涼太 (NTT/東北大), 壹岐 太一, 長谷川 拓, 西田 京介, 齋藤 邦子 (NTT), 鈴木 潤 (東北大)",視覚的に表現された文書から成るコーパスを知識源に持つ新たな検索拡張生成（RAG）フレームワークであるVDocRAG を提案する．VDocRAG は多様な文書を画像形式で統一的に理解することで，視覚的文書に含まれる図や表などの視覚情報を直接利用できる．VDocRAG の性能向上を目的として，大規模視覚言語モデルを検索タスクに適応させる新たな自己教師あり事前学習タスクを提案する．更に，多様な文書形式を網羅するオープンドメイン視覚文書質問応答データセットであるOpenDocVQA を導入する．実験により，VDocRAG は従来のテキストベースRAG を大幅に上回る性能を示し，優れた汎化能力を有することが確認された．
C9:情報検索・テキストマイニング3月13日（木） 10:20-11:50   C会場(1F会議室103),C9-5,検索エンジンを指向したLLMのアラインメント,/proceedings/annual_meeting/2025/pdf_dir/C9-5.pdf,"○益子 怜 (横浜市立大), 木村 賢 (サイバーエージェント), 越仲 孝文 (横浜市立大)","大規模言語モデル(LLM) の応用の一つに, 検索エンジン最適化(SEO) の目的に沿った高品質なWebコンテンツ生成が挙げられる. 本研究では, コンテンツの品質指標であるユーザ評価をターゲットとしたLLM の調整(アラインメント) を行い, 高品質かつ長文のコンテンツの生成を目指す. Google 検索により取得したWeb コンテンツと, コンテンツに対しユーザ評価ラベルを付与したデータセットを利用して, 指示チューニングとDirect Preference Optimization(DPO) によるアラインメントを行なった. 評価の結果, 生成コンテンツの質と長さの両面で改善が確認できた."
C9:情報検索・テキストマイニング3月13日（木） 10:20-11:50   C会場(1F会議室103),C9-6,RAGの応答正確性と連続応答性能の自動評価,/proceedings/annual_meeting/2025/pdf_dir/C9-6.pdf,"○岩間 太, 竹内 幹雄 (IBM)",RAG に基づく質問応答システムによる応答の正確性を自動評価する方法を提案する。特徴は、知識ベース中のコンテキストを、質問、正答例と同時に考慮して、生成回答をLLM で評価する点である。特にコンテキストの選び方に工夫を施す。また、マルチターンの質問応答における連続応答の性能を測るための評価観点を導入し、この観点での評価を自動化する。その後、人手評価との相関、および、連続応答性能の差の検出に基づいた評価実験を実施し、これらの提案手法の有効性、実効性を確認する。
D9:対話(2)3月13日（木） 10:20-11:50   D会場(1F会議室107),D9-1,Japanese MT-bench++: より自然なマルチターン対話設定の日本語大規模ベンチマーク,/proceedings/annual_meeting/2025/pdf_dir/D9-1.pdf,"○植松 拓也, 福田 創, 河原 大輔 (早大), 柴田 知秀 (LINEヤフー)","大規模言語モデル(LLM) の能力を網羅的に評価するのは大変に難しい課題である。LLM のベンチマークの一つに、マルチターンの対話的タスク遂行能力を評価するMT-bench があり、日本文化に合うように改編されたJapanese MT-bench も構築されている。しかし、これらのデータセットは80 問と小規模であることと、2 ターン目の質問が1 ターン目の回答に依存していないという問題がある。我々はクラウドソーシングを用いることにより、5,000 問程度にまで大規模化し、より広範に評価を行えるベンチマークを構築する。1 ターン目の質問はワーカー、回答はワーカーとLLM によって作成することにより、多様な回答を得る。2 ターン目の質問を作成する際は1 ターン目の各回答に対して作成し、より自然な対話設定となるようにする。"
D9:対話(2)3月13日（木） 10:20-11:50   D会場(1F会議室107),D9-2,Exploring LLM-based Data Synthesis Strategies for Conversational Semantic Frame Analysis,/proceedings/annual_meeting/2025/pdf_dir/D9-2.pdf,"○◊松田 思鵬, Yin Jou Huang, Fei Cheng (京大), 清丸 寛一 (NII), 村脇 有吾 (京大)","Creating training data for supervised learning mod-els has traditionally been time-consuming and costly.However, recent advancements in large language models(LLMs) have enabled many studies to leverage these mod-els for synthesizing training data. In this paper, we exploredata synthesis strategies for conversational semantic frameanalysis, a complex task involving the extraction of enti-ties and relations from dialogue contexts. We propose twonovel methods tailored for this purpose: Forward Synthesisand Reverse Synthesis. Our results demonstrate that For-ward Synthesis can achieve performance levels comparableto its creator LLM. Additionally, we provide an in-depthanalysis of Reverse Synthesis, highlighting the challengesin this approach."
D9:対話(2)3月13日（木） 10:20-11:50   D会場(1F会議室107),D9-3,「松下幸之助」 再現AIシステムの開発,/proceedings/annual_meeting/2025/pdf_dir/D9-3.pdf,"○大西 直 (松尾研究所), 高岸 智 (パナソニックホールディングス), 鎌田 理久 (松尾研究所), 山西 宏平 (パナソニックホールディングス), 神崎 雄介, 小林 拓, 徐 暁琳, 菅原 陸, 杉浦 いぶき, 篠崎 友悠 (松尾研究所), 河村 岳 (パナソニックホールディングス)",本研究では、松下幸之助の思想や発言を忠実に再現する「松下幸之助」再現AI システムを開発した。音声認識、返答生成、音声合成、動画生成の4 つのAI モデルを統合し、ユーザとの自然な対話を可能にした。本システムは、膨大な著作物や音声データを学習対象とし、データクレンジングやリアルタイム処理の最適化、さらにドメイン知識の活用により、精度と自然さを大幅に向上させている。実験結果では、提案手法が返答生成の正確性、松下幸之助らしさ、応答の適切な長さなどの評価項目で高い性能を示し、史実に基づく自然な応答生成を実現した。これにより、企業理念の継承や文化的遺産の保存など、多様な領域での生成AI 技術の新たな応用可能性が示唆された。
D9:対話(2)3月13日（木） 10:20-11:50   D会場(1F会議室107),D9-4,MQM-Chat: 対話翻訳のための多次元品質指標,/proceedings/annual_meeting/2025/pdf_dir/D9-4.pdf,"○◊Yunmeng Li (東北大), 鈴木 潤 (東北大/理研), 森下 睦 (フューチャー/東北大), 阿部 香央莉 (MLS/東北大/理研), 乾 健太郎 (MBZUAI/東北大/理研)",対話翻訳におけるスタイライズされたコンテンツや対話の一貫性は，機械翻訳にとって重要な課題である．本研究では，これらの問題を評価する指標として「対話翻訳のための多次元品質評価基準（MQM-Chat）」を提案する．MQM-Chat は曖昧さ，流行語，対話不整合性などの7 種類のエラータイプで構成される．5 つの機械翻訳モデルで生成した対話データに対し，人間によるアノテーションを行った結果，MQM-Chat は既存の評価基準よりも効果的にエラーを分類し，対話特有の問題を明確に示した．
D9:対話(2)3月13日（木） 10:20-11:50   D会場(1F会議室107),D9-5,対話データにおける個人の評価傾向の違いの分析 - 個人の評価傾向を反映した対話システム自動評価に向けて -,/proceedings/annual_meeting/2025/pdf_dir/D9-5.pdf,"○亀山 京右, 駒谷 和範 (阪大)",良い対話システムの定義はシステムの用途や評価する個人によって様々である．本研究では，システム設計者など特定の個人の評価傾向を反映した対話システムの自動評価手法を目指す．事前調査として，対話評価における個人差を定量的に分析した．具体的には，対話評価用データセットに付与されている各評価者の評価値から評価傾向の違いを検証した．結果として，評価者間の相関は低く，重視する評価軸の相違が確認された．
D9:対話(2)3月13日（木） 10:20-11:50   D会場(1F会議室107),D9-6,人はなぜ笑うのか？対話における笑いの根拠ラベルの半自動構築,/proceedings/annual_meeting/2025/pdf_dir/D9-6.pdf,"○井上 昂治, Mikey Elmers, Divesh Lala, 河原 達也 (京大)",笑いは人間どうしの対話において多面的なシグナルとして機能するが、これを適切に認識・生成することは、自然な対話の実現を目指す対話システムにとって大きな課題である。本研究では、日本語対話データに対して「笑うことができる文脈（laughablecontext）」をアノテーションし、さらにその判断の根拠を分類するためのラベルを、大規模言語モデル（LLM）を活用して半自動的に構築した。まず複数のアノテーターにより、対話データの各発話に対して、対話相手が笑うことができるか否かの二値を判定してもらった。次に，LLM を用いてこの二値の判断の根拠を説明する文を生成し、さらにこられを分類する根拠ラベルを生成した。その結果、「共感と親近感」「ユーモアと意外性」「リラックスした雰囲気」などを含む10 種類のラベルが生成された。また、LLM に上記の二値判断を認識させたところ、F1 スコアで43.1%となり、LLM が自然な対話における笑いを認識することの課題と可能性を明らかにした。
E9:テーマセッション3: 認知・脳と自然言語処理(2)3月13日（木） 10:20-11:50   E会場(1F会議室108),E9-1,統語情報は脳情報デコーディングに寄与するのか？,/proceedings/annual_meeting/2025/pdf_dir/E9-1.pdf,"○赤間 美香, 梶川 康平, 大関 洋平 (東大)",近年、大規模言語モデル（LLM）を活用し、脳活動データから言語表現を直接復元する脳情報デコーディングの手法が注目されている。一方、言語学や認知神経科学では、脳活動と言語表現の間に統語構造などの中間表現が存在することが広く想定されてきた。では、脳情報デコーディングにおいて、言語表現を直接復元するのではなく、統語情報のような中間表現を明示的に利用することで、デコーディング精度が向上する可能性はあるのだろうか。本研究では、脳波データを用いて言語生成を行うBrainLLM を活用し、品詞情報を中間表現として取り入れることで、デコーディング精度が向上するのか検証した。その結果、統語情報の考慮がデコーダーの性能向上に寄与する可能性が示唆された。
E9:テーマセッション3: 認知・脳と自然言語処理(2)3月13日（木） 10:20-11:50   E会場(1F会議室108),E9-2,Cognitive Preference Optimization: 脳情報による言語モデルの選好最適化,/proceedings/annual_meeting/2025/pdf_dir/E9-2.pdf,"○原田 宥都, 大関 洋平 (東大)",近年の大規模言語モデルの性能向上において、Direct Preference Optimization (DPO) によるモデルのアラインメントの成功が大きな役割を果たしている。しかし、学習で用いられるラベルの作成には多大なコストが必要であり、作業者の負担も大きい。本研究では、作業者がテキストを読んでいる際の脳波から選好情報を抽出し、それに基づきモデルを学習する手法としてCognitive Preference Optimization (CPO) を新たに提案する。CPO では、作業者はテキストを読むだけでラベルを作成でき、負担の軽減が期待できる。人間のフィードバックを用いた場合と比較して、手法の妥当性を検証した。
E9:テーマセッション3: 認知・脳と自然言語処理(2)3月13日（木） 10:20-11:50   E会場(1F会議室108),E9-3,二重課題は言語モデルの合理的な言語理解ストラテジーを促進する,/proceedings/annual_meeting/2025/pdf_dir/E9-3.pdf,"○江村 玲 (東北大/NII), 菅原 朔 (NII)",計算に使うメモリ資源を制限すると，言語モデルは人間の読み時間をより正確に予測する．本研究は，この知見は言語理解ストラテジーにも当てはまるのか調べた．具体的には，GPT-4o は，人間と同じように，メモリ資源が制限されると，非妥当な文を妥当な意味で理解するという合理的な言語理解ストラテジーを使用しやすくなるか検証した．メモリ資源の制約のために，“The 2 cocktail + blended 3 =...”のように，計算問題と言語理解を同時に行う二重課題を設計して実行した．結果，このようなストラテジーの変化を観察した．これは，合理的な言語理解ストラテジーへの転換はメモリ資源の制限が原因の一つであることを支持する．
E9:テーマセッション3: 認知・脳と自然言語処理(2)3月13日（木） 10:20-11:50   E会場(1F会議室108),E9-4,しりとり単語系列の特徴を制御する認知的要因に関する認知モデルを利用した調査,/proceedings/annual_meeting/2025/pdf_dir/E9-4.pdf,"○西川 純平, 佐々木 康佑, 森田 純哉 (静大)",LLM の進展は目覚ましく，人間の言語機能に迫る部分もある．伴って，人間の言語使用を理解するための研究の意義も高まっている．本研究では，言語使用に関するシンプルな課題として「しりとり」に注目し，その特徴に関わる認知的要因を明らかにすることを目的とする．このために，認知アーキテクチャの基本的な記憶メカニズムを基盤としてしりとりの遂行をモデル化し，そのパラメータを調整するシミュレーションによって，しりとりの単語系列に現れる特徴を調査する．結果として，語彙の活性化と抑制や意味的な連想の設定によって，特徴の異なるしりとり単語系列が得られた．しりとりの特徴を制御可能なモデルの構築により，HAI 研究や言語獲得支援研究への刺激としての応用が期待される．
E9:テーマセッション3: 認知・脳と自然言語処理(2)3月13日（木） 10:20-11:50   E会場(1F会議室108),E9-5,母音想起時における脳信号の周波数特性に基づいた想起区間検出,/proceedings/annual_meeting/2025/pdf_dir/E9-5.pdf,"○栗栖 駿, 入部 百合絵 (愛県大)",音声想起時脳波から想起言語を識別する研究が進められている．音声認識とは異なり，脳波による音声言語識別の研究では，想起区間が明確ではないため，広範囲に想起区間を対象としている．そのため，想起していない区間から言語情報を検出することになるため，識別精度の劣化が考えられる．そこで本稿では，想起言語の識別精度向上を目標に，5 母音を対象とした音声想起時脳波における想起区間検出について報告する．本報告では，定 Q 変換による時間周波数特性とコヒーレンス解析による位相同期を用いて想起と無想起の差異を測るとともに，それらの特徴をもとに3DCNN により想起区間検出を行った．その結果，位相同期では，最大約80%の精度で想起区間推定に成功したが，個人差が大きく生じていることが分かった．一方，時間周波数特性を用いた想起区間検出は，約70%の精度を得た．
E9:テーマセッション3: 認知・脳と自然言語処理(2)3月13日（木） 10:20-11:50   E会場(1F会議室108),E9-6,調音運動前の言語中枢間の位相同期を用いた母音認識,/proceedings/annual_meeting/2025/pdf_dir/E9-6.pdf,"○長瀬 南帆, 入部 百合絵 (愛県大)",近年，発話したときの脳波を言語に変換するBrain to Text の研究が進められている．このシステムには，舌や口唇などの調音器官の障害により明瞭な発音が困難である人々への意思伝達支援が期待されている．しかし，脳波は信号雑音比が低い上，調音器官の運動，すなわち調音運動による筋電図信号が重畳されるなど，雑音の重畳が課題である．そこで本研究は，雑音の少ない調音運動前の脳波から日本語5 母音を認識することを目的とする．特に，言語を音声として出力するための準備を担うブローカ野とウェルニッケ野の2 つの言語中枢に着目する．調音運動前の言語中枢間の位相同期を用いることで，日本語5 母音の認識精度が69.6%を達成した．
P9:ポスター3月13日（木） 10:20-11:50   P会場(2Fコンベンションホール3+4),P9-1,オンラインニュースコメントを対象としたアスペクトベースのコメントフィルタリングシステム,/proceedings/annual_meeting/2025/pdf_dir/P9-1.pdf,"○笠原 璃音, 大和 淳司, 菊井 玄一郎 (工学院大)",SNS やオンラインニュースのコメント欄では，誹謗中傷など知りたくない情報に触れることが多く，精神的な負担を感じる人が増えている．NG ワード設定によるフィルタリングの手法もあるが，攻撃的なコメントを完全に防ぐことは難しい．また，既存のコメント表示アルゴリズムは古いコメントを優位に扱う仕様であるため，新しく投稿された有益なコメントが埋もれてしまい，得たい情報を得ることができないという問題もある．これらの課題を解決するために，誹謗中傷表現を含まない建設的なコメントを抽出し，建設的度合いを閲覧者が調節できるシステムを提案した．本研究では，コメントのアスペクト情報を基に建設的度合いを推定する推定器を作成し，GPT4 と比較した実験で提案手法の有効性を確認した．
P9:ポスター3月13日（木） 10:20-11:50   P会場(2Fコンベンションホール3+4),P9-2,事前学習コーパス内の特定の属性への言及の急激な変化の調査,/proceedings/annual_meeting/2025/pdf_dir/P9-2.pdf,"○大萩 雅也, 綿岡 晃輝, 高山 隼矢, 吉川 克正 (SB Intuitions)","Web からクロールされた事前学習コーパス内の有害性を含む文章がLLM の有害な出力を引き出すことは知られているが、事前学習コーパス内の有害性が時とともにどのように変化するかは十分に調査されていない。特に、紛争の勃発や移民問題などの社会問題を通じて2,3 年単位で世論に起きた急激な変化がどのようにコーパスに影響を与えるかは未だ調査されていない。本研究では近年その取り巻く環境が大きく変わった民族に対する言及がどのように変化しているかを、事前学習に用いられることの多いCommonCrawl の日本語データを対象として調査する。結果としてCommonCrawl では紛争などの事象が発生した時期を境として、特定の属性に対する有害な文脈を伴う言及が増加することが確認された。"
P9:ポスター3月13日（木） 10:20-11:50   P会場(2Fコンベンションホール3+4),P9-3,Advancements in Sentiment Analysis: A Methodological Examination of News using multiple LLMs,/proceedings/annual_meeting/2025/pdf_dir/P9-3.pdf,"Muhammad Ali Mahmood (GIK Institute), ○◊Iffat Maab (NII), Muhammad Sibtain, Asima Sarwar (GIK Institute), Muhammad Arsalan (TU Braunschweig), Masroor Hussain (GIK Institute)","As the digital news consumption continues to grow,sentiment analysis has become essential for understand-ing public opinion and the impact of media. TraditionalNLP methods often fail to capture the in-depth emotions innews content, especially when taken from various mediasources. This work identiﬁes gaps in the use of ﬁne-tuneddeep learning models and large language models (LLMs)without ﬁne-tuning in the sentiment analysis of news arti-cles, oﬀering enhanced insights across various model fam-ilies. In our work, we collect news from BBC, and annotateBBC dataset using the proprietary OpenAI GPT-3.5-turbomodel, and ﬁne-tune models such as DistilBERT, BERT,and RoBERTa-large. We also compare ﬁne-tuned modelswith LLM variants including Llama-3 and Qwen-2 modelswithout any model ﬁne-tuning through crafted prompts.Our results show that RoBERTa-large achieved the highestperformance, delivering an accuracy of 86%."
P9:ポスター3月13日（木） 10:20-11:50   P会場(2Fコンベンションホール3+4),P9-4,Investigating Implicit Reasoning in Counter-Argument Logical Structure Analysis,/proceedings/annual_meeting/2025/pdf_dir/P9-4.pdf,"○Wenzhi Wang (東北大/理研), Paul Reisert (Beyond Reason), 内藤 昭一 (東北大/理研/リコー), 井之上 直也 (JAIST/理研), 震明 万智 (東北大), Surawat Pothong (JAIST), Jungmin Choi (理研), 乾 健太郎 (MBZUAI/東北大/理研)","Counter-ArgumentLogicalStructureAnalysis(CALSA) is a task that analyzes logic patterns of acounter-argument in relation to an initial argument.Itholds substantial educational value, as informative feed-back for improving counter-arguments can be providedbased on the analyzed logic pattern.However, due tothe complex nature of the task, the implicit reasoningskills required to identify these underlying logic patternspresent signiﬁcant challenges for current LLMs.Toaddress this, we explore decomposing the logic patternsinto ﬁne-grained logic components and tackling themindividually.Our experimental results demonstrateimprovements compared to identifying coarse-grainedlogic patterns.More importantly, we ﬁnd that whetherpredicted logic patterns can be considered plausibledeeply depends on the degree of implicitness involved ininterpreting an argument."
P9:ポスター3月13日（木） 10:20-11:50   P会場(2Fコンベンションホール3+4),P9-5,YouTube動画コメントを用いた視聴者感情の推定と感情処理能力の比較,/proceedings/annual_meeting/2025/pdf_dir/P9-5.pdf,"○菅野 祐希 (工学院大), 坂野 遼平 (一橋大)",YouTube やTikTok に代表される動画共有サービスは，現代において様々な人の行動や選択に大きな影響力を持つようになっている．それにより動画共有サービスはビジネスやマーケティングの場としても活用されるようになった．視聴者が動画を閲覧することでどのような感情を得るかという情報は，視聴者とマーケターの両方において有益となる．本稿では，オンライン動画共有サービス上にアップロードされた動画に付けられたコメントから，動画の視聴者に引き起こされる感情の推定を行う手法を提案する．BERT 及び数種類の大規模言語モデル(LLM)を用い，動画コメントを利用した各モデルの感情推定に関する能力の違いを明らかにする．提案手法では，7 種類の感情の強さを成分とした7 次元ベクトルにより感情を表現し，推定を行う．実験の結果，
P9:ポスター3月13日（木） 10:20-11:50   P会場(2Fコンベンションホール3+4),P9-6,LLM を利用した Zero Shot 評判分析の性能調査,/proceedings/annual_meeting/2025/pdf_dir/P9-6.pdf,"○佐藤 匠真, 新納 浩幸 (茨大)",本論文では，LLM を利用したZero Shot の評判分析における性能調査について報告する．実験では，評判分析のデータとしてWebis-CLS-10 データセットを使用し，LLM としてGPT-3.5-turbo，GPT-4o，Llama 3.1-Swallow-8B を用いた．結果として，極性判定では，LLM を利用した場合，Zero Shot でも高い精度が得られることが確認された．一方で，livedoor記事のカテゴリ分類を行う場合には，Zero Shot の精度が低いという結果となった．また，Zero Shot で日本語のAmazon レビューの評判分析を実施する際，LLM にその判定根拠を提示させると精度が低下することが確認された．
P9:ポスター3月13日（木） 10:20-11:50   P会場(2Fコンベンションホール3+4),P9-7,SNS投稿によるユーザの意見変化の予測と要因分析,/proceedings/annual_meeting/2025/pdf_dir/P9-7.pdf,"○増川 哲太, 狩野 芳伸 (静大)","ソーシャルメディアの普及により，個人が意見を発信し，他者の意見を取り入れることが容易になった．本研究では，対象ユーザの投稿文履歴，リポストした投稿文履歴，これら履歴のいいね数やリポスト数から, 直後に意見が変化するかの予測を試みた．結果, 80%前後の予測性能を達成し, リポスト投稿文が顕著に予測に貢献すること, 要因として投稿文内容からの直接の予測よりもユーザ属性からの間接的な予測が大きいと思われることが分かった."
P9:ポスター3月13日（木） 10:20-11:50   P会場(2Fコンベンションホール3+4),P9-8,テキスト平易化パラレルコーパスに基づく教師なし文難易度推定,/proceedings/annual_meeting/2025/pdf_dir/P9-8.pdf,"○宮田 莉奈 (愛媛大/朝日新聞社), 浦川 通, 田森 秀明 (朝日新聞社), 梶原 智之 (愛媛大)",本研究では、絶対的な文難易度が付与されていないコーパスから文難易度推定器を訓練し、所与の文集合を難易度でランキングする課題に取り組む。文難易度は読み手の知識に依存するため、客観的かつ絶対的な難易度の判定には専門家による高コストな評価が必要となる。そのため、絶対的な文難易度が付与されたコーパスは少ないが、2 文間の相対的な文難易度が付与されたテキスト平易化パラレルコーパスは比較的多くの言語で利用できる。本研究では、多言語展開を念頭に置き、テキスト平易化パラレルコーパスに基づく文難易度推定の手法を提案する。英語における評価実験の結果、提案手法は既存の教師なし文難易度推定の性能を上回るとともに、絶対的な文難易度のラベル付きコーパスで訓練した教師あり手法にも匹敵する性能を達成した。
P9:ポスター3月13日（木） 10:20-11:50   P会場(2Fコンベンションホール3+4),P9-9,ソーシャルメディアにおける投稿およびユーザの政治的傾向予測と政治的投稿フィルタによる性能向上,/proceedings/annual_meeting/2025/pdf_dir/P9-9.pdf,"○佐橋 優人, 狩野 芳伸 (静大)",ソーシャルメディア投稿の政治的傾向を予測することを目的とし，政治的投稿であるか検出するモデルを事前に構築したうえで，データを政治的投稿かどうかでフィルタしてから，学習・評価する方法を提案する．異なるソーシャルメディアプラットフォームの投稿を用いた検証では，フィルタを用いる提案手法がフィルタなしの評価結果を大幅に上回り，国会議員投稿におけるアカウントの与野党分類では最大でF1 値が13 ポイント向上した．
P9:ポスター3月13日（木） 10:20-11:50   P会場(2Fコンベンションホール3+4),P9-10,発話スタイルの類似とユーザ本人による対話の好ましさの相関,/proceedings/annual_meeting/2025/pdf_dir/P9-10.pdf,"○沼屋 征海, 守屋 彰二 (東北大), 佐藤 志貴 (東北大/サイバーエージェント), 赤間 怜奈, 鈴木 潤 (東北大/理研)",対話システムのユーザ本人にとって好ましい応答生成に向け，ユーザの嗜好等を発話内容に反映する試みが盛んに行われている．一方，生成する発話のスタイルもシステムへの印象に影響を与える可能性が先行研究で示唆されている．本研究では，ユーザの過去発話に対するシステム発話のスタイル類似度を自動評価する手法を提案し，システム発話のスタイル類似度とユーザによるシステムの主観評価との相関を調査する．両者の間で正の相関を確認し，発話スタイルの類似がユーザ個人にとっての対話の好ましさの一側面となっていることを明らかにした．
P9:ポスター3月13日（木） 10:20-11:50   P会場(2Fコンベンションホール3+4),P9-11,Short and long-range comedy generation and understanding using Large Language Models,/proceedings/annual_meeting/2025/pdf_dir/P9-11.pdf,"○◊Edison Marrese-Taylor (産総研/東大), Machel Reid (グーグル), Alfredo Solano (東大)","We study the automatic detection and generation of hu-morous and ironic text, both in short and long range scenar-ios. For the former, we propose a style-transfer approach,which we utilize to generate humorous news headlines byexploiting a combination of classiﬁcation and generativemodels based on medium-sized language models. For thelatter, we introduce a new dataset of full stand-up comedyspecial scripts, which we use as an arena to generate andclassify humorous content using LLMs."
P9:ポスター3月13日（木） 10:20-11:50   P会場(2Fコンベンションホール3+4),P9-12,係り受け木を考慮するグラフ畳み込みニューラルネットワークによる日本語アスペクトベース感情分析,/proceedings/annual_meeting/2025/pdf_dir/P9-12.pdf,"○山口 真, 狩野 芳伸 (静大)",アスペクトベースの感情分析は，文中の複数のアスペクト語に対する感情極性を特定するタスクである．近年の研究では極性の推定をするために係り受け木を用いてアスペクト語に対するオピニオン語を特定する手法が提案されているが，この手法は英語においてのみ実験されており，日本語における研究では，係り受け木を用いたものはない．そこで本研究では，日本語において係り受け木を用いてアスペクトベースの感情分析を行う手法を提案する．日本語データセットでの感情分析実験により，我々の提案手法が既存の手法よりも優れていることを示す．
P9:ポスター3月13日（木） 10:20-11:50   P会場(2Fコンベンションホール3+4),P9-13,Sentiment Analysis of YouTube Videos in the 2024 Indonesian Presidential Election,/proceedings/annual_meeting/2025/pdf_dir/P9-13.pdf,"○◊Zaidan Yahya, 秋葉 友良 (豊橋技科大), 木村 泰知 (小樽商大), 御器谷 裕樹 (慶應大), 森 浩太 (JDSC), 吉田 光男 (筑波大), 粕谷 祐子 (慶應大)","Social media platforms like YouTube have become pow-erful tools for shaping public opinion during elections inrecent years. This study examines the sentiments in theYouTube videos concerning three presidential candidatesin the 2024 Indonesian election. We ﬁrst classify the videosinto three categories: candidate’s oﬃcial channel, publicnews, and third-party-created sources. Next, we performsentiment analysis on each video and calculate a metric, theSentiment Impact Score (SIS), to quantify the overall sen-timent dynamics. Our ﬁndings reveal a signiﬁcant shift inpublic sentiment, ultimately favoring the elected candidate,especially among the third-party created videos."
P9:ポスター3月13日（木） 10:20-11:50   P会場(2Fコンベンションホール3+4),P9-14,評価対象抽出における関連タスクを利用したfew-shot 選択手法,/proceedings/annual_meeting/2025/pdf_dir/P9-14.pdf,"○今里 昂樹, 嶋田 和孝 (九工大)",本研究では，評価対象抽出を対象とし，その対象タスクと関連したタスクを利用した効果的なfew-shot 選択手法を提案する．評価対象抽出は，テキストから評価の対象となる特定の要素を抽出するタスクであり，データセットの不足が課題となっている．提案手法では，関連タスクとして極性分類のデータを活用し，Information Gain（IG）を用いてfew-shot を選択することで，評価対象抽出の訓練データ不足の問題を補いながらモデルの性能向上を目指す．実験では5 分割交差検証を実施し，ベースラインを上回る精度を達成した．
P9:ポスター3月13日（木） 10:20-11:50   P会場(2Fコンベンションホール3+4),P9-15,絵文字のマッピングを用いた感情表現の分析手法の検討,/proceedings/annual_meeting/2025/pdf_dir/P9-15.pdf,"○津田 恵佑, 深草 理貴, 森 辰則 (横国大)",テキストと付随する絵文字の表す感情は一致することが普通であるが、そうでないものも存在する。テキストと絵文字の感情の組み合わせには様々な類型があり、それらがどのような感情の機微を示しているのかを自動的に読み取るのは現状困難である。本論文は、絵文字付きテキストのテキストと絵文字の感情を同一平面上で可視化するマッピングを行うことで、その分布からレトリカル絵文字を定量的に検出し、それらの持つ感情の機微の分析を行った。この結果を用いることにより、絵文字付きテキストの感情分析をより詳細に行えるようになることが期待できる。
P9:ポスター3月13日（木） 10:20-11:50   P会場(2Fコンベンションホール3+4),P9-16,大規模言語モデルによる日本語スタイル変換の性能評価,/proceedings/annual_meeting/2025/pdf_dir/P9-16.pdf,"○花房 健太郎, 柳本 大輝, 梶原 智之, 二宮 崇 (愛媛大)",本研究では，日本語における大規模言語モデルのスタイル変換性能を広く調査する．まず，英語において研究されてきた11 種類のスタイル変換を対象に，それぞれ120 件の日本語文対を人手で作成し，日本語スタイル変換の評価用データセットを構築した．そして，12 種類の日本語大規模言語モデルを対象に，0-shot および20-shot の文脈内学習によるスタイル変換の性能を評価した．評価実験の結果，指示チューニング済みのモデルは指示チューニング前のモデルよりもスタイル変換の性能が大幅に改善されること，パラメータ数の多いモデルの方がfew-shot文脈内学習によって性能がより改善されること，factual →romance およびoﬀensive →non-oﬀensive のスタイル変換が難しいことが明らかになった．
P9:ポスター3月13日（木） 10:20-11:50   P会場(2Fコンベンションホール3+4),P9-17,教師有り学習モデルと大規模言語モデルを組み合わせた低評価レビューを考慮したレビュー文書の評価値推定,/proceedings/annual_meeting/2025/pdf_dir/P9-17.pdf,"○竹尾 匡貴, 嶋田 和孝 (九工大)",本研究では，教師有り学習モデルと大規模言語モデルを組み合わせた，レビュー文書の評価値推定に取り組む．低評価なレビュー文書は，高評価なレビュー文書に比べて少数派であることが考えられる．そのような場合，教師有り学習モデルによる分類では，特に少数派のクラスの精度が悪化する傾向がある．そこで，低評価レビュー文書の推定にのみ，追加学習無くタスクを解ける大規模言語モデルを導入する．実験の結果から，教師有り学習モデルやデータ拡張手法よりも少数派クラスの精度が改善したことを確認した．また，大規模言語モデルのみの推定よりも，全体の精度バランスが良いことも確認した．
P9:ポスター3月13日（木） 10:20-11:50   P会場(2Fコンベンションホール3+4),P9-18,バックトラッキングを活用したマルチエージェントシステムによる複数制約充足プランニング,/proceedings/annual_meeting/2025/pdf_dir/P9-18.pdf,"○守屋 彰二 (SB Intuitions/東北大), 大萩 雅也 (SB Intuitions)",大規模言語モデル(LLM) の発展に伴い，旅行計画や経路探索などの実世界の応用タスクを自律的に解決するLLM エージェントの実現が期待されている．しかし，単一のLLM エージェントが複数の制約を同時に満たすプランニングを行うことは依然として困難である．この課題に対し，タスクを細分化して負荷を分散させるマルチエージェントシステムの協調アプローチが有効であると考えられる．本研究では，実世界旅行計画ベンチマーク『TravelPlanner』を対象とし，複数制約充足プランニングにおけるマルチエージェントシステムの有効性を検証した．実験の結果，制約充足率の向上が確認された一方で，エージェント間の情報伝達の欠落など，マルチエージェントシステム特有の課題も確認された．
P9:ポスター3月13日（木） 10:20-11:50   P会場(2Fコンベンションホール3+4),P9-19,TEPPAY: ゲームのプレイ動画を入力とする実況AI Tuberシステムの提案,/proceedings/annual_meeting/2025/pdf_dir/P9-19.pdf,"○栗原 健太郎 (AI Shift/サイバーエージェント), 吉野 哲平, 高市 暁広, 岩田 伸治 (サイバーエージェント), 長澤 春希 (AI Shift/サイバーエージェント), 佐藤 志貴, 岩崎 祐貴 (サイバーエージェント)",YouTuber やVTuber などの動画配信への関心が高まっている。しかし、動画配信を支援するソフトウェアの複雑さや、実況能力への不安から動画配信の参入障壁は高い。本研究では、大規模言語モデル等を活用して気軽な実況配信を実現するシステム:TEPPAY を提案する。TEPPAY はシーン検出や発話生成などを行う7 つのモジュールで構成されている。TEPPAY を構成するモジュールの性能調査の結果、配信に必要な最低限の性能は担保しているものの、視聴者の興味を惹く魅力的な実況動画を作成する上でいくつか課題があることを確認した。
P9:ポスター3月13日（木） 10:20-11:50   P会場(2Fコンベンションホール3+4),P9-20,行動認識の粒度アライメントに基づく予定の履行認識,/proceedings/annual_meeting/2025/pdf_dir/P9-20.pdf,"○藤田 一天 (NAIST), 河野 誠也 (理研/NAIST), 吉野 幸一郎 (科学大/理研/NAIST)",キャプショニングなどを用いた状況認識により，動画内のユーザ行動を自然言語で表現することが可能になった．しかし，このように認識されたユーザー行動を事前に定義された行動予定と比較して履行判断に用いようとする場合，テキストで表現される行動の粒度が問題となる．そこで，本研究では言い換えモデルを用いてテキストで認識した動画内のユーザー行動を言い換え，行動予定に対してアライメントを取るモデルを提案する．言い換えによって生成された行動とあらかじめ定義された予定行動を自動評価手法によって比較し，履行が判断できる閾値を設定することで予定の履行を適切に評価できることを確認した．
P9:ポスター3月13日（木） 10:20-11:50   P会場(2Fコンベンションホール3+4),P9-21,Psychological Investigation of Personality Knowledge in a Large Language Model,/proceedings/annual_meeting/2025/pdf_dir/P9-21.pdf,"○趙 梓程 (京大/理研), 岩井 律子 (理研), 淺井 二千夏 (京大), 熊田 孝恒 (京大/理研)","The purpose of this study is to investigate the knowledgeof personality in a LLM using a psychometric methodol-ogy. In Experiment 1, a standard psychological question-naire is used to measure the personality proﬁle of the LLMand showed that the model has some knowledge aboutpersonality.Experiment 2 examined the scores of BigFive personality questions in the LLM when a wide rangeof personality descriptions were submitted as prompts tothe model. The results showed that the LLM has similarpersonality knowledge as humans. Implications for LLMresearch and psychological research are discussed."
P9:ポスター3月13日（木） 10:20-11:50   P会場(2Fコンベンションホール3+4),P9-22,関連研究節自動生成に向けた引用論文の最適配置,/proceedings/annual_meeting/2025/pdf_dir/P9-22.pdf,"○大鹿 雅史, 笹野 遼平 (名大)",関連研究節生成のためには，引用する論文を決定した上で，どのような段落構成や順序で論文を引用するかという論文配置を考える必要がある．しかし，関連研究節自動生成に関する既存研究では，引用すべき論文を推薦する引用推薦や，引用論文と引用順が与えれらた場合に関連研究節を自動生成する研究は多く行われているものの，引用論文の最適配置には着目されてこなかった．本研究では，関連研究節の自動生成に向けた引用論文の最適配置に取り組む．具体的には，引用論文を段落ごとにまとめるクラスタリング，段落順の決定，段落内の引用順決定という3 タスクに分解し，各タスクを解くことで引用論文の最適配置を実現する．
P9:ポスター3月13日（木） 10:20-11:50   P会場(2Fコンベンションホール3+4),P9-23J,近傍事例を用いた対話における感情認識,/proceedings/annual_meeting/2025/pdf_dir/P9-23.pdf,"○石渡 太智 (NHK), 後藤 淳 (N財団), 山田 寛章, 徳永 健伸 (科学大)",
Q9:ポスター3月13日（木） 10:20-11:50   Q会場(1F会議室101AB),Q9-1,生成型自動要約の信頼性向上を目的とした数値情報の誤り検出と修正手法,/proceedings/annual_meeting/2025/pdf_dir/Q9-1.pdf,"○松井 我颯 (釧路高専), 石川 晴基 (豊橋技科大), 中島 陽子, 本間 宏利 (釧路高専), 秋葉 友良 (豊橋技科大)",自動要約技術は地方議会の議事録やネットニュースなどの情報の処理に有用だが，生成型要約において数値情報の誤りが問題となっている．本研究は，自動要約における数値情報の正確性を向上させるため，松井らが提案した二つの手法であるセグメントの特定による数値探索手法（SSR: SegmentSummaryRevision）と係り受け解析に基づく数値探索手法（DSR: Dependency-basedSummaryRevision）を組み合わせた手法を提案する．提案手法では，まず原文から要約に用いられている数値が含まれる文を特定し，次に用いて特定した文と要約文の数値を文脈に基づき比較する．この一連の処理により，要約文中の数値を識別し，修正する．
Q9:ポスター3月13日（木） 10:20-11:50   Q会場(1F会議室101AB),Q9-2,言語のインクリメンタルな処理の仕組みは普遍的か？：投機性によるparsing strategy再考,/proceedings/annual_meeting/2025/pdf_dir/Q9-2.pdf,"○石井 太河, 宮尾 祐介 (東大)",自然言語はインクリメンタルに読み書きされるが、異なる言語でも、インクリメンタルな処理の仕組みは言語普遍的なのだろうか？本研究では、系列・構造の両方をインクリメンタルに予測する統語的言語モデルが「系列の背後にある統語構造をどの程度投機的に予測するか」をパラメタとし、次トークン予測や構文解析において最適なパラメタが言語共通かを分析する。実験の結果、最適な戦略の言語共通性はタスクやビームサイズにより異なることが観察され、人間と言語モデルの処理メカニズムの違いに関する示唆が得られた。
Q9:ポスター3月13日（木） 10:20-11:50   Q会場(1F会議室101AB),Q9-3,近現代の日本語文学作品における発表年次の予測,/proceedings/annual_meeting/2025/pdf_dir/Q9-3.pdf,"○小川 稜真, 久野 雅樹 (電通大)","本研究では,文学作品のテキストデータを用いた年次予測の可能性を検討した. まず, 芥川龍之介の作品を対象に, TF-IDF を特徴量として複数の回帰モデルを用い, 初出年の予測を行った. その後, 青空文庫に収録された大量の作品に対象を拡大し, 同様に年次予測を試みた. いずれの場合も, 予測は一定の精度で可能であることが示され, 使用される語彙のパタンが年次の推定に有効であることがわかった. 特に, ランダムフォレスト回帰が他のモデルと比較して優れた予測性能を示した."
Q9:ポスター3月13日（木） 10:20-11:50   Q会場(1F会議室101AB),Q9-4,Shift-Reduce 法に基づく漸進的係り受け解析と未入力文節主辞トークン予測の同時実行とその評価,/proceedings/annual_meeting/2025/pdf_dir/Q9-4.pdf,"○橋本 優希, 大野 誠寛 (東京電機大), 松原 茂 (名大)",同時通訳や字幕生成などの音声言語システムに対して，音声入力の途中で随時，構文情報を提供することを目的に，文節が入力されるごとに係り受け構造を同定し出力するという漸進的係り受け解析手法が提案されている．本稿では，さらに豊かな情報を後段のシステムに提供するため，漸進的係り受け解析と未入力文節主辞トークン予測を同時実行する手法を提案する．また，提案手法と人間の漸進的係り受け解析結果を比較し考察する．
Q9:ポスター3月13日（木） 10:20-11:50   Q会場(1F会議室101AB),Q9-5,大規模言語モデルによる要求仕様書の品質評価,/proceedings/annual_meeting/2025/pdf_dir/Q9-5.pdf,"○鈴木 淳 (デンソークリエイト), 村瀬 文彦 (デンソー), 水野 伸洋 (デンソーアイティラボラトリ), 髙木 理恵子, 不破 慎之介 (デンソークリエイト), 塚原 裕史 (デンソーアイティラボラトリ), 中江 俊博 (デンソー)","車載ソフト開発を高品質かつ低コストに実現するために，人手による作業をできる限り自動化することが急務となっている．本研究では特に要求仕様書の品質評価(要求インスペクション) において大規模言語モデル(LLM) による自動化が可能であるかを具体的な事例によって分析した．分析対象として過去に人手で行われたインスペクション結果を用いて，どの程度それらの結果を再現することができるかという再現率及び人手では見逃されていた問題箇所がどれくらい漏れなく指摘できるかという適合率を評価し, LLM 活用の有効性と課題を分析した．その結果, LLM 単独では必ずしも十分な精度を得ることができないが, 正規表現や形態素解析などのルールベース処理や従来の自然言語処理による前後処理と組合わせることで精度を向上できる示唆を得た."
Q9:ポスター3月13日（木） 10:20-11:50   Q会場(1F会議室101AB),Q9-6,大規模言語モデルを用いたシフト還元型句構造解析,/proceedings/annual_meeting/2025/pdf_dir/Q9-6.pdf,"○中根 稜介, 前川 在 (科学大), 上垣外 英剛 (NAIST), 平尾 努 (金大), 奥村 学 (科学大)",大規模言語モデル(LLM) は言語生成のみならず，さまざまなNLP タスクにおいて良好な結果を残している．本稿では，談話構造解析の一つである修辞構造解析において顕著な結果を残した，LLM によるシフト還元型解析法を拡張した句構造解析法を提案する．提案法は，シフト還元型解析でありながら，明示的にスタックとキューを持たず，解析位置をあらわすタグとその左右のテキストでそれを代替する．提案手法を，Penn Treebank (PTB) を用いて訓練し，PTB，Multi-domain Constituent Treebank(MCTB) を用いて評価した結果，従来のLLM を用いたseq2seq モデルによる解析法よりもドメインの違いに頑健であり，どのような文長に対しても安定して高い性能であることを確認した．
Q9:ポスター3月13日（木） 10:20-11:50   Q会場(1F会議室101AB),Q9-7,End-to-Endモデルに基づく漸進的係り受け解析と未入力文節主辞予測の同時実行,/proceedings/annual_meeting/2025/pdf_dir/Q9-7.pdf,"○海野 博揮 (名大), 大野 誠寛 (東京電機大), 伊藤 滉一朗, 松原 茂樹 (名大)",同時通訳のようなリアルタイム言語処理システムでは，文を構成する要素が順次入力される状況において，その入力に即応した出力が求められる．このようなシステムで構文情報を利用できるようにするために，漸進的係り受け解析の研究が行われている．本論文では，深層学習モデルを用いて，End-to-End で漸進的係り受け解析を行う手法を提案する．本手法では，未入力の係り先文節の主辞予測を同時に実行し，漸進的係り受け解析の精度向上を図る．実験により提案手法の解析性能を評価した．
Q9:ポスター3月13日（木） 10:20-11:50   Q会場(1F会議室101AB),Q9-8,大規模言語モデルを用いたカタカナ語の意味分類における出力傾向分析,/proceedings/annual_meeting/2025/pdf_dir/Q9-8.pdf,"○小滝 主紀, 佐々木 稔 (茨大)",大規模言語モデル(LLM) を用いた外来語の意味推論において、和製英語の存在など元来の英単語の意味との違いがモデルの精度に影響を与える可能性がある。外来語の意味を正確に捉えるために、本研究ではBCCWJ から抽出したデータでLLM をFine-tuning し、現状のカタカナ語の意味推論の精度及び出力傾向を分析、精度向上への方策を探る。複数の実験の結果、Zero-shot learning ではFine-tuningの有効性が確認できなかったが、対照的にFew-shotlearning では約10 ％の精度の向上が見られた。出力傾向分析によってモデルの苦手な語義や単語の傾向を得られたため、今後の研究への寄与を期待する。
Q9:ポスター3月13日（木） 10:20-11:50   Q会場(1F会議室101AB),Q9-9,Exploring Dynamic Few-Shot Prompting for Word Sense Disambiguation in Historical Chinese,/proceedings/annual_meeting/2025/pdf_dir/Q9-9.pdf,"○Micah Kitsunai, Deborah Watty, Shu-Kai Hsieh (台灣大)","This paper proposes a method for word sense disam-biguation in historical Chinese texts using general-purposeLLMs (GPT-4o and GPT-4o-mini). The results show thatthe larger model performs better and few-shot examplesimprove performance, though the eﬀectiveness of dynamicexample selection remains unclear. The best-performingsetup is applied to visualize the change in meaning of acharacter over approximately 3,000 years of Chinese textdata, demonstrating the potential of this approach for track-ing semantic evolution."
Q9:ポスター3月13日（木） 10:20-11:50   Q会場(1F会議室101AB),Q9-10,生成データに基づいた日本語の時間関係推定,/proceedings/annual_meeting/2025/pdf_dir/Q9-10.pdf,"○小國 怜美 (お茶大), 持橋 大地 (統数研/国語研), 小林 一郎 (お茶大)",時間関係認識は，自然言語理解において必要となる正確な文脈理解のための重要なタスクである．人が用いる常識的な知識を学習させることで，時間関係を捉えることが可能な言語モデルを構築する試みが行われている．本研究では，先行研究[1] の手法に倣って，イベントの生起状態を正規分布で表現し，その位置の相対関係により時間関係識別を行った．その際に大規模言語モデルを用いて，Allen の区間代数[2] の定義に従ってデータセットを新たに生成して学習を行ったところ，モデルの精度向上を確認できた．
Q9:ポスター3月13日（木） 10:20-11:50   Q会場(1F会議室101AB),Q9-11,複単語表現検出におけるLLMファインチューニングの有効性,/proceedings/annual_meeting/2025/pdf_dir/Q9-11.pdf,"○井手 佑翼 (NAIST), Joshua Tanner (Resolve Research), Adam Nohejl, Justin Vasselli, 上垣外 英剛, 渡辺 太郎 (NAIST)",複単語表現、すなわちイディオム性を持つ単語の系列の検出は、機械翻訳など様々な下流タスクで重要な役割を果たす。本研究では、これまで複単語表現検出で用いられてこなかった大規模言語モデルのファインチューニングについて検証する。比較対象として、先行研究で優れた性能を示したエンコーダベースのシステムの検証も行う。実験の結果、提案手法が先行手法を大きく上回る性能を見せた。一方、提案手法を含む全手法で、再現率の低さが課題であることも明らかになった。また、モデルサイズを考慮した比較の結果から、メモリ効率の観点ではエンコーダベースの手法に利があることを示唆する。
Q9:ポスター3月13日（木） 10:20-11:50   Q会場(1F会議室101AB),Q9-12,CCGに基づく否定スコープ認識,/proceedings/annual_meeting/2025/pdf_dir/Q9-12.pdf,"○小島 健太郎, 加藤 芳秀, 松原 茂樹 (名大)",否定スコープ認識とは否定要素の影響が及ぶ範囲である否定スコープを特定するタスクである．このタスクはヒューリスティックなルールに基づく手法やニューラルモデルに基づく手法など様々なアプローチで取り組まれている．しかし，言語理論に基づいて否定スコープを求める研究はあまり行われていない．本論文では，否定スコープを言語理論に基づいて求めるアプローチの一つとしてCCGに基づく手法を提案する．本手法では，意味表現としてラムダ式を採用し，否定要素とそのスコープの関係を，ラムダ式の関数と引数の関係に関する一つの原理で説明する．否定スコープデータセットを用いて本手法の性能を評価し，手法の課題を明らかにする．
Q9:ポスター3月13日（木） 10:20-11:50   Q会場(1F会議室101AB),Q9-13,視覚情報による曖昧性解消コーパスの検討,/proceedings/annual_meeting/2025/pdf_dir/Q9-13.pdf,"○李 相明 (NAIST/理研), 河野 誠也 (理研/NAIST), 吉野 幸一郎 (科学大/理研/NAIST)",自然言語の曖昧性の解消は、システムとユーザ間の意味の一致を達成する上で解決すべき重大な課題である。そのためには、実世界での視覚情報と自然言語の統合処理が鍵となる。本研究では、既存のVision & Language Model を対象に、視覚情報を利用した曖昧性理解能力を評価するためのデータセットの検討を行った。さらに、試験的に収集したデータを用いて、曖昧性が解消された文と画像の識別能力を測定することでVLM が視覚情報を活用して曖昧性を解消する能力を評価した。実験結果に基づき、既存モデルの曖昧性解消能力の可能性を探求するとともに、エラーケースの分析を行った。この分析から、モデルが持つ曖昧性に対する弱点と、ベンチマークやデータセットの今後の課題について考察を行った。
Q9:ポスター3月13日（木） 10:20-11:50   Q会場(1F会議室101AB),Q9-14,和歌の埋め込みに基づく本歌取りの推定,/proceedings/annual_meeting/2025/pdf_dir/Q9-14.pdf,"○小川 隼斗, 堀尾 海斗, 河原 大輔 (早大)","本研究では, 和歌に特化した埋め込みモデルとそれを応用した本歌推定モデルを構築する. はじめに事前学習済みの言語モデルを対照学習し和歌に特化した埋め込みモデルを構築する. 次にこのモデルから得られる埋め込みベクトルおよびそれから抽出した特徴量を用いて, 本歌取りをしている和歌の本歌を推定する機械学習モデルを学習する. 本歌とその本歌取りとされる歌のペアデータを用いて本歌推定モデルを評価し, 一定の精度で本歌の推定が可能であることを示した."
Q9:ポスター3月13日（木） 10:20-11:50   Q会場(1F会議室101AB),Q9-15,Towards a Comparison of Japanese and English Metaphor,/proceedings/annual_meeting/2025/pdf_dir/Q9-15.pdf,"○◊Rowan Hall Maudslay (ケンブリッジ大), 古宮 嘉那子 (TUAT), 浅原 正幸 (NINJAL/SOKENDAI), Simone Teufel (ケンブリッジ大)","In this paper, we report on preliminary experiments inwhich we attempt to use large language models to com-pare Japanese and English metaphors. More speciﬁcally,we investigate how well GPT is able to translate Japanesemetaphors into English. We ﬁnd that while GPT is able toproduce high quality sentence translations, it is often notsuccessfully able to identify the key metaphorical word ina longer metaphorical phrase. Nevertheless, we ﬁnd thatusing GPT we are able to easily identify several cases ofJapanese metaphor not present in conventional English."
Q9:ポスター3月13日（木） 10:20-11:50   Q会場(1F会議室101AB),Q9-16,比喩検出における大規模言語モデルを用いた前後補助文脈の活用,/proceedings/annual_meeting/2025/pdf_dir/Q9-16.pdf,"○林 拓哉, 佐々木 稔 (茨大)",比喩検出は、文字通りには解釈できない比喩表現を検出するタスクであり、文脈情報が重要である。過去の研究では、ChatGPT を用いて生成した補助文をターゲット文の前に追加する手法が提案され、精度向上が示されたものの、十分ではなかった。本論文では、ターゲット文の前後に補助文を追加する手法を提案し、比喩検出の精度向上を図った。複数のデータセットを用いた実験では、補助文の追加により精度、適合率、F1 スコアが過去の研究より向上したことが確認された。本研究は補助文生成の有効性を示しており、今後はより多様な文脈構成や最新の生成モデルを活用する可能性を探る必要がある。
Q9:ポスター3月13日（木） 10:20-11:50   Q会場(1F会議室101AB),Q9-17,ルールベースの深層格定義および自動付与とそのLLM統合による含意関係認識における効果検証,/proceedings/annual_meeting/2025/pdf_dir/Q9-17.pdf,"○荒沢 康平, 狩野 芳伸 (静大)",LLM（Large Language Model、大規模言語モデル）の発展に伴い、多くの言語処理タスクでLLM が高い性能を発揮している。しかし、深層格で表現されるような複雑な事物の関係を正確に捉えられているかは不明である。我々は独自に定義した深層格とその付与ルール群に基づき、ルールベースの深層格自動付与システムを構築した。その出力とLLM を組み合わせることで、言語処理タスクの性能が一般に向上しうると期待する。本研究では性能検証として、JNLI データセットを用いて含意関係認識を行った。その結果、GPT-4o との組み合わせで正解率が
Q9:ポスター3月13日（木） 10:20-11:50   Q会場(1F会議室101AB),Q9-18,ツリーバンクの言語学的妥当性の自動評価,/proceedings/annual_meeting/2025/pdf_dir/Q9-18.pdf,"○富田 朝 (お茶大), 谷中 瞳 (東大), 戸次 大介 (お茶大)",自然言語推論において、理論言語学に基づく解析手法では、推論の精度は統語解析の妥当性に依存する。統語解析の妥当性を保証するには、パーザの学習・評価に用いるデータが言語学的に妥当であることが重要であるが、統語構造を提供するツリーバンクの妥当性評価は十分に行われておらず、従来の手法では言語学的妥当性を適切に捉えることができない。そこで本研究では、理論言語学と型理論を基盤とする新たな評価手法を提案し、この評価手法を用いてツリーバンクの妥当性評価を行う。
Q9:ポスター3月13日（木） 10:20-11:50   Q会場(1F会議室101AB),Q9-19,自動ファクトチェックのための事実の分解による含意関係認識,/proceedings/annual_meeting/2025/pdf_dir/Q9-19.pdf,"○雨宮 正弥, 狩野 芳伸 (静大)",含意関係認識は、ファクトチェック自動化において有望なアプローチの一つである。しかし、既存の含意関係認識手法をそのまま適用するだけでは、正確な検証が難しい場合がある。本研究では、前提文や仮定文を個別の事実に分解し、分解した要素に対して含意関係認識を行う手法を提案する。独自に構築したファクトチェック性能評価データセットにおいて、提案手法を導入することでLLM 単独よりもgpt-4o において9.34、llmjp-3 において20.67 ポイントのAccuracy 向上を達成し、その有効性を示した。
Q9:ポスター3月13日（木） 10:20-11:50   Q会場(1F会議室101AB),Q9-20,大規模言語モデルを用いたStory Intention Graph の自動生成の精度改善,/proceedings/annual_meeting/2025/pdf_dir/Q9-20.pdf,"○吉川 祐輔, 井上 壮志 (IPI), 銭本 友樹, 東中 竜一郎 (名大)","対話システムが物語を理解できれば，話者の価値観や経験などをより深く理解することができるようになると考えられる．先行研究で我々は，物語の表現としてElson によって提案されたStory IntentionGraph (SIG) に着目し，大規模言語モデル（LLM）を用いて，物語文からSIG の自動生成に取り組んだ．しかしながら，SIG の構造は複雑であり，物語文からSIG を自動生成する精度は高くなかった．本研究では，より高度な推論が可能と考えられるLLM を用いたSIG の自動生成の改善を行う．具体的には, LLM としてGPT-4o, および，推論力に優れたOpenAI o1 を採用し, プロンプトへのshot の導入を行った．実験では，自動生成されたSIG を，人手によって作成されたSIG と比較した．その結果，OpenAI o1 にshot の追加を行うことで，人手作成SIG の約76%という比較的高い精度でSIG を自動生成可能なことが分かった．"
Q9:ポスター3月13日（木） 10:20-11:50   Q会場(1F会議室101AB),Q9-21,文の埋め込みに効果的な静的単語ベクトルの獲得,/proceedings/annual_meeting/2025/pdf_dir/Q9-21.pdf,"○和田 崇史, 平川 優伎, 清水 良太郎, 川島 貴大, 斎藤 侑輝 (ZOZO NEXT)","本研究は, 文の埋め込みに有効な静的単語ベクトル(Static Word Embedding) を提案する. 文ベクトルを出力するように事前学習されたSentence Transformerから単語ベクトルを抽出し, さらに主成分分析と知識蒸留を行うことで文表現に適した単語ベクトルを獲得する. 計56 個の英語のデータセットから成るMassive Text Embedding Benchmark (MTEB) で実験を行い, 既存手法の精度を大幅に上回ることを示した."
Q9:ポスター3月13日（木） 10:20-11:50   Q会場(1F会議室101AB),Q9-22,訓練不要な条件付きテキスト埋め込み,/proceedings/annual_meeting/2025/pdf_dir/Q9-22.pdf,"○山田 康輔, 張 培楠 (サイバーエージェント)",条件付きテキスト埋め込みは、特定の側面に焦点を当てたテキストの埋め込み表現であり、与えられた条件に基づくテキスト同士の類似度の算出を可能にする。従来手法は、大規模な訓練データによる指示学習や意味的テキスト類似度算出タスクによる微調整が求められ、開発コストが高い。そこで本研究では、生成型LLM をテキストエンコーダとして条件付き一語制約プロンプトを用いる、訓練不要で高品質な条件付きテキスト埋め込みPonTE を提案する。条件付き意味的類似度テキスト類似度とテキストクラスタリングによる二つの実験を通じて、提案手法は追加の訓練なしで従来手法以上の性能を達成することを示す。
Q9:ポスター3月13日（木） 10:20-11:50   Q会場(1F会議室101AB),Q9-23J,How Domain Adaptation of BERT Improves Syntactic Parsing of Math Text,/proceedings/annual_meeting/2025/pdf_dir/Q9-23.pdf,"○吉田 琉夏, 松崎 拓也 (東京理科大)",
Q9:ポスター3月13日（木） 10:20-11:50   Q会場(1F会議室101AB),Q9-24J,Semantic Shift Stability: 学習コーパス内の単語の意味変化を用いた事前学習済みモデルの時系列性能劣化の監査,/proceedings/annual_meeting/2025/pdf_dir/Q9-24.pdf,"○石原 祥太郎 (日経), 高橋 寛武 (独立研究者), 白井 穂乃 (日経)",
A10:機械翻訳(2)3月13日（木） 13:00-14:30   A会場(2Fコンベンションホール1+2),A10-1,Data Augmentation for Manipuri-English Neural Machine Translation,/proceedings/annual_meeting/2025/pdf_dir/A10-1.pdf,"○◊申 小靖, Yves Lepage (早大)","Neural Machine Translation (NMT) for low-resourcelanguages like Manipuri, a Sino-Tibetan language, is con-strained by limited parallel corpora. This study applies adata augmentation technique, end sentence generation, toimprove Manipuri-English NMT performance by creatingadditional parallel sentence pairs from existing datasets.Experiments on three datasets―the EM corpus, PMIn-dia corpus, and WMT23 corpus― demonstrate that theproposed method consistently improves translation qual-ity. For the WMT23 dataset, BLEU scores increased from"
A10:機械翻訳(2)3月13日（木） 13:00-14:30   A会場(2Fコンベンションホール1+2),A10-2,llmMT+1: 非英語言語対 LLM 翻訳の実現法の検討,/proceedings/annual_meeting/2025/pdf_dir/A10-2.pdf,"○傅 星儿 (京大), 永田 昌明 (NTT), Chenhui Chu (京大)",近年，大規模言語モデルを使った機械翻訳が注目を集めている．しかし，そのモデルの多くは英語中心の言語対のみを対象としており，英語を含まない非英語言語対の翻訳がサポートされておらず，性能が低い問題が残されている．この問題に対して本論文では，対象言語の訓練状況に応じて3 つに場合分けして，英語中心の翻訳モデルにおいて非英語言語対の翻訳を実現する方法について体系的に検討する．
A10:機械翻訳(2)3月13日（木） 13:00-14:30   A会場(2Fコンベンションホール1+2),A10-3,Towards Equitable Translation: Gender Bias in Large Language Models,/proceedings/annual_meeting/2025/pdf_dir/A10-3.pdf,"○◊Hong Hai Ngo, Yunmeng Li (東北大), 坂口 慶祐 (東北大/理研)","Machine translation (MT) systems often struggle withhandling gender distinctions in languages with grammati-cal gender. In this paper, we evaluate the performance of"
A10:機械翻訳(2)3月13日（木） 13:00-14:30   A会場(2Fコンベンションホール1+2),A10-4,BiMax: Bidirectional MaxSim Score for Bilingual Document Alignment,/proceedings/annual_meeting/2025/pdf_dir/A10-4.pdf,"○Xiaotian Wang, Takehito Utsuro (筑波大), Masaaki Nagata (NTT)","Document alignment is necessary for the hierarchicalmining [1, 2], which aligns documents across source andtarget languages within the same web domain.Severalhigh-precision sentence embedding-based methods havebeen developed, such as TK-PERT [3] and Optimal Trans-port (OT) [4, 5].However, given the massive scale ofweb mining data, both accuracy and speed must be consid-ered. In this paper, we propose a cross-lingual sentence-level Bidirectional Maxsim score (BiMax) for computingdoc-to-doc similarity, to improve eﬃciency compared tothe OT method. Meanwhile, we also conduct a compre-hensive analysis to investigate the performance of currentstate-of-the-art multilingual sentence embedding models."
A10:機械翻訳(2)3月13日（木） 13:00-14:30   A会場(2Fコンベンションホール1+2),A10-5,小説会話文の翻訳へ向けた逆翻訳を用いた話者埋め込みの作成,/proceedings/annual_meeting/2025/pdf_dir/A10-5.pdf,"○長門 亜優奈, 松崎 拓也 (東京理科大)",日本語の発話には，性別や性格などの発話者のキャラクター性が現れることが多い．一方，英語の発話は必ずしもそうではない．そのため，英語の小説を日本語に機械翻訳する際に，発話は発話者のキャラクター性に反する表現で翻訳されることがある．これを防ぐ方法として，発話の翻訳の際に，話者の特徴を反映した話者埋め込みを入力に加えることが考えられる．本論文では，その準備として，日本語の発話文における発話者の特徴の現れている部分をマスクし，その部分を当てることで話者埋め込みを訓練することを試みた．その結果，性別などのキャラクター性を話者埋め込みとして抽出できること，また，発話文における発話者の特徴の現れている部分を推測することに話者埋め込みの利用が効果的であることを示す．
A10:機械翻訳(2)3月13日（木） 13:00-14:30   A会場(2Fコンベンションホール1+2),A10-6,逆翻訳を用いたアイヌ語・日本語機械翻訳の改善における研究,/proceedings/annual_meeting/2025/pdf_dir/A10-6.pdf,"○菅原 葵, Karol Nowakowski (公益大), Michal Ptaszynski, Nick Overacker (北見工大)","本研究では, 逆翻訳を用いて少資源言語であるアイヌ語と日本語の機械翻訳の精度向上を目指した. 元の対訳コーパスのみを利用して, 反復的逆翻訳手法とランダムサンプリングによる疑似対訳文生成手法を用い, さらに, 外部の日本語の単言語データを活用した. 結果として, 外部の日本語の単言語データを利用するよりも元の対訳コーパスのみを利用して逆翻訳を行った方が良い結果となった."
B10:形態素・構文・意味解析3月13日（木） 13:00-14:30   B会場(1F会議室102),B10-1,不均衡最適輸送を用いた意味変化検出,/proceedings/annual_meeting/2025/pdf_dir/B10-1.pdf,"○岸野 稜, 山際 宏明 (京大), 永田 亮 (甲南大/理研), 横井 祥 (国語研/東北大/理研), 下平 英寿 (京大/理研)",新旧のコーパスから得られる対象単語の文脈付き単語埋め込みの集合を比較することで，時代の経過に伴う単語の意味変化を検出できるようになった．ただし既存手法は，対象単語の意味が全体としてどのくらい変化したかを測るものであり，個々の使用事例に踏み込んだ分析には至っていない．本稿では，新旧コーパスにおける文脈付き単語埋め込みの集合の間に不均衡最適輸送を適用し，使用事例間のアラインメントの過不足に注目することで，語義の消失・出現を自然に定式化できることを示す．特に，対象単語の使用事例ごとに，その事例における語義での単語使用頻度の変化を測るSense UsageShift (SUS) という量を導入する．SUS を用いることで，使用事例ごとの意味変化の定量化が可能であることを，評価実験を通して示す．
B10:形態素・構文・意味解析3月13日（木） 13:00-14:30   B会場(1F会議室102),B10-2,ドメインモデルに基づいて技術文書中の矛盾を検出する方法,/proceedings/annual_meeting/2025/pdf_dir/B10-2.pdf,○山田 隆弘 (CMT),本稿では，技術文書のように厳密に事実を伝えるべき文書中の矛盾を検出する方法について議論する．文書中の矛盾を放置したままにすると重要な損害がもたらされる場合は多い．例えば，システムの開発において，文書中の矛盾に気付かずにシステムを製造してしまうと，テスト時に不具合が発生し，製造をやり直すことになる．本稿では，技術文書中の矛盾を検出する基本的な方法を提案する．特に，システム開発において実際に発生しやすい矛盾に焦点を当てる．
B10:形態素・構文・意味解析3月13日（木） 13:00-14:30   B会場(1F会議室102),B10-3,反語文の情報格納―英語、中国語、日本語の比較から,/proceedings/annual_meeting/2025/pdf_dir/B10-3.pdf,○伊藤 さとみ (お茶大),反語文は，疑問文の統語形式をとりながら，意味的には関連の陳述命題を断言する構文である．本研究では，反語文の陳述命題が会話の共通基盤に格納されるやり方は，言語によって異なっていると主張する．英語では陳述命題は前提として組み込まれるのに対し，日本語では会話の共通基盤の最上段の文脈に組み込まれる．さらに，中国語では，書面語は英語と同じように前提として処理され，口語では日本語と同じように共通基盤の最上段の文脈に組み込まれる．この格納方法の違いは，反語文における否定極性成分の認可の可否と反語文の陳述命題を後続文脈で指示できるかどうかに反映されている．
B10:形態素・構文・意味解析3月13日（木） 13:00-14:30   B会場(1F会議室102),B10-4,JDD-PAS:規範的な日本語日常対話コーパスへの意味役割ラベル・述語項構造付与,/proceedings/annual_meeting/2025/pdf_dir/B10-4.pdf,"○吉野 幸一郎 (科学大/理研/NAIST), 李 相明 (NAIST/理研), 波部 英子 (理研), 大村 舞, 浅原 正幸 (国語研), 若狭 絢 (東北大), 赤間 怜奈, 鈴木 潤 (東北大/理研)",人間同士の対話・コミュニケーションのモデル化する上で、対話中にやりとりされた発話が持つ構文・意味構造や談話構造は重要な役割を持つ。本研究はこうした対話分析に活用可能で、また既存の意味役割解析が対話においてどの程度利活用可能かを測るテストベッドを作成する目的で、日本語日常対話コーパスへの意味役割ラベル・述語項構造のアノテーションを行った。構築したアノテーションスキーマ・フレームワークを用いることで、1 人月あたり300 対話程度のアノテーションが可能であり、今後の対話研究に本枠組みを用いることが出来そうな見通しが立ったことを報告する。
B10:形態素・構文・意味解析3月13日（木） 13:00-14:30   B会場(1F会議室102),B10-5,読み推定のための教師なし単語分割,/proceedings/annual_meeting/2025/pdf_dir/B10-5.pdf,"○内海 慶 (SB Intuitions), 森 信介 (京大)",従来，読みの推定を行う形態素解析では教師あり学習が用いられてきた．しかし，人手による読み情報の付与はコストが大きく，読み付きコーパスは一部の言語資源に限られている．一方で，読みの付与された単語辞書や生コーパスは入手可能なものが多数存在している．そこで本研究では，読みを含む単語辞書と生コーパスを用いて読み推定と単語分割の教師なし学習の提案を行う．提案手法を用いることで，教師なし学習手法でF 値90 程度の読み推定精度を達成した．
B10:形態素・構文・意味解析3月13日（木） 13:00-14:30   B会場(1F会議室102),B10-6,言語モデルを用いた定量的推論機能の実現に向けて,/proceedings/annual_meeting/2025/pdf_dir/B10-6.pdf,"○伊東 恵美, 小林 一郎 (お茶大)",本研究は，言語モデルに実世界に対応した定量的推論（特にファジィ推論）機能を組み込むことを目的とする．二つの物体が衝突した後の状態を言語モデルにより自然言語で推論すると同時に，推論の中に含まれる程度を表す表現に対する物理量を回帰型ニューラルネットワークを用いて学習させる．これにより定量的な状態変化を反映したファジィ推論により帰結となる定量的な物理量を表すメンバーシップ関数を推定する．特に，具体的な値で表せない「かなり」「少し」などの程度の表現の意味合いを学習させることを対象とし，その曖昧な表現を表すメンバーシップ関数として予測されたものの精度を測ることにより，推論の妥当性を検証する．
C10:LLM構築3月13日（木） 13:00-14:30   C会場(1F会議室103),C10-1,新聞記事からつくる 時事と社会に強い日本語LLM,/proceedings/annual_meeting/2025/pdf_dir/C10-1.pdf,"○服部 翔, 水木 栄, 藤井 一喜, 中村 泰士 (科学大/産総研), 塩谷 泰平 (科学大), 植木 快, 新妻 巧朗, 川畑 輝, 田森 秀明 (朝日新聞社), Youmi Ma, 前田 航希 (科学大), 大井 聖也 (科学大/産総研), 齋藤 幸史郎, 岡本 拓己, 石田 茂樹 (科学大), 横田 理央 (科学大/産総研), 高村 大也 (産総研), 岡崎 直観 (科学大/産総研)",大規模言語モデル（LLM）の事前学習において新聞記事はどのような恩恵をもたらすのか？本研究では，LLM の日本語継続事前学習における新聞記事データの有用性，およびその効果を引き出すための手法について報告する．はじめに，新聞記事のみを用いてLLM の継続事前学習を行ったが，テキスト量と多様性の不足のためか，十分な効果を得ることができなかった．そこで，ドメイン適応の既存研究を参考に，新聞記事をシードとしてLLM で合成データを生成し，継続事前学習のデータに追加した．実験の結果，合成データを併用することにより前述の問題を解消し，新聞記事に関連する分野を中心に，LLM の日本語能力が向上した．
C10:LLM構築3月13日（木） 13:00-14:30   C会場(1F会議室103),C10-2,国産農業用LLMのためのインストラクションデータ構築と構築されたLLMシステムの評価,/proceedings/annual_meeting/2025/pdf_dir/C10-2.pdf,"○石原 潤一, 小林 暁雄, 桂樹 哲雄, 大友 将宏 (農研機構), 橋本 祥 (筑波大), 阪本 浩太郎 (BESNA), 杉村 安都武 (三重農研所), 米丸 淳一 (農研機構), 安藤 まや, 後藤 美智子, 関根 聡 (いちから), 川村 隆浩 (農研機構)",農研機構は、内閣府「研究開発とSociety 5.0 との橋渡しプログラム（BRIDGE）」におけるAI 農業社会実装プロジェクト」にて、農業分野に特化した日本語大規模言語モデルの開発を進めている。本研究では、三重県農業研究所より提供を受けたイチゴに関するマニュアル類を元にインストラクションデータを構築を行い、これを用いてElyza-8B モデルに対しインストラクションチューニングを実施した。本稿では、これらのデータおよびモデルの構築の概要について解説したのち、実際にこのモデルが専門知識を含んだ回答ができているかをLLM as a Judge にて評価する手法を提案する。
C10:LLM構築3月13日（木） 13:00-14:30   C会場(1F会議室103),C10-3,日本語を主とした日・英・中トリリンガル700億パラメータモデルの構築,/proceedings/annual_meeting/2025/pdf_dir/C10-3.pdf,"○中島 大, 野崎 雄太, 佐藤 諒, 池田 純一, 阿部 宏幸, 伊藤 真也, 長谷川 慶, 中村 聡史, 麻場 直喜 (リコー)","我々は, 日本語を主とした700 億パラメータの日本語・英語・中国語のトリリンガル大規模言語モデル(LLM: Large Language Model) を転移学習によって開発した. 開発にあたっては, トークナイザーの差替, カリキュラム学習, モデルマージといった複数の手法を順に組み合わせた. 本稿ではその手法の詳細と, 評価結果を報告する.結果として, 継続事前学習においては日本語に転移学習済のモデルをベースに学習を行ったことに起因すると思われる日本語性能の飽和が見られたものの, その後のSFT, 及びモデルマージによって, 元モデルと比較して大幅な指示追従性能の向上が確かめられた."
C10:LLM構築3月13日（木） 13:00-14:30   C会場(1F会議室103),C10-4,ELAINE-medLLM: 英語、日本語、中国語に対応したバイオ医療ドメイン大規模言語モデル,/proceedings/annual_meeting/2025/pdf_dir/C10-4.pdf,"○矢野 憲, 浅田 真生 (産総研), 三輪 誠 (豊田工大/産総研), Sophia Ananiadou (マンチェスター大/産総研), 辻井 潤一 (産総研)",Meta のLlama-3-8B をベースに、バイオ医療ドメインに特化し3 ヶ国語（英日中）に対応した大規模言語モデルELAINE (EngLish-jApanese-chINesE)-medLLMを提案する。本LLM は多様で大規模な3 ヶ国語のバイオ医療分野のコーパスを用いて継続事前学習を行い、医療ドメインのQA データセット用いた教師ありファインチューニング(SFT) により学習した。
C10:LLM構築3月13日（木） 13:00-14:30   C会場(1F会議室103),C10-5,大規模言語モデルの再パラメタ化に基づく初期化による損失スパイクの抑制,/proceedings/annual_meeting/2025/pdf_dir/C10-5.pdf,"○西田 光甫, 西田 京介, 齋藤 邦子 (NTT)",大規模言語モデル(LLM) の事前学習中に損失関数値が突然発散してしまう損失スパイクがLLM 事前学習の課題である．本研究は，パラメータのノルムに対するパラメータ更新量のノルムの相対値であるパラメータの更新比率がモデル内で不均一であり，この不均一性が損失スパイクの一因であることを指摘した．本研究は，全てのパラメータにゲートパラメータを導入し，共通の標準偏差によって初期化することを提案した．提案手法が，13B モデルのLLM の事前学習においてモデル内の更新比率を均一化し，損失スパイクを抑制することを確認した．
C10:LLM構築3月13日（木） 13:00-14:30   C会場(1F会議室103),C10-6,大規模言語モデルにおけるSupervised Fine-tuningの包括的検証,/proceedings/annual_meeting/2025/pdf_dir/C10-6.pdf,"○原田 宥都, 山内 悠輔 (NII/東大), 小田 悠介 (NII), 大関 洋平 (東大), 宮尾 祐介 (NII/東大), 高木 優 (NII)",大規模言語モデルを人間の意図に合わせるアライメントのためには、事後学習としてのSupervised Fine-tuning (SFT) が不可欠である。しかしながら、ベースモデルの種類や学習データの特性が下流タスクの性能に与える影響について、広範な検証はほとんど行われていない。そこで本研究では、複数の大規模言語モデルと多様な学習データを用いて全245 種類のSFT モデルを訓練する。それらのモデルをさまざまな下流タスクで包括的に評価することで、先行研究で提案されてきた知見や定説を実証的に検証する。また、作成したすべてのファインチューニング済みモデルを公開予定である。
D10:質問応答，対話(3)3月13日（木） 13:00-14:30   D会場(1F会議室107),D10-1,LLMによるクイズの自動生成と質問応答への応用,/proceedings/annual_meeting/2025/pdf_dir/D10-1.pdf,"○小林 俊介 (早大), 河原 大輔 (早大/NII)",生成モデルとして広く使用されるようになった大規模言語モデル(LLM) の使用用途の1 つとして、学習データ生成が検討、研究されている。本研究では、LLM を用いたクイズデータの自動生成と評価により、学習データの拡張を実施し、質問応答に応用する。生成したクイズについてLLM と人手による評価を比較した結果、LLM は基本的なルールや文法を理解してデータを評価できる一方で、文字数のカウントなど一部に苦手な要素が存在することを確認した。また、生成されたクイズデータを質問応答システムに応用した結果、人手の学習データには及ばないものの、学習効果があることを確認した。
D10:質問応答，対話(3)3月13日（木） 13:00-14:30   D会場(1F会議室107),D10-2,RAGに基づく韓国語法令・判例に対する質問応答,/proceedings/annual_meeting/2025/pdf_dir/D10-2.pdf,"○徐 基皓 (韓国中央警察学校), 宇津呂 武仁 (筑波大)",本論文では，大規模言語モデルを活用して，韓国語における刑事業務に関連する法規の解釈に基づく質問応答の性能を改善する手法を提案する．本論文においては，インターネットで公開されている刑事業務に関する法令の条文および判例情報を蓄積し，RAG(Retrieval-AugmentedGeneration，検索拡張生成) の枠組みのもとで質問に関連する法令条文および判例を検索し，これらの関連法令・判例をふまえて，大規模言語モデルによって質問に関する推論を行うことにより，質問に対する的確な回答を生成するシステムを開発する．本システムの応用事例として，韓国の刑法分野において，捜査における意思決定および法的解釈の局面での支援用途が挙げられる．
D10:質問応答，対話(3)3月13日（木） 13:00-14:30   D会場(1F会議室107),D10-3,Fusion-in-LLM: 質問応答タスクにおけるRAG,/proceedings/annual_meeting/2025/pdf_dir/D10-3.pdf,○太刀岡 勇気 (デンソーITラボ),質問応答タスクにおいて、大規模言語モデル(LLM) の知識を補うために検索拡張生成(RAG) がよく使われるが、Retriever により得られた複数の異なるコンテキストを活用する方法に課題がある。一般的にはコンテキストを逐次的に入力しながら前の答えを書き直すかどうかをLLM 自身に判定させる(逐次RAG)。一方でfusion-in-decoder と呼ばれる方法では得られたコンテキストをすべて結合してデコーダーに入力し、デコーダーに回答を生成させる。ここではLLM を並列に用いて質問応答を行う方法(fusion-in-LLM) を提案し、AI 王を用いたクイズのための質問応答タスクの実験により、逐次RAGよりもfusion-in-LLM のほうが質問応答タスクに回答する性能が高いことを示す。
D10:質問応答，対話(3)3月13日（木） 13:00-14:30   D会場(1F会議室107),D10-4,対話要約の種別が対話の引継ぎに及ぼす影響の調査,/proceedings/annual_meeting/2025/pdf_dir/D10-4.pdf,"○山下 紗苗, 東中 竜一郎 (名大)",対話要約は，対話を事後に確認して内容を把握するだけでなく，進行中の対話に途中から参加する対話の引継ぎにも有用と考えられる．しかし，対話要約には，文章形式，対話形式，キーワード形式などの種別があり，これらの中でどれが最も対話の引継ぎに有用であるかは明らかでない．そこで，本研究では，対話要約の種別が対話の引継ぎに及ぼす影響の定量的な評価を目的とし，これらの種別について要約を作成した上で，対話を引継ぐ際の負荷と，要約を基に作成した次発話の適切さを評価した．結果として，対話の引継ぎには対話形式の抽象型要約が有用であることが確認できた．また，対話の引継ぎにおける，要約の各種別の特性を明確化できた．
D10:質問応答，対話(3)3月13日（木） 13:00-14:30   D会場(1F会議室107),D10-5,質問誘導に基づくアンケート対話システムの開発,/proceedings/annual_meeting/2025/pdf_dir/D10-5.pdf,"○銭本 友樹, 吉田 麻里子, 堀 涼, 浦田 真由, 井上 愛子 (名大), 林 尊弘 (愛知医療大), 東中 竜一郎 (名大)",少子高齢化が進む中で，高齢者の健康状況を適切に把握することは重要な課題である．そこで本研究では，日常的な雑談の中で所望のアンケートの回答を聞き出し，高齢者の負担なく健康状態を把握することができる質問誘導に基づくアンケート対話システムを提案する．また，対話で得られた回答を適切な選択肢に対応づけることで，アンケートと同じ形式の回答を得る手法を提案する．人間評価実験と，高齢者に実生活でアンケート対話システムと2 週間対話してもらう実証実験を行い，アンケート対話システムがアンケートを代替し得るかを検証した．
D10:質問応答，対話(3)3月13日（木） 13:00-14:30   D会場(1F会議室107),D10-6,Multi-Relational Multi-Party Chat Corpus: 話者間の関係性に着目したマルチパーティ雑談対話コーパス,/proceedings/annual_meeting/2025/pdf_dir/D10-6.pdf,"○津田 太郎, 山下 紗苗 (名大), 井上 昂治, 河原 達也 (京大), 東中 竜一郎 (名大)",近年の対話システムの飛躍的な発展にもかかわらず，3 人以上のマルチパーティ対話に対応した対話システムは少ない．そこで，我々は，そのような対話システムを実現するための対話リソースとして，マルチパーティ対話コーパスMulti-RelationalMulti-Party Chat Corpus (MRMP) を構築した．本コーパスは初対面の話者のみからなる初対面対話と家族関係の話者と初対面の話者からなる家族入り対話の
E10:テーマセッション3: 認知・脳と自然言語処理(3)3月13日（木） 13:00-14:30   E会場(1F会議室108),E10-1,BrainLMを用いた多言語学習での転移学習性能の検証,/proceedings/annual_meeting/2025/pdf_dir/E10-1.pdf,"○羅 桜, 小林 一郎 (お茶大)",近年，言語による刺激とそれに誘起された脳活動との対応関係を捉えた事前学習済みマルチモーダル言語モデルであるBrainLM が提案された．本研究では、このモデルをさらに発展させ、英語だけであった言語刺激をフランス語および中国語へと拡張し多言語からなるBrainLM の開発を行った．言語刺激の拡張には，転移学習を利用することで多言語タスクでのモデルによる脳内状態予測能力を向上させた.特に、英仏間の整合性判別のための二値分類タスクにおいて多言語対応したBrainLM は51.75%という最高精度を達成した. また，脳内状態予測タスクにおいて，転移学習の前後で相関係数が約3%から
E10:テーマセッション3: 認知・脳と自然言語処理(3)3月13日（木） 13:00-14:30   E会場(1F会議室108),E10-2,CCGによる日本語脳波データのモデリング,/proceedings/annual_meeting/2025/pdf_dir/E10-2.pdf,"磯野 真之介 (東大/DC2), 梶川 康平 (東大), ○杉本 侑嗣 (阪大), 浅原 正幸 (国語研), 大関 洋平 (東大)",計算心理言語学では、人間の文理解において、どのような表象がどのように構築されているのかが探究されてきた。この問いに取り組むのに、Combinatory Categorial Grammar (CCG) が有望な文法理論であることが、日本語や英語の読み時間や脳血流のデータを用いた先行研究で示唆されている。そこで本研究では、日本語を対象とした新たな脳波データセットを構築した上で、CCG による指標が脳波の予測に寄与するのか検証する。統語操作の適用数および作業記憶の負荷に関する指標が、それぞれ事象関連電位を予測することを示す。
E10:テーマセッション3: 認知・脳と自然言語処理(3)3月13日（木） 13:00-14:30   E会場(1F会議室108),E10-3,大規模言語モデルの浅い層が人間の速い言語処理を再現する,/proceedings/annual_meeting/2025/pdf_dir/E10-3.pdf,"○栗林 樹生 (MBZUAI), 大関 洋平 (東大), Souhaib Ben Taieb (MBZUAI), 乾 健太郎 (MBZUAI/東北大/理研), Timothy Baldwin (MBZUAI/メルボルン大)",本研究では，大規模ニューラル言語モデルの中間層から得られる次単語予測確率が人間の読み活動・脳波データをうまく説明できることを報告する．これは，大きな言語モデルの計算する確率ほど人間の振る舞いから逸脱してしまうという既存の報告を覆すものであり，大規模言語モデルの認知的妥当性が過小評価されていたことを示唆する．さらに，人間の比較的速い反応（最初の視線停留など）は浅い層で，遅い反応（脳波N400 など）は深い層で再現される傾向が見られ，言語モデル内部でのレイヤ方向の漸進的処理と，人間の異なるタイムスケールの反応との対応をとる新たな方向性を提示する．
E10:テーマセッション3: 認知・脳と自然言語処理(3)3月13日（木） 13:00-14:30   E会場(1F会議室108),E10-4,Skip-bigrams reconstruct trigrams in 2-word languages,/proceedings/annual_meeting/2025/pdf_dir/E10-4.pdf,○日髙 昇平 (JAIST),"In natural language processing, it has been empiricallyknown that skip-grams, co-occurrence statistics of twowords with some number of words in between them, isan eﬀective source of data to learn semantic nature of thewords. In this study, we propose a new theoretical accountfor why a set of skip-grams is eﬀective at least for two-wordlanguages, by giving a theorem that a set of trigram prob-abilities is representable with a set of skip bigrams. Thisrepresentation theorem justiﬁes the use of skip bigrams orso-called shiftgrams as a computationally eﬃcient sourceto access higher order n-gram."
E10:テーマセッション3: 認知・脳と自然言語処理(3)3月13日（木） 13:00-14:30   E会場(1F会議室108),E10-5,Triple-Phase Transition: 脳との関係から捉える大規模言語モデルの学習ダイナミクス,/proceedings/annual_meeting/2025/pdf_dir/E10-5.pdf,"中木 裕子, 多田 圭吾, ○吉野 草太, 西本 伸志 (阪大/NICT), 高木 優 (NII)",大規模言語モデル（LLMs）の学習時，ある能力を学習過程で突然獲得する現象が知られている．このようなLLMs の変化は相転移（Phase Transition）現象と呼ばれ，その原因としてLLMs の内部状態における相転移が示唆されているが，その実態は未解明の点が多い．本研究で我々はLLMs の相転移についてLLMs の内部表現とヒト脳活動を対比させることにより解釈することを試みる．具体的には，学習過程における，LLMs と脳の類似度，LLMs の内部状態，下流タスク精度の変化という3 つの観点を統合した解析を行い，LLMs の学習ダイナミクスに新たな解釈を与える．我々は，LLMs が下流タスクの能力を獲得する過程で，脳との対応や内部状態に3 段階の相転移が起きることを示す．
P10:ポスター3月13日（木） 13:00-14:30   P会場(2Fコンベンションホール3+4),P10-1,法的三段論法に基づく段階的プロンプトによる司法試験自動解答,/proceedings/annual_meeting/2025/pdf_dir/P10-1.pdf,"○翁長 駿光, 狩野 芳伸 (静大)","本研究は, 法的自然言語処理タスクにおいて大規模言語モデルの推論性能を向上させる, 新しい段階的推論手法を提案する. 提案手法は法的三段論法に基づき, 事例整理, 条文整理, あてはめ, 結論という4つの手順に沿って条文と事例の整合性を論理的に評価することで, 解答の精度と解釈可能性の向上を図る. 我が国の司法試験（民法短答式問題）の自動解答性能を評価するCOLIEE データセットを用いた実験で, 提案手法のプロンプトを適用することで,GPT-4o, Llama3.1 およびCOLIEE 2024 の最高性能手法のいずれに対してもaccuracy で1.8 ポイント以上の性能向上を達成した. 提案手法はLLM 非依存であると考えられるため, 現時点のState-of-the-Art の性能を達成したといえる."
P10:ポスター3月13日（木） 13:00-14:30   P会場(2Fコンベンションホール3+4),P10-2,Detecting Individual Decision-Making Dialogues in Conversation,/proceedings/annual_meeting/2025/pdf_dir/P10-2.pdf,"○◊苏 为文, 吉永 直樹, 豊田 正史, 王 子晗, 周 宇涵 (東大)","Decision-making is an essential part of our daily lives,especially in dialogue. It involves group decision-making,where we strive to reach a consensus with others, or in-dividual decision-making primarily based on our indepen-dent thinking. Collecting decision-making data helps usanalyze our daily behaviors and engage in self-reﬂection.In this study, aiming to detect individual decision-makingdialogues in conversation automatically, we annotate thedecision-seeking (e.g., “Would you like to form a bandwith me?”) and decision-making utterances in a dialoguedataset. We then investigate the LLMs’ ability to detectindividual decision-making and conduct an error analysisto analyze the mistakes in the detection processes."
P10:ポスター3月13日（木） 13:00-14:30   P会場(2Fコンベンションホール3+4),P10-3,LLM を用いた対話印象評価による対話システム学習とその分析,/proceedings/annual_meeting/2025/pdf_dir/P10-3.pdf,"○吉田 快 (NAIST/理研), 水上 雅博 (NTT), 河野 誠也 (理研/NAIST), クルンカライ カナサイ (理研), 杉山 弘晃 (NTT), 吉野 幸一郎 (科学大/理研/NAIST)",RLAIF を対話システム学習に適応する上では、シングルターンの対話だけでなく、対話文脈全体の一貫性、個性、共感性などの対話印象を向上させる必要がある。本研究では、対話印象評価のための報酬モデルの比較、及びその報酬をフィードバックとしたシステムの対話印象の改善を行った。自動評価と人手評価の結果、個々の対話印象の向上だけでなく、応答の自然さも向上することが示された。
P10:ポスター3月13日（木） 13:00-14:30   P会場(2Fコンベンションホール3+4),P10-4,リアルタイム音声対話システムのための応答タイミングと短文応答の同時予測,/proceedings/annual_meeting/2025/pdf_dir/P10-4.pdf,"○大中 緋慧 (NAIST/理研), 河野 誠也 (理研/NAIST), 大西 一誉 (NAIST/理研), 吉野 幸一郎 (NAIST/理研/科学大)",対話における応答タイミングは発話者の意図を表現するための有用な手段である．この観点から応答タイミングを予測する手法の研究が進んでいる．他方で，このような手法を有効に活用するためには，音声合成などの生成モジュールの遅延を緩和する仕組みが必要となる．このような背景に基づき，応答タイミングと遅延緩和のための短文応答を同時予測するモデルを提案する．提案手法は応答すべきか否かを連続的に予測しながら，応答と判定した際に対照学習に基づくランキング付けにより適切な短文応答を選ぶ．二つのタスクでの客観評価を行い，応答タイミング，短文応答選択の両方で同条件の比較手法に対して優れた結果であることを確認した．
P10:ポスター3月13日（木） 13:00-14:30   P会場(2Fコンベンションホール3+4),P10-5,キャラクターの2面性を表出する発話の生成に関する検討,/proceedings/annual_meeting/2025/pdf_dir/P10-5.pdf,"○岩田 伸治, 伊原 滉也, 佐藤 志貴, 馬場 惇, 邊土名 朝飛 (サイバーエージェント), 山崎 眞洋, 塩塚 勇気 (QualiArts), 吉本 暁文 (サイバーエージェント)",ユーザにコンテンツを長く楽しんでもらう方法の1 つとして，既存キャラクターを模した対話システムの実現がある．実現にはユーザがキャラクターらしさを感じる応答の生成が重要である．先行研究ではキャラクターの性格の一貫性が重視されてきたが，主に表出している性格から考えると意外性を感じさせる性格（以降，2 面性）の表出もキャラクターの再現には重要だと考えられる．そこで，本研究ではLLM が2 面性を表出した発話生成が可能かを調査した．結果として2 面性を感じさせるような発話を生成できない場合が多いことを明らかにした．そして，2 面性を表出できていない発話の特徴分析を行い，今後の展望を明らかにした．
P10:ポスター3月13日（木） 13:00-14:30   P会場(2Fコンベンションホール3+4),P10-6,擬似選好チューニングによる対話応答のペルソナ一貫性向上,/proceedings/annual_meeting/2025/pdf_dir/P10-6.pdf,"○高山 隼矢, 大萩 雅也, 水本 智也, 吉川 克正 (SB Intuitions)",本稿では、擬似的な選好データを用いた選好チューニングによって、対話応答生成におけるペルソナと生成応答の間の一貫性を向上させる手法を提案する。提案手法では、あるペルソナ情報付き対話データに対して、他の対話からランダムに抽出したペルソナ情報を用いて応答を生成し、これらの応答を擬似負例として扱う。参照応答を正例として扱うことで、擬似的な選好データを作成する。実験では、擬似選好データを用いて選好チューニングを行ったモデルが、通常の教師あり学習のみを用いたモデルや、ペルソナと発話間の含意関係に基づく報酬によって強化学習したモデルと比較して、より一貫性のある自然な応答を生成することを示す。
P10:ポスター3月13日（木） 13:00-14:30   P会場(2Fコンベンションホール3+4),P10-7,メモと圧縮を用いた効率的なメモリモジュールを持つ対話システムの構築,/proceedings/annual_meeting/2025/pdf_dir/P10-7.pdf,"○谷口 伊織, 南 泰浩 (電通大)",過去情報の整合性を維持しながら応答を生成する「長期一貫性」能力は，人間らしい対話システム構築において重要な要素の一つである．これを可能にする手法として，人間の長期記憶を模したメモリモジュールを用いる手法がある[1]．最も単純な方法は，対話履歴をメモリに保存し，次の応答生成時にその対話履歴をユーザの応答とともにプロンプト入力に加えることだが，入力可能なシーケンス長の制限やV-RAM 消費量の増大など，様々な問題が発生する．本研究では，これらの問題を解決するため，長期一貫性を持ったオープンドメイン対話が可能なMemochat[2] と対話圧縮モジュールを組み合わせて，高効率なメモリモジュールを持った対話システムを提案する．対話履歴を保存する際，トピックごとに対話履歴を分割し，それらの要約と対話，トピック名を三つ組にしたメモを生成する．さらに，単純な対話圧縮モデルを用いて対話内容を短縮してメモリに保存し，後の応答生成の際にそれを利用することで，モデルへの入力トークン数を抑えつつ，過去記憶に忠実な応答生成を可能にする．公開されたデータセット及び[2] で採用されたデータセットを基に訓練用データセットを再構築し，メモ生成，検索，長期一貫性を持った応答能力の向上を図る．また，メモ生成時に分割した対話履歴内の助詞，助動詞を除去するモジュールで対話を圧縮することで，メモリモジュールの記憶効率性を上げる．最後に，対話ターンが長い対話データセットを用いて長期一貫性及びメモリ効率を検証し，その有効性を確認した．
P10:ポスター3月13日（木） 13:00-14:30   P会場(2Fコンベンションホール3+4),P10-8,ユーザに適応する対話システムのためのLLMを用いた自我状態推定,/proceedings/annual_meeting/2025/pdf_dir/P10-8.pdf,"○掛川 脩人, 山田 剛一, 増田 英孝 (東京電機大)",対話システムの発展によって，ユーザへのより適応する返答が求められるようになった．この適応する返答を行うために交流分析に注目し，交流分析を用いた対話システム作成を目指している． しかし，交流分析の対話システムには発話単位でのユーザの自我状態と呼ばれる発話者の心の状態の情報が必要になる． 本研究では，大規模言語モデルを用いて対話中のテキストから自我状態を推定することを検討する．実験の結果として，プロンプトに文脈情報や自我状態の説明文，分類の例を入力することによって精度向上だけでなく，出力の精度向上も確認した．
P10:ポスター3月13日（木） 13:00-14:30   P会場(2Fコンベンションホール3+4),P10-9,なりきり雑談システムを評価するためのキャライメージの評価者間一致に関する検証-４択クイズを用いた原作者とファンの比較-,/proceedings/annual_meeting/2025/pdf_dir/P10-9.pdf,"○連 慎治, 伊藤 敏彦 (北大)",近年，架空の人物になりきって応答を生成する雑談対話システムの研究が盛んである．多くの研究が「キャラらしさ」の評価を人間による多数決で行っているが，この評価方法がなりきりの正確さを評価できているかは不明である．そこで，本稿では人間同士で「キャラらしさ」のイメージがどのくらい一致しているのかを確認する手法を提案する．具体的には，数名のファンがキャラらしいセリフとキャラらしくないセリフを書き，4 択クイズを作成する．別の人間がクイズを解き，一致率などを分析することでキャライメージの違いを調べる．結果，原作者とファンと作品を知らない人が持つイメージに異なる特徴が見られた．
P10:ポスター3月13日（木） 13:00-14:30   P会場(2Fコンベンションホール3+4),P10-10,語り手の発話の言い換えにより語りに傾聴を示す応答の生成,/proceedings/annual_meeting/2025/pdf_dir/P10-10.pdf,"○茂木 光志, 伊藤 滉一朗 (名大), 村田 匡輝 (豊田高専), 松原 茂樹 (名大)",語る機会を創出するために，会話エージェントが語りの聴き手を担うことが期待されている．これらが聴き手として認められるためには，語り手に対して傾聴態度を示す発話（傾聴応答）を生成することが有効である．傾聴応答の1 つに，語り手の発話を言い換える応答（言い換え応答）がある．言い換え応答を適切に生成できれば，語りを理解していることを示すことに寄与する．本論文では，大規模言語モデルによる言い換え応答の生成可能性を検証する．生成実験を行い，その性能を評価した．
P10:ポスター3月13日（木） 13:00-14:30   P会場(2Fコンベンションホール3+4),P10-11,対話評価における参照応答集合の妥当性と言語モデルが出力する応答の多様性の関係,/proceedings/annual_meeting/2025/pdf_dir/P10-11.pdf,"○佐藤 魁 (東北大), 吉野 幸一郎 (科学大/理研/NAIST), 赤間 怜奈, 鈴木 潤 (東北大/理研)",雑談対話システムの性能を参照応答に基づいて評価する際，評価の妥当性を担保するためには，参照応答集合が評価対象の対話履歴に対して想定される応答候補を十分に網羅している必要がある．本研究では，言語モデルが出力する応答の多様性が，評価に必要な参照応答集合の大きさを予測する指標として有用であるかを検討した．実験の結果，少数の参照応答でも評価可能と分類された対話履歴は，それ以外の対話履歴と比較して応答候補の多様性が低いことが確認された．得られた結果から言語モデルが出力する応答の多様性が，必要な参照応答集合の予測に有用である可能性が示唆された．
P10:ポスター3月13日（木） 13:00-14:30   P会場(2Fコンベンションホール3+4),P10-12,状態遷移モデルおよび大規模言語モデルを用いた半構造化インタビューのモデル化,/proceedings/annual_meeting/2025/pdf_dir/P10-12.pdf,"○長谷川 遼, 花 一傑, 宇津呂 武仁 (筑波大), 橋本 慧海, 中野 幹生, 白松 俊 (名工大)",本論文では，半構造化インタビューを対象として，状態遷移モデルと大規模言語モデルを組み合わせた対話制御の枠組みのモデル化を提案する．具体的には，状態遷移モデルの各状態におけるインタビュアの発話生成，および，インタビュー対象者の発話理解に基づく条件分岐判断において大規模言語モデルを適用する．そして，インタビュー対象者の回答に応じて質問項目のスロットを生成・更新しながら，インタビュー対話における柔軟な対話制御を実現する．また，提案手法により，複数のインタビュー対象者との間のインタビュー対話を通じて，インタビューテーマの話題構造を構築し，半構造化インタビューを効率よくモデル化する仕組みを実現する．
P10:ポスター3月13日（木） 13:00-14:30   P会場(2Fコンベンションホール3+4),P10-13,AdPsyche: 広告心理学に基づく選好データセット,/proceedings/annual_meeting/2025/pdf_dir/P10-13.pdf,"○三田 雅人, 村上 聡一朗, 本多 右京 (サイバーエージェント), 岡 達志 (慶應大)",広告文生成は，個々のニーズに応じた広告文を自動生成する技術であり，広告文の誘引性を高めることが広告効果を向上させるうえで重要である．しかし，広告の魅力を左右する要因は十分に解明されておらず，広告効果の高い広告を作成する際の方略が立てにくい．本研究では，広告誘引性における影響要因を分析するために広告特有の特性を考慮した選好データセットAdPsyche を構築し，Bradley-Terry-Luce モデルを要因分析に援用することで，心理的特性が広告選好に与える影響を明らかにする．
P10:ポスター3月13日（木） 13:00-14:30   P会場(2Fコンベンションホール3+4),P10-14,大規模言語モデルを用いたソフトウェア仕様書の用語チェック,/proceedings/annual_meeting/2025/pdf_dir/P10-14.pdf,"○金井 健一郎, 安部 夏樹, 加羽澤 優, 内出 隼人, 斉藤 辰彦 (三菱電機)","本研究では，ソフトウェア仕様書の品質向上を目的に，大規模言語モデル(Large Language Model, LLM)を活用した自動レビュー手法を提案する．本手法ではRetrieval-Augmented Generation (RAG)を用いて，レビュー対象に関連する情報を取得し，レビュー観点毎に自動レビューを実行する．用語統一をレビュー観点とした実験を行った結果，性能に課題が残るものの，正しく指摘できる例もあり，知見が得られた．また，レビューの性能向上にはプロンプト内の表の形式を統一させることやレビュー対象に関連する情報を必要な情報に絞ることが重要であることが示唆された．しかし，他にも性能が低い要因があると考えられ，要因の特定は今後の課題である．"
P10:ポスター3月13日（木） 13:00-14:30   P会場(2Fコンベンションホール3+4),P10-15,誤りを経験して修正する：誤りデータの正例扱いによる対照学習,/proceedings/annual_meeting/2025/pdf_dir/P10-15.pdf,"○薛 強, 滝口 哲也, 有木 康雄 (神戸大)",近年，大規模言語モデルの性能向上に伴い，対照学習（contrastive learning）を活用した誤生成抑制の手法が注目を集めている．本研究では，人間の「失敗から学ぶ」学習プロセスを模倣し，対照学習において誤りをあえて一度強化してから修正を行う新たな学習手法を提案する．具体的には，通常の正例データと負例データに加え，負例データの誤りトークンをあえて「正例扱い」するデータを作り，一時的に誤りを増幅させてから再度誤りを強く抑制する学習ステップを導入する．これによりモデルが誤りを深く認識し，修正効果の向上を狙う．OpenDialKGを用いた対話生成タスクの実験では，提案手法が従来の対照学習よりも高い性能を示すことを確認した．
P10:ポスター3月13日（木） 13:00-14:30   P会場(2Fコンベンションホール3+4),P10-16,対話に対する共感のアノテーションと共感制御可能な対話モデルの構築,/proceedings/annual_meeting/2025/pdf_dir/P10-16.pdf,"○鈴江 万碧, 堀尾 海斗, 折田 奈甫, 河原 大輔 (早大)",本研究は，Bloom [1] が提案する情動的共感と認知的共感の二軸を用いて，既存の対話コーパスに共感に関するアノテーションを付与した．アノテーション手法の検討においてクラウドソーシングとGPT-4o による自動アノテーションを比較したところ，後者の方が評価用に作成した人手によるアノテーションとより高い一致率を示した．このGPT-4o によるアノテーションを用いて対話モデルの学習を行い，共感を制御した応答生成を評価した結果，ベースラインモデルを大幅に上回る精度を達成した．
P10:ポスター3月13日（木） 13:00-14:30   P会場(2Fコンベンションホール3+4),P10-17,LLM ベースのマルチエージェントによる TRPG ゲームマスターシステムの実現,/proceedings/annual_meeting/2025/pdf_dir/P10-17.pdf,"○箕成 侑音, 上乃 聖, 李 晃伸 (名工大)",TRPG のゲームマスターにはプレイヤーからの要望に応えるための柔軟な応答が要求される．このような自由度の高い対話の実現はこれまで困難であったが，大規模言語モデル(LLM) の登場によりその可能性は飛躍的に向上した．本研究では，LLM のゲームマスターとしての能力を評価し課題を分析する．また，応答の質を向上させるため複数エージェントを用いてフィードバックを行い応答を改善する手法を提案し，その有効性を検証する．
P10:ポスター3月13日（木） 13:00-14:30   P会場(2Fコンベンションホール3+4),P10-18,適応的対話システムのための終盤の会話を予測する埋め込みモデルの構築,/proceedings/annual_meeting/2025/pdf_dir/P10-18.pdf,"○飯塚 慎也, 東中 竜一郎 (名大)",本研究では，対話相手に適応した応答生成を目指し，序盤の対話から，その話者との終盤の対話を予測するための埋め込みモデルを構築する．具体的には，対照学習を利用し，話し方に基づいて序盤と終盤とを紐づける埋め込みモデルを学習する．さらに，最近傍探索ライブラリであるFaiss を用いて序盤の対話から，類似した話し方を持つユーザの終盤の対話を獲得する仕組みを構築する．本手法の評価では，旅行代理店タスク対話コーパス（Tabidachi）およびRealPersonaChat（RPC）コーパスを使用し，提案モデルが序盤の対話から終盤の対話を予測するための埋め込み表現の獲得に有効であることを確認した．
P10:ポスター3月13日（木） 13:00-14:30   P会場(2Fコンベンションホール3+4),P10-19,疑似対話データとPreferenceデータを用いたドメイン特化対話への日本語LLMチューニングの検証,/proceedings/annual_meeting/2025/pdf_dir/P10-19.pdf,"○山崎 天, 高山 隼矢 (SB Intuitions), 佐藤 京也 (SB Intuitions/都立大), 大萩 雅也, 吉川 克正, 水本 智也 (SB Intuitions)",本研究は、日本語で学習された大規模言語モデル（LLM）を観光対話システムに適応させるため、効率的なデータ作成とチューニング手法を検証することを目的とする。疑似対話データを用いたSupervisedFine-Tuning（SFT）および少量のPreference データを用いたチューニングを実施し、観光案内タスクにおける対話の自然性、一貫性、満足度、信頼性への寄与を評価した。実験では、汎用指示チューニングのみのモデル、SFT モデル、Preference モデルを比較した結果、SFT モデルは対話の自然性と満足度を大幅に向上させる効果が確認された。一方、PreferenceモデルではHallucination の抑制が可能であったが、満足度の向上には課題が残った。
P10:ポスター3月13日（木） 13:00-14:30   P会場(2Fコンベンションホール3+4),P10-20,思考発話を利用した個人の発話及び性格特性再現,/proceedings/annual_meeting/2025/pdf_dir/P10-20.pdf,"○石倉 誠也, 山田 寛章 (科学大), 平岡 達也 (MBZUAI), 山田 広明 (富士通), 徳永 健伸 (科学大)",本研究は，思考発話を付与した対話データを用いてファインチューニングを行うことで，個人の発話及び性格特性を再現する手法を提案する．具体的には，LLM を用いて既存の対話データセットに対して対象人物の思考発話を付与する．そして，そのデータを用いてモデルを訓練することで，対象人物の話し方や感情，思考を再現する．著名人・著名キャラクターの再現に焦点を当てた先行研究に比べて，本研究は多様な特性を持つ個人の発話と性格特性を再現できる可能性を示した．
P10:ポスター3月13日（木） 13:00-14:30   P会場(2Fコンベンションホール3+4),P10-21,対話システムにおける個人特性を考慮した破綻度合い推定,/proceedings/annual_meeting/2025/pdf_dir/P10-21.pdf,"○山田 竜彰, 坪倉 和哉, 入部 百合絵 (愛県大), 北岡 教英 (豊橋技科大)",ユーザが対話破綻に対して破綻と判断する度合い（以降，破綻度合いと呼ぶ）には個人差があることが報告されている．そのため，対話を円滑に進めるために必要な対話修復の戦略を考える際，破綻に対して修復すべきかどうか，あるいはどのように修復すべきかといった判断をするときに，破綻度合いの個人差は無視できない．そこで本研究では，そのような個人差が生じる要因が性格や年代，性別などの個人特性と関係していると考え，個人特性を考慮した破綻度合いの推定手法を提案する．加えて，破綻度合いはこれまでの対話履歴にも依存するため，対話履歴と個人特性に関する情報を併用して破綻度合いを推定する．システムの発話に対する破綻度合いとユーザの個人特性のデータを収集し，個人特性が破綻度合いに与える影響について調査を行った結果，勤勉性や神経症傾向などの7 種類の個人特性によって破綻度合いに差が生じることが明らかとなった．また分析の結果に基づき破綻度合い推定器を構築した結果，8 割以上の精度（accuracy）を得ることができ，対話修復への活用が期待できる．
P10:ポスター3月13日（木） 13:00-14:30   P会場(2Fコンベンションホール3+4),P10-22,小説における台詞と口調，地の文を活用した台詞の発話者特定手法,/proceedings/annual_meeting/2025/pdf_dir/P10-22.pdf,"○岩本 和真, 安藤 一秋 (香川大)",雑談対話コーパスの構築コストが高いという課題を解決するため，本研究では小説の台詞を用いた対話コーパスの自動構築に取り組んでいる．小説には様々な人物が登場するため，単に台詞を抽出するのみでは口調の一貫性を保ったコーパスが構築できない．そこで本稿では，台詞と口調，台詞周辺の地の文から得られる手がかりを用いて，台詞の発話者を特定する手法を提案する．実験の結果，ルールベースで発話者を特定する手法と比べて，提案手法はPrecision をほとんど減少せずに，Recall を向上できることを確認した．
P10:ポスター3月13日（木） 13:00-14:30   P会場(2Fコンベンションホール3+4),P10-23,RAG を利用した傾聴応答生成の検証,/proceedings/annual_meeting/2025/pdf_dir/P10-23.pdf,"○松本 奈々, 安藤 一秋 (香川大)",近年，日本の総人口に占める高齢者人口の割合は過去最高となり，要介護者数も増加している．介護現場において，高齢者の発言を傾聴することは信頼関係を築くために重要である．しかし，近年の介護士の人材不足や介護負担等から被介護者に十分な時間をかけることが困難である．本稿では，外部情報に基づき応答を生成するRAG（Retrieval-Augmented Generation）を用いて，傾聴応答の生成可能性を検証する．評価実験では，傾聴応答の生成件数や，ファインチューニングの必要性に注目して考察する．
P10:ポスター3月13日（木） 13:00-14:30   P会場(2Fコンベンションホール3+4),P10-24,カウンセリングドメインに特化してfine-tuning を行ったLLMに対するActive Listening Skillの評価,/proceedings/annual_meeting/2025/pdf_dir/P10-24.pdf,"○三浦 拓人, Natthawut Kertkeidkachorn (JAIST), 小島 治幸 (金大), 白井 清昭 (JAIST)",近年，カウンセリングに特化したLarge LanguageModel(LLM) の開発が盛んに行われ，様々な観点からの評価が必要となっている．我々は，相手の話を理解していることを示す能力であるActive ListeningSkill(ALS) に着目する．カウンセラーのALS は患者の自己開示を促すなど，カウンセリングにとって重要である．本研究では，カウンセリング対話でﬁne-tuning したLLM を基にカウンセリングチャットボットを作成し，ALS に関連するいくつかの評価項目によって当該ボットを評価した．評価の結果，一般的なLLM と比べて，我々が作成したモデルは言い換えや要約によるALS によって，自己開示をユーザに促すことができることを示した．
Q10:ポスター3月13日（木） 13:00-14:30   Q会場(1F会議室101AB),Q10-1,技能者インタビュー対話におけるコツ発話の表出に至った発話列の特徴の分析,/proceedings/annual_meeting/2025/pdf_dir/Q10-1.pdf,"○樽谷 洋希, Yin Jou Huang, 松田 思鵬, 村脇 有吾, 黒橋 禎夫, 近 大志 (京大), 岡久 太郎 (静大)",筆者らは技能者からその技能について聞き出すインタビューを収集した技能者インタビュー対話コーパスを構築し，このコーパスを用いてコツを含む発話(コツ発話) を効果的に引き出すインタビューの特徴を解明することを目的として研究を行っている．本論文はこの技能者インタビュー対話コーパスにおける多面的なアノテーションを用いて，コツ発話の表出を予測するロジスティック回帰モデルを構築し，その予測精度とモデルの特徴，またそこから考察されるコツ発話の表出に関わるインタビューの特徴について報告する．
Q10:ポスター3月13日（木） 13:00-14:30   Q会場(1F会議室101AB),Q10-2,異種属性の内容的特徴をハイパーグラフにより統合するエンティティ表現学習,/proceedings/annual_meeting/2025/pdf_dir/Q10-2.pdf,"○西出 隆盛, 三輪 誠 (豊田工大)",エンティティの内容を表す名前や説明などのテキストで表される様々な異なる種類の属性情報に含まれるエンティティの内容的な特徴を反映したエンティティ表現を獲得する新たなハイパーグラフ表現学習手法を提案する．具体的には，属性情報をエンティティとは異なるノードとして統合したハイパーグラフを定義し，その上で新たに提案するアテンション機構を利用した異種ハイパーグラフエンコーダと属性情報からエンティティを予測するエンティティ予測損失を導入し，属性情報に含まれるエンティティの内容的な特徴をエンティティ表現に統合する．PubMed データセットを対象としたノード分類において，提案手法が既存手法と比較して高い分類性能を示すことを確認した．
Q10:ポスター3月13日（木） 13:00-14:30   Q会場(1F会議室101AB),Q10-3,Hybrid-SET: 意味的類似性とセットカバレッジを考慮したfew-shot例選出手法,/proceedings/annual_meeting/2025/pdf_dir/Q10-3.pdf,"○朱 晨成 (九工大), 谷口 友紀, 大熊 智子 (旭化成), 嶋田 和孝 (九工大)",材料・化学分野のテキストに対して，固有表現抽出を試みる場合，学習に使えるデータが十分でないことやアノテーションに高度な専門知識が必要であるという問題点がある．一方で，大規模言語モデル（LLM）は少量事例（few-shot 例）に基づき，分類や推論が可能である．LLM は提供する事例によって回答の精度が大きく変化することから，適切な例を選択するための方法を設計することが重要である．本研究では，文の意味的類似性とセットカバレッジを考慮したfew-shot 例選出手法Hybrid-SET を提案する．実験結果からHybrid-SET は既存の選択手法より優れていることを示す．
Q10:ポスター3月13日（木） 13:00-14:30   Q会場(1F会議室101AB),Q10-4,固有表現候補の用語情報を取得するLLMを用いた固有表現抽出,/proceedings/annual_meeting/2025/pdf_dir/Q10-4.pdf,"○与那覇 竜馬, 三輪 誠 (豊田工大)",生物医学分野における大規模言語モデルを用いた固有表現抽出を対象に，抽出モデルに合わせた用語情報の取得を行うために，一度，抽出した候補について用語情報を取得し，その用語情報を利用して再度抽出を行う2 段階の抽出手法を提案する．また，取得した用語情報の種類及びその組み合わせが抽出性能に与える影響を調査する．統合医学用語システムUMLS を用語辞典として，BC5CDR データセットを対象に評価を行った結果，用語情報を利用することで，提案手法による抽出性能の向上を確認できた．特に用語の定義とカテゴリを，用語の定義がない場合に親概念の定義を利用しながら，組み合わせる方法が有効であることがわかった．
Q10:ポスター3月13日（木） 13:00-14:30   Q会場(1F会議室101AB),Q10-5,偏向LLMエージェントの協調による知識階層の誤り訂正,/proceedings/annual_meeting/2025/pdf_dir/Q10-5.pdf,"○三島 輝瑠, 佐々木 裕 (豊田工大)",本研究は，大規模言語モデルを用いて知識階層を自動構築し，視点の異なる複数のLLM による協調的な評価を通して上位下位関係の誤りを検出・訂正する手法を提案する．大規模言語モデルを用いて知識階層を自動構築すると階層関係の誤りが避けられないため，異なる視点が与えられて偏向した複数のLLM エージェントが協調的に誤りを検出することでその自動訂正を目指す．具体的には，LLM が生成した初期オントロジーに対して，複数のLLM がそれぞれ異なる視点から階層関係の正しさを評価する．これにより，単一のLLM では捉えきれない誤りを検出することが可能とする．交通教則文書からの概念階層構築に関する実験において，LLM の協調により階層誤り検出のF1 スコアを5 ポイント向上させることができ，その有効性が示された．
Q10:ポスター3月13日（木） 13:00-14:30   Q会場(1F会議室101AB),Q10-6,日本の刑事事件を対象とした法律相談システム,/proceedings/annual_meeting/2025/pdf_dir/Q10-6.pdf,"○中下 咲帆, 菊池 英明 (早大), 藤倉 将平, 則竹 理宇 (LawFlow)",本研究は，⽇本の刑法を対象とした法律相談システムの構築を⽬指して「罪名」「量刑」「量刑根拠」 の3 つの予測に取り組んだ. 弁護⼠へのヒアリングを基に構築した罪名データベースを参照するように設計した罪名予測モジュールは，正解割合の平均が
Q10:ポスター3月13日（木） 13:00-14:30   Q会場(1F会議室101AB),Q10-7,データセット間の関連性推定におけるメタデータの利用,/proceedings/annual_meeting/2025/pdf_dir/Q10-7.pdf,"○伊藤 滉一朗, 松原 茂樹 (名大)",近年，オープンサイエンスが世界規模で推進され，データセットやコードなどの研究成果の公開促進に加えて，そのアクセス性が重要視されている．アクセス性を高めるための要素の1 つとして，研究成果間で関連付けることが挙げられる．そこで本論文では，研究成果の一種であるデータセットを対象に，それらの間の関連性を推定することの実現性を検証する．データセットに付与されたメタデータを用いてBERT ベースのモデルによって関連性を推定する手法を実装し，実験により推定性能を評価した．
Q10:ポスター3月13日（木） 13:00-14:30   Q会場(1F会議室101AB),Q10-8,不動産情報抽出業務の効率化に向けた大規模言語モデルを用いたアンサンブル手法,/proceedings/annual_meeting/2025/pdf_dir/Q10-8.pdf,"○齊藤 佑太郎 (estie), 叶内 晨 (NLPeanuts/estie), 松本 健太郎, 岩成 達哉 (estie)",本研究では，不動産業界におけるプレスリリースからの情報収集業務を効率化するため，大規模言語モデル（LLM）の出力を統合したアンサンブル手法を提案する．LLM による情報抽出は精度が向上しているものの，複雑なタスクでは抽出漏れや誤抽出が依然として課題であり，結果の信頼性を担保するためには人手による確認が必要とされている．提案手法では，複数のLLM の出力をルールベースで統合し，モデル間の出力の一致を活用して人手チェックの優先順位を付けることで，作業を効率化する．実験の結果，提案手法はLLM を単体で利用した場合と比較して抽出精度が向上し，確認作業の負担を大幅に削減できることが示された．
Q10:ポスター3月13日（木） 13:00-14:30   Q会場(1F会議室101AB),Q10-9,視覚的質問応答による文書情報抽出における同時多項目推論,/proceedings/annual_meeting/2025/pdf_dir/Q10-9.pdf,"○Mengsay Loem, 保坂 大樹 (Sansan)",視覚的質問応答は、文書画像から構造化された情報を抽出する上で有望な手法である。しかし、従来の手法では、抽出対象となる各項目を個別に質問応答する方式で実現されることが多く、項目間に内在する依存関係を十分に活用できていない可能性がある。本研究では、関連性のある複数項目を同時に推論する手法を検討し、その有効性を実証する。実世界のデータセットを用いて評価した結果、相互依存性が高い項目群において、同時に推論する手法は従来の手法を大幅に上回る抽出精度を示し、相互依存性が低い項目に対しても同等の水準を維持できることを示した。また、項目数や項目間の関連の強さが抽出精度に及ぼす影響を分析し、視覚的質問応答に基づく情報抽出を効果的に実現するための知見を提示する。
Q10:ポスター3月13日（木） 13:00-14:30   Q会場(1F会議室101AB),Q10-10,半教師あり学習を用いた単語アライメントの改善,/proceedings/annual_meeting/2025/pdf_dir/Q10-10.pdf,"○◊苗 中濤 (東大), 永田 昌明 (NTT), 鶴岡 慶雅 (東大)",単語アライメントは自然言語処理の重要な基礎タスクである。既存の手法はほとんどTransformerエンコーダモデルに基づいている。本研究では、Transformer デコーダモデルに基づく単語アライナーを提案する。また、翻訳文ペアをラベルなしデータとして活用し、Transformer エンコーダベースおよびTransformer デコーダベースの単語アライナーの両方に適用可能な単語アライメントのための半教師あり学習手法を提案する。実験結果は、数万の翻訳文ペアを用いた提案手法が、単語アライメントデータセットにおいて、現在の最先端手法を上回ることを示している。
Q10:ポスター3月13日（木） 13:00-14:30   Q会場(1F会議室101AB),Q10-11,Cosine Similarity as Logits?: Few-shot Knowledge Graph Completion with Embedding Vectors of a Generative PLM and its Application in Knowledge Probing,/proceedings/annual_meeting/2025/pdf_dir/Q10-11.pdf,"○◊Tomoyki Jinno, Kazuki Hayashi, Yusuke Sakai, Hidetaka Kamigaito, Taro Watanabe (NAIST)","The Knowledge graph completion (KGC) task aims topredict missing relations in knowledge graphs (KGs). Re-cently, text-based KGC approaches have gained attentionbut they present challenges: encoder-based methods re-quire ﬁne-tuning making it non-ideal when an ideal KG fortraining cannot be obtained, such as when KG is sparse orpredicting new relation-types. Meanwhile, decoder-basedmethods make prediction by generating tokens, where en-tity disambiguation becomes a challenge. KGC is also usedin knowledge proving, which aims to evaluate the knowl-edge retrieval capability of pre-trained language models(PLMs), but existing probes for generative PLM capable ofranking all multi-token and single-token entities are com-putationally ineﬃcient. To address these problems, we pro-pose DEER, an encoder-based few-shot KGC, leveraging agenerative PLM that achieves a linear inference time com-plexity. Our experiment shows that DEER outperforms aﬁne-tuned KGC model in a relationally inductive settingand aligns with an existing knowledge-probing method,positioning it as a possible alternative."
Q10:ポスター3月13日（木） 13:00-14:30   Q会場(1F会議室101AB),Q10-12,地方議会の予算表を対象としたLLMによる表形式変換を用いたRAGの提案,/proceedings/annual_meeting/2025/pdf_dir/Q10-12.pdf,"○前多 陸玖, 木村 泰知 (小樽商大)",本研究では，MBLink（Mineutes-to-Budget-Linking）で提供されている小樽市の令和4 年度の議会会議録と予算表に対して，表の含まれる文書の前処理において，マルチモーダルLLM(M-LLM) を使用することによる，検索における精度への影響を検証する．また，embedding model 間の性能差やChunkSize，Overlap Size の値の影響を検証する．
Q10:ポスター3月13日（木） 13:00-14:30   Q会場(1F会議室101AB),Q10-13,製造業ドメインにおける日本語LLMの性能調査,/proceedings/annual_meeting/2025/pdf_dir/Q10-13.pdf,"○上原 大暉, 田中 宏治, 金井 健一郎, 内出 隼人, 伍井 啓恭, 斉藤 辰彦 (三菱電機)","特定分野を対象とした日本語向けの大規模言語モデル（LLM）に関する性能評価の取り組みが知られている。しかしながら、製造業分野においては日本語LLM の性能調査が不十分である。本研究では、製造業関連機器についての質問応答タスクに対して複数の事前学習済み日本語LLM の性能を比較し、製造業分野における専門知識の学習にどの日本語LLM が適しているかを調査した。結果、教師ありファインチューニング（Supervised Fine Tuning, SFT）を施したLLM において、SFT 前後でRouge-L が"
Q10:ポスター3月13日（木） 13:00-14:30   Q会場(1F会議室101AB),Q10-14,健康経営度調査テキストに対する定量評価およびレコメンドアルゴリズムの提案,/proceedings/annual_meeting/2025/pdf_dir/Q10-14.pdf,"○林 和希, 參木 裕之 (大和総研)",近年、従業員等への健康投資を行うことで、従業員の活力や企業の生産性を向上させる「健康経営」に対する関心が高まっている。本研究では、健康経営度調査票内の「健康経営課題、それに対する施策実施の結果、効果検証結果」の文章を定量的に評価する手法を提案した。また、この評価スコアを利用して各企業の健康経営課題に対して適切かつ多様、なおかつ各企業の健康経営評価の改善に繋がるような施策を提案するレコメンドシステムを開発した。
Q10:ポスター3月13日（木） 13:00-14:30   Q会場(1F会議室101AB),Q10-15,LLM を用いた関係抽出のデータ拡張におけるデータ選定と利用方法の検討,/proceedings/annual_meeting/2025/pdf_dir/Q10-15.pdf,"○小島 大世, 三輪 誠 (豊田工大)",関係抽出におけるLLM を用いたデータ拡張において，生成されたデータを評価するための指標と拡張データを利用する学習手法について提案する．具体的には，生成されたテキストの正しい関係トリプルの内容の保持と多様性の評価のため，元の訓練データのテキストと生成されたテキストの比較方法について検討・比較を行う．また，拡張データと訓練データの分布の違いによる悪影響を抑えるために拡張データと訓練データを順に学習に利用する手法について提案する．DrugProt データセットを利用した実験では，拡張データの違いが抽出性能に大きく影響することと提案した学習手法によって拡張データによる悪影響を抑えられることを確認した．
Q10:ポスター3月13日（木） 13:00-14:30   Q会場(1F会議室101AB),Q10-16,複数文章からの表生成における生成AIの利用と評価手法の比較,/proceedings/annual_meeting/2025/pdf_dir/Q10-16.pdf,"○野田 直哉, 村田 真樹 (鳥取大)","村田ら[1], 野田ら[2] は情報整理の一環としてWeb 上の複数の関連した文章から表を生成していた. これらの研究での表の評価として, 予め用意した正解の表との類似性で自動評価を行っていたが,出力された表の構造が正解のものと異なる場合, 実際の表生成の性能を正しく評価できないと考えられた.本稿の研究では, より信頼性のある評価を目指し, 人手で評価をした. 村田らと野田らの単語ベクトルとChatGPT を使用した手法をそれぞれ評価したところ, 自動評価では単語ベクトルの手法のほうが性能が高かったが, 人手での評価ではChatGPT の手法のほうが高くなった. 人手評価の単語ベクトル, ChatGPT の手法の性能はそれぞれ0.79, 0.90 であった.また自動評価の問題である, 正解と出力の表の構造が異なる点について, 調査をしたところ, 実際に評価に影響を及ぼしていることがわかった."
Q10:ポスター3月13日（木） 13:00-14:30   Q会場(1F会議室101AB),Q10-17,LLMを用いた交通分野固有表現抽出データセットの自動構築,/proceedings/annual_meeting/2025/pdf_dir/Q10-17.pdf,"○井田 龍希, 西出 隆盛, 三輪 誠 (豊田工大)",LLM を用いた交通分野における新しい固有表現抽出データセットの自動構築について提案する．既存のFindVehicle は15 種類の限られたテンプレートに固有表現を置換して作成されており，実際の交通状況で見られる多様な表現を十分にカバーしていない．そこで本研究では，FindVehicle で利用された固有表現辞書を活用し，大規模言語モデルにより固有表現を含む文を生成することで，より自然で多様なデータを作成する．生成データの品質を人手で検証し，FindVehicle のみでは対応できない多様な文脈に対する固有表現抽出を実現した．
Q10:ポスター3月13日（木） 13:00-14:30   Q会場(1F会議室101AB),Q10-18,Sentence BERTを用いた源氏物語内の古今和歌集引用の検出,/proceedings/annual_meeting/2025/pdf_dir/Q10-18.pdf,"○叶内 琉聖, 古宮 嘉那子 (農工大)",本研究ではSentence BERT を用いて、源氏物語における古今和歌集の序文や和歌からの引用の検出を行った。コーパスから、源氏物語の一文と古今和歌集の一文あるいは一句のペアを作り、この二文をモデルへの入力とした。このとき、源氏物語の一文に古今和歌集の一文あるいは一句が引用されていれば正例、引用されていなければ負例として、二値分類を行った。負例の数は、正例の数との比で設定した。実験の結果、正例と負例の比を1:58 にしたシステムにおいて、69.6%のF 値で古今和歌集からの引用を検出した。また、実験によってシステムが、表記の異なる言葉や作中に何度も登場する語句による引用の検出を苦手としていることが分かった。
Q10:ポスター3月13日（木） 13:00-14:30   Q会場(1F会議室101AB),Q10-19,デコーダモデルを用いた生物医学イベント抽出,/proceedings/annual_meeting/2025/pdf_dir/Q10-19.pdf,"○金児 一矢, 三輪 誠 (豊田工大)",生物医学イベント抽出は階層的な構造のイベントが多く現れるため，イベント間の関係も考慮した抽出が必要となる．従来研究ではエンコーダモデルを利用した手法が多く提案されているが，モデルサイズなどの制約から，複雑な関係を捉える言語能力に限界があった．そこで，本研究では生物医学分野におけるデコーダモデルを用いた階層的な構造を持ったイベント抽出の実現を目指し，質問応答を繰り返して，階層的なイベントを抽出できるようにデコーダモデルをファインチューニングする手法を提案する．実験ではベースモデルにLLaMA-3.2，データセットにGENIA2011 を用いて，性能を評価する．
Q10:ポスター3月13日（木） 13:00-14:30   Q会場(1F会議室101AB),Q10-20,小説のセリフを利用した登場人物に紐づく人間関係語の抽出,/proceedings/annual_meeting/2025/pdf_dir/Q10-20.pdf,"○安田 大朗, 安藤 一秋 (香川大)",日常対話を目的とした非タスク指向型対話システムは，ユーザと長期的な信頼関係を構築するために，深く対話を継続する必要がある．システムの実現には，人間同士のコミュニケーションのように共生や共感といった視点が重要であり，ユーザの個々の情報を把握・活用する必要がある．本研究では，ユーザの情報として人間関係に着目する．また，小説の台詞から登場人物の人間関係を抽出できれば，日常対話におけるユーザの人間関係も抽出できるという仮説のもと，日常対話の代替として小説の台詞を活用する．本稿では，台詞に出現する登場人物とその人物に紐づく人間関係語を抽出するモデルを検討する．実験の結果，0.6618 のF 値で人間関係語を抽出できることを確認した．
Q10:ポスター3月13日（木） 13:00-14:30   Q会場(1F会議室101AB),Q10-21,固有表現抽出タスクの形式の学習と様々なドメインへの適用,/proceedings/annual_meeting/2025/pdf_dir/Q10-21.pdf,"○石井 奏人, 新妻 巧朗, 田森 秀明 (朝日新聞社)",新聞社では，分析の目的や対象文書のドメインに応じた固有表現抽出（NER）が求められる．従来どおり，特定のドメインごとにNER モデルをファインチューニングするには，教師データの作成などに高いコストがかかる．一方，大規模言語モデル（LLM）を用いたFew-shot 推論なども検討できるが，精度は十分とはいえない．そこで本研究では，LLMに対するNER プロンプトのフォーマットと，NERタスクそのものの形式を学習させるファインチューニング手法を提案する．このモデルでFew-shot 推論を行い，少量のデータのみで特定のドメイン・ラベルへ適用させたNER を行う．
Q10:ポスター3月13日（木） 13:00-14:30   Q会場(1F会議室101AB),Q10-22,診断のサマリー作成支援に向けた会話記録のトピック分類,/proceedings/annual_meeting/2025/pdf_dir/Q10-22.pdf,"○橋本 和磨 (早大), 北出 祐, 辻川 剛範, 久保 雅洋 (NEC)",2024 年度から施行された医師の働き方改革によって，医療現場では医師の業務の効率化が求められている．特に，書類の作成は大きな負担となっており，書類作成業務支援が医師の労働時間短縮に貢献することが期待されている．本研究では，医師による診察のサマリー作成を支援するため，外来診察における医師と患者の模擬会話記録を用いて，発話ごとにトピックのマルチラベル分類を行う手法を提案した．実験の結果，提案手法はベースライン手法を上回る性能を示し，診察会話における発話ごとのトピック分類において有効性が確認された．
Q10:ポスター3月13日（木） 13:00-14:30   Q会場(1F会議室101AB),Q10-23,生成AIを用いた単語間における類推,/proceedings/annual_meeting/2025/pdf_dir/Q10-23.pdf,"○田代 寛治, 村田 真樹 (鳥取大)","「発想や類推を機械によって行う, あるいは人間の類推の補助が出来ないか」というテーマで研究を行う. 例として(爆発物) - (ガソリン) →(水素) からエンジンの代替エネルギーの発想を得るなどである.以前の村田の研究[1] では, 「ネコ」という単語の属性を考え, その属性に「大きい」という属性を追加することで「トラ」という単語を類推して,「ネコを大きくするとトラが導き出される」拡大や縮小の類推を行った. 田代の研究[2] では, 類似する２単語の引き算により得られる属性を類推する研究を行った. これらの研究ではMcRae のデータセット[3] を基に研究を進めた.本研究は, 入力次第で様々な類推が可能なChatGPT を使用し,「田代の研究で行った類推との比較」,「McRae と同様のデータセットの作成」,「ChatGPT による様々な類推」を行った. 田代の研究の引き算の類推では類推性能0.46 であったが, 本研究の引き算の類推では類推性能0.48 に向上した.ChatGPT で引き算の類推を行う時も集合で引き算をした場合の方が向上することが分かった. また,McRae のようなデータセット生成で意味の一致を正解とした場合, 性能F 値0.61 と高性能なデータセット作成が可能であることが分かった. 9 種類のオズボーンのチェックリスト[4] でのChatGPT を用いた類推において, 類推性能0.88 で類推できることを確認できた."
Q10:ポスター3月13日（木） 13:00-14:30   Q会場(1F会議室101AB),Q10-24,埋め込みモデルベースの教師なしキーフレーズ抽出における長文に対する抽出精度の改善,/proceedings/annual_meeting/2025/pdf_dir/Q10-24.pdf,○藤原 知樹 (ABEJA),キーフレーズ抽出は情報検索や要約に活用できる技術である．本稿の目的は埋め込みモデルを用いた教師なしキーフレーズ抽出における長文に対する抽出精度の改善である．埋め込みモデルベースの手法では，文章全体とフレーズとの類似度を直接算出するため，長文においてテキスト長の大きな差が原因で精度が低下しやすい．提案手法では文単位の埋め込みを用いて重要な文を絞り込むことで，既存手法に比べ長文へのキーフレーズ抽出精度が改善した．開発したキーフレーズ抽出ツールおよび日本語の評価データセットはhttps://github.com/flatton/keyphrase extraction tools にて公開予定である．
Q10:ポスター3月13日（木） 13:00-14:30   Q会場(1F会議室101AB),Q10-25,ニュース記事中の企業名のEntity LinkingにおけるQuestion Answeringを用いた曖昧性解消,/proceedings/annual_meeting/2025/pdf_dir/Q10-25.pdf,"○齋藤 慎一朗, 髙橋 寛治 (Sansan)",ニュース記事と、記事に登場する企業名の法人番号を紐付けたい。しかし、同名企業が存在する場合、一意に特定できないことがある。既存手法では、ニュース記事と、企業情報のベクトルの類似度が最も大きい法人番号を出力しているが、企業データベースが持つ他のテキスト情報を有効活用できる手法ではない。そこで、GPT によるQuestionAnswering を利用し、他のテキスト情報を適切に活用可能なEntity Linking を提案する。提案手法により、既存手法に対し65%ポイントの性能改善を確認した。さらに、Web 検索結果のテキストを追加で与えることで、5%ポイントの性能改善を確認した。
